24/04/20 20:27:20 INFO hbase.HBaseTestingUtility: Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
24/04/20 20:27:20 INFO util.GSet: VM type       = 64-bit
24/04/20 20:27:20 INFO util.GSet: 2% max memory = 16.86 MB
24/04/20 20:27:20 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/04/20 20:27:20 INFO util.GSet: recommended=2097152, actual=2097152
24/04/20 20:27:20 INFO namenode.FSNamesystem: fsOwner=idflakies
24/04/20 20:27:20 INFO namenode.FSNamesystem: supergroup=supergroup
24/04/20 20:27:20 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/04/20 20:27:20 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/04/20 20:27:20 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/04/20 20:27:20 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/04/20 20:27:20 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:20 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/name1 has been successfully formatted.
24/04/20 20:27:20 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:20 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/name2 has been successfully formatted.
24/04/20 20:27:20 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
24/04/20 20:27:20 INFO util.GSet: VM type       = 64-bit
24/04/20 20:27:20 INFO util.GSet: 2% max memory = 16.86 MB
24/04/20 20:27:20 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/04/20 20:27:20 INFO util.GSet: recommended=2097152, actual=2097152
24/04/20 20:27:20 INFO namenode.FSNamesystem: fsOwner=idflakies
24/04/20 20:27:20 INFO namenode.FSNamesystem: supergroup=supergroup
24/04/20 20:27:20 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/04/20 20:27:20 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/04/20 20:27:20 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/04/20 20:27:20 INFO namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
24/04/20 20:27:20 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/04/20 20:27:20 INFO common.Storage: Number of files = 1
24/04/20 20:27:20 INFO common.Storage: Number of files under construction = 0
24/04/20 20:27:20 INFO common.Storage: Image file of size 115 loaded in 0 seconds.
24/04/20 20:27:20 INFO common.Storage: Edits file /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
24/04/20 20:27:20 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:21 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:21 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:21 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 20:27:21 INFO namenode.NameCache: initialized with 0 entries 0 lookups
24/04/20 20:27:21 INFO namenode.FSNamesystem: Finished loading FSImage in 140 msecs
24/04/20 20:27:21 INFO namenode.FSNamesystem: Total number of blocks = 0
24/04/20 20:27:21 INFO namenode.FSNamesystem: Number of invalid blocks = 0
24/04/20 20:27:21 INFO namenode.FSNamesystem: Number of under-replicated blocks = 0
24/04/20 20:27:21 INFO namenode.FSNamesystem: Number of  over-replicated blocks = 0
24/04/20 20:27:21 INFO hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 20 msec
24/04/20 20:27:21 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
24/04/20 20:27:21 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
24/04/20 20:27:21 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
24/04/20 20:27:21 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
24/04/20 20:27:21 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/04/20 20:27:21 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/04/20 20:27:21 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/04/20 20:27:21 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/04/20 20:27:21 INFO ipc.Server: Starting SocketReader
24/04/20 20:27:21 INFO namenode.NameNode: Namenode up at: localhost/127.0.0.1:36241
24/04/20 20:27:21 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
24/04/20 20:27:21 INFO http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
24/04/20 20:27:21 INFO http.HttpServer: dfs.webhdfs.enabled = false
24/04/20 20:27:21 INFO http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
24/04/20 20:27:21 INFO http.HttpServer: listener.getLocalPort() returned 42207 webServer.getConnectors()[0].getLocalPort() returned 42207
24/04/20 20:27:21 INFO http.HttpServer: Jetty bound to port 42207
24/04/20 20:27:21 INFO mortbay.log: jetty-6.1.26
24/04/20 20:27:21 INFO mortbay.log: Extract jar:file:/home/idflakies/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar!/webapps/hdfs to /tmp/Jetty_localhost_42207_hdfs____.6rhz2z/webapp
24/04/20 20:27:21 INFO mortbay.log: Started SelectChannelConnector@localhost:42207
24/04/20 20:27:21 INFO namenode.NameNode: Web-server up at: localhost:42207
24/04/20 20:27:21 INFO ipc.Server: IPC Server Responder: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server listener on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 0 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 1 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 2 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 3 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 4 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 5 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 7 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 6 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 8 on 36241: starting
24/04/20 20:27:21 INFO ipc.Server: IPC Server handler 9 on 36241: starting
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/data/data2
24/04/20 20:27:21 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
24/04/20 20:27:21 WARN util.MBeans: Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:151)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:930)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:21 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/data/data1, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/04/20 20:27:21 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/ce3a41b1-940c-4977-8cc4-ee66db9f0c4a/dfscluster_1e872653-9a92-4824-a40a-5ab342d63041/dfs/data/data2, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/04/20 20:27:21 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:21 INFO hbase.HBaseTestingUtility: Shutting down minicluster
24/04/20 20:27:21 INFO hbase.HBaseTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:21 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/c41e1189-7d7d-42e7-9e5c-117008d02f65/dfscluster_896424d2-608b-4530-a1a4-7a3fdb3209ff/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/c41e1189-7d7d-42e7-9e5c-117008d02f65/dfscluster_896424d2-608b-4530-a1a4-7a3fdb3209ff/dfs/data/data2
24/04/20 20:27:22 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestPublisher.setUpBeforeClass(TestPublisher.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 2 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/3ab1eb84-2d2f-4f61-aa00-1327d3a8d5e4/dfscluster_dab3b40f-f19e-454c-b148-89298423ba65/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/3ab1eb84-2d2f-4f61-aa00-1327d3a8d5e4/dfscluster_dab3b40f-f19e-454c-b148-89298423ba65/dfs/data/data2
24/04/20 20:27:22 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.master.TestMaster.beforeAllTests(TestMaster.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/709810a3-2bfe-43a9-9b08-987d4f054169/dfscluster_bbb8cfd2-99f7-4235-97a1-c25d074950d3/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/709810a3-2bfe-43a9-9b08-987d4f054169/dfscluster_bbb8cfd2-99f7-4235-97a1-c25d074950d3/dfs/data/data2
24/04/20 20:27:22 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestSubscriber.setUpBeforeClass(TestSubscriber.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:22 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/bb16b864-0954-49f1-8a66-edf518e9bc28/dfscluster_73733225-cfab-4268-8a47-fab700b592ea/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/bb16b864-0954-49f1-8a66-edf518e9bc28/dfscluster_73733225-cfab-4268-8a47-fab700b592ea/dfs/data/data2
24/04/20 20:27:23 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.setUpBeforeClass(TestJdbcResultFormatter.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.tearDownAfterClass(TestJdbcResultFormatter.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/50afa25f-adb7-42b0-88f2-e9e65c71e36d/dfscluster_d981ad4f-68f9-4fe9-9528-8a8dfc3e3420/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/50afa25f-adb7-42b0-88f2-e9e65c71e36d/dfscluster_d981ad4f-68f9-4fe9-9528-8a8dfc3e3420/dfs/data/data2
24/04/20 20:27:23 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.fserver.redo.TestRedoLog.before(TestRedoLog.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
2013-04-13 04:04:545
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,name from User where user_id=1 limit 1;
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, name]
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 20:27:23 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false]]], fetchRows=0]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,photo_id,full_url,thumbnail_url from Photo where user_id=99999999999 and photo_id=0.1;
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL TableSource Photo
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem photo_id
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem full_url
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem thumbnail_url
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, photo_id, full_url, thumbnail_url]
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 99999999999 AND photo_id = 0.1
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
2 Filter Field:
	Field user_id  Type EQUAL Value 99999999999
	Field photo_id  Type EQUAL Value 0.1
	


24/04/20 20:27:23 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x17Hv\xE7\xFF\x00\x00\x00\x00\x00 from Photo
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=Photo, primayKey=[0, 0, 0, 23, 72, 118, -25, -1, 0, 0, 0, 0, 0], columns=[ColumnAction [tableName=Photo, familyName=cf, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=photo_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=full_url, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=thumbnail_url, value=null, isIndex=false]]], fetchRows=0]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1;
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 20:27:23 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1 for update ;
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 20:27:23 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 20:27:23 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 20:27:23 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
--------------------------------------------
SELECT			SELECT
STAR			*
FROM			FROM
IDENTIFIER		T
WHERE			WHERE
IDENTIFIER		F1
EQ			=
QUES			?
ORDER			ORDER
BY			BY
IDENTIFIER		F2
EOF			null
--------------------------------------------
24/04/20 20:27:23 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table MetricsEntityGroupWrapperStub DEADBEEF001
24/04/20 20:27:23 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/04/20 20:27:23 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/04/20 20:27:23 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TWO
24/04/20 20:27:23 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/e5d4837b-78eb-4a5a-b356-e98ca2d739db/dfscluster_7fb8d076-87a8-4bfb-85a1-96a39f165e48/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/e5d4837b-78eb-4a5a-b356-e98ca2d739db/dfscluster_7fb8d076-87a8-4bfb-85a1-96a39f165e48/dfs/data/data2
24/04/20 20:27:23 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestPreparedStatement.beforeClass(TestPreparedStatement.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestPreparedStatement.afterClass(TestPreparedStatement.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES IN Photo;
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/04/20 20:27:23 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES FROM Photo;
24/04/20 20:27:23 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User2 {Required Int64 user_id; Required String name; }  primary key(user_id),  entity group root,  entity group key(user_id),  partition by range('aaa', 'zzz', 10); 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User2 { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=[[B@54361a9, [B@32232e55, [B@5217f3d0, [B@37ebc9d8, [B@293bb8a5, [B@2416a51, [B@6fa590ba, [B@6e9319f, [B@72e34f77]]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@2fab4aff]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL DROP INDEX PhotosByTime ON Photo;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: DropIndexPlan DropIndexPlan [indexName=PhotosByTime, tableName=Photo]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@532a02d9]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTag on Photo(tag);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTag
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@611f8234]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES LIKE 'pattern'
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL SHOW CREATE TABLE Photo
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL TRUNCATE TABLE Photo;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: TruncateTablePlan TruncateTablePlan [tableNames=[Photo]]
24/04/20 20:27:24 INFO druid.TestDruidDDLParser: TruncateTablePlan [tableNames=[Photo]]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy1 int32 FIRST
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  OPTIONAL INT32 dummy1 COLUMNFAMILY d;
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string columnfamily cf comment 'aaa'
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY cf;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy2 int32 AFTER thumbnail_url
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL INT32 dummy2 COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE COLUMN thumbnail_url thumbnail_url INT32
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url thumbnail_url INT32
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url rename_url INT64;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT64 rename_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo DROP COLUMN full_url, DROP COLUMN thumbnail_url;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);

CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  REQUIRED INT64 time COLUMNFAMILY d;
  REQUIRED STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  REPEATED STRING tag COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;

24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL DROP TABLE Photo;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo], ifExists=false]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL DROP TABLE IF EXISTS Photo, User;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo, User], ifExists=false]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 20:27:24 DEBUG druid.DruidParser: Parsing SQL DESCRIBE Photo;
24/04/20 20:27:24 DEBUG druid.DruidDDLParser: DescTablePlan DescTablePlan 
24/04/20 20:27:24 INFO server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:51959
24/04/20 20:27:24 INFO persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/idflakies/alibaba/wasp/target/test-data/edbfa585-5a1d-48b2-b0a4-7619566bde66/dfscluster_360839d9-a51e-4ff4-ab7a-80ef3c853f91/zookeeper_0/version-2/snapshot.0
24/04/20 20:27:24 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:35656
24/04/20 20:27:24 DEBUG master.FMaster: Set serverside FConnection retries=100
24/04/20 20:27:24 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMaster
24/04/20 20:27:24 DEBUG zookeeper.ZKUtil: master:36675 opening connection to ZooKeeper with ensemble (localhost:51959)
24/04/20 20:27:24 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 37969@22e8d89dc231
24/04/20 20:27:24 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:35672
24/04/20 20:27:24 INFO persistence.FileTxnLog: Creating new log file: log.1
24/04/20 20:27:24 DEBUG zookeeper.ZooKeeperWatcher: master:36675 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
24/04/20 20:27:24 DEBUG zookeeper.ZooKeeperWatcher: master:36675-0xff8efd3134af0000 connected
24/04/20 20:27:24 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMasterMonitorProtocol
24/04/20 20:27:24 DEBUG ipc.NettyTransceiver: Using Netty bootstrap options: {connectTimeoutMillis=3000, tcpNoDelay=true}
24/04/20 20:27:24 DEBUG ipc.NettyTransceiver: Connecting to 22e8d89dc231/172.17.0.2:36675
24/04/20 20:27:24 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036] OPEN
24/04/20 20:27:24 INFO ipc.NettyTransceiver: Successfully connected to bookie: 22e8d89dc231/172.17.0.2:36675
24/04/20 20:27:24 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036, /172.17.0.2:54236 => 22e8d89dc231/172.17.0.2:36675] BOUND: /172.17.0.2:54236
24/04/20 20:27:24 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036, /172.17.0.2:54236 => 22e8d89dc231/172.17.0.2:36675] CONNECTED: 22e8d89dc231/172.17.0.2:36675
24/04/20 20:27:24 DEBUG ipc.NettyServer: [id: 0x053d290f, /172.17.0.2:54236 => /172.17.0.2:36675] OPEN
24/04/20 20:27:24 DEBUG ipc.NettyServer: [id: 0x053d290f, /172.17.0.2:54236 => /172.17.0.2:36675] BOUND: /172.17.0.2:36675
24/04/20 20:27:24 DEBUG ipc.NettyServer: [id: 0x053d290f, /172.17.0.2:54236 => /172.17.0.2:36675] CONNECTED: /172.17.0.2:54236
24/04/20 20:27:24 WARN ipc.NettyServer: Unable to read call parameters for client /172.17.0.2:54236
com.alibaba.wasp.ipc.ServerNotRunningYetException: Server is not running yet
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.messageReceived(NettyServer.java:203)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75)
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.handleUpstream(NettyServer.java:171)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:563)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:45)
	at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/20 20:27:24 ERROR ipc.NettyTransceiver: Fatal Exception.
24/04/20 20:27:24 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 1 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/3d363f51-3e1d-440a-8027-b9771834d7c9/dfscluster_94b40291-1dc6-4722-97f8-916b92254b36/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/3d363f51-3e1d-440a-8027-b9771834d7c9/dfscluster_94b40291-1dc6-4722-97f8-916b92254b36/dfs/data/data2
24/04/20 20:27:24 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 20:27:24 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 20:27:24 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.plan.execute.TestExecutionEngine.before(TestExecutionEngine.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
