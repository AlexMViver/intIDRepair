24/04/20 21:00:19 INFO hbase.HBaseTestingUtility: Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
24/04/20 21:00:19 INFO util.GSet: VM type       = 64-bit
24/04/20 21:00:19 INFO util.GSet: 2% max memory = 16.86 MB
24/04/20 21:00:19 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/04/20 21:00:19 INFO util.GSet: recommended=2097152, actual=2097152
24/04/20 21:00:19 INFO namenode.FSNamesystem: fsOwner=idflakies
24/04/20 21:00:19 INFO namenode.FSNamesystem: supergroup=supergroup
24/04/20 21:00:19 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/04/20 21:00:19 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/04/20 21:00:19 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/04/20 21:00:19 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/name1 has been successfully formatted.
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/name2 has been successfully formatted.
24/04/20 21:00:19 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
24/04/20 21:00:19 INFO util.GSet: VM type       = 64-bit
24/04/20 21:00:19 INFO util.GSet: 2% max memory = 16.86 MB
24/04/20 21:00:19 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/04/20 21:00:19 INFO util.GSet: recommended=2097152, actual=2097152
24/04/20 21:00:19 INFO namenode.FSNamesystem: fsOwner=idflakies
24/04/20 21:00:19 INFO namenode.FSNamesystem: supergroup=supergroup
24/04/20 21:00:19 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/04/20 21:00:19 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/04/20 21:00:19 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/04/20 21:00:19 INFO namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
24/04/20 21:00:19 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/04/20 21:00:19 INFO common.Storage: Number of files = 1
24/04/20 21:00:19 INFO common.Storage: Number of files under construction = 0
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 loaded in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Edits file /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/04/20 21:00:19 INFO namenode.NameCache: initialized with 0 entries 0 lookups
24/04/20 21:00:19 INFO namenode.FSNamesystem: Finished loading FSImage in 95 msecs
24/04/20 21:00:19 INFO namenode.FSNamesystem: Total number of blocks = 0
24/04/20 21:00:19 INFO namenode.FSNamesystem: Number of invalid blocks = 0
24/04/20 21:00:19 INFO namenode.FSNamesystem: Number of under-replicated blocks = 0
24/04/20 21:00:19 INFO namenode.FSNamesystem: Number of  over-replicated blocks = 0
24/04/20 21:00:19 INFO hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
24/04/20 21:00:19 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
24/04/20 21:00:19 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
24/04/20 21:00:19 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
24/04/20 21:00:19 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
24/04/20 21:00:19 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/04/20 21:00:19 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/04/20 21:00:19 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/04/20 21:00:19 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/04/20 21:00:19 INFO ipc.Server: Starting SocketReader
24/04/20 21:00:20 INFO namenode.NameNode: Namenode up at: localhost/127.0.0.1:39843
24/04/20 21:00:20 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
24/04/20 21:00:20 INFO http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
24/04/20 21:00:20 INFO http.HttpServer: dfs.webhdfs.enabled = false
24/04/20 21:00:20 INFO http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
24/04/20 21:00:20 INFO http.HttpServer: listener.getLocalPort() returned 42283 webServer.getConnectors()[0].getLocalPort() returned 42283
24/04/20 21:00:20 INFO http.HttpServer: Jetty bound to port 42283
24/04/20 21:00:20 INFO mortbay.log: jetty-6.1.26
24/04/20 21:00:20 INFO mortbay.log: Extract jar:file:/home/idflakies/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar!/webapps/hdfs to /tmp/Jetty_localhost_42283_hdfs____frubrt/webapp
24/04/20 21:00:20 INFO mortbay.log: Started SelectChannelConnector@localhost:42283
24/04/20 21:00:20 INFO namenode.NameNode: Web-server up at: localhost:42283
24/04/20 21:00:20 INFO ipc.Server: IPC Server Responder: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server listener on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 0 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 1 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 2 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 3 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 4 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 5 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 6 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 7 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 8 on 39843: starting
24/04/20 21:00:20 INFO ipc.Server: IPC Server handler 9 on 39843: starting
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/data/data2
24/04/20 21:00:20 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
24/04/20 21:00:20 WARN util.MBeans: Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:151)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:930)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:20 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/data/data1, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/04/20 21:00:20 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/0ba59916-062e-4a71-9442-993e27bcf273/dfscluster_836284d4-2751-452d-8237-2c6ba7cc933c/dfs/data/data2, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/04/20 21:00:20 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:20 INFO hbase.HBaseTestingUtility: Shutting down minicluster
24/04/20 21:00:20 INFO hbase.HBaseTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:20 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/c83927fa-eb14-462e-8dae-697c178a28f2/dfscluster_c4bb584d-ec9d-49d2-9b98-b00f3aeea795/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/c83927fa-eb14-462e-8dae-697c178a28f2/dfscluster_c4bb584d-ec9d-49d2-9b98-b00f3aeea795/dfs/data/data2
24/04/20 21:00:20 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:20 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 21:00:20 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestPublisher.setUpBeforeClass(TestPublisher.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:20 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 2 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/5039b030-27e3-4933-9b7b-ddf5dc285474/dfscluster_35b2a654-9894-4111-b852-b9a64350fd70/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/5039b030-27e3-4933-9b7b-ddf5dc285474/dfscluster_35b2a654-9894-4111-b852-b9a64350fd70/dfs/data/data2
24/04/20 21:00:21 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.master.TestMaster.beforeAllTests(TestMaster.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/766a3ec3-d460-468a-8986-027d1a138299/dfscluster_6c4a5881-c2c7-4cd0-8e2e-992d4307112a/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/766a3ec3-d460-468a-8986-027d1a138299/dfscluster_6c4a5881-c2c7-4cd0-8e2e-992d4307112a/dfs/data/data2
24/04/20 21:00:21 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestSubscriber.setUpBeforeClass(TestSubscriber.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/789d8c6a-df3a-4c41-8e14-fa5e0018c0a9/dfscluster_1bdadc8f-3510-4b5d-a573-64749cac4b24/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/789d8c6a-df3a-4c41-8e14-fa5e0018c0a9/dfscluster_1bdadc8f-3510-4b5d-a573-64749cac4b24/dfs/data/data2
24/04/20 21:00:21 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.setUpBeforeClass(TestJdbcResultFormatter.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.tearDownAfterClass(TestJdbcResultFormatter.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:21 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/6af93879-99f5-4902-8bbd-899f26e6edb2/dfscluster_524d496f-ddb1-42e3-bf6e-65bfa3989397/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/6af93879-99f5-4902-8bbd-899f26e6edb2/dfscluster_524d496f-ddb1-42e3-bf6e-65bfa3989397/dfs/data/data2
24/04/20 21:00:22 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/04/20 21:00:22 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/04/20 21:00:22 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.fserver.redo.TestRedoLog.before(TestRedoLog.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,name from User where user_id=1 limit 1;
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, name]
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 21:00:22 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false]]], fetchRows=0]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,photo_id,full_url,thumbnail_url from Photo where user_id=99999999999 and photo_id=0.1;
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL TableSource Photo
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem photo_id
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem full_url
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem thumbnail_url
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, photo_id, full_url, thumbnail_url]
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 99999999999 AND photo_id = 0.1
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
2 Filter Field:
	Field user_id  Type EQUAL Value 99999999999
	Field photo_id  Type EQUAL Value 0.1
	


24/04/20 21:00:22 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x17Hv\xE7\xFF\x00\x00\x00\x00\x00 from Photo
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=Photo, primayKey=[0, 0, 0, 23, 72, 118, -25, -1, 0, 0, 0, 0, 0], columns=[ColumnAction [tableName=Photo, familyName=cf, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=photo_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=full_url, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=thumbnail_url, value=null, isIndex=false]]], fetchRows=0]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1;
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 21:00:22 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1 for update ;
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/04/20 21:00:22 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/04/20 21:00:22 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/04/20 21:00:22 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
2013-04-13 04:04:334
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/04/20 21:00:22 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/04/20 21:00:22 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
--------------------------------------------
SELECT			SELECT
STAR			*
FROM			FROM
IDENTIFIER		T
WHERE			WHERE
IDENTIFIER		F1
EQ			=
QUES			?
ORDER			ORDER
BY			BY
IDENTIFIER		F2
EOF			null
--------------------------------------------
24/04/20 21:00:22 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table MetricsEntityGroupWrapperStub DEADBEEF001
24/04/20 21:00:22 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/04/20 21:00:22 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/04/20 21:00:22 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TWO
24/04/20 21:00:22 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/37e611fc-409b-497c-93ce-30848d920c2b/dfscluster_9c1a4c30-fef2-46c5-80a1-50b17dd962a3/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/37e611fc-409b-497c-93ce-30848d920c2b/dfscluster_9c1a4c30-fef2-46c5-80a1-50b17dd962a3/dfs/data/data2
24/04/20 21:00:22 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestPreparedStatement.beforeClass(TestPreparedStatement.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestPreparedStatement.afterClass(TestPreparedStatement.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
