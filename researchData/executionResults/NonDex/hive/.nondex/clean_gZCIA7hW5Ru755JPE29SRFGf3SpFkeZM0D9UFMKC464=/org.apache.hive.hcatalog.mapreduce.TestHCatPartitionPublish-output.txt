SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,117705 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@40a4337a]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@40a4337a) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@3d285d7e
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@1e66f1f5
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,030809 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 48762659
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T08:33:44.490-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-08:33:46.300, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-08:33:46.301, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@1e66f1f5 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@1e66f1f5
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@1e66f1f5 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@45f45fa1...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@45f45fa1 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@79dc5318
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@40a4337a
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@40a4337a) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@40a4337a] started OK.
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T08:33:46,752  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T08:33:47,369  INFO [main] v2.MiniMRYarnCluster: mkdir: file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_hcat_partitionpublish_4706475705433890904/hadoop-yarn/staging
2024-04-24T08:33:47,401  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:33:47,418  INFO [main] net.ServerSocketUtil: Using port 9188
2024-04-24T08:33:47,437  INFO [main] resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-04-24T08:33:47,519  INFO [main] security.Groups: clearing userToGroupsMap cache
2024-04-24T08:33:47,608  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2024-04-24T08:33:47,717  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2024-04-24T08:33:47,723  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2024-04-24T08:33:47,783  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher
2024-04-24T08:33:47,785  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2024-04-24T08:33:47,787  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2024-04-24T08:33:47,790  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2024-04-24T08:33:48,003  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T08:33:48,032  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-resourcemanager.properties,hadoop-metrics2.properties
2024-04-24T08:33:48,051  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T08:33:48,051  INFO [main] impl.MetricsSystemImpl: ResourceManager metrics system started
2024-04-24T08:33:48,076  INFO [main] security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2024-04-24T08:33:48,084  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2024-04-24T08:33:48,100  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2024-04-24T08:33:48,118  INFO [main] util.HostsFileReader: Refreshing hosts (include/exclude) list
2024-04-24T08:33:48,283  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$1
2024-04-24T08:33:48,397  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2024-04-24T08:33:48,399  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2024-04-24T08:33:48,401  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2024-04-24T08:33:48,402  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2024-04-24T08:33:48,403  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2024-04-24T08:33:48,405  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2024-04-24T08:33:48,406  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2024-04-24T08:33:48,420  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$CustomContainerManagerImpl
2024-04-24T08:33:48,421  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$ShortCircuitedNodeManager
2024-04-24T08:33:48,421  INFO [main] impl.MetricsSystemImpl: NodeManager metrics system started (again)
2024-04-24T08:33:48,509  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2024-04-24T08:33:48,512  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2024-04-24T08:33:48,639  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2024-04-24T08:33:48,741  INFO [main] resource.ResourceUtils: Unable to find 'node-resources.xml'.
2024-04-24T08:33:48,773  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system started (again)
2024-04-24T08:33:48,774  INFO [main] hs.JobHistory: JobHistory Init
2024-04-24T08:33:48,802  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:33:48,816  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:33:48,823  INFO [main] hs.HistoryFileManager: Perms after creating 504, Expected: 1023
2024-04-24T08:33:48,823  INFO [main] hs.HistoryFileManager: Explicitly setting permissions to : 1023, rwxrwxrwt
2024-04-24T08:33:48,831  INFO [main] hs.HistoryFileManager: Initializing Existing Jobs...
2024-04-24T08:33:48,831  INFO [main] hs.HistoryFileManager: Found 0 directories to load
2024-04-24T08:33:48,831  INFO [main] hs.HistoryFileManager: Existing job initialization finished. 0.0% of cache is occupied.
2024-04-24T08:33:48,836  INFO [main] hs.CachedHistoryStorage: CachedHistoryStorage Init
2024-04-24T08:33:48,957  INFO [Thread-71] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:33:48,960  INFO [Thread[Thread-72,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:33:48,961  INFO [Thread[Thread-72,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:33:49,096  INFO [Thread-71] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:33:49,100  WARN [Thread-71] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:33:49,106  INFO [Thread-71] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:33:49,109  INFO [Thread-71] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context jobhistory
2024-04-24T08:33:49,109  INFO [Thread-71] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:33:49,110  INFO [Thread-71] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:33:49,113  INFO [Thread-71] http.HttpServer2: adding path spec: /jobhistory/*
2024-04-24T08:33:49,113  INFO [Thread-71] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:33:49,585  INFO [Thread-71] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:33:49,587  INFO [Thread-71] http.HttpServer2: Jetty bound to port 45399
abr 24, 2024 8:33:49 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices as a root resource class
abr 24, 2024 8:33:49 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:33:49 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:33:49 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:33:49 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:50 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:50 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
2024-04-24T08:33:50,585  INFO [Thread-71] webapp.WebApps: Web app jobhistory started at 45399
2024-04-24T08:33:50,613  INFO [Thread-71] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB to the server
2024-04-24T08:33:50,616  INFO [Thread-71] hs.HistoryClientService: Instantiated HistoryClientService at Lenovo-Bot/127.0.1.1:34437
2024-04-24T08:33:50,619  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e981ca4] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:33:51,999  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:33:52,001  INFO [Thread[Thread-98,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:33:52,001  INFO [Thread[Thread-98,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:33:52,004  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2024-04-24T08:33:52,022  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2024-04-24T08:33:52,029  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@bdd2027] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:33:52,043  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2024-04-24T08:33:52,143  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2024-04-24T08:33:52,156  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:33:52,157  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:33:52,158  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: adding path spec: /cluster/*
2024-04-24T08:33:52,161  INFO [main] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:33:52,162  INFO [main] http.HttpServer2: adding path spec: /app/*
2024-04-24T08:33:52,162  INFO [main] http.HttpServer2: adding path spec: /proxy/*
abr 24, 2024 8:33:52 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:33:52,242  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:33:52,243  INFO [main] http.HttpServer2: Jetty bound to port 44407
2024-04-24T08:33:52,249  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:33:52,265  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:33:52,266  INFO [Thread[Thread-275,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:33:52,267  INFO [Thread[Thread-275,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:33:52 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:52 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:33:52,807  INFO [main] webapp.WebApps: Web app cluster started at 44407
2024-04-24T08:33:52,848  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2024-04-24T08:33:52,905  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2024-04-24T08:33:52,920  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2024-04-24T08:33:52,993  INFO [main] mapred.IndexCache: IndexCache created with max memory = 10485760
2024-04-24T08:33:53,010  INFO [main] mapred.ShuffleHandler: mapreduce_shuffle listening on port 40395
2024-04-24T08:33:53,011  WARN [main] tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2024-04-24T08:33:53,014  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:33:53,014  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:33:53,015  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:33:53,016  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2024-04-24T08:33:53,016  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:33:53,016  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:33:53,017  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2024-04-24T08:33:53,017  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2024-04-24T08:33:53,017  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2024-04-24T08:33:53,017  INFO [main] http.HttpServer2: adding path spec: /node/*
2024-04-24T08:33:53,017  INFO [main] http.HttpServer2: adding path spec: /ws/*
abr 24, 2024 8:33:53 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:33:53,039  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:33:53,040  INFO [main] http.HttpServer2: Jetty bound to port 41211
2024-04-24T08:33:53,043  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:33:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:33:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:33:53,349  INFO [main] webapp.WebApps: Web app node started at 41211
2024-04-24T08:33:53,350  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1220ef43] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:33:53,464  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager address: Lenovo-Bot:37465
2024-04-24T08:33:53,464  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager web address: Lenovo-Bot:44407
2024-04-24T08:33:53,464  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer address: Lenovo-Bot:34437
2024-04-24T08:33:53,465  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer web address: Lenovo-Bot:45399
2024-04-24T08:33:53,470  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
2024-04-24T08:33:53,735  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:33:53,735  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:33:53,735  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:33:53,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:33:53,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:33:53,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:33:53,737  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:33:53,737  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:33:53,737  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:33:53,737  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:33:53,737  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:33:53,759  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-24T08:33:54,654  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_35123;create=true
2024-04-24T08:33:55,489  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:33:55,572  INFO [MetaStoreThread-35123] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
2024-04-24T08:33:55,692  INFO [MetaStoreThread-35123] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:33:55,731  INFO [MetaStoreThread-35123] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:33:55,732  INFO [MetaStoreThread-35123] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T08:33:55,732  INFO [MetaStoreThread-35123] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T08:33:55,745  WARN [MetaStoreThread-35123] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T08:33:55,749  INFO [MetaStoreThread-35123] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T08:33:55,772  INFO [MetaStoreThread-35123] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T08:33:55,776  INFO [MetaStoreThread-35123] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T08:33:56,238  INFO [MetaStoreThread-35123] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T08:33:56,238  INFO [MetaStoreThread-35123] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@641b2d6c, with PersistenceManager: null will be shutdown
2024-04-24T08:33:56,267  INFO [MetaStoreThread-35123] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@641b2d6c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@638835b9 created in the thread with id: 401
2024-04-24T08:33:56,489  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:33:57,490  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:33:58,490  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:33:58,606  INFO [MetaStoreThread-35123] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@641b2d6c from thread id: 401
2024-04-24T08:33:58,619  INFO [MetaStoreThread-35123] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-24T08:33:58,668  INFO [MetaStoreThread-35123] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T08:33:58,717  INFO [MetaStoreThread-35123] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T08:33:58,730  INFO [MetaStoreThread-35123] metastore.HMSHandler: Added admin role in metastore
2024-04-24T08:33:58,732  INFO [MetaStoreThread-35123] metastore.HMSHandler: Added public role in metastore
2024-04-24T08:33:58,780  INFO [MetaStoreThread-35123] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T08:33:58,788  INFO [MetaStoreThread-35123] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T08:33:59,008  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Started the new metaserver on port [35123]...
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: TCP keepalive = true
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Enable SSL = false
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Compaction HMS parameters:
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.initiator.on = false
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.worker.threads = 0
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: hive.metastore.runworker.in = metastore
2024-04-24T08:33:59,012  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.history.retention.attempted = 2
2024-04-24T08:33:59,013  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.history.retention.failed = 3
2024-04-24T08:33:59,013  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.history.retention.succeeded = 3
2024-04-24T08:33:59,013  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.initiator.failed.compacts.threshold = 2
2024-04-24T08:33:59,013  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: metastore.compactor.enable.stats.compression
2024-04-24T08:33:59,013  WARN [MetaStoreThread-35123] metastore.HiveMetaStore: Compactor Initiator is turned Off. Automatic compaction will not be triggered.
2024-04-24T08:33:59,013  WARN [MetaStoreThread-35123] metastore.HiveMetaStore: Invalid number of Compactor Worker threads(0) on HMS
2024-04-24T08:33:59,013  INFO [MetaStoreThread-35123] metastore.HiveMetaStore: Direct SQL optimization = true
2024-04-24T08:33:59,519  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:33:59,522  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/35123) is created
2024-04-24T08:33:59,522  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 35123 with warehouse dir: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/35123 with jdbcUrl: jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_35123;create=true
2024-04-24T08:33:59,576  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:33:59,576  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35123]
2024-04-24T08:33:59,576  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35123)
2024-04-24T08:33:59,593  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35123) current connections: 1
2024-04-24T08:33:59,674  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:33:59,674  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:33:59,675  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:33:59,677  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ed2df52, with PersistenceManager: null will be shutdown
2024-04-24T08:33:59,678  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ed2df52, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59c8da2e created in the thread with id: 411
2024-04-24T08:33:59,693  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ed2df52 from thread id: 411
2024-04-24T08:33:59,819  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testHCatPartitionedTable, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:string, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T08:33:59,844  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/35123/testhcatpartitionedtable
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:34:00,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:34:00,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:34:00,304  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:34:00,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:34:00,305  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:34:00,305  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:34:00,305  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T08:34:00,307  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T08:34:00,348  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T08:34:00,397  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:34:00,397  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35123]
2024-04-24T08:34:00,397  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35123)
2024-04-24T08:34:00,398  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35123) current connections: 2
2024-04-24T08:34:00,399  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T08:34:00,456  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:34:00,457  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:34:00,457  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:34:00,458  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2deb1cb6, with PersistenceManager: null will be shutdown
2024-04-24T08:34:00,458  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2deb1cb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4032a1b8 created in the thread with id: 418
2024-04-24T08:34:00,465  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2deb1cb6 from thread id: 418
2024-04-24T08:34:00,522  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:34:00,611  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:34:00,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:34:00,742  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:34:00,742  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:34:00,742  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:34:00,942  INFO [main] client.RMProxy: Connecting to ResourceManager at Lenovo-Bot/127.0.1.1:37465
2024-04-24T08:34:01,843  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:34:01,843  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:34:01,843  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:34:01,844  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:34:01,844  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:34:01,844  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:34:01,844  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:34:01,844  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:34:01,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:34:01,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:34:01,845  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:34:01,846  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:34:01,852  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:34:02,499  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T08:34:02,510  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T08:34:02,650  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T08:34:02,857  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T08:34:02,913  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1713972831962_0001
2024-04-24T08:34:02,913  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T08:34:03,326  INFO [main] mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
2024-04-24T08:34:04,177  INFO [main] impl.YarnClientImpl: Submitted application application_1713972831962_0001
2024-04-24T08:34:04,216  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T08:34:04,216  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T08:34:04,299  INFO [main] mapreduce.Job: The url to track the job: http://Lenovo-Bot:0/proxy/application_1713972831962_0001/
2024-04-24T08:34:04,301  INFO [main] mapreduce.Job: Running job: job_1713972831962_0001
2024-04-24T08:34:05,227  INFO [Socket Reader #1 for port 38193] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:11,694  INFO [Socket Reader #1 for port 41757] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:13,464  INFO [main] mapreduce.Job: Job job_1713972831962_0001 running in uber mode : false
2024-04-24T08:34:13,467  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T08:34:14,143  INFO [Socket Reader #1 for port 38193] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:14,156  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713972831962_0001
2024-04-24T08:34:17,642  INFO [main] mapreduce.Job: Task Id : attempt_1713972831962_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:34:18,964  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner started
2024-04-24T08:34:18,965  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner complete
2024-04-24T08:34:19,038  INFO [Socket Reader #1 for port 38193] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:19,556  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713972831962_0001
2024-04-24T08:34:22,713  INFO [main] mapreduce.Job: Task Id : attempt_1713972831962_0001_m_000000_1, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:34:24,076  INFO [Socket Reader #1 for port 38193] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:24,817  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713972831962_0001
2024-04-24T08:34:28,750  INFO [main] mapreduce.Job: Task Id : attempt_1713972831962_0001_m_000000_2, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:34:30,108  INFO [Socket Reader #1 for port 38193] ipc.Server: Auth successful for appattempt_1713972831962_0001_000001 (auth:SIMPLE)
2024-04-24T08:34:30,438  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713972831962_0001
2024-04-24T08:34:34,784  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T08:34:39,822  INFO [main] mapreduce.Job: Job job_1713972831962_0001 failed with state FAILED due to: Task failed task_1713972831962_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2024-04-24T08:34:40,045  INFO [main] mapreduce.Job: Counters: 9
	Job Counters 
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=3
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=13880
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=13880
		Total vcore-milliseconds taken by all map tasks=13880
		Total megabyte-milliseconds taken by all map tasks=14213120
2024-04-24T08:34:40,067  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:34:40,095  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:34:40,113  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:34:40,193  WARN [ContainersLauncher #0] nodemanager.DefaultContainerExecutor: Exit code from container container_1713972831962_0001_01_000001 is : 143
2024-04-24T08:34:57,234 ERROR [Thread[Thread-275,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:34:57,241  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T08:34:57,247  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T08:34:57,247 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T08:34:57,253  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:34:57,253  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T08:34:57,253  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:34:57,253  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T08:34:57,253 ERROR [Thread[Thread-98,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:34:57,254  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:34:57,254  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:34:57,255  INFO [main] impl.MetricsSystemImpl: Stopping JobHistoryServer metrics system...
2024-04-24T08:34:57,273  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system stopped.
2024-04-24T08:34:57,273  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system shutdown complete.
2024-04-24T08:34:57,278  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T08:34:57,278  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T08:34:57,283 ERROR [Thread[Thread-72,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:34:57,316  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T08:34:57,316  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T08:34:57,317  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2deb1cb6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4032a1b8 will be shutdown
2024-04-24T08:34:57,317  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
