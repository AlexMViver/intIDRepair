SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,104043 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@6c6cb480]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@6c6cb480) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@1a677343
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@63475ace
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,025599 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 3561800
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T08:24:01.808-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-08:24:03.404, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-08:24:03.405, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@63475ace initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@63475ace
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@63475ace OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@400cff1a...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@400cff1a OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@768fc0f2
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@6c6cb480
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@6c6cb480) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@6c6cb480] started OK.
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T08:24:03,674  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T08:24:04,203  INFO [main] v2.MiniMRYarnCluster: file:/tmp/hadoop-yarn/staging exists! deleting...
2024-04-24T08:24:04,204  INFO [main] v2.MiniMRYarnCluster: mkdir: file:/tmp/hadoop-yarn/staging
2024-04-24T08:24:04,229  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:24:04,248  INFO [main] net.ServerSocketUtil: Using port 9188
2024-04-24T08:24:04,276  INFO [main] resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-04-24T08:24:04,347  INFO [main] security.Groups: clearing userToGroupsMap cache
2024-04-24T08:24:04,407  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2024-04-24T08:24:04,501  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2024-04-24T08:24:04,506  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2024-04-24T08:24:04,545  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher
2024-04-24T08:24:04,547  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2024-04-24T08:24:04,549  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2024-04-24T08:24:04,550  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2024-04-24T08:24:04,696  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T08:24:04,716  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-resourcemanager.properties,hadoop-metrics2.properties
2024-04-24T08:24:04,732  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T08:24:04,732  INFO [main] impl.MetricsSystemImpl: ResourceManager metrics system started
2024-04-24T08:24:04,751  INFO [main] security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2024-04-24T08:24:04,756  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2024-04-24T08:24:04,767  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2024-04-24T08:24:04,778  INFO [main] util.HostsFileReader: Refreshing hosts (include/exclude) list
2024-04-24T08:24:04,905  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$1
2024-04-24T08:24:04,985  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2024-04-24T08:24:04,986  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2024-04-24T08:24:04,987  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2024-04-24T08:24:04,988  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2024-04-24T08:24:04,989  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2024-04-24T08:24:04,989  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2024-04-24T08:24:04,990  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2024-04-24T08:24:04,999  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$CustomContainerManagerImpl
2024-04-24T08:24:04,999  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$ShortCircuitedNodeManager
2024-04-24T08:24:05,000  INFO [main] impl.MetricsSystemImpl: NodeManager metrics system started (again)
2024-04-24T08:24:05,072  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2024-04-24T08:24:05,074  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2024-04-24T08:24:05,174  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2024-04-24T08:24:05,228  INFO [main] resource.ResourceUtils: Unable to find 'node-resources.xml'.
2024-04-24T08:24:05,250  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system started (again)
2024-04-24T08:24:05,250  INFO [main] hs.JobHistory: JobHistory Init
2024-04-24T08:24:05,270  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:24:05,281  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:24:05,287  INFO [main] hs.HistoryFileManager: Perms after creating 504, Expected: 1023
2024-04-24T08:24:05,287  INFO [main] hs.HistoryFileManager: Explicitly setting permissions to : 1023, rwxrwxrwt
2024-04-24T08:24:05,293  INFO [main] hs.HistoryFileManager: Initializing Existing Jobs...
2024-04-24T08:24:05,293  INFO [main] hs.HistoryFileManager: Found 0 directories to load
2024-04-24T08:24:05,294  INFO [main] hs.HistoryFileManager: Existing job initialization finished. 0.0% of cache is occupied.
2024-04-24T08:24:05,296  INFO [main] hs.CachedHistoryStorage: CachedHistoryStorage Init
2024-04-24T08:24:05,383  INFO [Thread-69] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:24:05,386  INFO [Thread[Thread-70,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:24:05,386  INFO [Thread[Thread-70,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:24:05,475  INFO [Thread-69] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:24:05,479  WARN [Thread-69] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:24:05,484  INFO [Thread-69] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:24:05,485  INFO [Thread-69] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context jobhistory
2024-04-24T08:24:05,486  INFO [Thread-69] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:24:05,486  INFO [Thread-69] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:24:05,489  INFO [Thread-69] http.HttpServer2: adding path spec: /jobhistory/*
2024-04-24T08:24:05,489  INFO [Thread-69] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:24:05,821  INFO [Thread-69] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:24:05,824  INFO [Thread-69] http.HttpServer2: Jetty bound to port 35867
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices as a root resource class
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:24:06 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:06 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
2024-04-24T08:24:06,747  INFO [Thread-69] webapp.WebApps: Web app jobhistory started at 35867
2024-04-24T08:24:06,781  INFO [Thread-69] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB to the server
2024-04-24T08:24:06,784  INFO [Thread-69] hs.HistoryClientService: Instantiated HistoryClientService at Lenovo-Bot/127.0.1.1:43727
2024-04-24T08:24:06,788  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2cd5f325] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:24:06,900  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:24:06,901  INFO [Thread[Thread-96,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:24:06,901  INFO [Thread[Thread-96,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:24:06,904  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2024-04-24T08:24:06,921  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2024-04-24T08:24:06,928  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@299270eb] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:24:06,944  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2024-04-24T08:24:07,044  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2024-04-24T08:24:07,057  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:24:07,057  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:24:07,058  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: adding path spec: /cluster/*
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:24:07,061  INFO [main] http.HttpServer2: adding path spec: /app/*
2024-04-24T08:24:07,062  INFO [main] http.HttpServer2: adding path spec: /proxy/*
abr 24, 2024 8:24:07 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:24:07,121  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:24:07,121  INFO [main] http.HttpServer2: Jetty bound to port 38963
2024-04-24T08:24:07,126  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:24:07,137  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:24:07,138  INFO [Thread[Thread-273,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:24:07,139  INFO [Thread[Thread-273,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:24:07 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:24:07,607  INFO [main] webapp.WebApps: Web app cluster started at 38963
2024-04-24T08:24:07,639  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2024-04-24T08:24:07,693  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2024-04-24T08:24:07,708  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2024-04-24T08:24:07,781  INFO [main] mapred.IndexCache: IndexCache created with max memory = 10485760
2024-04-24T08:24:07,796  INFO [main] mapred.ShuffleHandler: mapreduce_shuffle listening on port 39923
2024-04-24T08:24:07,797  WARN [main] tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2024-04-24T08:24:07,799  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:24:07,799  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:24:07,800  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:24:07,801  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2024-04-24T08:24:07,801  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:24:07,801  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:24:07,801  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2024-04-24T08:24:07,801  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2024-04-24T08:24:07,802  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2024-04-24T08:24:07,802  INFO [main] http.HttpServer2: adding path spec: /node/*
2024-04-24T08:24:07,802  INFO [main] http.HttpServer2: adding path spec: /ws/*
abr 24, 2024 8:24:07 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:24:07,822  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:24:07,823  INFO [main] http.HttpServer2: Jetty bound to port 36327
2024-04-24T08:24:07,825  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:24:07 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:07 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:24:08 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:24:08,092  INFO [main] webapp.WebApps: Web app node started at 36327
2024-04-24T08:24:08,093  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5edacf20] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:24:08,193  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager address: Lenovo-Bot:39235
2024-04-24T08:24:08,194  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager web address: Lenovo-Bot:38963
2024-04-24T08:24:08,194  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer address: Lenovo-Bot:43727
2024-04-24T08:24:08,194  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer web address: Lenovo-Bot:35867
2024-04-24T08:24:08,324  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started (again)
2024-04-24T08:24:08,369  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T08:24:08,379  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T08:24:08,407  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T08:24:08,462  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T08:24:08,555  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local436561159_0001
2024-04-24T08:24:08,555  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T08:24:08,669  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T08:24:08,670  INFO [main] mapreduce.Job: Running job: job_local436561159_0001
2024-04-24T08:24:08,671  INFO [Thread-354] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T08:24:08,676  INFO [Thread-354] mapreduce.MultiOutputFormat: Creating output committer for alias: out1
2024-04-24T08:24:08,681  INFO [Thread-354] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,681  INFO [Thread-354] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,681  INFO [Thread-354] mapreduce.MultiOutputFormat: Creating output committer for alias: out2
2024-04-24T08:24:08,682  INFO [Thread-354] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,682  INFO [Thread-354] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,683  INFO [Thread-354] mapreduce.MultiOutputFormat: Creating output committer for alias: out3
2024-04-24T08:24:08,684  INFO [Thread-354] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.MultiOutputFormat$MultiOutputCommitter
2024-04-24T08:24:08,687  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling setupJob for alias: out1
2024-04-24T08:24:08,703  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling setupJob for alias: out2
2024-04-24T08:24:08,712  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling setupJob for alias: out3
2024-04-24T08:24:08,744  INFO [Thread-354] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T08:24:08,745  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local436561159_0001_m_000000_0
2024-04-24T08:24:08,775  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: out1
2024-04-24T08:24:08,775  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,775  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,776  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: out2
2024-04-24T08:24:08,777  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,777  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,777  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: out3
2024-04-24T08:24:08,779  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: out1
2024-04-24T08:24:08,779  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: out2
2024-04-24T08:24:08,779  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: out3
2024-04-24T08:24:08,783  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T08:24:08,790  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/input5448006769032619798txt:0+29
2024-04-24T08:24:08,821  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T08:24:08,821  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T08:24:08,821  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T08:24:08,821  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T08:24:08,821  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T08:24:08,825  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T08:24:08,836  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T08:24:08,836  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T08:24:08,836  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T08:24:08,836  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 50; bufvoid = 104857600
2024-04-24T08:24:08,836  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
2024-04-24T08:24:08,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T08:24:08,875  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local436561159_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T08:24:08,878  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T08:24:08,878  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local436561159_0001_m_000000_0' done.
2024-04-24T08:24:08,880  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local436561159_0001_m_000000_0: Counters: 17
	File System Counters
		FILE: Number of bytes read=2269507
		FILE: Number of bytes written=2778175
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=5
		Map output bytes=50
		Map output materialized bytes=66
		Input split bytes=151
		Combine input records=0
		Spilled Records=5
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=544735232
	File Input Format Counters 
		Bytes Read=29
2024-04-24T08:24:08,880  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local436561159_0001_m_000000_0
2024-04-24T08:24:08,881  INFO [Thread-354] mapred.LocalJobRunner: map task executor complete.
2024-04-24T08:24:08,884  INFO [Thread-354] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T08:24:08,884  INFO [pool-22-thread-1] mapred.LocalJobRunner: Starting task: attempt_local436561159_0001_r_000000_0
2024-04-24T08:24:08,898  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating output committer for alias: out1
2024-04-24T08:24:08,899  INFO [pool-22-thread-1] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,899  INFO [pool-22-thread-1] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,899  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating output committer for alias: out2
2024-04-24T08:24:08,900  INFO [pool-22-thread-1] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,900  INFO [pool-22-thread-1] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:08,900  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating output committer for alias: out3
2024-04-24T08:24:08,901  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Calling setupTask for alias: out1
2024-04-24T08:24:08,901  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Calling setupTask for alias: out2
2024-04-24T08:24:08,901  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Calling setupTask for alias: out3
2024-04-24T08:24:08,901  INFO [pool-22-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T08:24:08,905  INFO [pool-22-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e78dcfc
2024-04-24T08:24:08,907  INFO [pool-22-thread-1] impl.MetricsSystemImpl: JobTracker metrics system started (again)
2024-04-24T08:24:08,925  INFO [pool-22-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T08:24:08,928  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local436561159_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T08:24:08,963  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local436561159_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2024-04-24T08:24:08,964  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local436561159_0001_m_000000_0
2024-04-24T08:24:08,965  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2024-04-24T08:24:08,968  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T08:24:08,969  INFO [pool-22-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T08:24:08,969  INFO [pool-22-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T08:24:08,981  INFO [pool-22-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T08:24:08,982  INFO [pool-22-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 54 bytes
2024-04-24T08:24:08,986  INFO [pool-22-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 62 bytes to disk to satisfy reduce memory limit
2024-04-24T08:24:08,986  INFO [pool-22-thread-1] reduce.MergeManagerImpl: Merging 1 files, 66 bytes from disk
2024-04-24T08:24:08,987  INFO [pool-22-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T08:24:08,987  INFO [pool-22-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T08:24:08,987  INFO [pool-22-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 54 bytes
2024-04-24T08:24:08,988  INFO [pool-22-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T08:24:08,989  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating record writer for alias: out1
2024-04-24T08:24:08,990  INFO [pool-22-thread-1] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:08,990  INFO [pool-22-thread-1] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:09,003  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating record writer for alias: out2
2024-04-24T08:24:09,004  INFO [pool-22-thread-1] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:09,004  INFO [pool-22-thread-1] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:09,054  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Creating record writer for alias: out3
2024-04-24T08:24:09,060  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Closing record writer for alias: out1
2024-04-24T08:24:09,060  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Closing record writer for alias: out2
2024-04-24T08:24:09,060  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Closing record writer for alias: out3
2024-04-24T08:24:09,061  INFO [pool-22-thread-1] mapred.Task: Task:attempt_local436561159_0001_r_000000_0 is done. And is in the process of committing
2024-04-24T08:24:09,062  INFO [pool-22-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T08:24:09,062  INFO [pool-22-thread-1] mapred.Task: Task attempt_local436561159_0001_r_000000_0 is allowed to commit now
2024-04-24T08:24:09,062  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Calling commitTask for alias: out1
2024-04-24T08:24:09,064  INFO [pool-22-thread-1] output.FileOutputCommitter: Saved output of task 'attempt_local436561159_0001_r_000000_0' to file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_multiout_6218582146527001623/MultiOutWithReduce/out1
2024-04-24T08:24:09,064  INFO [pool-22-thread-1] mapreduce.MultiOutputFormat: Calling commitTask for alias: out2
2024-04-24T08:24:09,065  INFO [pool-22-thread-1] output.FileOutputCommitter: Saved output of task 'attempt_local436561159_0001_r_000000_0' to file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_multiout_6218582146527001623/MultiOutWithReduce/out2
2024-04-24T08:24:09,067  INFO [pool-22-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T08:24:09,067  INFO [pool-22-thread-1] mapred.Task: Task 'attempt_local436561159_0001_r_000000_0' done.
2024-04-24T08:24:09,067  INFO [pool-22-thread-1] mapred.Task: Final Counters for attempt_local436561159_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=2269671
		FILE: Number of bytes written=2778402
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=66
		Reduce input records=5
		Reduce output records=6
		Spilled Records=5
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=630718464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:24:09,067  INFO [pool-22-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local436561159_0001_r_000000_0
2024-04-24T08:24:09,068  INFO [Thread-354] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24T08:24:09,068  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling commitJob for alias: out1
2024-04-24T08:24:09,075  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling commitJob for alias: out2
2024-04-24T08:24:09,082  INFO [Thread-354] mapreduce.MultiOutputFormat: Calling commitJob for alias: out3
2024-04-24T08:24:09,676  INFO [main] mapreduce.Job: Job job_local436561159_0001 running in uber mode : false
2024-04-24T08:24:09,678  INFO [main] mapreduce.Job:  map 100% reduce 100%
2024-04-24T08:24:09,681  INFO [main] mapreduce.Job: Job job_local436561159_0001 completed successfully
2024-04-24T08:24:09,712  INFO [main] mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=4539178
		FILE: Number of bytes written=5556577
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=5
		Map output bytes=50
		Map output materialized bytes=66
		Input split bytes=151
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=66
		Reduce input records=5
		Reduce output records=6
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=1175453696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=29
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:24:09,734  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started (again)
2024-04-24T08:24:09,746  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T08:24:09,752  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T08:24:09,785  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T08:24:09,808  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T08:24:09,828  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1227820281_0002
2024-04-24T08:24:09,828  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T08:24:09,934  INFO [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-alex/mapred/local/1713972249853/input2601725224129555030txt <- /home/alex/Repositories/hive/hcatalog/core/input2601725224129555030txt
2024-04-24T08:24:09,938  INFO [main] mapred.LocalDistributedCacheManager: Localized file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/input2601725224129555030txt as file:/tmp/hadoop-alex/mapred/local/1713972249853/input2601725224129555030txt
2024-04-24T08:24:09,961  INFO [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-alex/mapred/local/1713972249854/input1574526268457911086txt <- /home/alex/Repositories/hive/hcatalog/core/input1574526268457911086txt
2024-04-24T08:24:09,963  INFO [main] mapred.LocalDistributedCacheManager: Localized file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/input1574526268457911086txt as file:/tmp/hadoop-alex/mapred/local/1713972249854/input1574526268457911086txt
2024-04-24T08:24:09,994  INFO [main] mapred.LocalDistributedCacheManager: file:/tmp/hadoop-alex/mapred/local/1713972249853/input2601725224129555030txt
2024-04-24T08:24:09,994  INFO [main] mapred.LocalDistributedCacheManager: file:/tmp/hadoop-alex/mapred/local/1713972249854/input1574526268457911086txt
2024-04-24T08:24:09,995  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T08:24:09,995  INFO [main] mapreduce.Job: Running job: job_local1227820281_0002
2024-04-24T08:24:09,996  INFO [Thread-420] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T08:24:09,996  INFO [Thread-420] mapreduce.MultiOutputFormat: Creating output committer for alias: out1
2024-04-24T08:24:09,997  INFO [Thread-420] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:09,997  INFO [Thread-420] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:09,998  INFO [Thread-420] mapreduce.MultiOutputFormat: Creating output committer for alias: out2
2024-04-24T08:24:09,998  INFO [Thread-420] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:09,998  INFO [Thread-420] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:09,998  INFO [Thread-420] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.MultiOutputFormat$MultiOutputCommitter
2024-04-24T08:24:09,999  INFO [Thread-420] mapreduce.MultiOutputFormat: Calling setupJob for alias: out1
2024-04-24T08:24:10,010  INFO [Thread-420] mapreduce.MultiOutputFormat: Calling setupJob for alias: out2
2024-04-24T08:24:10,019  INFO [Thread-420] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T08:24:10,019  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1227820281_0002_m_000000_0
2024-04-24T08:24:10,024  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: out1
2024-04-24T08:24:10,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:10,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:10,025  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: out2
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: out1
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: out2
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T08:24:10,026  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/input2601725224129555030txt:0+11
2024-04-24T08:24:10,031  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating record writer for alias: out1
2024-04-24T08:24:10,032  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:10,032  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:10,044  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating record writer for alias: out2
2024-04-24T08:24:10,044  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:24:10,045  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:24:10,056  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T08:24:10,057  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Closing record writer for alias: out1
2024-04-24T08:24:10,057  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Closing record writer for alias: out2
2024-04-24T08:24:10,059  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1227820281_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T08:24:10,060  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T08:24:10,060  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1227820281_0002_m_000000_0 is allowed to commit now
2024-04-24T08:24:10,060  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling commitTask for alias: out1
2024-04-24T08:24:10,061  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1227820281_0002_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_multiout_6218582146527001623/MultiOutNoReduce/out1
2024-04-24T08:24:10,061  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling commitTask for alias: out2
2024-04-24T08:24:10,062  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1227820281_0002_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_multiout_6218582146527001623/MultiOutNoReduce/out2
2024-04-24T08:24:10,062  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T08:24:10,063  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1227820281_0002_m_000000_0' done.
2024-04-24T08:24:10,063  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1227820281_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2270069
		FILE: Number of bytes written=3272409
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=4
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=630718464
	File Input Format Counters 
		Bytes Read=11
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:24:10,063  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1227820281_0002_m_000000_0
2024-04-24T08:24:10,063  INFO [Thread-420] mapred.LocalJobRunner: map task executor complete.
2024-04-24T08:24:10,064  INFO [Thread-420] mapreduce.MultiOutputFormat: Calling commitJob for alias: out1
2024-04-24T08:24:10,070  INFO [Thread-420] mapreduce.MultiOutputFormat: Calling commitJob for alias: out2
2024-04-24T08:24:10,997  INFO [main] mapreduce.Job: Job job_local1227820281_0002 running in uber mode : false
2024-04-24T08:24:10,997  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T08:24:10,998  INFO [main] mapreduce.Job: Job job_local1227820281_0002 completed successfully
2024-04-24T08:24:11,004  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2270069
		FILE: Number of bytes written=3272409
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=4
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=630718464
	File Input Format Counters 
		Bytes Read=11
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:24:11,007  INFO [main] mapreduce.TestMultiOutputFormat: Verifying file contents
2024-04-24T08:24:11,054 ERROR [Thread[Thread-273,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:24:11,059  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T08:24:11,063  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T08:24:11,063 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T08:24:11,064  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:24:11,065  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T08:24:11,065  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:24:11,065  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:24:11,065  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T08:24:11,065 ERROR [Thread[Thread-96,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:24:11,065  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:24:11,068  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T08:24:11,068  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T08:24:11,069 ERROR [Thread[Thread-70,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
