SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,093863 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@702657cc]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@702657cc) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@26794848
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@79d8407f
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,026539 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 3174753
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T08:23:45.244-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-08:23:46.821, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-08:23:46.821, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@79d8407f initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@79d8407f
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@79d8407f OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@ca263c2...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@ca263c2 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@79dc5318
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@702657cc
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@702657cc) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@702657cc] started OK.
2024-04-24T08:23:46,983  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T08:23:47,400  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T08:23:47,470  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:47,470  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:47,470  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:47,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:47,471  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:47,471  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:47,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:47,472  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:47,472  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:47,473  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:47,473  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:47,499  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-24T08:23:48,237  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_38735;create=true
2024-04-24T08:23:49,061  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:23:49,125  INFO [MetaStoreThread-38735] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
2024-04-24T08:23:49,248  INFO [MetaStoreThread-38735] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:23:49,277  INFO [MetaStoreThread-38735] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:23:49,281  INFO [MetaStoreThread-38735] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T08:23:49,281  INFO [MetaStoreThread-38735] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T08:23:49,304  WARN [MetaStoreThread-38735] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T08:23:49,309  INFO [MetaStoreThread-38735] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T08:23:49,324  INFO [MetaStoreThread-38735] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T08:23:49,329  INFO [MetaStoreThread-38735] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T08:23:49,829  INFO [MetaStoreThread-38735] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T08:23:49,829  INFO [MetaStoreThread-38735] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64276f85, with PersistenceManager: null will be shutdown
2024-04-24T08:23:49,881  INFO [MetaStoreThread-38735] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64276f85, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68b8dad6 created in the thread with id: 17
2024-04-24T08:23:50,062  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:23:51,063  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:23:52,012  INFO [MetaStoreThread-38735] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64276f85 from thread id: 17
2024-04-24T08:23:52,026  INFO [MetaStoreThread-38735] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-24T08:23:52,063  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T08:23:52,376  INFO [MetaStoreThread-38735] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T08:23:52,427  INFO [MetaStoreThread-38735] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T08:23:52,441  INFO [MetaStoreThread-38735] metastore.HMSHandler: Added admin role in metastore
2024-04-24T08:23:52,443  INFO [MetaStoreThread-38735] metastore.HMSHandler: Added public role in metastore
2024-04-24T08:23:52,506  INFO [MetaStoreThread-38735] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T08:23:52,515  INFO [MetaStoreThread-38735] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T08:23:52,728  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Started the new metaserver on port [38735]...
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: TCP keepalive = true
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Enable SSL = false
2024-04-24T08:23:52,731  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Compaction HMS parameters:
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.initiator.on = false
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.worker.threads = 0
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: hive.metastore.runworker.in = metastore
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.history.retention.attempted = 2
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.history.retention.failed = 3
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.history.retention.succeeded = 3
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.initiator.failed.compacts.threshold = 2
2024-04-24T08:23:52,732  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: metastore.compactor.enable.stats.compression
2024-04-24T08:23:52,733  WARN [MetaStoreThread-38735] metastore.HiveMetaStore: Compactor Initiator is turned Off. Automatic compaction will not be triggered.
2024-04-24T08:23:52,733  WARN [MetaStoreThread-38735] metastore.HiveMetaStore: Invalid number of Compactor Worker threads(0) on HMS
2024-04-24T08:23:52,733  INFO [MetaStoreThread-38735] metastore.HiveMetaStore: Direct SQL optimization = true
2024-04-24T08:23:53,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:23:53,108  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735) is created
2024-04-24T08:23:53,109  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 38735 with warehouse dir: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735 with jdbcUrl: jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_38735;create=true
2024-04-24T08:23:53,257  INFO [main] v2.MiniMRYarnCluster: mkdir: file:/tmp/hadoop-yarn/staging
2024-04-24T08:23:53,279  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:23:53,294  INFO [main] net.ServerSocketUtil: Using port 9188
2024-04-24T08:23:53,302  INFO [main] resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-04-24T08:23:53,369  INFO [main] security.Groups: clearing userToGroupsMap cache
2024-04-24T08:23:53,429  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2024-04-24T08:23:53,542  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2024-04-24T08:23:53,548  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2024-04-24T08:23:53,591  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher
2024-04-24T08:23:53,592  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2024-04-24T08:23:53,594  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2024-04-24T08:23:53,595  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2024-04-24T08:23:53,720  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T08:23:53,737  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-resourcemanager.properties,hadoop-metrics2.properties
2024-04-24T08:23:53,751  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T08:23:53,751  INFO [main] impl.MetricsSystemImpl: ResourceManager metrics system started
2024-04-24T08:23:53,769  INFO [main] security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2024-04-24T08:23:53,773  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2024-04-24T08:23:53,785  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2024-04-24T08:23:53,796  INFO [main] util.HostsFileReader: Refreshing hosts (include/exclude) list
2024-04-24T08:23:53,890  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$1
2024-04-24T08:23:53,967  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2024-04-24T08:23:53,969  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2024-04-24T08:23:53,970  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2024-04-24T08:23:53,970  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2024-04-24T08:23:53,971  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2024-04-24T08:23:53,971  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2024-04-24T08:23:53,972  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2024-04-24T08:23:53,980  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$CustomContainerManagerImpl
2024-04-24T08:23:53,981  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.MiniYARNCluster$ShortCircuitedNodeManager
2024-04-24T08:23:53,981  INFO [main] impl.MetricsSystemImpl: NodeManager metrics system started (again)
2024-04-24T08:23:54,072  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2024-04-24T08:23:54,075  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2024-04-24T08:23:54,203  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2024-04-24T08:23:54,268  INFO [main] resource.ResourceUtils: Unable to find 'node-resources.xml'.
2024-04-24T08:23:54,289  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system started (again)
2024-04-24T08:23:54,289  INFO [main] hs.JobHistory: JobHistory Init
2024-04-24T08:23:54,306  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:23:54,315  INFO [main] jobhistory.JobHistoryUtils: Default file system is set solely by core-default.xml therefore -  ignoring
2024-04-24T08:23:54,321  INFO [main] hs.HistoryFileManager: Perms after creating 504, Expected: 1023
2024-04-24T08:23:54,322  INFO [main] hs.HistoryFileManager: Explicitly setting permissions to : 1023, rwxrwxrwt
2024-04-24T08:23:54,327  INFO [main] hs.HistoryFileManager: Initializing Existing Jobs...
2024-04-24T08:23:54,327  INFO [main] hs.HistoryFileManager: Found 0 directories to load
2024-04-24T08:23:54,327  INFO [main] hs.HistoryFileManager: Existing job initialization finished. 0.0% of cache is occupied.
2024-04-24T08:23:54,330  INFO [main] hs.CachedHistoryStorage: CachedHistoryStorage Init
2024-04-24T08:23:54,407  INFO [Thread-78] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:23:54,410  INFO [Thread[Thread-79,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:23:54,411  INFO [Thread[Thread-79,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:23:54,506  INFO [Thread-78] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:23:54,511  WARN [Thread-78] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:23:54,517  INFO [Thread-78] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:23:54,520  INFO [Thread-78] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context jobhistory
2024-04-24T08:23:54,520  INFO [Thread-78] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:23:54,520  INFO [Thread-78] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:23:54,523  INFO [Thread-78] http.HttpServer2: adding path spec: /jobhistory/*
2024-04-24T08:23:54,523  INFO [Thread-78] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:23:54,851  INFO [Thread-78] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:23:54,854  INFO [Thread-78] http.HttpServer2: Jetty bound to port 34757
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices as a root resource class
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:23:55 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
2024-04-24T08:23:55,713  INFO [Thread-78] webapp.WebApps: Web app jobhistory started at 34757
2024-04-24T08:23:55,740  INFO [Thread-78] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB to the server
2024-04-24T08:23:55,744  INFO [Thread-78] hs.HistoryClientService: Instantiated HistoryClientService at Lenovo-Bot/127.0.1.1:37531
2024-04-24T08:23:55,748  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77ef44c3] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:23:55,942  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:23:55,943  INFO [Thread[Thread-105,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:23:55,943  INFO [Thread[Thread-105,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:23:55,948  INFO [main] event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2024-04-24T08:23:55,967  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2024-04-24T08:23:55,975  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36f7d7b] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:23:55,994  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2024-04-24T08:23:56,080  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2024-04-24T08:23:56,094  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:23:56,095  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:23:56,096  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: adding path spec: /cluster/*
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: adding path spec: /ws/*
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: adding path spec: /app/*
2024-04-24T08:23:56,099  INFO [main] http.HttpServer2: adding path spec: /proxy/*
abr 24, 2024 8:23:56 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:23:56,178  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:23:56,178  INFO [main] http.HttpServer2: Jetty bound to port 33243
2024-04-24T08:23:56,184  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:23:56,201  INFO [main] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2024-04-24T08:23:56,202  INFO [Thread[Thread-282,5,main]] delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2024-04-24T08:23:56,202  INFO [Thread[Thread-282,5,main]] delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:23:56 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:23:56,651  INFO [main] webapp.WebApps: Web app cluster started at 33243
2024-04-24T08:23:56,711  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2024-04-24T08:23:56,736  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2024-04-24T08:23:56,751  INFO [main] pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2024-04-24T08:23:56,807  INFO [main] mapred.IndexCache: IndexCache created with max memory = 10485760
2024-04-24T08:23:56,826  INFO [main] mapred.ShuffleHandler: mapreduce_shuffle listening on port 45647
2024-04-24T08:23:56,827  WARN [main] tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2024-04-24T08:23:56,828  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-04-24T08:23:56,829  WARN [main] http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2024-04-24T08:23:56,830  INFO [main] http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-04-24T08:23:56,831  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2024-04-24T08:23:56,831  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-24T08:23:56,831  INFO [main] http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-24T08:23:56,831  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2024-04-24T08:23:56,831  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2024-04-24T08:23:56,832  INFO [main] http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2024-04-24T08:23:56,832  INFO [main] http.HttpServer2: adding path spec: /node/*
2024-04-24T08:23:56,832  INFO [main] http.HttpServer2: adding path spec: /ws/*
abr 24, 2024 8:23:56 AM com.google.inject.servlet.GuiceFilter setPipeline
WARNING: Multiple Servlet injectors detected. This is a warning indicating that you have more than one GuiceFilter running in your web application. If this is deliberate, you may safely ignore this message. If this is NOT deliberate however, your application may not work as expected.
2024-04-24T08:23:56,855  INFO [main] webapp.WebApps: Registered webapp guice modules
2024-04-24T08:23:56,855  INFO [main] http.HttpServer2: Jetty bound to port 34011
2024-04-24T08:23:56,859  INFO [main] server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class
abr 24, 2024 8:23:56 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
abr 24, 2024 8:23:57 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2024-04-24T08:23:57,092  INFO [main] webapp.WebApps: Web app node started at 34011
2024-04-24T08:23:57,093  INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@68dfda77] util.JvmPauseMonitor: Starting JVM pause monitor
2024-04-24T08:23:57,162  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager address: Lenovo-Bot:32909
2024-04-24T08:23:57,162  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN ResourceManager web address: Lenovo-Bot:33243
2024-04-24T08:23:57,162  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer address: Lenovo-Bot:37531
2024-04-24T08:23:57,163  INFO [main] v2.MiniMRYarnCluster: MiniMRYARN HistoryServer web address: Lenovo-Bot:34757
2024-04-24T08:23:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:57,213  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:23:57,214  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:38735]
2024-04-24T08:23:57,214  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:38735)
2024-04-24T08:23:57,228  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:38735) current connections: 1
2024-04-24T08:23:57,251  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test1	
2024-04-24T08:23:57,251  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:23:57,252  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:23:57,252  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b3339fd, with PersistenceManager: null will be shutdown
2024-04-24T08:23:57,253  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b3339fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79116692 created in the thread with id: 410
2024-04-24T08:23:57,264  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b3339fd from thread id: 410
2024-04-24T08:23:57,291  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test2	
2024-04-24T08:23:57,294  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test3	
2024-04-24T08:23:57,313  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:test1, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:), FieldSchema(name:value, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:test1, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:ds, type:string, comment:), FieldSchema(name:cluster, type:string, comment:)], parameters:null, viewOriginalText:null, viewExpandedText:null, tableType:null, catName:hive, ownerType:USER)	
2024-04-24T08:23:57,323  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test1
2024-04-24T08:23:57,464  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:test2, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:test2, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:ds, type:string, comment:), FieldSchema(name:cluster, type:string, comment:)], parameters:null, viewOriginalText:null, viewExpandedText:null, tableType:null, catName:hive, ownerType:USER)	
2024-04-24T08:23:57,467  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test2
2024-04-24T08:23:57,484  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:test3, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:), FieldSchema(name:value, type:string, comment:), FieldSchema(name:extra, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:test3, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:ds, type:string, comment:), FieldSchema(name:cluster, type:string, comment:)], parameters:null, viewOriginalText:null, viewExpandedText:null, tableType:null, catName:hive, ownerType:USER)	
2024-04-24T08:23:57,488  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test3
2024-04-24T08:23:57,508  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-24T08:23:57,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T08:23:57,508  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b3339fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@79116692 will be shutdown
2024-04-24T08:23:57,509  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:23:57,509  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:23:57,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:57,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:57,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:57,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:57,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:57,564  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:57,564  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T08:23:57,565  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_38735;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T08:23:57,576  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T08:23:57,587  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:23:57,587  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:38735]
2024-04-24T08:23:57,587  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:38735)
2024-04-24T08:23:57,587  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:38735) current connections: 1
2024-04-24T08:23:57,591  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=3 delay=1 lifetime=0
2024-04-24T08:23:57,622  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:57,622  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:23:57,622  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:23:57,623  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61cd194a, with PersistenceManager: null will be shutdown
2024-04-24T08:23:57,623  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61cd194a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cb1fa61 created in the thread with id: 420
2024-04-24T08:23:57,626  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61cd194a from thread id: 420
2024-04-24T08:23:57,642  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test1	
2024-04-24T08:23:57,698  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:57,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:57,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:57,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:57,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:57,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:57,761  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:57,842  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:57,843  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:57,843  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:57,843  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:57,843  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:57,850  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:57,850  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T08:23:57,851  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_38735;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T08:23:57,854  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:57,856  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test2	
2024-04-24T08:23:57,867  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:23:57,924  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:57,924  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:57,924  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:57,924  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:57,924  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:57,925  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:57,925  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T08:23:57,926  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/core/target/tmp/junit_metastore_db_38735;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T08:23:57,928  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:57,931  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test3	
2024-04-24T08:23:57,941  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:23:57,987  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started (again)
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:58,046  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:58,047  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:58,048  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:58,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:58,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:58,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:58,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:58,110  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:58,110  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:58,110  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:58,110  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:58,110  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:58,111  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:58,111  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:58,111  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:58,112  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:58,159  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:58,160  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:58,160  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:58,160  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:58,160  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:58,186  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T08:23:58,193  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T08:23:58,221  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T08:23:58,271  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T08:23:58,315  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1578056862_0001
2024-04-24T08:23:58,316  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T08:23:58,455  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T08:23:58,455  INFO [main] mapreduce.Job: Running job: job_local1578056862_0001
2024-04-24T08:23:58,457  INFO [Thread-378] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T08:23:58,461  INFO [Thread-378] mapreduce.MultiOutputFormat: Creating output committer for alias: test1
2024-04-24T08:23:58,469  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,469  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,477  INFO [Thread-378] mapreduce.MultiOutputFormat: Creating output committer for alias: test2
2024-04-24T08:23:58,482  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,482  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,485  INFO [Thread-378] mapreduce.MultiOutputFormat: Creating output committer for alias: test3
2024-04-24T08:23:58,489  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,489  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,492  INFO [Thread-378] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.MultiOutputFormat$MultiOutputCommitter
2024-04-24T08:23:58,496  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling setupJob for alias: test1
2024-04-24T08:23:58,497  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,497  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,512  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling setupJob for alias: test2
2024-04-24T08:23:58,513  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,513  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,528  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling setupJob for alias: test3
2024-04-24T08:23:58,529  INFO [Thread-378] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,529  INFO [Thread-378] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,569  INFO [Thread-378] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T08:23:58,570  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1578056862_0001_m_000000_0
2024-04-24T08:23:58,593  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: test1
2024-04-24T08:23:58,597  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,597  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,599  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: test2
2024-04-24T08:23:58,602  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,603  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,604  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating output committer for alias: test3
2024-04-24T08:23:58,609  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,609  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,611  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: test1
2024-04-24T08:23:58,612  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,612  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,612  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: test2
2024-04-24T08:23:58,613  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,613  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,614  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling setupTask for alias: test3
2024-04-24T08:23:58,614  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,615  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,618  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T08:23:58,622  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/target/tmp/test_multitable_6111790716899855593/MultiTableInput.txt:0+12
2024-04-24T08:23:58,633  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating record writer for alias: test1
2024-04-24T08:23:58,641  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,641  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,726  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating record writer for alias: test2
2024-04-24T08:23:58,736  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,736  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,753  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Creating record writer for alias: test3
2024-04-24T08:23:58,760  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,760  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Closing record writer for alias: test1
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 1,  Compr Total Column Value Length: 1
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 1,  Compr Total Column Value Length: 1
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Closing record writer for alias: test2
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 1,  Compr Total Column Value Length: 1
2024-04-24T08:23:58,788  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Closing record writer for alias: test3
2024-04-24T08:23:58,789  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 1,  Compr Total Column Value Length: 1
2024-04-24T08:23:58,789  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 1,  Compr Total Column Value Length: 1
2024-04-24T08:23:58,789  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#2 : Plain Total Column Value Length: 5,  Compr Total Column Value Length: 5
2024-04-24T08:23:58,797  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1578056862_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T08:23:58,797  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,797  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,802  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T08:23:58,802  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1578056862_0001_m_000000_0 is allowed to commit now
2024-04-24T08:23:58,802  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,802  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,807  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling commitTask for alias: test1
2024-04-24T08:23:58,807  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,807  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1578056862_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test1/_SCRATCH0,797077453758776/ds=1/cluster=ag
2024-04-24T08:23:58,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,822  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,828  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling commitTask for alias: test2
2024-04-24T08:23:58,828  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,828  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,842  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1578056862_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test2/_SCRATCH0,5064709258691442/ds=1/cluster=ag
2024-04-24T08:23:58,842  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,842  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,848  INFO [LocalJobRunner Map Task Executor #0] mapreduce.MultiOutputFormat: Calling commitTask for alias: test3
2024-04-24T08:23:58,848  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T08:23:58,848  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T08:23:58,861  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1578056862_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/38735/test3/_SCRATCH0,07318963685043711/ds=1/cluster=ag
2024-04-24T08:23:58,862  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T08:23:58,862  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1578056862_0001_m_000000_0' done.
2024-04-24T08:23:58,864  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1578056862_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2269534
		FILE: Number of bytes written=3493806
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Input split bytes=179
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=772800512
	File Input Format Counters 
		Bytes Read=28
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:23:58,864  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1578056862_0001_m_000000_0
2024-04-24T08:23:58,865  INFO [Thread-378] mapred.LocalJobRunner: map task executor complete.
2024-04-24T08:23:58,866  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling commitJob for alias: test1
2024-04-24T08:23:58,914  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:58,914  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:58,915  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:58,916  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:58,916  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:58,916  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:58,916  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:58,917  INFO [Thread-378] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:23:58,917  INFO [Thread-378] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:38735]
2024-04-24T08:23:58,917  INFO [Thread-378] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:38735)
2024-04-24T08:23:58,918  INFO [Thread-378] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:38735) current connections: 2
2024-04-24T08:23:58,918  INFO [Thread-378] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=3 delay=1 lifetime=0
2024-04-24T08:23:58,919  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:58,920  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:23:58,920  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:23:58,920  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3418751e, with PersistenceManager: null will be shutdown
2024-04-24T08:23:58,920  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3418751e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be4b662 created in the thread with id: 501
2024-04-24T08:23:58,924  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3418751e from thread id: 501
2024-04-24T08:23:58,990  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:58,990  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:58,991  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:58,992  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table test1 has new partitions [{cluster=ag, ds=1}].
2024-04-24T08:23:59,025  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.default.test1[1,ag]	
2024-04-24T08:23:59,049  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2024-04-24T08:23:59,050  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=add_partitions	
2024-04-24T08:23:59,070  INFO [HMSHandler #0] utils.MetaStoreServerUtils: Updating partition stats fast for: test1
2024-04-24T08:23:59,078  INFO [HMSHandler #0] utils.MetaStoreServerUtils: Updated size to 79
2024-04-24T08:23:59,196  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:59,233  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:59,234  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:59,234  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:59,234  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:59,236  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T08:23:59,236  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling commitJob for alias: test2
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:59,277  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:59,278  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:59,278  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:59,278  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:59,278  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:59,278  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:59,278  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:59,278  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:59,292  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table test2 has new partitions [{cluster=ag, ds=1}].
2024-04-24T08:23:59,315  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.default.test2[1,ag]	
2024-04-24T08:23:59,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2024-04-24T08:23:59,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=add_partitions	
2024-04-24T08:23:59,333  INFO [HMSHandler #1] utils.MetaStoreServerUtils: Updating partition stats fast for: test2
2024-04-24T08:23:59,340  INFO [HMSHandler #1] utils.MetaStoreServerUtils: Updated size to 74
2024-04-24T08:23:59,372  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T08:23:59,404  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:59,404  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:59,404  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:59,404  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:59,405  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:59,405  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:59,406  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:59,407  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T08:23:59,407  INFO [Thread-378] mapreduce.MultiOutputFormat: Calling commitJob for alias: test3
2024-04-24T08:23:59,446  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:59,446  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:59,446  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:59,446  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:59,447  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:59,447  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:59,448  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:59,460  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table test3 has new partitions [{cluster=ag, ds=1}].
2024-04-24T08:23:59,461  INFO [main] mapreduce.Job: Job job_local1578056862_0001 running in uber mode : false
2024-04-24T08:23:59,462  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T08:23:59,483  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.default.test3[1,ag]	
2024-04-24T08:23:59,486  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2024-04-24T08:23:59,487  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=add_partitions	
2024-04-24T08:23:59,497  INFO [HMSHandler #2] utils.MetaStoreServerUtils: Updating partition stats fast for: test3
2024-04-24T08:23:59,504  INFO [HMSHandler #2] utils.MetaStoreServerUtils: Updated size to 88
2024-04-24T08:23:59,534  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:23:59,565  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:23:59,566  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:23:59,566  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:23:59,566  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:23:59,566  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:23:59,566  WARN [Thread-378] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:23:59,566  INFO [Thread-378] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:23:59,567  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:23:59,568  INFO [Thread-378] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T08:24:00,465  INFO [main] mapreduce.Job: Job job_local1578056862_0001 completed successfully
2024-04-24T08:24:00,482  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2269534
		FILE: Number of bytes written=3493806
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Input split bytes=179
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=772800512
	File Input Format Counters 
		Bytes Read=28
	File Output Format Counters 
		Bytes Written=0
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:24:00,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:24:00,540  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:24:00,540  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:24:00,540  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:24:00,540  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:24:01,252  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,256  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,260  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,260  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,260  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,262  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,262  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T08:24:01,323  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:24:01,323  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:38735]
2024-04-24T08:24:01,323  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:38735)
2024-04-24T08:24:01,324  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:38735) current connections: 3
2024-04-24T08:24:01,331  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T08:24:01,355  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_functions	
2024-04-24T08:24:01,356  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:24:01,356  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:24:01,357  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b7f1626, with PersistenceManager: null will be shutdown
2024-04-24T08:24:01,357  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b7f1626, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1a1cc898 created in the thread with id: 571
2024-04-24T08:24:01,361  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b7f1626 from thread id: 571
2024-04-24T08:24:01,382  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test1	
2024-04-24T08:24:01,395  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:24:01,403  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_with_auth : tbl=hive.default.test1	
2024-04-24T08:24:01,514  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[0]
2024-04-24T08:24:01,535  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T08:24:01,552  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[0]
2024-04-24T08:24:01,552  INFO [main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_0:1, 
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:24:01,589  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:24:01,590  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:24:01,590  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:24:01,590  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:24:01,590  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:24:01,600  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test2	
2024-04-24T08:24:01,606  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:24:01,607  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_with_auth : tbl=hive.default.test2	
2024-04-24T08:24:01,618  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[0]
2024-04-24T08:24:01,625  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T08:24:01,629  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[0]
2024-04-24T08:24:01,629  INFO [main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_0:1, 
2024-04-24T08:24:01,666  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:24:01,666  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:24:01,667  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:24:01,678  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.test3	
2024-04-24T08:24:01,688  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:24:01,689  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_with_auth : tbl=hive.default.test3	
2024-04-24T08:24:01,699  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[0]
2024-04-24T08:24:01,706  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T08:24:01,710  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[0]
2024-04-24T08:24:01,711  INFO [main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_0:1, 
2024-04-24T08:24:01,742  INFO [main] mapreduce.TestHCatMultiOutputFormat: File permissions verified
2024-04-24T08:24:01,779 ERROR [Thread[Thread-282,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:24:01,784  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T08:24:01,789  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T08:24:01,789 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T08:24:01,790  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:24:01,790  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T08:24:01,791  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:24:01,791  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:24:01,791 ERROR [Thread[Thread-105,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:24:01,791  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T08:24:01,791  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:24:01,796  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T08:24:01,796  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T08:24:01,797 ERROR [Thread[Thread-79,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:24:01,813  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 2
2024-04-24T08:24:01,813  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T08:24:01,813  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61cd194a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cb1fa61 will be shutdown
2024-04-24T08:24:01,813  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T08:24:01,813  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T08:24:01,814  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3418751e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5be4b662 will be shutdown
2024-04-24T08:24:01,814  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:24:01,814  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T08:24:01,814  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
