SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,108601 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@79e4c792]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@79e4c792) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@3e08ff24
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@740fb309
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,019515 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 1651233823
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-23T18:04:39.214-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/23-18:04:41.202, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=2024/04/23-00:00:00.000, current=2024/04/23-18:04:41.203, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@740fb309 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@740fb309
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@740fb309 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@6913c1fb...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@6913c1fb OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@70ab2d48
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@79e4c792
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@79e4c792) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@79e4c792] started OK.
2024-04-23T18:04:41,306  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-23T18:04:41,853  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-23T18:04:41,941  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T18:04:41,941  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T18:04:41,942  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T18:04:41,942  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T18:04:41,942  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T18:04:41,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T18:04:41,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T18:04:41,946  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T18:04:41,946  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T18:04:41,947  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T18:04:41,947  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T18:04:41,983  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-23T18:04:42,856  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/ql/target/tmp/junit_metastore_db_35919;create=true
2024-04-23T18:04:43,893  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-23T18:04:43,981  INFO [MetaStoreThread-35919] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
2024-04-23T18:04:44,111  INFO [MetaStoreThread-35919] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:44,155  INFO [MetaStoreThread-35919] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:44,161  INFO [MetaStoreThread-35919] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-23T18:04:44,161  INFO [MetaStoreThread-35919] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-23T18:04:44,186  WARN [MetaStoreThread-35919] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T18:04:44,192  INFO [MetaStoreThread-35919] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-23T18:04:44,213  INFO [MetaStoreThread-35919] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T18:04:44,217  INFO [MetaStoreThread-35919] hikari.HikariDataSource: HikariPool-1 - Start completed.
log4j: Trying to find [log4j.xml] using context classloader sun.misc.Launcher$AppClassLoader@7f31245a.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@7f31245a class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader sun.misc.Launcher$AppClassLoader@7f31245a.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@7f31245a class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (DataNucleus.General).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-23T18:04:44,863  INFO [MetaStoreThread-35919] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-23T18:04:44,864  INFO [MetaStoreThread-35919] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@353fd354, with PersistenceManager: null will be shutdown
2024-04-23T18:04:44,894  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-23T18:04:44,916  INFO [MetaStoreThread-35919] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@353fd354, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@639f35b5 created in the thread with id: 17
2024-04-23T18:04:45,895  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-23T18:04:46,895  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-23T18:04:47,564  INFO [MetaStoreThread-35919] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@353fd354 from thread id: 17
2024-04-23T18:04:47,577  INFO [MetaStoreThread-35919] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-23T18:04:47,896  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-23T18:04:47,955  INFO [MetaStoreThread-35919] metastore.HMSHandler: Started creating a default database with name: default
2024-04-23T18:04:48,018  INFO [MetaStoreThread-35919] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-23T18:04:48,036  INFO [MetaStoreThread-35919] metastore.HMSHandler: Added admin role in metastore
2024-04-23T18:04:48,039  INFO [MetaStoreThread-35919] metastore.HMSHandler: Added public role in metastore
2024-04-23T18:04:48,126  INFO [MetaStoreThread-35919] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-23T18:04:48,134  INFO [MetaStoreThread-35919] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T18:04:48,333  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2024-04-23T18:04:48,338  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Started the new metaserver on port [35919]...
2024-04-23T18:04:48,338  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2024-04-23T18:04:48,338  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2024-04-23T18:04:48,338  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: TCP keepalive = true
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Enable SSL = false
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Compaction HMS parameters:
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.initiator.on = false
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.worker.threads = 0
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: hive.metastore.runworker.in = metastore
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.history.retention.attempted = 2
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.history.retention.failed = 3
2024-04-23T18:04:48,339  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.history.retention.succeeded = 3
2024-04-23T18:04:48,340  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.initiator.failed.compacts.threshold = 2
2024-04-23T18:04:48,340  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: metastore.compactor.enable.stats.compression
2024-04-23T18:04:48,340  WARN [MetaStoreThread-35919] metastore.HiveMetaStore: Compactor Initiator is turned Off. Automatic compaction will not be triggered.
2024-04-23T18:04:48,340  WARN [MetaStoreThread-35919] metastore.HiveMetaStore: Invalid number of Compactor Worker threads(0) on HMS
2024-04-23T18:04:48,340  INFO [MetaStoreThread-35919] metastore.HiveMetaStore: Direct SQL optimization = true
2024-04-23T18:04:48,915  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:48,934  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919) is created
2024-04-23T18:04:48,935  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 35919 with warehouse dir: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919 with jdbcUrl: jdbc:derby:memory:/home/alex/Repositories/hive/ql/target/tmp/junit_metastore_db_35919;create=true
Hive Session ID = 5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:48,960  INFO [main] SessionState: Hive Session ID = 5f10ac28-ec81-408e-b819-6040e6f910ab
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:48,974  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:49,032  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:49,036  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:49,040  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:49,498  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,503  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,507  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,507  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,507  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,509  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,509  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T18:04:49,567  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:49,568  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:49,569  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:49,585  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:49,611  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:49,644  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_functions	
2024-04-23T18:04:49,646  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:49,646  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:49,648  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2245886b, with PersistenceManager: null will be shutdown
2024-04-23T18:04:49,649  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2245886b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49cc3963 created in the thread with id: 33
2024-04-23T18:04:49,658  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2245886b from thread id: 33
2024-04-23T18:04:49,688  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testtable	
2024-04-23T18:04:49,724  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:49,726  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-23T18:04:49,730  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:49,731  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:49,731  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2245886b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49cc3963 will be shutdown
2024-04-23T18:04:49,731  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:49,732  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:49,732  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:49,732  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:49,732  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:49,733  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:49,734  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:49,784  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:49,784  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:49,784  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:49,785  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 2
2024-04-23T18:04:49,786  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:49,795  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table_for_testtable, dbName:default, owner:pchakka, createTime:1713920689, lastAccessTime:0, retention:10, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:int, comment:int -- first column), FieldSchema(name:col2, type:string, comment:string -- second column), FieldSchema(name:col3, type:double, comment:double -- thrift column)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:512, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{mapkey.delim=3, serialization.format=1, collection.delim=2, line.delim=
, field.delim=1}), bucketCols:[col1], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:ds, type:string, comment:partition column, date but in string format as date type is not yet supported in QL)], parameters:{bucketing_version=2, comment=this is a test table created as part junit tests}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false, catName:hive, ownerType:USER)	
2024-04-23T18:04:49,796  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:49,797  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:49,798  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b5f8146, with PersistenceManager: null will be shutdown
2024-04-23T18:04:49,799  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b5f8146, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a0eba82 created in the thread with id: 36
2024-04-23T18:04:49,805  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b5f8146 from thread id: 36
2024-04-23T18:04:49,816  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testtable
2024-04-23T18:04:49,931  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testtable	
2024-04-23T18:04:50,026  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:50,037  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: default	
2024-04-23T18:04:50,041  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testtable	
2024-04-23T18:04:50,054  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:50,059  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.table_for_testtable	
2024-04-23T18:04:50,299  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testtable	
2024-04-23T18:04:50,305  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:50,305  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:50,307  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-23T18:04:50,307  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:50,307  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b5f8146, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a0eba82 will be shutdown
2024-04-23T18:04:50,307  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:50,308  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:50,312  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:50,321  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:50,325  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:50,329  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:50,331  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,333  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:50,333  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:50,335  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73414a6a, with PersistenceManager: null will be shutdown
2024-04-23T18:04:50,336  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73414a6a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42f89f7e created in the thread with id: 35
2024-04-23T18:04:50,342  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73414a6a from thread id: 35
2024-04-23T18:04:50,346  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:50,349  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table_for_testpartition, dbName:default, owner:alex, createTime:1713920690, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:hr, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
2024-04-23T18:04:50,354  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition
2024-04-23T18:04:50,386  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,404  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:50,411  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,434  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition/ds=2008-04-08/hr=12
2024-04-23T18:04:50,466  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,476  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition/ds=2008-04-08/hr=13
2024-04-23T18:04:50,491  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,501  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition/ds=2008-04-08/hr=14
2024-04-23T18:04:50,515  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,526  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition/ds=2008-04-07/hr=12
2024-04-23T18:04:50,544  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,555  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testpartition/ds=2008-04-07/hr=13
2024-04-23T18:04:50,573  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,648  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_with_auth : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,715  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_with_auth : tbl=hive.default.table_for_testpartition[2008-04-07,12]	
2024-04-23T18:04:50,810  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_spec_by_expr : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:50,839  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PartFilterExprUtil: Unable to make the expression tree from expression string [(true and true)]Error parsing partition filter; lexer error: null; exception NoViableAltException(15@[])
2024-04-23T18:04:50,902  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T18:04:50,903  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T18:04:50,903  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T18:04:50,903  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T18:04:50,903  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T18:04:50,903  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T18:04:50,904  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T18:04:50,904  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T18:04:50,904  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T18:04:50,904  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T18:04:50,904  WARN [TThreadPoolServer WorkerProcess-%d] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T18:04:50,978  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_ps_with_auth : tbl=hive.default.table_for_testpartition[2008-04-07,]	
2024-04-23T18:04:51,011  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_ps_with_auth : tbl=hive.default.table_for_testpartition[2008-04-08,]	
2024-04-23T18:04:51,049  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_ps_with_auth : tbl=hive.default.table_for_testpartition[,13]	
2024-04-23T18:04:51,082  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_ps_with_auth : tbl=hive.default.table_for_testpartition[,]	
2024-04-23T18:04:51,087  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Redirecting to directSQL enabled API: db: default tbl: table_for_testpartition partVals: ,
2024-04-23T18:04:51,097  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_ps_with_auth : tbl=hive.default.table_for_testpartition[,14]	
2024-04-23T18:04:51,125  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:51,132  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:51,134  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.table_for_testpartition	
2024-04-23T18:04:51,231  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:51,231  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:51,232  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:51,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:51,232  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@73414a6a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@42f89f7e will be shutdown
2024-04-23T18:04:51,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:51,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,233  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,240  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,243  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,247  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:51,248  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:51,248  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,250  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,258  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,261  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,264  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:51,265  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:51,265  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:51,265  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:51,266  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:51,267  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:51,268  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions	
2024-04-23T18:04:51,270  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:51,270  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:51,271  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e7167d2, with PersistenceManager: null will be shutdown
2024-04-23T18:04:51,271  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e7167d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f055fd2 created in the thread with id: 60
2024-04-23T18:04:51,301  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e7167d2 from thread id: 60
2024-04-23T18:04:51,305  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:51,306  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table_for_testAutoPurgeTablesAndPartitions, dbName:default, owner:alex, createTime:1713920691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:hr, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
2024-04-23T18:04:51,309  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testautopurgetablesandpartitions
2024-04-23T18:04:51,343  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions	
2024-04-23T18:04:51,352  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:51,353  WARN [main] metadata.Hive: Cannot get a table snapshot for table_for_testAutoPurgeTablesAndPartitions
2024-04-23T18:04:51,360  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.default.table_for_testAutoPurgeTablesAndPartitions newtbl=table_for_testautopurgetablesandpartitions	
2024-04-23T18:04:51,384  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2024-04-23T18:04:51,444  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testautopurgetablesandpartitions	
2024-04-23T18:04:51,457  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testautopurgetablesandpartitions/ds=20141216/hr=12
2024-04-23T18:04:51,478  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_with_auth : tbl=hive.default.table_for_testautopurgetablesandpartitions[20141216,12]	
2024-04-23T18:04:51,505  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_partition : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions[20141216,12]	
2024-04-23T18:04:51,505  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Partition values:[20141216, 12]
2024-04-23T18:04:51,577  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will purge pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testautopurgetablesandpartitions/ds=20141216/hr=12 directly, skipping trash.
2024-04-23T18:04:51,581  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions	
2024-04-23T18:04:51,594  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:51,595  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions	
2024-04-23T18:04:51,715  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testAutoPurgeTablesAndPartitions	
2024-04-23T18:04:51,719  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:51,720  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:51,720  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:51,721  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:51,721  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e7167d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f055fd2 will be shutdown
2024-04-23T18:04:51,721  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,722  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:51,722  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:51,729  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,734  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:51,738  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:51,739  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:51,739  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:51,739  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:51,739  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:51,743  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:51,743  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: db_for_testgettables	
2024-04-23T18:04:51,744  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:51,744  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:51,745  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@417ba51e, with PersistenceManager: null will be shutdown
2024-04-23T18:04:51,745  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@417ba51e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69cffcff created in the thread with id: 68
2024-04-23T18:04:51,749  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@417ba51e from thread id: 68
2024-04-23T18:04:51,757  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:db_for_testgettables, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-23T18:04:51,764  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db
2024-04-23T18:04:51,764  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db
2024-04-23T18:04:51,767  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db
2024-04-23T18:04:51,772  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:51,790  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table1, dbName:db_for_testgettables, owner:alex, createTime:1713920691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:aint, type:int, comment:from deserializer), FieldSchema(name:astring, type:string, comment:from deserializer), FieldSchema(name:lint, type:array<int>, comment:from deserializer), FieldSchema(name:lstring, type:array<string>, comment:from deserializer), FieldSchema(name:lintstring, type:array<struct<myint:int,mystring:string,underscore_int:int>>, comment:from deserializer), FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), FieldSchema(name:attributes, type:map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>, comment:from deserializer), FieldSchema(name:unionfield1, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield2, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield3, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer, parameters:{serialization.format=org.apache.thrift.protocol.TBinaryProtocol, serialization.class=org.apache.hadoop.hive.serde2.thrift.test.Complex}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
2024-04-23T18:04:51,795  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db/table1
2024-04-23T18:04:51,822  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table2, dbName:db_for_testgettables, owner:alex, createTime:1713920691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:aint, type:int, comment:from deserializer), FieldSchema(name:astring, type:string, comment:from deserializer), FieldSchema(name:lint, type:array<int>, comment:from deserializer), FieldSchema(name:lstring, type:array<string>, comment:from deserializer), FieldSchema(name:lintstring, type:array<struct<myint:int,mystring:string,underscore_int:int>>, comment:from deserializer), FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), FieldSchema(name:attributes, type:map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>, comment:from deserializer), FieldSchema(name:unionfield1, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield2, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield3, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer, parameters:{serialization.format=org.apache.thrift.protocol.TBinaryProtocol, serialization.class=org.apache.hadoop.hive.serde2.thrift.test.Complex}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
2024-04-23T18:04:51,827  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db/table2
2024-04-23T18:04:51,859  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=db_for_testgettables tbls=null	
2024-04-23T18:04:51,926  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=db_for_testgettables tbls=null	
2024-04-23T18:04:51,931  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.db_for_testgettables.table1	
2024-04-23T18:04:51,941  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:51,945  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.db_for_testgettables.table1	
2024-04-23T18:04:51,955  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:51,956  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.db_for_testgettables.table1	
2024-04-23T18:04:51,990  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=db_for_testgettables tbls=null	
2024-04-23T18:04:51,993  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.db_for_testgettables.table2	
2024-04-23T18:04:52,000  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:52,001  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.db_for_testgettables.table2	
2024-04-23T18:04:52,008  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:52,009  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.db_for_testgettables.table2	
2024-04-23T18:04:52,046  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: db_for_testgettables	
2024-04-23T18:04:52,054  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#db_for_testgettables	
2024-04-23T18:04:52,054  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#db_for_testgettables	
2024-04-23T18:04:52,058  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#db_for_testgettables pat=*	
2024-04-23T18:04:52,064  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-23T18:04:52,090  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-23T18:04:52,134  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=db_for_testgettables pat=.*,type=MATERIALIZED_VIEW	
2024-04-23T18:04:52,138  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.db_for_testgettables along with all tables
2024-04-23T18:04:52,196  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T18:04:52,198  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-23T18:04:52,199  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T18:04:52,200  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-23T18:04:52,202  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T18:04:52,203  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-23T18:04:52,204  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T18:04:52,205  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-23T18:04:52,230  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db does not exist; Force to delete it.
2024-04-23T18:04:52,230 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/db_for_testgettables.db
2024-04-23T18:04:52,233  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,233  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,233  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:52,234  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:52,234  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@417ba51e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69cffcff will be shutdown
2024-04-23T18:04:52,234  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,234  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,235  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,242  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,244  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,248  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:52,249  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:52,249  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:52,249  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:52,250  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:52,250  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:52,252  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_test_thrifttable	
2024-04-23T18:04:52,252  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:52,253  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:52,253  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dea8c54, with PersistenceManager: null will be shutdown
2024-04-23T18:04:52,254  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dea8c54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45a03b3b created in the thread with id: 84
2024-04-23T18:04:52,268  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dea8c54 from thread id: 84
2024-04-23T18:04:52,271  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:52,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table_for_test_thrifttable, dbName:default, owner:alex, createTime:1713920692, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:aint, type:int, comment:from deserializer), FieldSchema(name:astring, type:string, comment:from deserializer), FieldSchema(name:lint, type:array<int>, comment:from deserializer), FieldSchema(name:lstring, type:array<string>, comment:from deserializer), FieldSchema(name:lintstring, type:array<struct<myint:int,mystring:string,underscore_int:int>>, comment:from deserializer), FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), FieldSchema(name:attributes, type:map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>>, comment:from deserializer), FieldSchema(name:unionfield1, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield2, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer), FieldSchema(name:unionfield3, type:uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>, comment:from deserializer)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer, parameters:{serialization.format=org.apache.thrift.protocol.TBinaryProtocol, serialization.class=org.apache.hadoop.hive.serde2.thrift.test.Complex}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false, catName:hive, ownerType:USER)	
2024-04-23T18:04:52,277  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_test_thrifttable
2024-04-23T18:04:52,294  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_test_thrifttable	
2024-04-23T18:04:52,351  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:52,355  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: default	
2024-04-23T18:04:52,357  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_test_thrifttable	
2024-04-23T18:04:52,363  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:52,364  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.table_for_test_thrifttable	
2024-04-23T18:04:52,400  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,400  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,400  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:52,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:52,401  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3dea8c54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45a03b3b will be shutdown
2024-04-23T18:04:52,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,402  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,409  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,411  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,414  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
DEBUG StatusLogger Starting StringOutputStreamManager StringStream
2024-04-23T18:04:52,419  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:52,419  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:52,419  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:52,420  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:52,421  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:52,428  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#	
2024-04-23T18:04:52,428  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:52,429  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:52,429  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd10fbd, with PersistenceManager: null will be shutdown
2024-04-23T18:04:52,429  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd10fbd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d477569 created in the thread with id: 99
2024-04-23T18:04:52,433  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd10fbd from thread id: 99
2024-04-23T18:04:52,438  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:52,438  INFO [main] metadata.Hive: Dumping metastore api call timing information for : test phase
2024-04-23T18:04:52,438  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getAllDatabases_()=17}
2024-04-23T18:04:52,438  INFO [main] metadata.Hive: Dumping metastore api call timing information for : test phase
2024-04-23T18:04:52,438  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T18:04:52,441  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,441  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,441  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:52,442  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:52,442  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cd10fbd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d477569 will be shutdown
2024-04-23T18:04:52,442  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,442  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,442  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,449  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,452  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,456  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:52,457  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:52,457  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:52,457  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:52,457  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:52,458  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:52,459  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: default	
2024-04-23T18:04:52,459  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:52,460  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:52,460  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4aeed313, with PersistenceManager: null will be shutdown
2024-04-23T18:04:52,460  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4aeed313, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bee182e created in the thread with id: 104
2024-04-23T18:04:52,464  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4aeed313 from thread id: 104
2024-04-23T18:04:52,466  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:52,466  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:52,466  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4aeed313, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bee182e will be shutdown
2024-04-23T18:04:52,467  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,467  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,467  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:52,467  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:52,467  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:52,468  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 1
2024-04-23T18:04:52,468  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:52,469  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: default	
2024-04-23T18:04:52,470  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:52,470  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:52,470  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31945a4d, with PersistenceManager: null will be shutdown
2024-04-23T18:04:52,470  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31945a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f0884 created in the thread with id: 105
2024-04-23T18:04:52,474  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31945a4d from thread id: 105
2024-04-23T18:04:52,475  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.connect.retries changed from 3 to 4
2024-04-23T18:04:52,476  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 0
2024-04-23T18:04:52,476  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:52,476  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@31945a4d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f0884 will be shutdown
2024-04-23T18:04:52,476  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,476  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:52,477  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:52,477  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,478  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,485  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,488  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:52,491  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T18:04:52,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T18:04:52,538  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T18:04:52,538  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T18:04:52,538  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T18:04:52,538  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T18:04:52,538  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = a863e843-e6c1-454a-ac3e-883b76f8e9d0
2024-04-23T18:04:52,539  INFO [main] SessionState: Hive Session ID = a863e843-e6c1-454a-ac3e-883b76f8e9d0
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,539  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,546  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/a863e843-e6c1-454a-ac3e-883b76f8e9d0
2024-04-23T18:04:52,549  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/a863e843-e6c1-454a-ac3e-883b76f8e9d0
2024-04-23T18:04:52,552  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/a863e843-e6c1-454a-ac3e-883b76f8e9d0/_tmp_space.db
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T18:04:52,592  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T18:04:52,593  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T18:04:52,593  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T18:04:52,593  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T18:04:52,593  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T18:04:52,593  WARN [Thread-93] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 7f5b0e57-4b7c-4541-a822-cd98328c1920
2024-04-23T18:04:52,594  INFO [Thread-93] SessionState: Hive Session ID = 7f5b0e57-4b7c-4541-a822-cd98328c1920
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,594  INFO [Thread-93] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:52,601  INFO [Thread-93] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7f5b0e57-4b7c-4541-a822-cd98328c1920
2024-04-23T18:04:52,604  INFO [Thread-93] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/7f5b0e57-4b7c-4541-a822-cd98328c1920
2024-04-23T18:04:52,606  INFO [Thread-93] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7f5b0e57-4b7c-4541-a822-cd98328c1920/_tmp_space.db
2024-04-23T18:04:52,608  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:52,609  INFO [main] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:52,609  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:52,609  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-23T18:04:52,615  WARN [main] hikari.HikariConfig: HikariPool-4 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T18:04:52,617  INFO [main] hikari.HikariDataSource: HikariPool-4 - Starting...
2024-04-23T18:04:52,673  INFO [main] pool.PoolBase: HikariPool-4 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T18:04:52,673  INFO [main] hikari.HikariDataSource: HikariPool-4 - Start completed.
2024-04-23T18:04:53,192  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-23T18:04:53,192  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976, with PersistenceManager: null will be shutdown
2024-04-23T18:04:53,192  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5438c17a created in the thread with id: 1
2024-04-23T18:04:54,082  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976 from thread id: 1
2024-04-23T18:04:54,129  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-23T18:04:54,144  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-23T18:04:54,167  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-23T18:04:54,168  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-23T18:04:54,223  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-23T18:04:54,223  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T18:04:54,224  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:54,272  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:54,273  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:54,273  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5438c17a will be shutdown
2024-04-23T18:04:54,274  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@675b18ff created in the thread with id: 1
2024-04-23T18:04:54,282  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T18:04:54,282  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:54,312 ERROR [main] metastore.RetryingHMSHandler: InvalidOperationException(message:Resource plan must be disabled to edit it.)
	at org.apache.hadoop.hive.metastore.ObjectStore.getMWMResourcePlan(ObjectStore.java:13224)
	at org.apache.hadoop.hive.metastore.ObjectStore.getMWMResourcePlan(ObjectStore.java:13200)
	at org.apache.hadoop.hive.metastore.ObjectStore.createPool(ObjectStore.java:13806)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy37.createPool(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_wm_pool(HMSHandler.java:9916)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy39.create_wm_pool(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createWMPool(HiveMetaStoreClient.java:4706)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:218)
	at com.sun.proxy.$Proxy48.createWMPool(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.createWMPool(Hive.java:6358)
	at org.apache.hadoop.hive.ql.metadata.TestHive.testWmNamespaceHandling(TestHive.java:494)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T18:04:54,344  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/a863e843-e6c1-454a-ac3e-883b76f8e9d0 on fs with scheme file
2024-04-23T18:04:54,344  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/a863e843-e6c1-454a-ac3e-883b76f8e9d0 on fs with scheme file
2024-04-23T18:04:54,350  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:54,350  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@54336976, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@675b18ff will be shutdown
2024-04-23T18:04:54,350  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:54,350  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:54,352  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:54,358  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T18:04:54,358  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:35919]
2024-04-23T18:04:54,359  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:35919)
2024-04-23T18:04:54,359  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:35919) current connections: 0
2024-04-23T18:04:54,360  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T18:04:54,361  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testDropPartitionsWithPurge	
2024-04-23T18:04:54,361  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T18:04:54,362  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T18:04:54,363  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-23T18:04:54,366  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-5 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T18:04:54,368  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-5 - Starting...
2024-04-23T18:04:54,369  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-5 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T18:04:54,370  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-5 - Start completed.
2024-04-23T18:04:54,864  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-23T18:04:54,865  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74d9e583, with PersistenceManager: null will be shutdown
2024-04-23T18:04:54,865  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74d9e583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6be4e865 created in the thread with id: 127
2024-04-23T18:04:55,392  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74d9e583 from thread id: 127
2024-04-23T18:04:55,400  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f10ac28-ec81-408e-b819-6040e6f910ab, clientType=HIVECLI]
2024-04-23T18:04:55,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:table_for_testDropPartitionsWithPurge, dbName:default, owner:alex, createTime:1713920695, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:hr, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
2024-04-23T18:04:55,405  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testdroppartitionswithpurge
2024-04-23T18:04:55,444  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testDropPartitionsWithPurge	
2024-04-23T18:04:55,459  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:55,460  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testdroppartitionswithpurge	
2024-04-23T18:04:55,474  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testdroppartitionswithpurge/ds=20141216/hr=12
2024-04-23T18:04:55,494  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_with_auth : tbl=hive.default.table_for_testdroppartitionswithpurge[20141216,12]	
2024-04-23T18:04:55,513  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_partition : tbl=hive.default.table_for_testDropPartitionsWithPurge[20141216,12]	
2024-04-23T18:04:55,514  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Partition values:[20141216, 12]
2024-04-23T18:04:55,604  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will purge pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testdroppartitionswithpurge/ds=20141216/hr=12 directly, skipping trash.
2024-04-23T18:04:55,606  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.default.table_for_testdroppartitionswithpurge	
2024-04-23T18:04:55,611  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testdroppartitionswithpurge/ds=20141216/hr=12
2024-04-23T18:04:55,623  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_with_auth : tbl=hive.default.table_for_testdroppartitionswithpurge[20141216,12]	
2024-04-23T18:04:55,630  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_partition : tbl=hive.default.table_for_testDropPartitionsWithPurge[20141216,12]	
2024-04-23T18:04:55,630  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Partition values:[20141216, 12]
2024-04-23T18:04:55,653  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move pfile:/home/alex/Repositories/hive/ql/target/warehouse/35919/table_for_testdroppartitionswithpurge/ds=20141216/hr=12 to trash-directory.
2024-04-23T18:04:55,662  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.table_for_testDropPartitionsWithPurge	
2024-04-23T18:04:55,670  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T18:04:55,671  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.table_for_testDropPartitionsWithPurge	
2024-04-23T18:04:55,788  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:55,788  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:55,788  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-23T18:04:55,788  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-23T18:04:55,788  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74d9e583, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6be4e865 will be shutdown
2024-04-23T18:04:55,789  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-23T18:04:55,789  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:55,789  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T18:04:55,795  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:55,799  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab
2024-04-23T18:04:55,802  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab/_tmp_space.db
2024-04-23T18:04:55,803  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
2024-04-23T18:04:55,803  INFO [main] cleanup.SyncCleanupService: Deleted directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/5f10ac28-ec81-408e-b819-6040e6f910ab on fs with scheme file
