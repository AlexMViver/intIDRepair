SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,109083 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@446a1e84]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@446a1e84) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@2d29b4ee
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,033724 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Configuration(HiveLog4j2Test), disableAnsi="null", header="null", Replace=null, pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", alwaysWriteExceptions="null", PatternSelector=null, noConsoleNoAnsi="null", charset="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", target="SYSTEM_ERR", direct="null", immediateFlush="null", bufferedIo="null", bufferSize="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", Configuration(HiveLog4j2Test), name="console", Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, PatternSelector=null, header="null", charset="null", noConsoleNoAnsi="null", alwaysWriteExceptions="null", footer="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", disableAnsi="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", maxRandomDelay="null", modulate="true")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(={}, max="30", tempCompressedFilePattern="null", fileIndex="null", min="null", Configuration(HiveLog4j2Test), compressionLevel="null", stopCustomActionsOnError="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(advertise="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), filePermissions="null", fileGroup="null", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", fileOwner="null", fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", append="null", advertiseURI="null", bufferSize="null", bufferedIo="null", immediateFlush="null", ignoreExceptions="null", Configuration(HiveLog4j2Test), name="DRFA", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 12598744775
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T07:36:46.907-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-07:36:49.295, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-07:36:49.296, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@49dc7102...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@49dc7102 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7096b474
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@446a1e84
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@446a1e84) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@446a1e84] started OK.
2024-04-24T07:36:49,471  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T07:36:50,046  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T07:36:50,118  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:36:50,119  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:36:50,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:36:50,120  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:36:50,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:36:50,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:36:50,121  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:36:50,121  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:36:50,122  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:36:50,122  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:36:50,123  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
Hive Session ID = 2c716b75-5e58-470e-bb13-1b77168fbc0a
2024-04-24T07:36:50,197  INFO [main] SessionState: Hive Session ID = 2c716b75-5e58-470e-bb13-1b77168fbc0a
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:50,214  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:50,649  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/2c716b75-5e58-470e-bb13-1b77168fbc0a
2024-04-24T07:36:50,653  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/2c716b75-5e58-470e-bb13-1b77168fbc0a
2024-04-24T07:36:50,657  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/2c716b75-5e58-470e-bb13-1b77168fbc0a/_tmp_space.db
2024-04-24T07:36:50,690  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2c716b75-5e58-470e-bb13-1b77168fbc0a, clientType=HIVESERVER2]
2024-04-24T07:36:50,764  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:51,058  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:51,106  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:51,114  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T07:36:51,115  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T07:36:51,147  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:51,155  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T07:36:52,135  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:52,140  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T07:36:53,026  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T07:36:53,026  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791, with PersistenceManager: null will be shutdown
2024-04-24T07:36:53,058  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@267dc982 created in the thread with id: 1
2024-04-24T07:36:57,186  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T07:36:57,186  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T07:36:57,186  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791 from thread id: 1
2024-04-24T07:36:57,387  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T07:36:57,438  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T07:36:57,492  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T07:36:57,495  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T07:36:57,679  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T07:36:57,687  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T07:36:57,688  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T07:36:57,689  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T07:36:57,693  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T07:36:57,694  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T07:36:57,724  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:57,729  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T07:36:57,732  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:57,732  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T07:36:57,735  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:57,739  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T07:36:57,742  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:57,743  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T07:36:57,751  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T07:36:57,755  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:58,055  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:58,891  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,891  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,893  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,895  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,912  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,916  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:58,920  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:59,015  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs
2024-04-24T07:36:59,018  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:36:59,018  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:36:59,018  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:36:59,019  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:36:59,022  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-04-24T07:36:59,030  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-04-24T07:36:59,053  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:36:59,053  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:36:59,054  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:36:59,054  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:36:59,055  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:36:59,056  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:36:59,085  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:36:59,093  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [user1] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:59,118  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:59,137  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:36:59,142  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:36:59,147  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/8cd46240-8da4-4d0f-865c-ecb5bceed17c/_tmp_space.db
2024-04-24T07:36:59,152  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:36:59,152  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:36:59,156  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:59,157  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:59,159  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@267dc982 will be shutdown
2024-04-24T07:36:59,161  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6dae70f9 created in the thread with id: 1
2024-04-24T07:36:59,194  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:59,195  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=user1 (auth:PROXY) via alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:59,199  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T07:36:59,310  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:59,310  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@333c8791, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6dae70f9 will be shutdown
2024-04-24T07:36:59,311  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:59,311  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T07:36:59,313  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:36:59,318  INFO [main] service.CompositeService: Session opened, SessionHandle [8cd46240-8da4-4d0f-865c-ecb5bceed17c], current sessions:1
2024-04-24T07:36:59,326  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : user1
2024-04-24T07:36:59,338  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] session.HiveSessionImpl: executing select 1 + 1
2024-04-24T07:36:59,364  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=24998a14-8008-42ff-8450-11c9b8c8f241] SessionHandle [8cd46240-8da4-4d0f-865c-ecb5bceed17c]
2024-04-24T07:36:59,365  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.OperationLogManager: The operation log location changes from /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156 to /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156.
2024-04-24T07:36:59,373  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", footer="null", noConsoleNoAnsi="null", PatternSelector=null, Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", alwaysWriteExceptions="null", disableAnsi="null", header="null", Replace=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(noConsoleNoAnsi="null", header="null", Configuration(HiveLog4j2Test), footer="null", charset="null", Replace=null, PatternSelector=null, alwaysWriteExceptions="null", pattern="%-5p : %m%n", disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156.test
2024-04-24T07:36:59,397  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156, startTime=1713969419357, sessionId=8cd46240-8da4-4d0f-865c-ecb5bceed17c, createTime=1713969419097, userName=user1, ipAddress=null]
2024-04-24T07:36:59,485  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Compiling command(queryId=alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156): select 1 + 1
2024-04-24T07:37:00,420  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:37:00,423  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33bdd01, with PersistenceManager: null will be shutdown
2024-04-24T07:37:00,424  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33bdd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@159ac15f created in the thread with id: 1
2024-04-24T07:37:00,439  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33bdd01 from thread id: 1
2024-04-24T07:37:00,848  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] reflections.Reflections: Reflections took 353 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:37:01,167  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] reflections.Reflections: Reflections took 247 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:37:01,386  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] reflections.Reflections: Reflections took 209 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:37:01,498  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156
2024-04-24T07:37:01,501  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:37:01,510  WARN [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] security.ShellBasedUnixGroupsMapping: unable to return groups for user user1
org.apache.hadoop.security.ShellBasedUnixGroupsMapping$PartialGroupNameException: The user name 'user1' is not found. id: ‘user1’: no such user
id: ‘user1’: no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:294) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:207) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:384) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:319) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:269) ~[hadoop-common-3.1.0.jar:?]
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3542) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2323) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2286) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache.get(LocalCache.java:3953) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3957) ~[guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4875) ~[guava-19.0.jar:?]
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:227) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1540) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1528) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator.setConf(HadoopDefaultAuthenticator.java:63) ~[classes/:?]
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthenticator(HiveUtils.java:408) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:990) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1758) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15104) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12507) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:417) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:411) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:125) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:204) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:267) ~[classes/:?]
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:281) ~[classes/:?]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:544) ~[classes/:?]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:518) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78) ~[classes/:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36) ~[classes/:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63) ~[classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59) ~[classes/:?]
	at com.sun.proxy.$Proxy46.executeStatement(Unknown Source) ~[?:?]
	at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:285) ~[classes/:?]
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:650) ~[classes/:?]
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.executeStatementInternal(ThriftCLIServiceClient.java:214) ~[classes/:?]
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.executeStatement(ThriftCLIServiceClient.java:185) ~[classes/:?]
	at org.apache.hive.service.cli.operation.TestOperationLogManager.testOperationLogManager(TestOperationLogManager.java:89) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T07:37:01,517  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=8cd46240-8da4-4d0f-865c-ecb5bceed17c, clientType=HIVESERVER2]
2024-04-24T07:37:01,521  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:37:01,522  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:37:01,522  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:37:01,530  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:37:01,544  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:37:03,348  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:37:04,430  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:37:04,439  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:37:04,464  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:37:04,464  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:37:04,537  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-59_433_2616375387478812220-1
2024-04-24T07:37:04,614  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:37:04,768  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:37:04,810  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:37:04,810  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156
2024-04-24T07:37:04,810  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:37:04,814  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:int, comment:null)], properties:null)
2024-04-24T07:37:04,849  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:37:04,852  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:37:04,857  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.SelectOperator: SELECT null
2024-04-24T07:37:04,857  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:37:04,865  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:37:04,865  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=137, flushCache_()=23, isCompatibleWith_(Configuration)=0, getAllFunctions_()=110}
2024-04-24T07:37:04,866  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Completed compiling command(queryId=alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156); Time taken: 5.384 seconds
2024-04-24T07:37:04,868  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:37:04,869  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T07:37:04,876  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Executing command(queryId=alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156): select 1 + 1
PREHOOK: query: select 1 + 1
2024-04-24T07:37:04,880  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: PREHOOK: query: select 1 + 1
PREHOOK: type: QUERY
2024-04-24T07:37:04,880  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:37:04,880  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1/-mr-10001
2024-04-24T07:37:04,880  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1/-mr-10001
POSTHOOK: query: select 1 + 1
2024-04-24T07:37:04,883  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: POSTHOOK: query: select 1 + 1
POSTHOOK: type: QUERY
2024-04-24T07:37:04,884  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:37:04,884  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1/-mr-10001
2024-04-24T07:37:04,884  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1/-mr-10001
2024-04-24T07:37:04,885  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:37:04,885  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T07:37:04,886  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Driver: Completed executing command(queryId=alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156); Time taken: 0.01 seconds
2024-04-24T07:37:04,887  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] common.LogUtils: Unregistered logging context.
2024-04-24T07:37:04,897  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=24998a14-8008-42ff-8450-11c9b8c8f241]
2024-04-24T07:37:04,897  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.OperationManager: Removed queryId: alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=24998a14-8008-42ff-8450-11c9b8c8f241] with tag: null
2024-04-24T07:37:04,898  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1
2024-04-24T07:37:04,899  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1 operation was queued
2024-04-24T07:37:04,899  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:37:04,901  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c/hive_2024-04-24_07-36-59_433_2616375387478812220-1
2024-04-24T07:37:04,901  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:37:04,901  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:37:04,901  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:0, 
2024-04-24T07:37:04,901  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:37:04,902  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:37:04,902  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/8cd46240-8da4-4d0f-865c-ecb5bceed17c/alex_20240424073659_186dc583-f497-49a9-b4e2-5b2e85573156 without delay
2024-04-24T07:37:04,911  INFO [main] service.CompositeService: Session closed, SessionHandle [8cd46240-8da4-4d0f-865c-ecb5bceed17c], current sessions:0
2024-04-24T07:37:04,912  INFO [8cd46240-8da4-4d0f-865c-ecb5bceed17c main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:37:04,913  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/8cd46240-8da4-4d0f-865c-ecb5bceed17c operation was queued
2024-04-24T07:37:04,913  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:37:04,913  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c operation was queued
2024-04-24T07:37:04,914  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/8cd46240-8da4-4d0f-865c-ecb5bceed17c
2024-04-24T07:37:04,926  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:37:04,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33bdd01, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@159ac15f will be shutdown
2024-04-24T07:37:04,926  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:37:04,926  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T07:37:04,928  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:37:04,928  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [user1] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:37:04,930  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:37:04,943  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:04,947  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:04,951  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/d2903554-d050-4bcb-ad39-b71371e7cbf1/_tmp_space.db
2024-04-24T07:37:04,952  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:37:04,952  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:37:04,952  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:04,952  INFO [main] service.CompositeService: Session opened, SessionHandle [d2903554-d050-4bcb-ad39-b71371e7cbf1], current sessions:1
2024-04-24T07:37:04,952  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : user1
2024-04-24T07:37:04,952  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] session.HiveSessionImpl: executing select 1 + 1
2024-04-24T07:37:04,955  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=774edcd8-09dc-45aa-badd-64587285bd7d] SessionHandle [d2903554-d050-4bcb-ad39-b71371e7cbf1]
2024-04-24T07:37:04,955  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.OperationLogManager: The operation log location changes from /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215 to /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215.
2024-04-24T07:37:04,956  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", Configuration(HiveLog4j2Test), footer="null", PatternSelector=null, Replace=null, pattern="%-5p : %m%n", charset="null", noConsoleNoAnsi="null", header="null", alwaysWriteExceptions="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", charset="null", header="null", Replace=null, alwaysWriteExceptions="null", footer="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215.test
2024-04-24T07:37:04,968  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215, startTime=1713969424953, sessionId=d2903554-d050-4bcb-ad39-b71371e7cbf1, createTime=1713969424928, userName=user1, ipAddress=null]
2024-04-24T07:37:04,971  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Compiling command(queryId=alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215): select 1 + 1
2024-04-24T07:37:04,976  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:37:04,979  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:37:04,979  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:37:04,981  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d94ac8a, with PersistenceManager: null will be shutdown
2024-04-24T07:37:04,981  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d94ac8a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@288b73c1 created in the thread with id: 1
2024-04-24T07:37:04,990  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d94ac8a from thread id: 1
2024-04-24T07:37:04,990  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:37:04,991  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=user1 (auth:PROXY) via alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:37:04,993  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215
2024-04-24T07:37:04,993  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:37:04,994  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d2903554-d050-4bcb-ad39-b71371e7cbf1, clientType=HIVESERVER2]
2024-04-24T07:37:04,994  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:37:04,994  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:37:04,994  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:37:04,994  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:37:04,995  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:37:05,032  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:37:05,179  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:37:05,180  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:37:05,183  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:37:05,183  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:37:05,185  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1/-mr-10001/.hive-staging_hive_2024-04-24_07-37-04_970_2162289873435254667-1
2024-04-24T07:37:05,196  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:37:05,203  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:37:05,206  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:37:05,207  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215
2024-04-24T07:37:05,207  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:37:05,207  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:int, comment:null)], properties:null)
2024-04-24T07:37:05,210  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:37:05,212  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:37:05,213  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.SelectOperator: SELECT null
2024-04-24T07:37:05,213  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:37:05,213  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:37:05,214  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=12}
2024-04-24T07:37:05,214  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Completed compiling command(queryId=alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215); Time taken: 0.243 seconds
2024-04-24T07:37:05,214  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:37:05,215  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T07:37:05,215  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Executing command(queryId=alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215): select 1 + 1
PREHOOK: query: select 1 + 1
2024-04-24T07:37:05,216  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: PREHOOK: query: select 1 + 1
PREHOOK: type: QUERY
2024-04-24T07:37:05,216  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:37:05,216  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1/-mr-10001
2024-04-24T07:37:05,216  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1/-mr-10001
POSTHOOK: query: select 1 + 1
2024-04-24T07:37:05,217  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: POSTHOOK: query: select 1 + 1
POSTHOOK: type: QUERY
2024-04-24T07:37:05,217  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:37:05,217  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1/-mr-10001
2024-04-24T07:37:05,217  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1/-mr-10001
2024-04-24T07:37:05,218  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:37:05,218  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T07:37:05,218  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Driver: Completed executing command(queryId=alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215); Time taken: 0.003 seconds
2024-04-24T07:37:05,219  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:37:05,220  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=774edcd8-09dc-45aa-badd-64587285bd7d]
2024-04-24T07:37:05,220  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.OperationManager: Removed queryId: alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=774edcd8-09dc-45aa-badd-64587285bd7d] with tag: null
2024-04-24T07:37:05,221  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1
2024-04-24T07:37:05,221  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1 operation was queued
2024-04-24T07:37:05,223  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1/hive_2024-04-24_07-37-04_970_2162289873435254667-1
2024-04-24T07:37:05,223  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:37:05,223  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:37:05,223  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:37:05,224  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:0, 
2024-04-24T07:37:05,224  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:37:05,224  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:37:05,224  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/d2903554-d050-4bcb-ad39-b71371e7cbf1/alex_20240424073704_b6b18a3a-6bd0-4f36-964d-bd7340c0e215 without delay
2024-04-24T07:37:05,234  INFO [main] operation.OperationLogManager: Deleted 1 expired operation logs
2024-04-24T07:37:05,234  INFO [main] operation.OperationLogManager: Deleted 1 expired operation log session dirs
2024-04-24T07:37:05,235  INFO [main] service.CompositeService: Session closed, SessionHandle [d2903554-d050-4bcb-ad39-b71371e7cbf1], current sessions:0
2024-04-24T07:37:05,236  INFO [d2903554-d050-4bcb-ad39-b71371e7cbf1 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:05,237  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/d2903554-d050-4bcb-ad39-b71371e7cbf1 operation was queued
2024-04-24T07:37:05,238  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/user1/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:05,238  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1 operation was queued
2024-04-24T07:37:05,238  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/d2903554-d050-4bcb-ad39-b71371e7cbf1
2024-04-24T07:37:05,240  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:37:05,240  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d94ac8a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@288b73c1 will be shutdown
2024-04-24T07:37:05,241  INFO [main] HiveMetaStore.audit: ugi=user1	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:37:05,241  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T07:37:05,242  INFO [main] operation.OperationLogManager: No expired operation logs found under the dir: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018
2024-04-24T07:37:05,243  INFO [main] operation.OperationLogManager: No expired operation log session dir under the dir: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018
2024-04-24T07:37:05,347  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:37:05,347  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:37:05,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:37:05,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:37:05,352  WARN [main] session.HiveSessionImpl: The operation log root directory is removed, recreating:/home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969425246_-345271239/operation_logs
2024-04-24T07:37:05,352  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969425246_-345271239/operation_logs/b57329ef-876c-4906-b96a-ee32a49b33eb
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:37:05,353  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:37:05,367  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b57329ef-876c-4906-b96a-ee32a49b33eb
2024-04-24T07:37:05,374  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/b57329ef-876c-4906-b96a-ee32a49b33eb
2024-04-24T07:37:05,380  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/b57329ef-876c-4906-b96a-ee32a49b33eb/_tmp_space.db
2024-04-24T07:37:05,380  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:37:05,380  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:37:05,382  INFO [main] operation.OperationLogManager: The operation log location changes from /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969425246_-345271239/operation_logs/b57329ef-876c-4906-b96a-ee32a49b33eb/alex_20240424073705_ab91fe1e-7aa3-45af-b7bd-49adaa925447 to /home/alex/Repositories/hive/service/target/tmp/org.apache.hive.service.cli.operation.TestOperationLogManager-1713969408365_-345271240/operation_logs_historic/Lenovo-Bot_10000_1713969419018/b57329ef-876c-4906-b96a-ee32a49b33eb/alex_20240424073705_ab91fe1e-7aa3-45af-b7bd-49adaa925447.
