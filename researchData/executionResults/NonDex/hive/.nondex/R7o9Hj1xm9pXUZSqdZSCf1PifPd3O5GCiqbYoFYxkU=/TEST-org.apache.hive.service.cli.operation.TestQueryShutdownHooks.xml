<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="24.912" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5662417000772434808.jar /home/alex/Repositories/hive/service/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire2797675758067715311tmp surefire_33298174072813766458556tmp"/>
    <property name="nondexExecid" value="R7o9Hj1xm9pXUZSqdZSCf1PifPd3O5GCiqbYoFYxkU="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/service/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/service/.nondex"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/service/.nondex"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="nondexStart" value="0"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="1016066"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5662417000772434808.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="19.734">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,118232 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@58e1d9d]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@58e1d9d) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@2d29b4ee
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,036550 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(alwaysWriteExceptions="null", header="null", charset="null", disableAnsi="null", noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", Replace=null, footer="null", PatternSelector=null, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(direct="null", target="SYSTEM_ERR", follow="null", bufferSize="null", bufferedIo="null", immediateFlush="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", ignoreExceptions="null", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(alwaysWriteExceptions="null", noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", disableAnsi="null", charset="null", Configuration(HiveLog4j2Test), footer="null", Replace=null, header="null", PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(fileIndex="null", compressionLevel="null", stopCustomActionsOnError="null", Configuration(HiveLog4j2Test), tempCompressedFilePattern="null", max="30", ={}, min="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", filePermissions="null", fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", advertise="null", advertiseURI="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), fileGroup="null", fileOwner="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), append="null", bufferedIo="null", bufferSize="null", immediateFlush="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", ignoreExceptions="null", Configuration(HiveLog4j2Test), ={}, Filter=null)
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 12597718136
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T07:36:13.991-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-07:36:16.425, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-07:36:16.426, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@7671cb68...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@7671cb68 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3e14c16d
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@58e1d9d
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@58e1d9d) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@58e1d9d] started OK.
2024-04-24T07:36:16,610  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T07:36:17,153  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T07:36:17,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:36:17,239  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:36:17,239  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:36:17,239  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:36:17,239  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:36:17,239  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:36:17,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:36:17,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:36:17,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:36:17,241  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:36:17,241  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:36:17,241  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 7518a2c8-b67d-4172-8dfb-821af1e5411b
2024-04-24T07:36:17,287  INFO [main] SessionState: Hive Session ID = 7518a2c8-b67d-4172-8dfb-821af1e5411b
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:17,302  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:17,756  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7518a2c8-b67d-4172-8dfb-821af1e5411b
2024-04-24T07:36:17,760  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/7518a2c8-b67d-4172-8dfb-821af1e5411b
2024-04-24T07:36:17,765  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7518a2c8-b67d-4172-8dfb-821af1e5411b/_tmp_space.db
2024-04-24T07:36:17,800  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7518a2c8-b67d-4172-8dfb-821af1e5411b, clientType=HIVESERVER2]
2024-04-24T07:36:17,878  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:18,167  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:18,216  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:18,226  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T07:36:18,226  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T07:36:18,259  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:18,265  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T07:36:19,268  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:19,271  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T07:36:20,138  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T07:36:20,138  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: null will be shutdown
2024-04-24T07:36:20,174  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@100c8b75 created in the thread with id: 1
2024-04-24T07:36:24,100  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T07:36:24,101  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T07:36:24,101  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336 from thread id: 1
2024-04-24T07:36:24,293  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T07:36:24,349  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T07:36:24,403  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T07:36:24,407  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T07:36:24,582  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T07:36:24,590  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T07:36:24,592  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T07:36:24,596  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T07:36:24,597  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T07:36:24,599  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T07:36:24,634  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:24,639  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T07:36:24,641  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:24,643  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T07:36:24,647  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:36:24,651  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T07:36:24,653  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:36:24,654  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T07:36:24,662  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T07:36:24,667  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:24,870  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:25,630  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,632  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,633  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,635  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,637  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,642  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,644  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:36:25,745  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:36:25,747  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:36:25,747  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:36:25,747  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:36:25,749  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:36:25,752  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-04-24T07:36:25,761  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-04-24T07:36:25,786  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:36:25,787  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:36:25,787  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:36:25,787  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:36:25,788  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:36:25,789  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:36:25,817  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:36:25,824  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:25,831  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:25,846  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a3de53ec-7f2f-451e-8102-79aa36436258
2024-04-24T07:36:25,851  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258
2024-04-24T07:36:25,854  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a3de53ec-7f2f-451e-8102-79aa36436258/_tmp_space.db
2024-04-24T07:36:25,858  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:36:25,859  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:36:25,861  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:25,861  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:25,864  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@100c8b75 will be shutdown
2024-04-24T07:36:25,865  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a301f3 created in the thread with id: 1
2024-04-24T07:36:25,891  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:25,892  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:25,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T07:36:25,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:25,995  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@53a301f3 will be shutdown
2024-04-24T07:36:25,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:25,995  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T07:36:25,997  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258
2024-04-24T07:36:26,002  INFO [main] service.CompositeService: Session opened, SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258], current sessions:1
2024-04-24T07:36:26,011  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:36:26,018  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:26,043  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=df69e4a2-3561-4138-ace8-75e5d1c21635] SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258]
2024-04-24T07:36:26,050  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", noConsoleNoAnsi="null", footer="null", Replace=null, charset="null", header="null", alwaysWriteExceptions="null", Configuration(HiveLog4j2Test), PatternSelector=null, disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(header="null", noConsoleNoAnsi="null", Replace=null, disableAnsi="null", Configuration(HiveLog4j2Test), charset="null", PatternSelector=null, footer="null", alwaysWriteExceptions="null", pattern="%-5p : %m%n")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608.test
2024-04-24T07:36:26,070  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608, startTime=1713969386034, sessionId=a3de53ec-7f2f-451e-8102-79aa36436258, createTime=1713969385828, userName=anonymous, ipAddress=null]
2024-04-24T07:36:26,149  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Compiling command(queryId=alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:27,075  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:27,078  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: null will be shutdown
2024-04-24T07:36:27,079  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7af1d072 created in the thread with id: 1
2024-04-24T07:36:27,092  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05 from thread id: 1
2024-04-24T07:36:27,474  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] reflections.Reflections: Reflections took 334 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:36:27,747  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] reflections.Reflections: Reflections took 214 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:36:27,948  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] reflections.Reflections: Reflections took 190 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:36:28,064  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
2024-04-24T07:36:28,067  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:28,067  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=a3de53ec-7f2f-451e-8102-79aa36436258, clientType=HIVESERVER2]
2024-04-24T07:36:28,073  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:28,073  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:28,073  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:28,079  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:28,095  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:29,808  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:30,807  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:30,813  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:30,835  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:30,835  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:30,905  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-26_108_555834966007884083-1
2024-04-24T07:36:30,971  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:31,100  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:31,133  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:31,224  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:31,233  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:31,233  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:31,233  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:31,233  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:31,233  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:31,234  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:31,240  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:31,240  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
2024-04-24T07:36:31,240  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:31,244  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:31,261  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:31,269  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:31,270  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=21, isCompatibleWith_(Configuration)=0, getAllFunctions_()=99, getAllTableConstraints_(AllTableConstraintsRequest)=119}
2024-04-24T07:36:31,272  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed compiling command(queryId=alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608); Time taken: 5.122 seconds
2024-04-24T07:36:31,273  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:31,274  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:36:31,280  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:31,285  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Executing command(queryId=alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:31,288  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:36:31,288  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:31,288  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001
2024-04-24T07:36:31,288  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001
2024-04-24T07:36:31,291  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
2024-04-24T07:36:31,292  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Query ID = alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
Total jobs = 1
2024-04-24T07:36:31,292  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:31,292  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:31,493  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:31,493  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:31,505  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:31,509  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:31,509  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/dummy_path
2024-04-24T07:36:31,603  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:31,633  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:31,805  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T07:36:31,825  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T07:36:31,849  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T07:36:31,849  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T07:36:31,888  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:31,941  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:31,957  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:31,962  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:31,964  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-24T07:36:31,978  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/dummy_path
2024-04-24T07:36:32,044  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:32,075  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:32,077  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:32,115  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:32,188  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1836927446_0001
2024-04-24T07:36:32,189  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:32,427  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:32,430  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:32,431  INFO [Thread-59] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:32,440  INFO [Thread-59] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:32,458  INFO [Thread-59] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:32,464  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1836927446_0001_m_000000_0
2024-04-24T07:36:32,520  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:32,531  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:32,541  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:32,574  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:32,586  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:32,599  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:32,602  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:32,607  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:32,607  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:32,611  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:32,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:32,614  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@13f13bb, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7f911971, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@49c83965
2024-04-24T07:36:32,632  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-26_108_555834966007884083-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:32,632  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-26_108_555834966007884083-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:32,632  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-26_108_555834966007884083-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:32,688  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:32,689  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:36:32,689  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:32,689  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:36:32,690  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:3, RECORDS_OUT_INTERMEDIATE:0, DESERIALIZE_ERRORS:0, 
2024-04-24T07:36:32,690  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:32,690  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:36:32,690  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:32,691  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:32,691  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:32,691  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:32,695  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-24T07:36:32,700  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:36:32,710  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1836927446_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T07:36:32,711  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:36:32,711  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1836927446_0001_m_000000_0' done.
2024-04-24T07:36:32,714  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1836927446_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5576
		FILE: Number of bytes written=1157168
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=340
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=895483904
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:36:32,715  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1836927446_0001_m_000000_0
2024-04-24T07:36:32,716  INFO [Thread-59] mapred.LocalJobRunner: map task executor complete.
2024-04-24 07:36:33,447 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:36:33,448  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Task: 2024-04-24 07:36:33,447 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1836927446_0001
2024-04-24T07:36:33,455  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.Task: Ended Job = job_local1836927446_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:33,472  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:36:33,472  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:33,472  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001
2024-04-24T07:36:33,472  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1/-mr-10001
2024-04-24T07:36:33,473  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:33,473  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:33,474  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:36:33,486  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:33,486  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:33,486  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed executing command(queryId=alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608); Time taken: 2.189 seconds
2024-04-24T07:36:33,489  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:33,493  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:33,495  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=78481965-6643-49d5-b5e4-db6000c61798] SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258]
2024-04-24T07:36:33,496  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", Configuration(HiveLog4j2Test), Replace=null, pattern="%-5p : %m%n", charset="null", noConsoleNoAnsi="null", footer="null", alwaysWriteExceptions="null", header="null", PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, disableAnsi="null", charset="null", pattern="%-5p : %m%n", Replace=null, alwaysWriteExceptions="null", footer="null", Configuration(HiveLog4j2Test), header="null", noConsoleNoAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d.test
2024-04-24T07:36:33,505  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d, startTime=1713969393493, sessionId=a3de53ec-7f2f-451e-8102-79aa36436258, createTime=1713969385828, userName=anonymous, ipAddress=null]
2024-04-24T07:36:33,506  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Compiling command(queryId=alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:33,509  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
2024-04-24T07:36:33,509  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:33,510  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:33,510  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:33,510  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:33,510  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:33,510  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:33,545  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:33,703  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:33,704  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:33,708  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:33,708  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:33,710  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1
2024-04-24T07:36:33,719  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:33,725  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:33,726  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:33,740  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:33,741  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:33,741  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
2024-04-24T07:36:33,741  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:33,741  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:33,743  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:33,743  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:33,744  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=14, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T07:36:33,744  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed compiling command(queryId=alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d); Time taken: 0.237 seconds
2024-04-24T07:36:33,746  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:33,747  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:33,747  INFO [HiveServer2-Background-Pool: Thread-114] common.LogUtils: Thread context registration is done.
2024-04-24T07:36:33,748  INFO [HiveServer2-Background-Pool: Thread-114] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:33,750  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=681cc599-63aa-4de3-84d4-e3a56ced45ae] SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258]
2024-04-24T07:36:33,751  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(header="null", charset="null", pattern="%-5p : %m%n", footer="null", PatternSelector=null, Replace=null, alwaysWriteExceptions="null", noConsoleNoAnsi="null", Configuration(HiveLog4j2Test), disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
2024-04-24T07:36:33,758  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Operation QUERY obtained 2 locks
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, charset="null", alwaysWriteExceptions="null", noConsoleNoAnsi="null", Configuration(HiveLog4j2Test), disableAnsi="null", pattern="%-5p : %m%n", PatternSelector=null, header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b.test
2024-04-24T07:36:33,763  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b, startTime=1713969393748, sessionId=a3de53ec-7f2f-451e-8102-79aa36436258, createTime=1713969385828, userName=anonymous, ipAddress=null]
2024-04-24T07:36:33,763  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Executing command(queryId=alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:33,764  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:36:33,764  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:33,764  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001
2024-04-24T07:36:33,764  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001
2024-04-24T07:36:33,764  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Compiling command(queryId=alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:33,765  WARN [HiveServer2-Background-Pool: Thread-114] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
2024-04-24T07:36:33,765  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Query ID = alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
Total jobs = 1
2024-04-24T07:36:33,765  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:33,765  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:33,767  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
2024-04-24T07:36:33,767  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:33,767  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:33,768  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:33,768  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:33,768  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:33,768  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:33,805  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:33,886  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:33,886  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:33,894  INFO [HiveServer2-Background-Pool: Thread-114] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:33,895  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:33,895  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/dummy_path
2024-04-24T07:36:33,910  INFO [HiveServer2-Background-Pool: Thread-114] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:33,912  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:33,915  WARN [HiveServer2-Background-Pool: Thread-114] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:33,929  WARN [HiveServer2-Background-Pool: Thread-114] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:33,943  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:33,950  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:33,951  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:33,952  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/dummy_path
2024-04-24T07:36:33,963  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:33,963  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:33,972  INFO [HiveServer2-Background-Pool: Thread-114] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:33,973  INFO [HiveServer2-Background-Pool: Thread-114] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:33,973  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:33,976  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:33,976  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:33,979  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1
2024-04-24T07:36:33,989  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:33,997  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:33,999  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:34,016  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:34,020  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:34,021  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
2024-04-24T07:36:34,021  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:34,021  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:34,023  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:34,023  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:34,023  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=8}
2024-04-24T07:36:34,024  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed compiling command(queryId=alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b); Time taken: 0.259 seconds
2024-04-24T07:36:34,028  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:34,028  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,029  INFO [HiveServer2-Background-Pool: Thread-146] common.LogUtils: Thread context registration is done.
2024-04-24T07:36:34,030  INFO [HiveServer2-Background-Pool: Thread-146] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:34,031  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=37d9d0bd-59b0-4793-81ea-673a2b7c02fd] SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258]
2024-04-24T07:36:34,031  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:34,031  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(noConsoleNoAnsi="null", PatternSelector=null, Configuration(HiveLog4j2Test), charset="null", alwaysWriteExceptions="null", pattern="%-5p : %m%n", footer="null", Replace=null, header="null", disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(alwaysWriteExceptions="null", Replace=null, pattern="%-5p : %m%n", noConsoleNoAnsi="null", disableAnsi="null", charset="null", Configuration(HiveLog4j2Test), header="null", footer="null", PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2.test
2024-04-24T07:36:34,044  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2, startTime=1713969394029, sessionId=a3de53ec-7f2f-451e-8102-79aa36436258, createTime=1713969385828, userName=anonymous, ipAddress=null]
2024-04-24T07:36:34,044  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Executing command(queryId=alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,045  INFO [HiveServer2-Background-Pool: Thread-146] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:36:34,045  INFO [HiveServer2-Background-Pool: Thread-146] SessionState: PREHOOK: type: QUERY
2024-04-24T07:36:34,045  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Compiling command(queryId=alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:34,045  INFO [HiveServer2-Background-Pool: Thread-146] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001
2024-04-24T07:36:34,045  INFO [HiveServer2-Background-Pool: Thread-146] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001
2024-04-24T07:36:34,046  WARN [HiveServer2-Background-Pool: Thread-146] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
2024-04-24T07:36:34,046  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Query ID = alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
Total jobs = 1
2024-04-24T07:36:34,046  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Total jobs = 1
Launching Job 1 out of 12024-04-24T07:36:34,048  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
2024-04-24T07:36:34,048  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting Semantic Analysis

2024-04-24T07:36:34,049  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:34,052  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:34,052  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:34,052  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:34,052  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:34,052  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:34,059  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: Submitting tokens for job: job_local2097071004_0002
2024-04-24T07:36:34,059  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:34,095  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:34,166  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,167  INFO [HiveServer2-Background-Pool: Thread-146] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,175  INFO [HiveServer2-Background-Pool: Thread-146] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:34,175  INFO [HiveServer2-Background-Pool: Thread-146] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:34,175  INFO [HiveServer2-Background-Pool: Thread-146] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/dummy_path
2024-04-24T07:36:34,192  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:34,196  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:34,196  INFO [Thread-107] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,196  INFO [Thread-107] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,200  INFO [HiveServer2-Background-Pool: Thread-146] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:34,201  INFO [Thread-107] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:34,201  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2097071004_0002_m_000000_0
2024-04-24T07:36:34,203  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:34,204  INFO [HiveServer2-Background-Pool: Thread-146] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,204  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:34,205  WARN [HiveServer2-Background-Pool: Thread-146] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,206  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:34,209  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,210  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:34,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:34,213  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:34,215  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:34,215  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:34,215  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:34,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:34,217  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@2b5a8267, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@370adb03, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@7aa50245
2024-04-24T07:36:34,218  WARN [HiveServer2-Background-Pool: Thread-146] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,231  WARN [HiveServer2-Background-Pool: Thread-146] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:34,239  WARN [HiveServer2-Background-Pool: Thread-146] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:34,239  INFO [HiveServer2-Background-Pool: Thread-146] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:34,241  INFO [HiveServer2-Background-Pool: Thread-146] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/dummy_path
2024-04-24T07:36:34,248  INFO [HiveServer2-Background-Pool: Thread-146] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:34,249  INFO [HiveServer2-Background-Pool: Thread-146] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:34,249  INFO [HiveServer2-Background-Pool: Thread-146] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:34,270  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:34,271  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:34,274  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:34,274  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:34,276  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1
2024-04-24T07:36:34,278  INFO [HiveServer2-Background-Pool: Thread-146] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:34,283  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:34,290  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:34,292  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:34,305  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:34,306  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:34,306  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
2024-04-24T07:36:34,306  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:34,306  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:34,307  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:34,308  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:34,308  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=12, isCompatibleWith_(Configuration)=1}
2024-04-24T07:36:34,308  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed compiling command(queryId=alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2); Time taken: 0.263 seconds
2024-04-24T07:36:34,309  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:34,309  INFO [HiveServer2-Background-Pool: Thread-188] common.LogUtils: Thread context registration is done.
2024-04-24T07:36:34,309  INFO [HiveServer2-Background-Pool: Thread-188] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:34,310  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,310  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:34,311  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Executing command(queryId=alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,312  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=096aa143-42c4-4d96-89c9-c449c71c0885] SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258]
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,312  INFO [HiveServer2-Background-Pool: Thread-188] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:36:34,312  INFO [HiveServer2-Background-Pool: Thread-188] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:34,312  INFO [HiveServer2-Background-Pool: Thread-188] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:34,312  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Thread context registration is done.
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001
2024-04-24T07:36:34,312  INFO [HiveServer2-Background-Pool: Thread-188] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", noConsoleNoAnsi="null", header="null", PatternSelector=null, Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", Replace=null, footer="null", charset="null", alwaysWriteExceptions="null")
2024-04-24T07:36:34,315  INFO [HiveServer2-Background-Pool: Thread-146] mapreduce.JobSubmitter: Submitting tokens for job: job_local259001027_0003
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, footer="null", Replace=null, Configuration(HiveLog4j2Test), disableAnsi="null", pattern="%-5p : %m%n", noConsoleNoAnsi="null", alwaysWriteExceptions="null", charset="null", header="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71.test
2024-04-24T07:36:34,326  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71, startTime=1713969394310, sessionId=a3de53ec-7f2f-451e-8102-79aa36436258, createTime=1713969385828, userName=anonymous, ipAddress=null]
2024-04-24T07:36:34,326  INFO [HiveServer2-Background-Pool: Thread-146] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:34,326  WARN [HiveServer2-Background-Pool: Thread-188] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
2024-04-24T07:36:34,326  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Query ID = alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
Total jobs = 1
2024-04-24T07:36:34,326  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:34,326  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:34,327  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Compiling command(queryId=alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,329  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
2024-04-24T07:36:34,329  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:34,329  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:34,330  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:34,330  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:34,330  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:34,330  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:34,365  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:34,424  INFO [HiveServer2-Background-Pool: Thread-146] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:34,425  INFO [Thread-144] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,425  INFO [HiveServer2-Background-Pool: Thread-146] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:34,425  INFO [Thread-144] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,428  INFO [Thread-144] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:34,428  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local259001027_0003_m_000000_0
2024-04-24T07:36:34,429  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:34,430  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:34,431  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:34,433  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,433  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:34,434  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:34,434  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,434  INFO [HiveServer2-Background-Pool: Thread-188] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,435  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:34,436  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:34,436  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:34,436  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:34,436  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:34,437  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@7404f501, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@1472cb61, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@c81ec3b
2024-04-24T07:36:34,441  INFO [HiveServer2-Background-Pool: Thread-188] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:34,442  INFO [HiveServer2-Background-Pool: Thread-188] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:34,442  INFO [HiveServer2-Background-Pool: Thread-188] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/dummy_path
2024-04-24T07:36:34,475  INFO [HiveServer2-Background-Pool: Thread-188] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:34,476  INFO [HiveServer2-Background-Pool: Thread-188] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,477  WARN [HiveServer2-Background-Pool: Thread-188] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,487  WARN [HiveServer2-Background-Pool: Thread-188] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,497  WARN [HiveServer2-Background-Pool: Thread-188] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:34,504  WARN [HiveServer2-Background-Pool: Thread-188] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:34,505  INFO [HiveServer2-Background-Pool: Thread-188] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:34,507  INFO [HiveServer2-Background-Pool: Thread-188] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/dummy_path
2024-04-24T07:36:34,513  INFO [HiveServer2-Background-Pool: Thread-188] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:34,513  INFO [HiveServer2-Background-Pool: Thread-188] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:34,514  INFO [HiveServer2-Background-Pool: Thread-188] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:34,534  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:34,535  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:34,539  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:34,539  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:34,540  INFO [HiveServer2-Background-Pool: Thread-188] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:34,541  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1
2024-04-24T07:36:34,548  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:34,555  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:34,557  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:34,570  INFO [HiveServer2-Background-Pool: Thread-188] mapreduce.JobSubmitter: Submitting tokens for job: job_local1974603530_0004
2024-04-24T07:36:34,570  INFO [HiveServer2-Background-Pool: Thread-188] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:34,572  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:34,573  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:34,573  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
2024-04-24T07:36:34,573  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:34,573  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:34,574  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:34,575  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:34,575  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=1, getAllTableConstraints_(AllTableConstraintsRequest)=11, isCompatibleWith_(Configuration)=0}
2024-04-24T07:36:34,575  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Completed compiling command(queryId=alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71); Time taken: 0.248 seconds
2024-04-24T07:36:34,576  INFO [HiveServer2-Background-Pool: Thread-229] common.LogUtils: Thread context registration is done.
2024-04-24T07:36:34,576  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:34,576  INFO [HiveServer2-Background-Pool: Thread-229] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:34,577  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:34,578  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Executing command(queryId=alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:36:34,578  INFO [HiveServer2-Background-Pool: Thread-229] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:36:34,579  INFO [HiveServer2-Background-Pool: Thread-229] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:34,579  INFO [HiveServer2-Background-Pool: Thread-229] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001
2024-04-24T07:36:34,579  INFO [HiveServer2-Background-Pool: Thread-229] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001
2024-04-24T07:36:34,580  WARN [HiveServer2-Background-Pool: Thread-229] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
2024-04-24T07:36:34,580  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Query ID = alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
Total jobs = 1
2024-04-24T07:36:34,580  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:34,580  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:34,658  INFO [HiveServer2-Background-Pool: Thread-188] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:34,659  INFO [HiveServer2-Background-Pool: Thread-188] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:34,659  INFO [Thread-180] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,659  INFO [Thread-180] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,661  INFO [Thread-180] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:34,661  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1974603530_0004_m_000000_0
2024-04-24T07:36:34,662  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:34,663  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:34,664  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:34,667  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,667  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:34,668  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:34,668  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:34,669  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:34,669  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:34,669  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:34,669  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:34,670  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@54094fc0, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@53a19bd0, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@589945f
2024-04-24T07:36:34,678  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,678  INFO [HiveServer2-Background-Pool: Thread-229] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:34,687  INFO [HiveServer2-Background-Pool: Thread-229] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:34,687  INFO [HiveServer2-Background-Pool: Thread-229] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:34,687  INFO [HiveServer2-Background-Pool: Thread-229] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/dummy_path
2024-04-24T07:36:34,700  INFO [HiveServer2-Background-Pool: Thread-229] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:34,702  INFO [HiveServer2-Background-Pool: Thread-229] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,704  WARN [HiveServer2-Background-Pool: Thread-229] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,710  WARN [HiveServer2-Background-Pool: Thread-229] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:34,722  WARN [HiveServer2-Background-Pool: Thread-229] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:34,727  WARN [HiveServer2-Background-Pool: Thread-229] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:34,728  INFO [HiveServer2-Background-Pool: Thread-229] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:34,729  INFO [HiveServer2-Background-Pool: Thread-229] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/dummy_path
2024-04-24T07:36:34,736  INFO [HiveServer2-Background-Pool: Thread-229] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:34,737  INFO [HiveServer2-Background-Pool: Thread-229] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:34,737  INFO [HiveServer2-Background-Pool: Thread-229] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:34,761  INFO [HiveServer2-Background-Pool: Thread-229] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:34,800  INFO [HiveServer2-Background-Pool: Thread-229] mapreduce.JobSubmitter: Submitting tokens for job: job_local75439565_0005
2024-04-24T07:36:34,800  INFO [HiveServer2-Background-Pool: Thread-229] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:34,880  INFO [HiveServer2-Background-Pool: Thread-229] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:34,881  INFO [Thread-211] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,881  INFO [HiveServer2-Background-Pool: Thread-229] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:34,881  INFO [Thread-211] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:34,883  INFO [Thread-211] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:34,884  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local75439565_0005_m_000000_0
2024-04-24T07:36:34,885  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:34,886  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:34,887  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:34,891  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:34,891  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:34,892  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:34,892  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:34,893  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:34,893  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:34,893  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:34,893  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:34,894  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@5216f6a6, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5fadd225, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@2a58204e
2024-04-24T07:36:35,102  INFO [main] service.CompositeService: Session closed, SessionHandle [a3de53ec-7f2f-451e-8102-79aa36436258], current sessions:0
2024-04-24T07:36:35,103  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=78481965-6643-49d5-b5e4-db6000c61798]
2024-04-24T07:36:35,103  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Removed queryId: alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=78481965-6643-49d5-b5e4-db6000c61798] with tag: null
2024-04-24T07:36:35,104  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
2024-04-24T07:36:35,105  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:36:35,107  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1
2024-04-24T07:36:35,107  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,106  WARN [Thread-107] mapred.LocalJobRunner: job_local2097071004_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:36:35,107  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 07:36:35,107 Stage-1 map = 0%,  reduce = 0%2024-04-24T07:36:35,107  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002/_tmp.000000_0

2024-04-24T07:36:35,107  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: 2024-04-24 07:36:35,107 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,107  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,108  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1 operation was queued
2024-04-24T07:36:35,108  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-2
2024-04-24T07:36:35,109  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-2 operation was queued
2024-04-24T07:36:35,109  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:35,110  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1
2024-04-24T07:36:35,110  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:35,110  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-2
2024-04-24T07:36:35,111  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
Ended Job = job_local2097071004_0002 with errors
2024-04-24T07:36:35,112 ERROR [HiveServer2-Background-Pool: Thread-114] exec.Task: Ended Job = job_local2097071004_0002 with errors
2024-04-24T07:36:35,112  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d without delay
2024-04-24T07:36:35,113  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=096aa143-42c4-4d96-89c9-c449c71c0885]
2024-04-24T07:36:35,114  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Removed queryId: alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=096aa143-42c4-4d96-89c9-c449c71c0885] with tag: null
2024-04-24T07:36:35,114  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
2024-04-24T07:36:35,116  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Shutting down task : Stage-1:MAPRED
Error during job, obtaining debugging information...
2024-04-24T07:36:35,120 ERROR [Thread-217] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:36:35,120  WARN [Thread-211] mapred.LocalJobRunner: job_local75439565_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:36:35,121  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-5
2024-04-24T07:36:35,121  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-5 operation was queued
2024-04-24T07:36:35,121  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1
2024-04-24T07:36:35,121  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1 operation was queued
2024-04-24T07:36:35,121  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:35,122  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,122  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 without delay
2024-04-24T07:36:35,122  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=681cc599-63aa-4de3-84d4-e3a56ced45ae]
2024-04-24T07:36:35,122  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-5
2024-04-24T07:36:35,122  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Removed queryId: alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=681cc599-63aa-4de3-84d4-e3a56ced45ae] with tag: null
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:36:35,123  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
2024-04-24T07:36:35,124  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T07:36:35,124  WARN [HiveServer2-Background-Pool: Thread-229] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:35,124  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_tmp.-ext-10002/000000_0
2024-04-24 07:36:35,120 Stage-1 map = 0%,  reduce = 0%2024-04-24T07:36:35,124  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1

2024-04-24T07:36:35,125  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,125  INFO [HiveServer2-Background-Pool: Thread-229] exec.Task: 2024-04-24 07:36:35,120 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,125  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,127  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-3
2024-04-24T07:36:35,128  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-3 operation was queued
2024-04-24T07:36:35,127  WARN [Thread-144] mapred.LocalJobRunner: job_local259001027_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:36:35,128  WARN [HiveServer2-Background-Pool: Thread-229] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:35,128  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1
2024-04-24T07:36:35,128  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1 operation was queued
2024-04-24T07:36:35,128  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:35,129  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-3
2024-04-24T07:36:35,129  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
Ended Job = job_local75439565_0005 with errors
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:36:35,134  WARN [HiveServer2-Background-Pool: Thread-146] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 07:36:35,134 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,133  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1
2024-04-24T07:36:35,138 ERROR [HiveServer2-Background-Pool: Thread-229] exec.Task: Ended Job = job_local75439565_0005 with errors
2024-04-24T07:36:35,143  INFO [HiveServer2-Background-Pool: Thread-146] exec.Task: 2024-04-24 07:36:35,134 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,138  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,149  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b without delay
2024-04-24T07:36:35,149  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=df69e4a2-3561-4138-ace8-75e5d1c21635]
2024-04-24T07:36:35,149  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Removed queryId: alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=df69e4a2-3561-4138-ace8-75e5d1c21635] with tag: null
2024-04-24T07:36:35,149  WARN [HiveServer2-Background-Pool: Thread-146] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:35,150  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1
Ended Job = job_local259001027_0003 with errors
2024-04-24T07:36:35,150 ERROR [HiveServer2-Background-Pool: Thread-146] exec.Task: Ended Job = job_local259001027_0003 with errors
2024-04-24T07:36:35,150  INFO [HiveServer2-Background-Pool: Thread-114] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:36:35,151  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,151  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,151 ERROR [HiveServer2-Background-Pool: Thread-114] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:36:35,153  INFO [HiveServer2-Background-Pool: Thread-114] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:35,153  INFO [HiveServer2-Background-Pool: Thread-114] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:35,153  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:36:35,155 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:36:35,156  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:35,157  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:36:35,157  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T07:36:35,157  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:35,157  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,157  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:35,158  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,158  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:35,171  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:36:35,171  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,171  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,172  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1 operation was queued
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
Error during job, obtaining debugging information...
2024-04-24T07:36:35,172 ERROR [Thread-222] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 without delay
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=37d9d0bd-59b0-4793-81ea-673a2b7c02fd]
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.OperationManager: Removed queryId: alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=37d9d0bd-59b0-4793-81ea-673a2b7c02fd] with tag: null
2024-04-24T07:36:35,172  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2
2024-04-24T07:36:35,173  WARN [HiveServer2-Background-Pool: Thread-188] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 07:36:35,173 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,174  INFO [HiveServer2-Background-Pool: Thread-188] exec.Task: 2024-04-24 07:36:35,173 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:35,174  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-26_108_555834966007884083-1
2024-04-24T07:36:35,176  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-04-24T07:36:35,176  WARN [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Driver: Shutting down task : Stage-1:MAPRED
Error during job, obtaining debugging information...
2024-04-24T07:36:35,177  WARN [Thread-180] mapred.LocalJobRunner: job_local1974603530_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:36:35,177  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1
2024-04-24T07:36:35,177 ERROR [Thread-221] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:36:35,177  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1 operation was queued
2024-04-24T07:36:35,177  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,178  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,178  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,178  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-4
2024-04-24T07:36:35,178  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-4 operation was queued
2024-04-24T07:36:35,179  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1
2024-04-24T07:36:35,179  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:35,179  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:36:35,179  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-4
2024-04-24T07:36:35,180  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2 without delay
2024-04-24T07:36:35,181  INFO [a3de53ec-7f2f-451e-8102-79aa36436258 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:36:35,186  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,187  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,187  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Executing command(queryId=alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d) has been interrupted after 1.39 seconds
2024-04-24T07:36:35,190  WARN [HiveServer2-Background-Pool: Thread-114] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:36:35,191  INFO [HiveServer2-Background-Pool: Thread-114] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:35,193  INFO [HiveServer2-Background-Pool: Thread-229] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:36:35,193 ERROR [HiveServer2-Background-Pool: Thread-229] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:36:35,194  INFO [HiveServer2-Background-Pool: Thread-229] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:35,194  INFO [HiveServer2-Background-Pool: Thread-229] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:35,194  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:36:35,196  INFO [HiveServer2-Background-Pool: Thread-146] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:36:35,197 ERROR [HiveServer2-Background-Pool: Thread-146] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:36:35,198  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a3de53ec-7f2f-451e-8102-79aa36436258 operation was queued
2024-04-24T07:36:35,198  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258 operation was queued
2024-04-24T07:36:35,200  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a3de53ec-7f2f-451e-8102-79aa36436258
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:36:35,201  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,201  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,201  INFO [HiveServer2-Background-Pool: Thread-229] ql.Driver: Executing command(queryId=alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71) has been interrupted after 0.615 seconds
2024-04-24T07:36:35,202  INFO [HiveServer2-Background-Pool: Thread-146] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:35,202  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258
2024-04-24T07:36:35,202  WARN [HiveServer2-Background-Pool: Thread-229] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:36:35,202  INFO [HiveServer2-Background-Pool: Thread-146] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:35,202  INFO [HiveServer2-Background-Pool: Thread-229] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:35,202  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:36:35,203  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,203  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:35,202  WARN [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Caught exception while closing operator
org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1461) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:686) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:187) [classes/:?]
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37) [classes/:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) [hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
2024-04-24T07:36:35,203  WARN [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Caught exception while closing operator
org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1461) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:686) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:187) [classes/:?]
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37) [classes/:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) [hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
2024-04-24T07:36:35,203  WARN [LocalJobRunner Map Task Executor #0] exec.MapOperator: Caught exception while closing operator
org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1461) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:686) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:708) [classes/:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:187) [classes/:?]
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37) [classes/:?]
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) [hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_506_5202768914093765110-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_506_5202768914093765110-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64) ~[classes/:?]
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890) ~[classes/:?]
	... 16 more
2024-04-24T07:36:35,203  INFO [HiveServer2-Background-Pool: Thread-146] ql.Driver: Executing command(queryId=alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b) has been interrupted after 1.153 seconds
2024-04-24T07:36:35,208  WARN [HiveServer2-Background-Pool: Thread-146] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:36:35,210  INFO [HiveServer2-Background-Pool: Thread-146] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:35,211 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:303)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:405)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:36:35,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:35,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:36:35,211 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:36:35,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:35,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:0, DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:35,211  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:36:35,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-33_764_7183833996967948331-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-33_764_7183833996967948331-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,213  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,213  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,213  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_327_4930393437977879091-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_327_4930393437977879091-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,215 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:561)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:36:35,215  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:35,215  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:36:35,215  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,215  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:35,216  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/a3de53ec-7f2f-451e-8102-79aa36436258/hive_2024-04-24_07-36-34_045_7545319561853144498-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-34_045_7545319561853144498-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:35,219  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:35,220  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7af1d072 will be shutdown
2024-04-24T07:36:35,220  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:35,220  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.6">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T07:36:35,254  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_0:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,254  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, RECORDS_OUT_OPERATOR_FS_2:1, 
2024-04-24T07:36:35,261  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_0:0, RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:36:35,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:36:35,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:36:35,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:36:35,328  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:36:35,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:36:35,328  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:36:35,329  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
Hive Session ID = 37d40e6d-944c-4d1d-a02b-6be240fc702e
2024-04-24T07:36:35,329  INFO [main] SessionState: Hive Session ID = 37d40e6d-944c-4d1d-a02b-6be240fc702e
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:35,330  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:35,340  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37d40e6d-944c-4d1d-a02b-6be240fc702e
2024-04-24T07:36:35,342  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/37d40e6d-944c-4d1d-a02b-6be240fc702e
2024-04-24T07:36:35,346  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37d40e6d-944c-4d1d-a02b-6be240fc702e/_tmp_space.db
2024-04-24T07:36:35,347  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=37d40e6d-944c-4d1d-a02b-6be240fc702e, clientType=HIVESERVER2]
2024-04-24T07:36:35,348  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:35,350  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:35,350  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:35,351  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: null will be shutdown
2024-04-24T07:36:35,352  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 created in the thread with id: 1
2024-04-24T07:36:35,356  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148 from thread id: 1
2024-04-24T07:36:35,357  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:35,357  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:35,358  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:36:35,358  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:36:35,358  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:36:35,358  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:36:35,358  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:36:35,359  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:36:35,362  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:36:35,363  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:36:35,376  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:36:35,377  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:35,378  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:35,386  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:35,390  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:35,393  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/85f5403f-d42e-45f7-8910-57b0a23e8abc/_tmp_space.db
2024-04-24T07:36:35,393  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:36:35,393  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:36:35,393  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:35,393  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 will be shutdown
2024-04-24T07:36:35,394  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:35,394  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T07:36:35,394  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:35,394  INFO [main] service.CompositeService: Session opened, SessionHandle [85f5403f-d42e-45f7-8910-57b0a23e8abc], current sessions:1
2024-04-24T07:36:35,394  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:36:35,394  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:35,396  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=1a3c246a-4c3d-4ddc-b957-71aa19fde663] SessionHandle [85f5403f-d42e-45f7-8910-57b0a23e8abc]
2024-04-24T07:36:35,396  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, alwaysWriteExceptions="null", disableAnsi="null", charset="null", header="null", footer="null", Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", Replace=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", Configuration(HiveLog4j2Test), alwaysWriteExceptions="null", header="null", Replace=null, PatternSelector=null, footer="null", noConsoleNoAnsi="null", pattern="%-5p : %m%n", charset="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199.test
2024-04-24T07:36:35,406  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199, startTime=1713969395395, sessionId=85f5403f-d42e-45f7-8910-57b0a23e8abc, createTime=1713969395377, userName=anonymous, ipAddress=null]
2024-04-24T07:36:35,407  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Compiling command(queryId=alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:35,408  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:35,409  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:35,409  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:35,410  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@448fa659, with PersistenceManager: null will be shutdown
2024-04-24T07:36:35,411  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@448fa659, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45c28c49 created in the thread with id: 1
2024-04-24T07:36:35,418  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@448fa659 from thread id: 1
2024-04-24T07:36:35,418  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:35,419  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:35,419  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199
2024-04-24T07:36:35,419  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=85f5403f-d42e-45f7-8910-57b0a23e8abc, clientType=HIVESERVER2]
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:35,420  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:35,451  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:35,545  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:35,545  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:35,551  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:35,551  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:35,553  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-35_406_893615005257434188-1
2024-04-24T07:36:35,559  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:35,563  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:35,564  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:35,578  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:35,581  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:35,581  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:35,581  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=9, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T07:36:35,582  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Completed compiling command(queryId=alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199); Time taken: 0.174 seconds
2024-04-24T07:36:35,582  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:35,583  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:36:35,584  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:35,584  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Executing command(queryId=alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:35,585  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:36:35,585  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:35,585  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001
2024-04-24T07:36:35,585  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001
2024-04-24T07:36:35,586  WARN [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199
2024-04-24T07:36:35,586  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Query ID = alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199
Total jobs = 1
2024-04-24T07:36:35,586  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:35,586  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:35,800  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:35,801  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:35,804  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:35,804  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:35,804  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/dummy_path
2024-04-24T07:36:35,818  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:35,819  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:35,820  WARN [85f5403f-d42e-45f7-8910-57b0a23e8abc main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:35,827  WARN [85f5403f-d42e-45f7-8910-57b0a23e8abc main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:35,839  WARN [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:35,844  WARN [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:35,845  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:35,847  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/dummy_path
2024-04-24T07:36:35,855  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:35,855  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:35,856  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:35,882  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:35,913  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1938237902_0006
2024-04-24T07:36:35,913  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:35,989  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:35,989  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:35,989  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:35,989  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:35,991  INFO [Thread-296] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:35,992  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1938237902_0006_m_000000_0
2024-04-24T07:36:35,995  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:35,996  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:36,001  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:36,003  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:36,003  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:36,006  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:36,006  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:36,007  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:36,007  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:36,007  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:36,007  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:36,008  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@a3b6c67, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@34aae073, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@162d184a
2024-04-24T07:36:36,008  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-35_406_893615005257434188-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:36,008  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-35_406_893615005257434188-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:36,009  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-35_406_893615005257434188-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T07:36:36,021  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:36,022  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:36,022  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, RECORDS_OUT_OPERATOR_FS_2:1, 
2024-04-24T07:36:36,023  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:36:36,026  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1938237902_0006_m_000000_0 is done. And is in the process of committing
2024-04-24T07:36:36,027  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:36:36,027  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1938237902_0006_m_000000_0' done.
2024-04-24T07:36:36,027  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1938237902_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33472
		FILE: Number of bytes written=6928463
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=340
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=981991424
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:36:36,027  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1938237902_0006_m_000000_0
2024-04-24T07:36:36,028  INFO [Thread-296] mapred.LocalJobRunner: map task executor complete.
2024-04-24T07:36:36,176  WARN [HiveServer2-Background-Pool: Thread-188] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1974603530_0004 with errors
2024-04-24T07:36:36,177 ERROR [HiveServer2-Background-Pool: Thread-188] exec.Task: Ended Job = job_local1974603530_0004 with errors
Error during job, obtaining debugging information...
2024-04-24T07:36:36,178 ERROR [Thread-303] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:36:36,184  INFO [HiveServer2-Background-Pool: Thread-188] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:36:36,184 ERROR [HiveServer2-Background-Pool: Thread-188] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:36:36,184  INFO [HiveServer2-Background-Pool: Thread-188] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:36,185  INFO [HiveServer2-Background-Pool: Thread-188] metadata.Hive: Total time spent in each metastore function (ms): {close_()=1}
MapReduce Jobs Launched: 
2024-04-24T07:36:36,185  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:36:36,185  WARN [HiveServer2-Background-Pool: Thread-188] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:36:36,186  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:36,186  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:36,186  INFO [HiveServer2-Background-Pool: Thread-188] ql.Driver: Executing command(queryId=alex_20240424073634_c9c5ddbe-8931-4794-b8e7-e3fd271795c2) has been interrupted after 1.873 seconds
2024-04-24T07:36:36,186  WARN [HiveServer2-Background-Pool: Thread-188] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:36:36,187  INFO [HiveServer2-Background-Pool: Thread-188] common.LogUtils: Unregistered logging context.
2024-04-24 07:36:36,992 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:36:36,992  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Task: 2024-04-24 07:36:36,992 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1938237902_0006
2024-04-24T07:36:36,994  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.Task: Ended Job = job_local1938237902_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:36,998  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:36:36,998  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:36,998  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001
2024-04-24T07:36:36,998  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1/-mr-10001
2024-04-24T07:36:36,998  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:36,999  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:36,999  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:36:36,999  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:36,999  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:36,999  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Completed executing command(queryId=alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199); Time taken: 1.414 seconds
2024-04-24T07:36:37,001  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:37,001  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:36:37,003  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4a2d200e-dcd0-4960-ac7f-2fe17fb3d51b] SessionHandle [85f5403f-d42e-45f7-8910-57b0a23e8abc]
2024-04-24T07:36:37,003  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, header="null", alwaysWriteExceptions="null", disableAnsi="null", footer="null", charset="null", noConsoleNoAnsi="null", pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, noConsoleNoAnsi="null", Replace=null, footer="null", alwaysWriteExceptions="null", header="null", Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", disableAnsi="null", charset="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd.test
2024-04-24T07:36:37,011  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd, startTime=1713969397001, sessionId=85f5403f-d42e-45f7-8910-57b0a23e8abc, createTime=1713969395377, userName=anonymous, ipAddress=null]
2024-04-24T07:36:37,014  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Compiling command(queryId=alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:36:37,018  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd
2024-04-24T07:36:37,018  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:37,019  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-04-24T07:36:37,020  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T07:36:37,228  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] reflections.Reflections: Reflections took 193 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:36:37,340  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd
2024-04-24T07:36:37,340  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:37,341  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T07:36:37,341  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:37,341  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=12, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T07:36:37,342  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Completed compiling command(queryId=alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd); Time taken: 0.327 seconds
2024-04-24T07:36:37,343  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:37,343  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T07:36:37,343  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Executing command(queryId=alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:36:37,344  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-04-24T07:36:37,344  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T07:36:37,345  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:36:37,345  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:36:37,346  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T07:36:37,538  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1713969397, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFilesErasureCoded=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, rawDataSize=0, totalSize=0, bucketing_version=2, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:36:37,835  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-04-24T07:36:37,835  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T07:36:37,835  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:36:37,835  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:36:37,836  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:37,836  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, createTable_(Table)=297}
2024-04-24T07:36:37,836  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Driver: Completed executing command(queryId=alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd); Time taken: 0.493 seconds
2024-04-24T07:36:37,837  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:37,838  INFO [main] service.CompositeService: Session closed, SessionHandle [85f5403f-d42e-45f7-8910-57b0a23e8abc], current sessions:0
2024-04-24T07:36:37,838  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=1a3c246a-4c3d-4ddc-b957-71aa19fde663]
2024-04-24T07:36:37,838  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Removed queryId: alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=1a3c246a-4c3d-4ddc-b957-71aa19fde663] with tag: null
2024-04-24T07:36:37,839  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1
2024-04-24T07:36:37,839  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1 operation was queued
2024-04-24T07:36:37,839  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:37,839  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:37,840  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073635_2bdcde3a-2b73-4df7-9a32-db23d6137199 without delay
2024-04-24T07:36:37,840  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4a2d200e-dcd0-4960-ac7f-2fe17fb3d51b]
2024-04-24T07:36:37,840  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.OperationManager: Removed queryId: alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4a2d200e-dcd0-4960-ac7f-2fe17fb3d51b] with tag: null
2024-04-24T07:36:37,840  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc/alex_20240424073637_ec69f10e-16a8-4047-9756-b82bb07bc1dd without delay
2024-04-24T07:36:37,840  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc/hive_2024-04-24_07-36-35_406_893615005257434188-1
2024-04-24T07:36:37,841  INFO [85f5403f-d42e-45f7-8910-57b0a23e8abc main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:37,842  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/85f5403f-d42e-45f7-8910-57b0a23e8abc operation was queued
2024-04-24T07:36:37,843  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc operation was queued
2024-04-24T07:36:37,843  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:37,843  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/85f5403f-d42e-45f7-8910-57b0a23e8abc
2024-04-24T07:36:37,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:37,844  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@448fa659, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45c28c49 will be shutdown
2024-04-24T07:36:37,845  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:37,845  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.548">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T07:36:37,920  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:36:37,920  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:36:37,920  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:36:37,920  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:36:37,920  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:36:37,921  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
Hive Session ID = 393a3f00-a6b5-4eef-92bf-e20e9ffd946c
2024-04-24T07:36:37,922  INFO [main] SessionState: Hive Session ID = 393a3f00-a6b5-4eef-92bf-e20e9ffd946c
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:37,922  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:37,930  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/393a3f00-a6b5-4eef-92bf-e20e9ffd946c
2024-04-24T07:36:37,934  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/393a3f00-a6b5-4eef-92bf-e20e9ffd946c
2024-04-24T07:36:37,937  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/393a3f00-a6b5-4eef-92bf-e20e9ffd946c/_tmp_space.db
2024-04-24T07:36:37,938  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=393a3f00-a6b5-4eef-92bf-e20e9ffd946c, clientType=HIVESERVER2]
2024-04-24T07:36:37,940  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:37,941  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:37,941  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:37,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@148f94dc, with PersistenceManager: null will be shutdown
2024-04-24T07:36:37,942  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@148f94dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f11d889 created in the thread with id: 1
2024-04-24T07:36:37,956  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@148f94dc from thread id: 1
2024-04-24T07:36:37,956  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:37,957  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:37,957  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:36:37,957  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:36:37,957  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:36:37,957  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:36:37,957  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:36:37,959  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T07:36:37,961  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T07:36:37,961  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:36:37,961  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:36:37,961  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:36:37,961  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:36:37,962  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:36:37,962  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:36:37,972  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:36:37,972  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:37,974  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:36:37,983  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:37,987  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:37,990  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42a7c8c8-4124-44d1-946f-512ef3520b0d/_tmp_space.db
2024-04-24T07:36:37,990  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:36:37,990  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:36:37,990  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:37,990  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@148f94dc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f11d889 will be shutdown
2024-04-24T07:36:37,991  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:37,991  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T07:36:37,991  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:37,991  INFO [main] service.CompositeService: Session opened, SessionHandle [42a7c8c8-4124-44d1-946f-512ef3520b0d], current sessions:1
2024-04-24T07:36:37,991  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:36:37,991  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:37,993  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=49ebb49a-0585-4052-8e82-9aacb4b2166d] SessionHandle [42a7c8c8-4124-44d1-946f-512ef3520b0d]
2024-04-24T07:36:37,993  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", noConsoleNoAnsi="null", PatternSelector=null, header="null", Configuration(HiveLog4j2Test), footer="null", alwaysWriteExceptions="null", pattern="%-5p : %m%n", Replace=null, disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Configuration(HiveLog4j2Test), PatternSelector=null, footer="null", noConsoleNoAnsi="null", header="null", alwaysWriteExceptions="null", Replace=null, disableAnsi="null", charset="null", pattern="%-5p : %m%n")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477.test
2024-04-24T07:36:38,002  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477, startTime=1713969397991, sessionId=42a7c8c8-4124-44d1-946f-512ef3520b0d, createTime=1713969397972, userName=anonymous, ipAddress=null]
2024-04-24T07:36:38,003  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Compiling command(queryId=alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:38,005  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:36:38,006  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:36:38,006  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:36:38,007  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f3a92fd, with PersistenceManager: null will be shutdown
2024-04-24T07:36:38,007  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f3a92fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e111e08 created in the thread with id: 1
2024-04-24T07:36:38,012  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f3a92fd from thread id: 1
2024-04-24T07:36:38,012  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:36:38,013  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:36:38,013  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477
2024-04-24T07:36:38,014  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:38,014  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=42a7c8c8-4124-44d1-946f-512ef3520b0d, clientType=HIVESERVER2]
2024-04-24T07:36:38,014  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:38,015  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:38,015  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:38,015  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:38,016  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:38,044  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:38,210  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:38,211  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:38,221  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:38,221  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:38,223  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-38_003_4747571068731161813-1
2024-04-24T07:36:38,229  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:38,232  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:38,233  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477
2024-04-24T07:36:38,250  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:38,251  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:38,252  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:38,252  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:38,252  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=82}
2024-04-24T07:36:38,253  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Completed compiling command(queryId=alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477); Time taken: 0.249 seconds
2024-04-24T07:36:38,253  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:38,253  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Executing command(queryId=alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001
2024-04-24T07:36:38,254  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001
2024-04-24T07:36:38,255  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477
2024-04-24T07:36:38,255  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Query ID = alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477
Total jobs = 1
2024-04-24T07:36:38,255  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:38,255  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:38,469  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:38,469  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:38,472  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:38,472  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:38,472  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/dummy_path
2024-04-24T07:36:38,487  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:38,488  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
DEBUG StatusLogger Removing appender alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
DEBUG StatusLogger Removing appender alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
DEBUG StatusLogger Deleting route with alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 key 
DEBUG StatusLogger Deleting route with alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 key 
DEBUG StatusLogger Stopping route with alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 key
DEBUG StatusLogger Stopping route with alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608 key
2024-04-24T07:36:38,489  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073626_78879b55-9753-4506-bdeb-47623782c608.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-04-24T07:36:38,497  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:38,508  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:38,516  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:38,517  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:38,519  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/dummy_path
2024-04-24T07:36:38,524  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:38,524  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:38,525  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:38,549  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:38,571  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.JobSubmitter: Submitting tokens for job: job_local453646297_0007
2024-04-24T07:36:38,571  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:38,661  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:36:38,662  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:36:38,662  INFO [Thread-346] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:38,662  INFO [Thread-346] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:38,664  INFO [Thread-346] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:38,664  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local453646297_0007_m_000000_0
2024-04-24T07:36:38,668  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:38,669  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:38,672  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:38,673  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:36:38,673  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:38,680  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:38,680  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:38,682  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:38,682  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:38,682  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:38,682  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:38,683  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@507df4d7, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@2123cf03, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@4991836d
2024-04-24T07:36:38,684  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-38_003_4747571068731161813-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:38,684  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-38_003_4747571068731161813-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:38,684  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-38_003_4747571068731161813-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:38,696  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:38,696  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:36:38,696  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:38,696  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:36:38,697  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_0:1, 
2024-04-24T07:36:38,698  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:36:38,702  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local453646297_0007_m_000000_0 is done. And is in the process of committing
2024-04-24T07:36:38,703  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:36:38,703  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local453646297_0007_m_000000_0' done.
2024-04-24T07:36:38,703  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local453646297_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39058
		FILE: Number of bytes written=8080833
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=983040000
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:36:38,703  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local453646297_0007_m_000000_0
2024-04-24T07:36:38,704  INFO [Thread-346] mapred.LocalJobRunner: map task executor complete.
2024-04-24 07:36:39,666 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:36:39,666  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Task: 2024-04-24 07:36:39,666 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local453646297_0007
2024-04-24T07:36:39,667  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.Task: Ended Job = job_local453646297_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:36:39,669  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:36:39,669  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:39,669  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001
2024-04-24T07:36:39,669  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1/-mr-10001
2024-04-24T07:36:39,669  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:39,670  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:39,670  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:36:39,670  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:39,670  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:39,670  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Completed executing command(queryId=alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477); Time taken: 1.415 seconds
2024-04-24T07:36:39,671  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:39,671  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:36:39,673  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=08e4dbee-dc4c-4f29-b386-d46cddd518a4] SessionHandle [42a7c8c8-4124-44d1-946f-512ef3520b0d]
2024-04-24T07:36:39,673  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", Replace=null, PatternSelector=null, footer="null", Configuration(HiveLog4j2Test), alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", charset="null", header="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(footer="null", header="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test), charset="null", disableAnsi="null", Replace=null, alwaysWriteExceptions="null", PatternSelector=null, noConsoleNoAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3.test
2024-04-24T07:36:39,684  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3, startTime=1713969399671, sessionId=42a7c8c8-4124-44d1-946f-512ef3520b0d, createTime=1713969397972, userName=anonymous, ipAddress=null]
2024-04-24T07:36:39,687  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Compiling command(queryId=alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Starting caching scope for: alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:39,689  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:36:39,717  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:39,841  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:36:39,841  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:36:39,845  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:36:39,846  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:36:39,847  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1
2024-04-24T07:36:39,855  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:36:39,862  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:36:39,863  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:36:39,878  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:36:39,879  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:36:39,879  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] parse.CalcitePlanner: Ending caching scope for: alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
2024-04-24T07:36:39,879  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:36:39,879  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:36:39,881  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:36:39,882  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:36:39,882  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=11, isCompatibleWith_(Configuration)=1}
2024-04-24T07:36:39,883  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Completed compiling command(queryId=alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3); Time taken: 0.195 seconds
2024-04-24T07:36:39,884  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] common.LogUtils: Unregistered logging context.
2024-04-24T07:36:39,884  INFO [HiveServer2-Background-Pool: Thread-439] common.LogUtils: Thread context registration is done.
2024-04-24T07:36:39,884  INFO [HiveServer2-Background-Pool: Thread-439] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:36:39,885  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:36:39,886  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Executing command(queryId=alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:36:39,886  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-04-24T07:36:39,886  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:36:39,886  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001
2024-04-24T07:36:39,887  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001
2024-04-24T07:36:39,887  WARN [HiveServer2-Background-Pool: Thread-439] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
2024-04-24T07:36:39,887  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Query ID = alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
Total jobs = 1
2024-04-24T07:36:39,887  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:36:39,887  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:36:40,004  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:40,004  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:36:40,011  INFO [HiveServer2-Background-Pool: Thread-439] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:36:40,012  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:36:40,012  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/dummy_path
2024-04-24T07:36:40,025  INFO [HiveServer2-Background-Pool: Thread-439] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:36:40,026  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:40,028  WARN [HiveServer2-Background-Pool: Thread-439] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:40,036  WARN [HiveServer2-Background-Pool: Thread-439] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:36:40,044  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:36:40,051  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:36:40,052  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:36:40,053  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/dummy_path
2024-04-24T07:36:40,059  INFO [HiveServer2-Background-Pool: Thread-439] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:36:40,059  INFO [HiveServer2-Background-Pool: Thread-439] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:36:40,059  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:36:40,082  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:36:40,106  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: Submitting tokens for job: job_local1098599312_0008
2024-04-24T07:36:40,106  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:36:40,190  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
DEBUG StatusLogger Removing appender alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
DEBUG StatusLogger Removing appender alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
2024-04-24T07:36:40,191  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:36:40,191  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: Job running in-process (local Hadoop)
DEBUG StatusLogger Deleting route with alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d key 
DEBUG StatusLogger Deleting route with alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d key 
DEBUG StatusLogger Stopping route with alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d key
DEBUG StatusLogger Stopping route with alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d key
2024-04-24T07:36:40,191  INFO [Thread-385] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_a3f04ad3-6412-4b95-a93f-66663eb44c1d, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
2024-04-24T07:36:40,193  INFO [Thread-385] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:36:40,193  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1098599312_0008_m_000000_0
2024-04-24T07:36:40,195  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:36:40,196  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:36:40,197  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:36:40,198  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:36:40,198  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:36:40,198  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:36:40,199  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:36:40,199  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:36:40,199  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:36:40,199  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:36:40,200  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:36:40,200  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@65e56d3f, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@9ff5b82, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@73c634e8
DEBUG StatusLogger Removing appender alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
DEBUG StatusLogger Removing appender alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
DEBUG StatusLogger Deleting route with alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 key 
DEBUG StatusLogger Deleting route with alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 key 
DEBUG StatusLogger Stopping route with alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 key
DEBUG StatusLogger Stopping route with alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71 key
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073634_e4bff05d-270d-47b7-beb7-361870d69a71.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
DEBUG StatusLogger Removing appender alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
DEBUG StatusLogger Removing appender alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
DEBUG StatusLogger Deleting route with alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b key 
DEBUG StatusLogger Deleting route with alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b key 
DEBUG StatusLogger Stopping route with alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b key
DEBUG StatusLogger Stopping route with alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b key
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/a3de53ec-7f2f-451e-8102-79aa36436258/alex_20240424073633_c2c72101-3942-4997-8075-87aacf176c0b.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-04-24T07:36:40,386  INFO [main] service.CompositeService: Session closed, SessionHandle [42a7c8c8-4124-44d1-946f-512ef3520b0d], current sessions:0
2024-04-24T07:36:40,386  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=49ebb49a-0585-4052-8e82-9aacb4b2166d]
2024-04-24T07:36:40,386  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Removed queryId: alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=49ebb49a-0585-4052-8e82-9aacb4b2166d] with tag: null
2024-04-24T07:36:40,386  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1
2024-04-24T07:36:40,386  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1 operation was queued
2024-04-24T07:36:40,386  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:40,387  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:40,387  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073637_cd165ced-f017-4440-aceb-49f6fefb4477 without delay
2024-04-24T07:36:40,387  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=08e4dbee-dc4c-4f29-b386-d46cddd518a4]
2024-04-24T07:36:40,387  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.OperationManager: Removed queryId: alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=08e4dbee-dc4c-4f29-b386-d46cddd518a4] with tag: null
2024-04-24T07:36:40,387  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3
2024-04-24T07:36:40,387  WARN [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-04-24T07:36:40,388  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:40,388  WARN [Thread-385] mapred.LocalJobRunner: job_local1098599312_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:36:40,388  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:40,388  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-38_003_4747571068731161813-1
2024-04-24T07:36:40,388  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:40,388  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:40,388  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1
2024-04-24 07:36:40,388 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:40,388  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: 2024-04-24 07:36:40,388 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:36:40,388  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1 operation was queued
2024-04-24T07:36:40,388  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-6
2024-04-24T07:36:40,389  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-6 operation was queued
2024-04-24T07:36:40,389  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:36:40,389  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:36:40,389  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:36:40,389  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d/alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3 without delay
2024-04-24T07:36:40,389  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1
Ended Job = job_local1098599312_0008 with errors
2024-04-24T07:36:40,389 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:36:40,389  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-6
2024-04-24T07:36:40,389 ERROR [HiveServer2-Background-Pool: Thread-439] exec.Task: Ended Job = job_local1098599312_0008 with errors
2024-04-24T07:36:40,389  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:36:40,389  INFO [42a7c8c8-4124-44d1-946f-512ef3520b0d main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:40,390  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:36:40,390  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:1, 
2024-04-24T07:36:40,390  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
Error during job, obtaining debugging information...
2024-04-24T07:36:40,391 ERROR [Thread-390] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T07:36:40,391  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42a7c8c8-4124-44d1-946f-512ef3520b0d operation was queued
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:36:40,391  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d operation was queued
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:40,391  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:40,391  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/42a7c8c8-4124-44d1-946f-512ef3520b0d
2024-04-24T07:36:40,391  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:36:40,392  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/42a7c8c8-4124-44d1-946f-512ef3520b0d/hive_2024-04-24_07-36-39_686_4050395920821048838-1/-mr-10001/.hive-staging_hive_2024-04-24_07-36-39_686_4050395920821048838-1/_tmp.-ext-10002/000000_0
2024-04-24T07:36:40,392  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:36:40,392  INFO [HiveServer2-Background-Pool: Thread-439] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-04-24T07:36:40,392  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f3a92fd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e111e08 will be shutdown
FAILED: Operation cancelled
2024-04-24T07:36:40,393 ERROR [HiveServer2-Background-Pool: Thread-439] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:36:40,393  INFO [HiveServer2-Background-Pool: Thread-439] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:36:40,393  INFO [HiveServer2-Background-Pool: Thread-439] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:36:40,393  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:36:40,393  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:36:40,393  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-04-24T07:36:40,393  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:36:40,394  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:40,394  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:36:40,394  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Executing command(queryId=alex_20240424073639_46e3ae81-11b2-442b-8471-02cc3b0968d3) has been interrupted after 0.507 seconds
]]></system-err>
  </testcase>
</testsuite>