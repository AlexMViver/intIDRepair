2024-04-24T12:40:17,267  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for TEST-CREATE_TOPIC-0
2024-04-24T12:40:17,300  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:17,314  INFO [data-plane-kafka-request-handler-1] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(TEST-CREATE_TOPIC-0)
2024-04-24T12:40:17,377  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:17,389  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562] Loading producer state till offset 0 with message format version 2
2024-04-24T12:40:17,394  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms
2024-04-24T12:40:17,396  INFO [data-plane-kafka-request-handler-1] log.LogManager: Created log for partition TEST-CREATE_TOPIC-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562/TEST-CREATE_TOPIC-0 with properties {message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, retention.bytes -> -1, preallocate -> false, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, unclean.leader.election.enable -> false, min.compaction.lag.ms -> 0, flush.ms -> 9223372036854775807, message.downconversion.enable -> true, delete.retention.ms -> 86400000, segment.index.bytes -> 10485760, segment.jitter.ms -> 0, min.cleanable.dirty.ratio -> 0.5, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, compression.type -> producer, max.compaction.lag.ms -> 9223372036854775807, cleanup.policy -> [delete], index.interval.bytes -> 4096, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.ms -> 604800000}.
2024-04-24T12:40:17,397  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] No checkpointed highwatermark is found for partition TEST-CREATE_TOPIC-0
2024-04-24T12:40:17,398  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] Log loaded for partition TEST-CREATE_TOPIC-0 with initial high watermark 0
2024-04-24T12:40:17,398  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] TEST-CREATE_TOPIC-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:40:17,420  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:17,420  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:17,420  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987617420
2024-04-24T12:40:17,427  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:17,429  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:17,440  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:17,448  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:17,448  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:17,448  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987617448
2024-04-24T12:40:17,458  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9290]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:17,492  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:17,492  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:17,492  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987617492
2024-04-24T12:40:17,494  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:40:17,499  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:17,499  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:17,501  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:17,501  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,505  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:17,514  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:17,514  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:17,514  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987617514
2024-04-24T12:40:17,516  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:6090]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 1000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 100
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 100
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:17,524  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:17,524  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:17,524  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987617524
2024-04-24T12:40:17,524  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:40:17,525  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:17,526  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,588  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:17,588  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,601  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:17,601  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,689  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:17,690  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,752  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:17,752  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,892  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:17,892  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:17,956  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:17,956  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:18,298  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:18,298  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:18,465  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:18,466  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:18,538 ERROR [main] kafka.SimpleKafkaWriter: WriterId [9584cd6b-01a0-41b0-9526-6e77dd537e00] lost record from Topic [t], delivery Semantic [AT_LEAST_ONCE] -> ACTION=ABORT, ERROR caused by [Topic t not present in metadata after 1000 ms.]
2024-04-24T12:40:18,541  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [9584cd6b-01a0-41b0-9526-6e77dd537e00]
2024-04-24T12:40:18,541  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [9584cd6b-01a0-41b0-9526-6e77dd537e00]
2024-04-24T12:40:18,541  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:40:18,548  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [9584cd6b-01a0-41b0-9526-6e77dd537e00] Delivery semantic [AT_LEAST_ONCE], Topic[t], Total sent Records [1], Total Lost Records [1]
2024-04-24T12:40:18,548 ERROR [main] kafka.SimpleKafkaWriter: Send Exception Aborting write from writerId [9584cd6b-01a0-41b0-9526-6e77dd537e00]
2024-04-24T12:40:18,549  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 0 ms.
2024-04-24T12:40:18,553  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:18,553  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:18,557  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:18,564  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:18,564  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:18,564  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987618564
2024-04-24T12:40:18,565  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:18,574  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:18,574  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:18,574  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987618574
2024-04-24T12:40:18,575  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [443009a5-d71f-4141-bfe0-bfb470bd4fee]
2024-04-24T12:40:18,596  INFO [data-plane-kafka-request-handler-2] zk.AdminZkClient: Creating topic 443009a5-d71f-4141-bfe0-bfb470bd4fee with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0))
2024-04-24T12:40:18,601  INFO [data-plane-kafka-request-handler-2] server.KafkaApis: [KafkaApi-0] Auto creation of topic 443009a5-d71f-4141-bfe0-bfb470bd4fee with 1 partitions and replication factor 1 is successful
2024-04-24T12:40:18,602  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New topics: [Set(443009a5-d71f-4141-bfe0-bfb470bd4fee)], deleted topics: [Set()], new partition replica assignment [Map(443009a5-d71f-4141-bfe0-bfb470bd4fee-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))]
2024-04-24T12:40:18,602  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for 443009a5-d71f-4141-bfe0-bfb470bd4fee-0
2024-04-24T12:40:18,611  WARN [kafka-producer-network-thread | producer-3] clients.NetworkClient: [Producer clientId=producer-3] Error while fetching metadata with correlation id 1 : {443009a5-d71f-4141-bfe0-bfb470bd4fee=LEADER_NOT_AVAILABLE}
2024-04-24T12:40:18,611  INFO [data-plane-kafka-request-handler-7] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(443009a5-d71f-4141-bfe0-bfb470bd4fee-0)
2024-04-24T12:40:18,612  INFO [kafka-producer-network-thread | producer-3] clients.Metadata: [Producer clientId=producer-3] Cluster ID: QB8_sWE-QWyoXCuujcHuyw
2024-04-24T12:40:18,615  INFO [data-plane-kafka-request-handler-7] log.Log: [Log partition=443009a5-d71f-4141-bfe0-bfb470bd4fee-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562] Loading producer state till offset 0 with message format version 2
2024-04-24T12:40:18,616  INFO [data-plane-kafka-request-handler-7] log.Log: [Log partition=443009a5-d71f-4141-bfe0-bfb470bd4fee-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms
2024-04-24T12:40:18,617  INFO [data-plane-kafka-request-handler-7] log.LogManager: Created log for partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-1802300163656124562/443009a5-d71f-4141-bfe0-bfb470bd4fee-0 with properties {flush.ms -> 9223372036854775807, unclean.leader.election.enable -> false, preallocate -> false, segment.jitter.ms -> 0, index.interval.bytes -> 4096, min.compaction.lag.ms -> 0, segment.bytes -> 1073741824, file.delete.delay.ms -> 60000, flush.messages -> 9223372036854775807, cleanup.policy -> [delete], message.downconversion.enable -> true, message.timestamp.difference.max.ms -> 9223372036854775807, delete.retention.ms -> 86400000, min.cleanable.dirty.ratio -> 0.5, compression.type -> producer, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.format.version -> 2.5-IV0, retention.bytes -> -1, segment.ms -> 604800000, max.message.bytes -> 1048588, retention.ms -> 604800000, segment.index.bytes -> 10485760, max.compaction.lag.ms -> 9223372036854775807}.
2024-04-24T12:40:18,617  INFO [data-plane-kafka-request-handler-7] cluster.Partition: [Partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 broker=0] No checkpointed highwatermark is found for partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0
2024-04-24T12:40:18,617  INFO [data-plane-kafka-request-handler-7] cluster.Partition: [Partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 broker=0] Log loaded for partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 with initial high watermark 0
2024-04-24T12:40:18,617  INFO [data-plane-kafka-request-handler-7] cluster.Partition: [Partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 broker=0] 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:40:18,869  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [2a524b30-2bbd-42b9-8350-e31ba70a8585]
2024-04-24T12:40:18,954  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [2a524b30-2bbd-42b9-8350-e31ba70a8585]
2024-04-24T12:40:18,954  INFO [main] producer.KafkaProducer: [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:40:18,959  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [2a524b30-2bbd-42b9-8350-e31ba70a8585] Delivery semantic [AT_LEAST_ONCE], Topic[443009a5-d71f-4141-bfe0-bfb470bd4fee], Total sent Records [17384], Total Lost Records [0]
2024-04-24T12:40:18,959  INFO [main] consumer.KafkaConsumer: [Consumer clientId=consumer-4, groupId=null] Subscribed to partition(s): 443009a5-d71f-4141-bfe0-bfb470bd4fee-0
2024-04-24T12:40:18,965  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Seeking to EARLIEST offset of partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0
2024-04-24T12:40:18,982  INFO [main] clients.Metadata: [Consumer clientId=consumer-4, groupId=null] Cluster ID: QB8_sWE-QWyoXCuujcHuyw
2024-04-24T12:40:19,002  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Resetting offset for partition 443009a5-d71f-4141-bfe0-bfb470bd4fee-0 to offset 0.
2024-04-24T12:40:19,220  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:19,220  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:19,408  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:19,409  INFO [main] server.KafkaServer: [KafkaServer id=0] shutting down
2024-04-24T12:40:19,409  INFO [main] server.KafkaServer: [KafkaServer id=0] Starting controlled shutdown
2024-04-24T12:40:19,418  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] Shutting down broker 0
2024-04-24T12:40:19,423  INFO [main] server.KafkaServer: [KafkaServer id=0] Controlled shutdown succeeded
2024-04-24T12:40:19,428  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutting down
2024-04-24T12:40:19,428  INFO [/config/changes-event-process-thread] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Stopped
2024-04-24T12:40:19,428  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutdown completed
2024-04-24T12:40:19,429  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopping socket server request processors
2024-04-24T12:40:19,437  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopped socket server request processors
2024-04-24T12:40:19,438  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shutting down
2024-04-24T12:40:19,439  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-04-24T12:40:19,442  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutting down
2024-04-24T12:40:19,600  INFO [ExpirationReaper-0-AlterAcls] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Stopped
2024-04-24T12:40:19,600  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-04-24T12:40:19,602  INFO [main] server.KafkaApis: [KafkaApi-0] Shutdown complete.
2024-04-24T12:40:19,603  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutting down
2024-04-24T12:40:19,689  INFO [ExpirationReaper-0-topic] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Stopped
2024-04-24T12:40:19,689  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutdown completed
2024-04-24T12:40:19,692  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutting down.
2024-04-24T12:40:19,694  INFO [main] transaction.ProducerIdManager: [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2024-04-24T12:40:19,695  INFO [main] transaction.TransactionStateManager: [Transaction State Manager 0]: Shutdown complete
2024-04-24T12:40:19,695  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutting down
2024-04-24T12:40:19,696  INFO [TxnMarkerSenderThread-0] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Stopped
2024-04-24T12:40:19,696  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutdown completed
2024-04-24T12:40:19,697  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutdown complete.
2024-04-24T12:40:19,697  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutting down.
2024-04-24T12:40:19,698  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutting down
2024-04-24T12:40:19,892  INFO [ExpirationReaper-0-Heartbeat] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Stopped
2024-04-24T12:40:19,892  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-04-24T12:40:19,894  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutting down
2024-04-24T12:40:20,093  INFO [ExpirationReaper-0-Rebalance] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Stopped
2024-04-24T12:40:20,093  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-04-24T12:40:20,095  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutdown complete.
2024-04-24T12:40:20,097  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shutting down
2024-04-24T12:40:20,097  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutting down
2024-04-24T12:40:20,098  INFO [LogDirFailureHandler] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Stopped
2024-04-24T12:40:20,098  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutdown completed
2024-04-24T12:40:20,099  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutting down
2024-04-24T12:40:20,102  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutdown completed
2024-04-24T12:40:20,103  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-04-24T12:40:20,104  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-04-24T12:40:20,104  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutting down
2024-04-24T12:40:20,187  INFO [ExpirationReaper-0-Fetch] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Stopped
2024-04-24T12:40:20,187  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutdown completed
2024-04-24T12:40:20,188  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutting down
2024-04-24T12:40:20,387  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutdown completed
2024-04-24T12:40:20,387  INFO [ExpirationReaper-0-Produce] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Stopped
2024-04-24T12:40:20,388  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-04-24T12:40:20,435  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:20,435  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:20,587  INFO [ExpirationReaper-0-DeleteRecords] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Stopped
2024-04-24T12:40:20,588  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-04-24T12:40:20,589  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutting down
2024-04-24T12:40:20,788  INFO [ExpirationReaper-0-ElectLeader] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Stopped
2024-04-24T12:40:20,788  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-04-24T12:40:20,794  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shut down completely
2024-04-24T12:40:20,796  INFO [main] log.LogManager: Shutting down.
2024-04-24T12:40:20,798  INFO [main] log.LogCleaner: Shutting down the log cleaner.
2024-04-24T12:40:20,799  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutting down
2024-04-24T12:40:20,799  INFO [kafka-log-cleaner-thread-0] log.LogCleaner: [kafka-log-cleaner-thread-0]: Stopped
2024-04-24T12:40:20,799  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutdown completed
2024-04-24T12:40:20,805  INFO [pool-9-thread-1] log.ProducerStateManager: [ProducerStateManager partition=443009a5-d71f-4141-bfe0-bfb470bd4fee-0] Writing producer snapshot at offset 17384
2024-04-24T12:40:20,826  INFO [main] log.LogManager: Shutdown complete.
2024-04-24T12:40:20,826  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutting down
2024-04-24T12:40:20,827  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutdown completed
2024-04-24T12:40:20,827  INFO [controller-event-thread] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Stopped
2024-04-24T12:40:20,830  INFO [main] controller.ZkPartitionStateMachine: [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-04-24T12:40:20,830  INFO [main] controller.ZkReplicaStateMachine: [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-04-24T12:40:20,830  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutting down
2024-04-24T12:40:20,830  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutdown completed
2024-04-24T12:40:20,830  INFO [Controller-0-to-broker-0-send-thread] controller.RequestSendThread: [RequestSendThread controllerId=0] Stopped
2024-04-24T12:40:20,833  INFO [main] controller.KafkaController: [Controller id=0] Resigned
2024-04-24T12:40:20,834  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closing.
2024-04-24T12:40:20,939  INFO [main] zookeeper.ZooKeeper: Session: 0x100096873e70000 closed
2024-04-24T12:40:20,941  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closed.
2024-04-24T12:40:20,942  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutting down
2024-04-24T12:40:21,368  INFO [ThrottledChannelReaper-Fetch] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Stopped
2024-04-24T12:40:21,368  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-04-24T12:40:21,368  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutting down
2024-04-24T12:40:21,498  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:21,498  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:22,368  INFO [ThrottledChannelReaper-Produce] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Stopped
2024-04-24T12:40:22,368  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutdown completed
2024-04-24T12:40:22,368  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutting down
2024-04-24T12:40:22,370  INFO [ThrottledChannelReaper-Request] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Stopped
2024-04-24T12:40:22,370  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutdown completed
2024-04-24T12:40:22,372  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutting down socket server
2024-04-24T12:40:22,393  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutdown completed
2024-04-24T12:40:22,396  INFO [main] server.KafkaServer: [KafkaServer id=0] shut down completed
2024-04-24T12:40:22,396  INFO [ConnnectionExpirer] server.NIOServerCnxnFactory: ConnnectionExpirerThread interrupted
2024-04-24T12:40:22,397  INFO [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0] server.NIOServerCnxnFactory: accept thread exitted run method
2024-04-24T12:40:22,397  INFO [NIOServerCxnFactory.SelectorThread-1] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:40:22,397  INFO [NIOServerCxnFactory.SelectorThread-0] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:40:22,398  INFO [main] server.ZooKeeperServer: shutting down
2024-04-24T12:40:22,398  INFO [main] server.SessionTrackerImpl: Shutting down
2024-04-24T12:40:22,398  INFO [main] server.PrepRequestProcessor: Shutting down
2024-04-24T12:40:22,398  INFO [main] server.SyncRequestProcessor: Shutting down
2024-04-24T12:40:22,398  INFO [ProcessThread(sid:0 cport:37309):] server.PrepRequestProcessor: PrepRequestProcessor exited loop!
2024-04-24T12:40:22,398  INFO [SyncThread:0] server.SyncRequestProcessor: SyncRequestProcessor exited!
2024-04-24T12:40:22,398  INFO [main] server.FinalRequestProcessor: shutdown of request processor complete
