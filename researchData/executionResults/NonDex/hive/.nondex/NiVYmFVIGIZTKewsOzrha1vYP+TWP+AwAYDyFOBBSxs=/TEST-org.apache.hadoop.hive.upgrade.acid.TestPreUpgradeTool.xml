<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="61.82" tests="6" errors="3" skipped="0" failures="2">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="nondexStart" value="0"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="Europe/Lisbon"/>
    <property name="user.country.format" value="PT"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="os.name" value="Linux"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire613189828883173225tmp surefire_39734786692482032131221tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="nondexExecid" value="NiVYmFVIGIZTKewsOzrha1vYP+TWP+AwAYDyFOBBSxs="/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="metastore.schema.verification" value="false"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="basedir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="file.separator" value="/"/>
    <property name="metastore.warehouse.dir" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/warehouse"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/derby.log"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="933178"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="javax.jdo.option.ConnectionURL" value="jdbc:derby:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/junit_metastore_db;create=true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="user.language.format" value="pt"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value=""/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="datanucleus.schema.autoCreateAll" value="true"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpgradeExternalTableNoReadPermissionForTable" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="10.717">
    <failure type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForTable(TestPreUpgradeTool.java:338)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2024-04-24T20:42:39,235  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-site.xml
2024-04-24T20:42:39,581  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:39,581  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:39,581  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:39,582  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:39,582  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:39,582  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:39,582  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:39,582  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:39,583  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:39,583  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:39,583  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:39,583  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:39,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:39,584  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:39,584  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:39,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:39,585  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:39,585  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:39,585  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:39,585  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:39,638  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:39,638  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:39,639  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:39,640  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:39,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:39,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:39,640  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:39,640  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:39,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:39,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:39,641  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:39,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:39,642  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:39,642  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:39,642  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:41,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:41,577  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:41,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:41,579  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:41,579  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:41,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:41,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:41,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:41,580  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:41,580  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:41,580  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:41,580  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:41,580  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:41,581  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:41,950  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T20:42:41,977  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af
2024-04-24T20:42:41,980  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af
2024-04-24T20:42:41,983  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db
2024-04-24T20:42:42,004  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=810f17e8-32cd-48d9-8479-d8ce125c00af, clientType=HIVECLI]
2024-04-24T20:42:42,005  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:42,485  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:42,486  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:42,487  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:42,488  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:42,488  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:42,506  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:42,916  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:42,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:42,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:42,917  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:42,917  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:42,917  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:42,918  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:42,920  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T20:42:44,063  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:44,065  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:44,117  WARN [main] metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2024-04-24T20:42:44,117  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T20:42:44,176  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2024-04-24T20:42:44,178  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2024-04-24T20:42:44,352  INFO [main] metastore.HiveMetaStore: 0: get_all_functions
2024-04-24T20:42:44,353  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T20:42:44,409  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): drop table if exists TExternal
2024-04-24T20:42:44,871  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:44,871  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:44,890  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:44,891  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:44,895  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:44,896  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 0.505 seconds
2024-04-24T20:42:44,899  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:44,899  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): drop table if exists TExternal
2024-04-24T20:42:45,003  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:45,004  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:45,004  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:45,007 ERROR [main] metadata.Hive: Table TExternal not found: default.TExternal table not found
2024-04-24T20:42:45,016  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:45,016  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:45,019  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:45,019  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 0.12 seconds
OK
2024-04-24T20:42:45,020  INFO [main] ql.Driver: OK
2024-04-24T20:42:45,020  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:45,021  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): create table TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:42:45,044  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:45,049  INFO [main] parse.CalcitePlanner: Creating table default.TExternal position=13
2024-04-24T20:42:45,058  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:45,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:45,062  INFO [main] metadata.HiveUtils: Adding metastore authorization provider: org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
2024-04-24T20:42:45,080  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:45,083  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:45,084  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:45,084  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 0.063 seconds
2024-04-24T20:42:45,084  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:45,087  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d)
2024-04-24T20:42:45,099  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:45,161  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:45,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:45,161  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:45,162  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:45,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:45,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:45,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:45,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:45,164  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:45,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:45,186  INFO [main] txn.TxnHandler: START========"HiveConf()"========
hiveDefaultUrl=null
hiveSiteURL=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-site.xml
hiveServer2SiteUrl=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hiveserver2-site.xml
hivemetastoreSiteUrl=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hivemetastore-site.xml
Values omitted for security reason if present: [javax.jdo.option.ConnectionPassword, hive.server2.keystore.password, fs.s3a.proxy.password, fs.s3.awsAccessKeyId, fs.s3n.awsSecretAccessKey, fs.s3n.awsAccessKeyId, fs.s3a.access.key, fs.s3a.secret.key, fs.s3.awsSecretAccessKey]
_hive.hdfs.session.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af:
_hive.local.session.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af:
_hive.tmp_table_space=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db
datanucleus.autoStartMechanismMode=ignored
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPool.maxPoolSize=4
datanucleus.connectionPoolingType=BONECP
datanucleus.identifierFactory=datanucleus1
datanucleus.plugin.pluginRegistryBundleCheck=LOG
datanucleus.rdbms.initializeColumnInfo=NONE
datanucleus.rdbms.useLegacyNativeValueStrategy=true
datanucleus.schema.autoCreateAll=true
datanucleus.schema.validateColumns=false
datanucleus.schema.validateConstraints=false
datanucleus.schema.validateTables=false
datanucleus.storeManagerType=rdbms
datanucleus.transactionIsolation=read-committed
dfs.ha.fencing.ssh.connect-timeout=30000
file.blocksize=67108864
file.bytes-per-checksum=512
file.client-write-packet-size=65536
file.replication=1
file.stream-buffer-size=4096
fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
fs.AbstractFileSystem.ftp.impl=org.apache.hadoop.fs.ftp.FtpFs
fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
fs.automatic.close=true
fs.client.resolve.remote.symlinks=true
fs.defaultFS=file:///
fs.df.interval=60000
fs.du.interval=600000
fs.ftp.host=0.0.0.0
fs.ftp.host.port=21
fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem
fs.har.impl.disable.cache=true
fs.permissions.umask-mode=022
fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem
fs.s3.block.size=67108864
fs.s3.buffer.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/s3
fs.s3.maxRetries=4
fs.s3.sleepTimeSeconds=10
fs.s3a.attempts.maximum=10
fs.s3a.buffer.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/s3a
fs.s3a.connection.establish.timeout=5000
fs.s3a.connection.maximum=15
fs.s3a.connection.ssl.enabled=true
fs.s3a.connection.timeout=50000
fs.s3a.fast.buffer.size=1048576
fs.s3a.fast.upload=false
fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
fs.s3a.max.total.tasks=1000
fs.s3a.multipart.purge=false
fs.s3a.multipart.purge.age=86400
fs.s3a.multipart.size=104857600
fs.s3a.multipart.threshold=2147483647
fs.s3a.paging.maximum=5000
fs.s3a.threads.core=15
fs.s3a.threads.keepalivetime=60
fs.s3a.threads.max=256
fs.s3n.block.size=67108864
fs.s3n.multipart.copy.block.size=5368709120
fs.s3n.multipart.uploads.block.size=67108864
fs.s3n.multipart.uploads.enabled=false
fs.scheme.class=dfs
fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
fs.trash.checkpoint.interval=0
fs.trash.interval=0
ftp.blocksize=67108864
ftp.bytes-per-checksum=512
ftp.client-write-packet-size=65536
ftp.replication=3
ftp.stream-buffer-size=4096
ha.failover-controller.cli-check.rpc-timeout.ms=20000
ha.failover-controller.graceful-fence.connection.retries=1
ha.failover-controller.graceful-fence.rpc-timeout.ms=5000
ha.failover-controller.new-active.rpc-timeout.ms=60000
ha.health-monitor.check-interval.ms=1000
ha.health-monitor.connect-retry-interval.ms=1000
ha.health-monitor.rpc-timeout.ms=45000
ha.health-monitor.sleep-after-disconnect.ms=1000
ha.zookeeper.acl=world:anyone:rwcda
ha.zookeeper.parent-znode=/hadoop-ha
ha.zookeeper.session-timeout.ms=5000
hadoop.bin.path=
    /usr/bin/hadoop:
hadoop.common.configuration.version=0.23.0
hadoop.http.authentication.kerberos.keytab=/home/alex/hadoop.keytab
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
hadoop.http.authentication.signature.secret.file=/home/alex/hadoop-http-auth-signature-secret
hadoop.http.authentication.simple.anonymous.allowed=true
hadoop.http.authentication.token.validity=36000
hadoop.http.authentication.type=simple
hadoop.http.cross-origin.allowed-headers=X-Requested-With,Content-Type,Accept,Origin
hadoop.http.cross-origin.allowed-methods=GET,POST,HEAD
hadoop.http.cross-origin.allowed-origins=*
hadoop.http.cross-origin.enabled=false
hadoop.http.cross-origin.max-age=1800
hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
hadoop.http.staticuser.user=dr.who
hadoop.jetty.logs.serve.aliases=true
hadoop.kerberos.kinit.command=kinit
hadoop.registry.jaas.context=Client
hadoop.registry.rm.enabled=false
hadoop.registry.secure=false
hadoop.registry.system.acls=sasl:yarn@, sasl:mapred@, sasl:hdfs@
hadoop.registry.zk.connection.timeout.ms=15000
hadoop.registry.zk.quorum=localhost:2181
hadoop.registry.zk.retry.ceiling.ms=60000
hadoop.registry.zk.retry.interval.ms=1000
hadoop.registry.zk.retry.times=5
hadoop.registry.zk.root=/registry
hadoop.registry.zk.session.timeout.ms=60000
hadoop.rpc.protection=authentication
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
hadoop.security.authentication=simple
hadoop.security.authorization=false
hadoop.security.crypto.buffer.size=8192
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
hadoop.security.group.mapping.ldap.directory.search.timeout=10000
hadoop.security.group.mapping.ldap.search.attr.group.name=cn
hadoop.security.group.mapping.ldap.search.attr.member=member
hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
hadoop.security.group.mapping.ldap.search.filter.user=(&(objectClass=user)(sAMAccountName={0}))
hadoop.security.group.mapping.ldap.ssl=false
hadoop.security.groups.cache.secs=300
hadoop.security.groups.cache.warn.after.ms=5000
hadoop.security.groups.negative-cache.secs=30
hadoop.security.instrumentation.requires.admin=false
hadoop.security.java.secure.random.algorithm=SHA1PRNG
hadoop.security.kms.client.authentication.retry-count=1
hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
hadoop.security.kms.client.encrypted.key.cache.size=500
hadoop.security.random.device.file.path=
    /dev/urandom:
hadoop.security.uid.cache.secs=14400
hadoop.ssl.client.conf=ssl-client.xml
hadoop.ssl.enabled=false
hadoop.ssl.enabled.protocols=TLSv1
hadoop.ssl.hostname.verifier=DEFAULT
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
hadoop.ssl.require.client.cert=false
hadoop.ssl.server.conf=ssl-server.xml
hadoop.tmp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp
hadoop.user.group.static.mapping.overrides=dr.who=;
hadoop.util.hash.type=murmur
hadoop.work.around.non.threadsafe.getpwuid=false
hive.allow.udf.load.on.demand=false
hive.analyze.stmt.collect.partlevel.stats=true
hive.archive.enabled=false
hive.async.log.enabled=true
hive.ats.hook.queue.capacity=64
hive.auto.convert.join=false
hive.auto.convert.join.hashtable.max.entries=40000000
hive.auto.convert.join.noconditionaltask=true
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join.use.nonstaged=false
hive.auto.convert.sortmerge.join=false
hive.auto.convert.sortmerge.join.bigtable.selection.policy=org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
hive.auto.convert.sortmerge.join.reduce.side=true
hive.auto.convert.sortmerge.join.to.mapjoin=false
hive.auto.progress.timeout=0s
hive.autogen.columnalias.prefix.includefuncname=false
hive.autogen.columnalias.prefix.label=_c
hive.binary.record.max.length=1000
hive.blobstore.optimizations.enabled=true
hive.blobstore.supported.schemes=s3,s3a,s3n
hive.blobstore.use.blobstore.as.scratchdir=false
hive.cache.expr.evaluation=true
hive.cbo.cnf.maxnodes=-1
hive.cbo.costmodel.cpu=0.000001
hive.cbo.costmodel.extended=false
hive.cbo.costmodel.hdfs.read=1.5
hive.cbo.costmodel.hdfs.write=10.0
hive.cbo.costmodel.local.fs.read=4.0
hive.cbo.costmodel.local.fs.write=4.0
hive.cbo.costmodel.network=150.0
hive.cbo.enable=true
hive.cbo.fallback.strategy=TEST
hive.cbo.returnpath.hiveop=
    false:
hive.cbo.show.warnings=true
hive.cli.errors.ignore=false
hive.cli.pretty.output.num.cols=-1
hive.cli.print.current.db=false
hive.cli.print.header=false
hive.cli.prompt=hive
hive.cli.tez.session.async=true
hive.cluster.delegation.token.store.class=org.apache.hadoop.hive.thrift.MemoryTokenStore
hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
hive.compactor.abortedtxn.threshold=1000
hive.compactor.check.interval=300s
hive.compactor.cleaner.run.interval=5000ms
hive.compactor.delta.num.threshold=10
hive.compactor.delta.pct.threshold=0.1
hive.compactor.history.reaper.interval=2m
hive.compactor.history.retention.attempted=2
hive.compactor.history.retention.failed=3
hive.compactor.history.retention.succeeded=3
hive.compactor.initiator.failed.compacts.threshold=2
hive.compactor.initiator.on=false
hive.compactor.max.num.delta=500
hive.compactor.worker.threads=0
hive.compactor.worker.timeout=86400s
hive.compat=0.12
hive.compute.query.using.stats=true
hive.compute.splits.in.am=true
hive.conf.hidden.list=javax.jdo.option.ConnectionPassword,hive.server2.keystore.password,fs.s3.awsAccessKeyId,fs.s3.awsSecretAccessKey,fs.s3n.awsAccessKeyId,fs.s3n.awsSecretAccessKey,fs.s3a.access.key,fs.s3a.secret.key,fs.s3a.proxy.password
hive.conf.internal.variable.list=hive.added.files.path,hive.added.jars.path,hive.added.archives.path
hive.conf.restricted.list=from.hivemetastore-site.xml
hive.conf.validation=true
hive.convert.join.bucket.mapjoin.tez=false
hive.count.open.txns.interval=1s
hive.counters.group.name=HIVE
hive.debug.localtask=false
hive.decode.partition.name=false
hive.default.fileformat=TextFile
hive.default.fileformat.managed=none
hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
hive.default.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.direct.sql.max.elements.in.clause=1000
hive.direct.sql.max.elements.values.clause=1000
hive.direct.sql.max.query.length=100
hive.display.partition.cols.separately=true
hive.downloaded.resources.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/810f17e8-32cd-48d9-8479-d8ce125c00af_resources
hive.driver.parallel.compilation=false
hive.druid.broker.address.default=localhost:8082
hive.druid.coordinator.address.default=localhost:8081
hive.druid.http.numConnection=20
hive.druid.http.read.timeout=PT1M
hive.druid.indexer.memory.rownum.max=75000
hive.druid.indexer.partition.size.max=5000000
hive.druid.indexer.segments.granularity=DAY
hive.druid.maxTries=5
hive.druid.metadata.base=druid
hive.druid.metadata.db.type=mysql
hive.druid.passiveWaitTimeMs=30000
hive.druid.select.distribute=true
hive.druid.select.threshold=10000
hive.druid.sleep.time=PT10S
hive.druid.storage.storageDirectory=/druid/segments
hive.druid.working.directory=/tmp/workingDirectory
hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml
hive.dummyparam.test.server.specific.config.metastoresite=from.hivemetastore-site.xml
hive.dummyparam.test.server.specific.config.override=from.hivemetastore-site.xml
hive.enforce.bucketmapjoin=false
hive.enforce.sortmergebucketmapjoin=false
hive.entity.capture.transform=false
hive.entity.separator=@
hive.error.on.empty.partition=false
hive.exec.check.crossproducts=true
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
hive.exec.concatenate.check.index=true
hive.exec.copyfile.maxnumfiles=1
hive.exec.copyfile.maxsize=33554432
hive.exec.counters.pull.interval=1000
hive.exec.default.partition.name=__HIVE_DEFAULT_PARTITION__
hive.exec.drop.ignorenonexistent=true
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=strict
hive.exec.infer.bucket.sort=false
hive.exec.infer.bucket.sort.num.buckets.power.two=false
hive.exec.input.listing.max.threads=0
hive.exec.job.debug.capture.stacktraces=true
hive.exec.job.debug.timeout=30000
hive.exec.local.scratchdir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/
hive.exec.max.created.files=100000
hive.exec.max.dynamic.partitions=1000
hive.exec.max.dynamic.partitions.pernode=100
hive.exec.mode.local.auto=false
hive.exec.mode.local.auto.input.files.max=4
hive.exec.mode.local.auto.inputbytes.max=134217728
hive.exec.orc.base.delta.ratio=8
hive.exec.orc.split.strategy=HYBRID
hive.exec.parallel=false
hive.exec.parallel.thread.number=8
hive.exec.perf.logger=org.apache.hadoop.hive.ql.log.PerfLogger
hive.exec.post.hooks=
hive.exec.pre.hooks=
hive.exec.rcfile.use.explicit.header=true
hive.exec.rcfile.use.sync.cache=true
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.rowoffset=false
hive.exec.schema.evolution=true
hive.exec.scratchdir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir
hive.exec.script.allow.partial.consumption=false
hive.exec.script.maxerrsize=100000
hive.exec.script.trust=false
hive.exec.show.job.failure.debug.info=true
hive.exec.stagingdir=.hive-staging
hive.exec.submit.local.task.via.child=false
hive.exec.submitviachild=false
hive.exec.tasklog.debug.timeout=20000
hive.exec.temporary.table.storage=default
hive.execution.engine=mr
hive.execution.mode=container
hive.exim.strict.repl.tables=true
hive.exim.uri.scheme.whitelist=hdfs,pfile,file,s3,s3a
hive.explain.dependency.append.tasktype=false
hive.explain.user=true
hive.fetch.output.serde=org.apache.hadoop.hive.serde2.DelimitedJSONSerDe
hive.fetch.task.aggr=false
hive.fetch.task.conversion=minimal
hive.fetch.task.conversion.threshold=1073741824
hive.file.max.footer=100
hive.fileformat.check=true
hive.groupby.limit.extrastep=true
hive.groupby.mapaggr.checkinterval=100000
hive.groupby.orderby.position.alias=false
hive.groupby.position.alias=false
hive.groupby.skewindata=false
hive.hash.table.inflation.factor=2.0
hive.hashtable.initialCapacity=100000
hive.hashtable.key.count.adjustment=1.0
hive.hashtable.loadfactor=0.75
hive.hbase.generatehfiles=false
hive.hbase.snapshot.restoredir=/tmp
hive.hbase.wal.enabled=true
hive.heartbeat.interval=1000
hive.hmshandler.force.reload.conf=false
hive.hmshandler.retry.attempts=10
hive.hmshandler.retry.interval=2000ms
hive.ignore.mapjoin.hint=false
hive.in.test=true
hive.in.tez.test=false
hive.index.compact.binary.search=true
hive.index.compact.file.ignore.hdfs=false
hive.index.compact.query.max.entries=10000000
hive.index.compact.query.max.size=10737418240
hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.insert.into.external.tables=true
hive.insert.into.multilevel.dirs=false
hive.int.timestamp.conversion.in.seconds=false
hive.io.rcfile.column.number.conf=0
hive.io.rcfile.record.buffer.size=4194304
hive.io.rcfile.record.interval=2147483647
hive.io.rcfile.tolerate.corruptions=false
hive.io.sarg.cache.max.weight.mb=10
hive.jar.path=
    ${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar:
hive.jobname.length=50
hive.join.cache.size=25000
hive.join.emit.interval=1000
hive.lazysimple.extended_boolean_literal=false
hive.limit.optimize.enable=false
hive.limit.optimize.fetch.max=50000
hive.limit.optimize.limit.file=10
hive.limit.pushdown.memory.usage=0.1
hive.limit.query.max.table.partition=-1
hive.limit.row.max.size=100000
hive.llap.allow.permanent.fns=true
hive.llap.am.liveness.connection.sleep.between.retries.ms=2000ms
hive.llap.am.liveness.connection.timeout.ms=10000ms
hive.llap.am.use.fqdn=false
hive.llap.auto.allow.uber=false
hive.llap.auto.auth=false
hive.llap.auto.enforce.stats=true
hive.llap.auto.enforce.tree=true
hive.llap.auto.enforce.vectorized=true
hive.llap.auto.max.input.size=10737418240
hive.llap.auto.max.output.size=1073741824
hive.llap.cache.allow.synthetic.fileid=true
hive.llap.client.consistent.splits=false
hive.llap.daemon.acl=*
hive.llap.daemon.am-reporter.max.threads=4
hive.llap.daemon.am.liveness.heartbeat.interval.ms=10000ms
hive.llap.daemon.communicator.num.threads=10
hive.llap.daemon.delegation.token.lifetime=14d
hive.llap.daemon.download.permanent.fns=false
hive.llap.daemon.logger=query-routing
hive.llap.daemon.memory.per.instance.mb=4096
hive.llap.daemon.num.executors=4
hive.llap.daemon.num.file.cleaner.threads=1
hive.llap.daemon.output.service.max.pending.writes=8
hive.llap.daemon.output.service.port=15003
hive.llap.daemon.output.service.send.buffer.size=131072
hive.llap.daemon.output.stream.timeout=120s
hive.llap.daemon.rpc.num.handlers=5
hive.llap.daemon.rpc.port=0
hive.llap.daemon.service.refresh.interval.sec=60s
hive.llap.daemon.shuffle.dir.watcher.enabled=false
hive.llap.daemon.task.preemption.metrics.intervals=30,60,300
hive.llap.daemon.task.scheduler.enable.preemption=true
hive.llap.daemon.task.scheduler.wait.queue.size=10
hive.llap.daemon.vcpus.per.instance=4
hive.llap.daemon.wait.queue.comparator.class.name=org.apache.hadoop.hive.llap.daemon.impl.comparator.ShortestJobFirstComparator
hive.llap.daemon.web.port=15002
hive.llap.daemon.web.ssl=false
hive.llap.daemon.xmx.headroom=5%
hive.llap.daemon.yarn.container.mb=-1
hive.llap.daemon.yarn.shuffle.port=15551
hive.llap.enable.grace.join.in.llap=false
hive.llap.execution.mode=none
hive.llap.file.cleanup.delay.seconds=300s
hive.llap.hs2.coordinator.enabled=true
hive.llap.io.allocator.alloc.max=16Mb
hive.llap.io.allocator.alloc.min=256Kb
hive.llap.io.allocator.arena.count=8
hive.llap.io.allocator.direct=false
hive.llap.io.allocator.mmap=false
hive.llap.io.allocator.mmap.path=
    /tmp:
hive.llap.io.cache.orc.alloc.max=2097152
hive.llap.io.cache.orc.alloc.min=32768
hive.llap.io.cache.orc.arena.size=8388608
hive.llap.io.cache.orc.size=8388608
hive.llap.io.decoding.metrics.percentiles.intervals=30
hive.llap.io.encode.alloc.size=256Kb
hive.llap.io.encode.enabled=true
hive.llap.io.encode.formats=org.apache.hadoop.mapred.TextInputFormat,
hive.llap.io.encode.slice.lrr=true
hive.llap.io.encode.slice.row.count=100000
hive.llap.io.encode.vector.serde.async.enabled=true
hive.llap.io.encode.vector.serde.enabled=true
hive.llap.io.lrfu.lambda=0.01
hive.llap.io.memory.mode=cache
hive.llap.io.memory.size=1Gb
hive.llap.io.metadata.fraction=0.1
hive.llap.io.nonvector.wrapper.enabled=true
hive.llap.io.orc.time.counters=true
hive.llap.io.threadpool.size=10
hive.llap.io.use.fileid.path=
    true:
hive.llap.io.use.lrfu=true
hive.llap.management.acl=*
hive.llap.management.rpc.port=15004
hive.llap.object.cache.enabled=true
hive.llap.orc.gap.cache=true
hive.llap.remote.token.requires.signing=true
hive.llap.skip.compile.udf.check=false
hive.llap.task.communicator.connection.sleep.between.retries.ms=2000ms
hive.llap.task.communicator.connection.timeout.ms=16000ms
hive.llap.task.communicator.listener.thread-count=30
hive.llap.task.scheduler.locality.delay=0ms
hive.llap.task.scheduler.node.disable.backoff.factor=1.5
hive.llap.task.scheduler.node.reenable.max.timeout.ms=10000ms
hive.llap.task.scheduler.node.reenable.min.timeout.ms=200ms
hive.llap.task.scheduler.num.schedulable.tasks.per.node=0
hive.llap.task.scheduler.timeout.seconds=60s
hive.llap.validate.acls=true
hive.load.dynamic.partitions.thread=15
hive.localize.resource.num.wait.attempts=5
hive.localize.resource.wait.interval=5000ms
hive.lock.manager=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
hive.lock.mapred.only.operation=false
hive.lock.numretries=100
hive.lock.sleep.between.retries=60s
hive.lockmgr.zookeeper.default.partition.name=__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
hive.log.every.n.records=0
hive.log.explain.output=false
hive.map.aggr=true
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.map.aggr.hash.min.reduction=0.5
hive.map.aggr.hash.percentmemory=0.5
hive.map.groupby.sorted=true
hive.mapjoin.bucket.cache.size=100
hive.mapjoin.check.memory.rows=100000
hive.mapjoin.followby.gby.localtask.max.memory.usage=0.55
hive.mapjoin.followby.map.aggr.hash.percentmemory=0.3
hive.mapjoin.hybridgrace.bloomfilter=true
hive.mapjoin.hybridgrace.hashtable=true
hive.mapjoin.hybridgrace.memcheckfrequency=1024
hive.mapjoin.hybridgrace.minnumpartitions=16
hive.mapjoin.hybridgrace.minwbsize=524288
hive.mapjoin.localtask.max.memory.usage=0.9
hive.mapjoin.max.gc.time.percentage=0.99
hive.mapjoin.optimized.hashtable=true
hive.mapjoin.optimized.hashtable.probe.percent=0.5
hive.mapjoin.optimized.hashtable.wbsize=8388608
hive.mapjoin.smalltable.filesize=25000000
hive.mapper.cannot.span.multiple.partitions=false
hive.mapred.local.mem=0
hive.mapred.partitioner=org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
hive.mapred.reduce.tasks.speculative.execution=true
hive.materializedview.fileformat=ORC
hive.materializedview.rewriting=true
hive.materializedview.serde=org.apache.hadoop.hive.ql.io.orc.OrcSerde
hive.max.open.txns=100000
hive.merge.cardinality.check=true
hive.merge.mapfiles=true
hive.merge.mapredfiles=false
hive.merge.nway.joins=true
hive.merge.orcfile.stripe.level=true
hive.merge.rcfile.block.level=true
hive.merge.size.per.task=256000000
hive.merge.smallfiles.avgsize=16000000
hive.merge.sparkfiles=false
hive.merge.tezfiles=false
hive.metadata.move.exported.metadata.to.trash=true
hive.metastore.aggregate.stats.cache.clean.until=0.8
hive.metastore.aggregate.stats.cache.enabled=true
hive.metastore.aggregate.stats.cache.fpp=0.01
hive.metastore.aggregate.stats.cache.max.full=0.9
hive.metastore.aggregate.stats.cache.max.partitions=10000
hive.metastore.aggregate.stats.cache.max.reader.wait=1000ms
hive.metastore.aggregate.stats.cache.max.variance=0.01
hive.metastore.aggregate.stats.cache.max.writer.wait=5000ms
hive.metastore.aggregate.stats.cache.size=10000
hive.metastore.aggregate.stats.cache.ttl=600s
hive.metastore.archive.intermediate.archived=_INTERMEDIATE_ARCHIVED
hive.metastore.archive.intermediate.extracted=_INTERMEDIATE_EXTRACTED
hive.metastore.archive.intermediate.original=_INTERMEDIATE_ORIGINAL
hive.metastore.authorization.storage.check.externaltable.drop=true
hive.metastore.authorization.storage.checks=false
hive.metastore.batch.retrieve.max=300
hive.metastore.batch.retrieve.table.partition.max=1000
hive.metastore.cache.pinobjtypes=Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
hive.metastore.client.cache.enabled=true
hive.metastore.client.cache.maxSize=10Mb
hive.metastore.client.cache.recordStats=true
hive.metastore.client.capability.check=true
hive.metastore.client.connect.retry.delay=1s
hive.metastore.client.drop.partitions.using.expressions=true
hive.metastore.client.socket.lifetime=0s
hive.metastore.client.socket.timeout=600s
hive.metastore.connect.retries=3
hive.metastore.direct.sql.batch.size=0
hive.metastore.disallow.incompatible.col.type.changes=true
hive.metastore.dml.events=false
hive.metastore.event.clean.freq=0s
hive.metastore.event.db.listener.timetolive=86400s
hive.metastore.event.expiry.duration=0s
hive.metastore.event.message.factory=org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory
hive.metastore.execute.setugi=true
hive.metastore.expression.proxy=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
hive.metastore.failure.retries=1
hive.metastore.fastpath=
    false:
hive.metastore.filter.hook=org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
hive.metastore.fs.handler.class=org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
hive.metastore.fshandler.threads=15
hive.metastore.hbase.aggr.stats.cache.entries=10000
hive.metastore.hbase.aggr.stats.hbase.ttl=604800s
hive.metastore.hbase.aggr.stats.invalidator.frequency=5s
hive.metastore.hbase.aggr.stats.memory.ttl=60s
hive.metastore.hbase.aggregate.stats.cache.size=10000
hive.metastore.hbase.aggregate.stats.false.positive.probability=0.01
hive.metastore.hbase.aggregate.stats.max.partitions=10000
hive.metastore.hbase.aggregate.stats.max.variance=0.1
hive.metastore.hbase.cache.clean.until=0.8
hive.metastore.hbase.cache.max.full=0.9
hive.metastore.hbase.cache.max.reader.wait=1000ms
hive.metastore.hbase.cache.max.writer.wait=5000ms
hive.metastore.hbase.cache.ttl=600s
hive.metastore.hbase.catalog.cache.size=50000
hive.metastore.hbase.connection.class=org.apache.hadoop.hive.metastore.hbase.VanillaHBaseConnection
hive.metastore.hbase.file.metadata.threads=1
hive.metastore.initial.metadata.count.enabled=true
hive.metastore.integral.jdo.pushdown=false
hive.metastore.kerberos.principal=hive-metastore/_HOST@EXAMPLE.COM
hive.metastore.limit.partition.request=-1
hive.metastore.metadb.dir=file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/metadb/
hive.metastore.metrics.enabled=false
hive.metastore.orm.retrieveMapNullsAsEmptyStrings=false
hive.metastore.port=9083
hive.metastore.pre.event.listeners=org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore
hive.metastore.sasl.enabled=false
hive.metastore.schema.verification=false
hive.metastore.schema.verification.record.version=false
hive.metastore.server.max.message.size=104857600
hive.metastore.server.max.threads=1000
hive.metastore.server.min.threads=200
hive.metastore.server.tcp.keepalive=true
hive.metastore.stats.ndv.densityfunction=false
hive.metastore.stats.ndv.tuner=0.0
hive.metastore.thrift.compact.protocol.enabled=false
hive.metastore.thrift.framed.transport.enabled=false
hive.metastore.try.direct.sql=true
hive.metastore.try.direct.sql.ddl=true
hive.metastore.txn.store.impl=org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
hive.metastore.use.SSL=false
hive.metastore.warehouse.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse
hive.msck.path.validation=
    throw:
hive.msck.repair.batch.size=0
hive.multi.insert.move.tasks.share.dependencies=false
hive.multigroupby.singlereducer=true
hive.mv.files.thread=15
hive.new.job.grouping.set.cardinality=30
hive.optimize.bucketingsorting=true
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.optimize.constant.propagation=true
hive.optimize.correlation=false
hive.optimize.cte.materialize.threshold=-1
hive.optimize.distinct.rewrite=true
hive.optimize.dynamic.partition.hashjoin=false
hive.optimize.filter.stats.reduction=false
hive.optimize.groupby=true
hive.optimize.index.autoupdate=false
hive.optimize.index.filter=false
hive.optimize.index.filter.compact.maxsize=-1
hive.optimize.index.filter.compact.minsize=5368709120
hive.optimize.index.groupby=false
hive.optimize.limittranspose=false
hive.optimize.limittranspose.reductionpercentage=1.0
hive.optimize.limittranspose.reductiontuples=0
hive.optimize.listbucketing=false
hive.optimize.metadataonly=false
hive.optimize.null.scan=true
hive.optimize.partition.columns.separate=true
hive.optimize.point.lookup=true
hive.optimize.point.lookup.min=31
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.optimize.ppd.windowing=true
hive.optimize.reducededuplication=true
hive.optimize.reducededuplication.min.reducer=4
hive.optimize.remove.identity.project=true
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
hive.optimize.semijoin.conversion=true
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.sort.dynamic.partition=false
hive.optimize.union.remove=false
hive.orc.cache.stripe.details.mem.size=256Mb
hive.orc.cache.use.soft.references=false
hive.orc.compute.splits.num.threads=10
hive.orc.splits.allow.synthetic.fileid=true
hive.orc.splits.directory.batch.ms=0
hive.orc.splits.include.file.footer=false
hive.orc.splits.include.fileid=true
hive.orc.splits.ms.footer.cache.enabled=false
hive.orc.splits.ms.footer.cache.ppd.enabled=true
hive.order.columnalignment=true
hive.orderby.position.alias=true
hive.parquet.timestamp.skip.conversion=true
hive.ppd.recognizetransivity=true
hive.ppd.remove.duplicatefilters=true
hive.prewarm.enabled=false
hive.prewarm.numcontainers=10
hive.query.reexecution.stats.persist.scope=query
hive.query.result.fileformat=SequenceFile
hive.query.results.cache.enabled=false
hive.query.timeout.seconds=0s
hive.querylog.enable.plan.progress=true
hive.querylog.location=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/tmp
hive.querylog.plan.progress.interval=60000ms
hive.reorder.nway.joins=true
hive.repl.cm.enabled=false
hive.repl.cm.interval=3600s
hive.repl.cm.retain=24h
hive.repl.cmrootdir=/user/hive/cmroot/
hive.repl.rootdir=/user/hive/repl/
hive.repl.task.factory=org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
hive.resultset.use.unique.column.names=true
hive.rework.mapredwork=false
hive.rpc.query.plan=false
hive.sample.seednumber=0
hive.scheduled.queries.executor.enabled=false
hive.scratch.dir.permission=700
hive.scratchdir.lock=false
hive.script.auto.progress=false
hive.script.operator.env.blacklist=hive.txn.valid.txns,hive.script.operator.env.blacklist
hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID
hive.script.operator.truncate.env=false
hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader
hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter
hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
hive.security.authorization.createtable.owner.grants=INSERT,SELECT,UPDATE,DELETE
hive.security.authorization.enabled=false
hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory
hive.security.authorization.sqlstd.confwhitelist=hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.thrift\.resultset\.default\.fetch\.size|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.strict\..*|hive\.tez\..*|hive\.vectorized\..*|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queuename|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.transpose\.aggr\.join|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketmapjoin|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.query\.result\.fileformat|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.cli\.tez\.session\.async|hive\.compat|hive\.exec\.concatenate\.check\.index|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.schema\.evolution|hive\.server2\.logging\.operation\.level|hive\.server2\.thrift\.resultset\.serialize\.in\.tasks|hive\.support\.special\.characters\.tablename|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.llap\.io\.enabled|hive\.llap\.io\.use\.fileid\.path|hive\.llap\.daemon\.service\.hosts|hive\.llap\.execution\.mode|hive\.llap\.auto\.allow\.uber|hive\.llap\.auto\.enforce\.tree|hive\.llap\.auto\.enforce\.vectorized|hive\.llap\.auto\.enforce\.stats|hive\.llap\.auto\.max\.input\.size|hive\.llap\.auto\.max\.output\.size|hive\.llap\.skip\.compile\.udf\.check|hive\.llap\.client\.consistent\.splits|hive\.llap\.enable\.grace\.join\.in\.llap|hive\.llap\.allow\.permanent\.fns|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id
hive.security.authorization.task.factory=org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
hive.security.command.whitelist=set,reset,dfs,add,list,delete,reload,compile
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.security.metastore.authorization.auth.reads=true
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
hive.serdes.using.metastore.for.schema=org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
hive.server.read.socket.timeout=10s
hive.server.tcp.keepalive=true
hive.server2.allow.user.substitution=true
hive.server2.async.exec.async.compile=false
hive.server2.async.exec.keepalive.time=10s
hive.server2.async.exec.shutdown.timeout=10s
hive.server2.async.exec.threads=100
hive.server2.async.exec.wait.queue.size=100
hive.server2.authentication=NONE
hive.server2.authentication.ldap.groupClassKey=groupOfNames
hive.server2.authentication.ldap.groupMembershipKey=member
hive.server2.authentication.ldap.guidKey=uid
hive.server2.clear.dangling.scratchdir=false
hive.server2.clear.dangling.scratchdir.interval=1800s
hive.server2.close.session.on.disconnect=true
hive.server2.compile.lock.timeout=0s
hive.server2.enable.doAs=true
hive.server2.global.init.file.location=${env:HIVE_CONF_DIR}
hive.server2.idle.operation.timeout=5d
hive.server2.idle.session.check.operation=true
hive.server2.idle.session.timeout=7d
hive.server2.in.place.progress=true
hive.server2.llap.concurrent.queries=-1
hive.server2.logging.operation.enabled=true
hive.server2.logging.operation.level=EXECUTION
hive.server2.logging.operation.log.location=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/alex/operation_logs
hive.server2.long.polling.timeout=5000ms
hive.server2.map.fair.scheduler.queue=true
hive.server2.max.start.attempts=30
hive.server2.metrics.enabled=false
hive.server2.operation.log.purgePolicy.timeToLive=5s
hive.server2.parallel.ops.in.session=true
hive.server2.session.check.interval=6h
hive.server2.sleep.interval.between.start.attempts=60s
hive.server2.support.dynamic.service.discovery=false
hive.server2.table.type.mapping=CLASSIC
hive.server2.tez.initialize.default.sessions=false
hive.server2.tez.session.lifetime=162h
hive.server2.tez.session.lifetime.jitter=3h
hive.server2.tez.sessions.custom.queue.allowed=true
hive.server2.tez.sessions.init.threads=16
hive.server2.tez.sessions.per.default.queue=1
hive.server2.thrift.client.connect.retry.limit=1
hive.server2.thrift.client.password=anonymous
hive.server2.thrift.client.retry.delay.seconds=1s
hive.server2.thrift.client.retry.limit=1
hive.server2.thrift.client.user=anonymous
hive.server2.thrift.exponential.backoff.slot.length=100ms
hive.server2.thrift.http.cookie.auth.enabled=true
hive.server2.thrift.http.cookie.is.httponly=true
hive.server2.thrift.http.cookie.is.secure=true
hive.server2.thrift.http.cookie.max.age=86400s
hive.server2.thrift.http.max.idle.time=1800s
hive.server2.thrift.http.path=
    cliservice:
hive.server2.thrift.http.port=10001
hive.server2.thrift.http.request.header.size=6144
hive.server2.thrift.http.response.header.size=6144
hive.server2.thrift.http.worker.keepalive.time=60s
hive.server2.thrift.login.timeout=20s
hive.server2.thrift.max.message.size=104857600
hive.server2.thrift.max.worker.threads=500
hive.server2.thrift.min.worker.threads=5
hive.server2.thrift.port=10000
hive.server2.thrift.resultset.default.fetch.size=1000
hive.server2.thrift.resultset.max.fetch.size=10000
hive.server2.thrift.resultset.serialize.in.tasks=false
hive.server2.thrift.sasl.qop=auth
hive.server2.thrift.worker.keepalive.time=60s
hive.server2.transport.mode=binary
hive.server2.use.SSL=false
hive.server2.webui.host=0.0.0.0
hive.server2.webui.max.historic.queries=25
hive.server2.webui.max.threads=50
hive.server2.webui.port=10002
hive.server2.webui.spnego.principal=HTTP/_HOST@EXAMPLE.COM
hive.server2.webui.use.spnego=false
hive.server2.webui.use.ssl=false
hive.server2.xsrf.filter.enabled=false
hive.server2.zookeeper.namespace=hiveserver2
hive.server2.zookeeper.publish.configs=true
hive.service.metrics.class=org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
hive.service.metrics.file.frequency=5s
hive.service.metrics.file.location=/tmp/report.json
hive.service.metrics.hadoop2.component=hive
hive.service.metrics.hadoop2.frequency=30s
hive.service.metrics.reporter=JSON_FILE, JMX
hive.session.history.enabled=false
hive.session.id=810f17e8-32cd-48d9-8479-d8ce125c00af
hive.session.silent=false
hive.skewjoin.key=100000
hive.skewjoin.mapjoin.map.tasks=10000
hive.skewjoin.mapjoin.min.split=33554432
hive.smbjoin.cache.rows=10000
hive.spark.client.connect.timeout=1000ms
hive.spark.client.future.timeout=60s
hive.spark.client.rpc.max.size=52428800
hive.spark.client.rpc.sasl.mechanisms=DIGEST-MD5
hive.spark.client.rpc.threads=8
hive.spark.client.secret.bits=256
hive.spark.client.server.connect.timeout=90000ms
hive.spark.dynamic.partition.pruning=false
hive.spark.dynamic.partition.pruning.max.data.size=104857600
hive.spark.exec.inplace.progress=true
hive.spark.job.monitor.timeout=60s
hive.spark.use.file.size.for.mapjoin=false
hive.spark.use.groupby.shuffle=true
hive.spark.use.op.stats=true
hive.ssl.protocol.blacklist=SSLv2,SSLv3
hive.stageid.rearrange=none
hive.start.cleanup.scratchdir=false
hive.stats.atomic=false
hive.stats.autogather=true
hive.stats.collect.scancols=false
hive.stats.collect.tablekeys=false
hive.stats.column.autogather=false
hive.stats.dbclass=fs
hive.stats.deserialization.factor=1.0
hive.stats.fetch.bitvector=true
hive.stats.fetch.column.stats=false
hive.stats.fetch.partition.stats=true
hive.stats.filter.in.factor=1.0
hive.stats.gather.num.threads=10
hive.stats.join.factor=1.1
hive.stats.key.prefix.reserve.length=0
hive.stats.list.num.entries=10
hive.stats.map.num.entries=10
hive.stats.max.variable.length=100
hive.stats.ndv.error=20.0
hive.stats.reliable=false
hive.strict.checks.bucketing=true
hive.strict.checks.cartesian.product=true
hive.strict.checks.large.query=false
hive.strict.checks.type.safety=true
hive.strict.timestamp.conversion=false
hive.support.concurrency=true
hive.support.quoted.identifiers=column
hive.support.special.characters.tablename=true
hive.test.authz.sstd.hs2.mode=false
hive.test.dummystats.aggregator=value2
hive.test.fail.compaction=false
hive.test.fail.heartbeater=false
hive.test.mode=false
hive.test.mode.prefix=test_
hive.test.mode.samplefreq=32
hive.test.rollbacktxn=false
hive.tez.auto.reducer.parallelism=false
hive.tez.bigtable.minsize.semijoin.reduction=1000000
hive.tez.bloom.filter.factor=2.0
hive.tez.bucket.pruning=false
hive.tez.bucket.pruning.compat=true
hive.tez.container.max.java.heap.fraction=0.8
hive.tez.container.size=-1
hive.tez.cpu.vcores=-1
hive.tez.dynamic.partition.pruning=true
hive.tez.dynamic.partition.pruning.max.data.size=104857600
hive.tez.dynamic.partition.pruning.max.event.size=1048576
hive.tez.dynamic.semijoin.reduction=true
hive.tez.dynamic.semijoin.reduction.threshold=0.5
hive.tez.enable.memory.manager=true
hive.tez.exec.inplace.progress=true
hive.tez.exec.print.summary=false
hive.tez.hs2.user.access=true
hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.tez.input.generate.consistent.splits=true
hive.tez.log.level=INFO
hive.tez.max.bloom.filter.entries=100000000
hive.tez.max.partition.factor=2.0
hive.tez.min.bloom.filter.entries=1000000
hive.tez.min.partition.factor=0.25
hive.tez.smb.number.waves=0.5
hive.tez.task.scale.memory.reserve-fraction.min=0.3
hive.tez.task.scale.memory.reserve.fraction=-1.0
hive.tez.task.scale.memory.reserve.fraction.max=0.5
hive.timedout.txn.reaper.interval=180s
hive.timedout.txn.reaper.start=100s
hive.transactional.events.mem=10000000
hive.transactional.table.scan=false
hive.transform.escape.input=false
hive.transpose.aggr.join=false
hive.txn.heartbeat.threadpool.size=5
hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
hive.txn.manager.dump.lock.state.on.acquire.timeout=false
hive.txn.max.open.batch=1000
hive.txn.operational.properties=0
hive.txn.strict.locking.mode=true
hive.txn.timeout=300s
hive.typecheck.on.insert=true
hive.udtf.auto.progress=false
hive.unlock.numretries=10
hive.user.install.directory=/user/
hive.users.in.admin.role=hive_admin_user
hive.variable.substitute=true
hive.variable.substitute.depth=40
hive.vectorized.adaptor.usage.mode=all
hive.vectorized.execution.enabled=false
hive.vectorized.execution.mapjoin.minmax.enabled=false
hive.vectorized.execution.mapjoin.native.enabled=true
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=false
hive.vectorized.execution.mapjoin.native.multikey.only.enabled=false
hive.vectorized.execution.mapjoin.overflow.repeated.threshold=-1
hive.vectorized.execution.reduce.enabled=true
hive.vectorized.execution.reduce.groupby.enabled=true
hive.vectorized.execution.reducesink.new.enabled=true
hive.vectorized.groupby.checkinterval=100000
hive.vectorized.groupby.flush.percent=0.1
hive.vectorized.groupby.maxentries=1000000
hive.vectorized.use.row.serde.deserialize=false
hive.vectorized.use.vector.serde.deserialize=true
hive.vectorized.use.vectorized.input.format=true
hive.warehouse.subdir.inherit.perms=true
hive.writeset.reaper.interval=60s
hive.zookeeper.clean.extra.nodes=false
hive.zookeeper.client.port=2181
hive.zookeeper.connection.basesleeptime=1000ms
hive.zookeeper.connection.max.retries=3
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.zookeeper.session.timeout=1200000ms
iceberg.hive.keep.stats=true
io.bytes.per.checksum=512
io.compression.codec.bzip2.library=system-native
io.file.buffer.size=4096
io.map.index.interval=128
io.map.index.skip=0
io.mapfile.bloom.error.rate=0.005
io.mapfile.bloom.size=1048576
io.native.lib.available=true
io.seqfile.compress.blocksize=1000000
io.seqfile.lazydecompress=true
io.seqfile.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/io/local
io.seqfile.sorter.recordlimit=1000000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
io.skip.checksum.errors=false
ipc.client.connect.max.retries=10
ipc.client.connect.max.retries.on.timeouts=45
ipc.client.connect.retry.interval=1000
ipc.client.connect.timeout=20000
ipc.client.connection.maxidletime=10000
ipc.client.fallback-to-simple-auth-allowed=false
ipc.client.idlethreshold=4000
ipc.client.kill.max=10
ipc.server.listen.queue.size=128
ipc.server.max.connections=0
javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.api.jdo.JDOPersistenceManagerFactory
javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver
javax.jdo.option.ConnectionPassword=
javax.jdo.option.ConnectionURL=jdbc:derby:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/junit_metastore_db;create=true
javax.jdo.option.ConnectionUserName=APP
javax.jdo.option.DetachAllOnCommit=true
javax.jdo.option.Multithreaded=true
javax.jdo.option.NonTransactionalRead=true
map.sort.class=org.apache.hadoop.util.QuickSort
mapred.child.java.opts=-Xmx200m
mapred.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/local
mapred.system.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/system
mapred.temp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/temp
mapreduce.am.max-attempts=2
mapreduce.app-submission.cross-platform=false
mapreduce.client.completion.pollinterval=5000
mapreduce.client.output.filter=FAILED
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.client.submit.file.replication=10
mapreduce.cluster.acls.enabled=false
mapreduce.cluster.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/local
mapreduce.cluster.temp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/temp
mapreduce.fileoutputcommitter.algorithm.version=1
mapreduce.framework.name=local
mapreduce.ifile.readahead=true
mapreduce.ifile.readahead.bytes=4194304
mapreduce.input.fileinputformat.list-status.num-threads=1
mapreduce.input.fileinputformat.split.maxsize=256000000
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.minsize.per.node=1
mapreduce.input.fileinputformat.split.minsize.per.rack=1
mapreduce.input.lineinputformat.linespermap=1
mapreduce.job.acl-modify-job= 
mapreduce.job.acl-view-job= 
mapreduce.job.classloader=false
mapreduce.job.committer.setup.cleanup.needed=true
mapreduce.job.complete.cancel.delegation.tokens=true
mapreduce.job.counters.max=120
mapreduce.job.emit-timeline-data=false
mapreduce.job.end-notification.max.attempts=5
mapreduce.job.end-notification.max.retry.interval=5000
mapreduce.job.end-notification.retry.attempts=0
mapreduce.job.end-notification.retry.interval=1000
mapreduce.job.hdfs-servers=file:///
mapreduce.job.jvm.numtasks=1
mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
mapreduce.job.maps=2
mapreduce.job.max.split.locations=10
mapreduce.job.maxtaskfailures.per.tracker=3
mapreduce.job.queuename=default
mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
mapreduce.job.reduce.slowstart.completedmaps=0.05
mapreduce.job.reducer.preempt.delay.sec=0
mapreduce.job.reduces=-1
mapreduce.job.running.map.limit=0
mapreduce.job.running.reduce.limit=0
mapreduce.job.speculative.minimum-allowed-tasks=10
mapreduce.job.speculative.retry-after-no-speculate=1000
mapreduce.job.speculative.retry-after-speculate=15000
mapreduce.job.speculative.slowtaskthreshold=1.0
mapreduce.job.speculative.speculative-cap-running-tasks=0.1
mapreduce.job.speculative.speculative-cap-total-tasks=0.01
mapreduce.job.split.metainfo.maxsize=10000000
mapreduce.job.token.tracking.ids.enabled=false
mapreduce.job.ubertask.enable=false
mapreduce.job.ubertask.maxmaps=9
mapreduce.job.ubertask.maxreduces=1
mapreduce.job.userlog.retain.hours=24
mapreduce.jobhistory.address=0.0.0.0:10020
mapreduce.jobhistory.admin.acl=*
mapreduce.jobhistory.admin.address=0.0.0.0:10033
mapreduce.jobhistory.cleaner.enable=true
mapreduce.jobhistory.cleaner.interval-ms=86400000
mapreduce.jobhistory.client.thread-count=10
mapreduce.jobhistory.datestring.cache.size=200000
mapreduce.jobhistory.done-dir=/tmp/hadoop-yarn/staging/history/done
mapreduce.jobhistory.http.policy=HTTP_ONLY
mapreduce.jobhistory.intermediate-done-dir=/tmp/hadoop-yarn/staging/history/done_intermediate
mapreduce.jobhistory.joblist.cache.size=20000
mapreduce.jobhistory.keytab=/etc/security/keytab/jhs.service.keytab
mapreduce.jobhistory.loadedjobs.cache.size=5
mapreduce.jobhistory.max-age-ms=604800000
mapreduce.jobhistory.minicluster.fixed.ports=false
mapreduce.jobhistory.move.interval-ms=180000
mapreduce.jobhistory.move.thread-count=3
mapreduce.jobhistory.principal=jhs/_HOST@REALM.TLD
mapreduce.jobhistory.recovery.enable=false
mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
mapreduce.jobhistory.recovery.store.fs.uri=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/mapred/history/recoverystore
mapreduce.jobhistory.recovery.store.leveldb.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/mapred/history/recoverystore:
mapreduce.jobhistory.webapp.address=0.0.0.0:19888
mapreduce.jobtracker.address=local
mapreduce.jobtracker.expire.trackers.interval=600000
mapreduce.jobtracker.handler.count=10
mapreduce.jobtracker.heartbeats.in.second=100
mapreduce.jobtracker.http.address=0.0.0.0:50030
mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapreduce.jobtracker.jobhistory.block.size=3145728
mapreduce.jobtracker.jobhistory.lru.cache.size=5
mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
mapreduce.jobtracker.maxtasks.perjob=-1
mapreduce.jobtracker.persist.jobstatus.active=true
mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapreduce.jobtracker.persist.jobstatus.hours=1
mapreduce.jobtracker.restart.recover=false
mapreduce.jobtracker.retiredjobs.cache.size=1000
mapreduce.jobtracker.staging.root.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/staging
mapreduce.jobtracker.system.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/system
mapreduce.jobtracker.taskcache.levels=2
mapreduce.jobtracker.taskscheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapreduce.jobtracker.tasktracker.maxblacklists=4
mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
mapreduce.map.cpu.vcores=1
mapreduce.map.log.level=INFO
mapreduce.map.maxattempts=4
mapreduce.map.memory.mb=1024
mapreduce.map.output.compress=false
mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.map.skip.maxrecords=0
mapreduce.map.skip.proc.count.autoincr=true
mapreduce.map.sort.spill.percent=0.80
mapreduce.map.speculative=true
mapreduce.output.fileoutputformat.compress=false
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.output.fileoutputformat.compress.type=RECORD
mapreduce.reduce.cpu.vcores=1
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.reduce.log.level=INFO
mapreduce.reduce.markreset.buffer.percent=0.0
mapreduce.reduce.maxattempts=4
mapreduce.reduce.memory.mb=1024
mapreduce.reduce.merge.inmem.threshold=1000
mapreduce.reduce.shuffle.connect.timeout=180000
mapreduce.reduce.shuffle.fetch.retry.enabled=false
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
mapreduce.reduce.shuffle.input.buffer.percent=0.70
mapreduce.reduce.shuffle.memory.limit.percent=0.25
mapreduce.reduce.shuffle.merge.percent=0.66
mapreduce.reduce.shuffle.parallelcopies=5
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
mapreduce.reduce.skip.maxgroups=0
mapreduce.reduce.skip.proc.count.autoincr=true
mapreduce.reduce.speculative=true
mapreduce.shuffle.connection-keep-alive.enable=false
mapreduce.shuffle.connection-keep-alive.timeout=5
mapreduce.shuffle.max.connections=0
mapreduce.shuffle.max.threads=0
mapreduce.shuffle.port=13562
mapreduce.shuffle.ssl.enabled=false
mapreduce.shuffle.ssl.file.buffer.size=65536
mapreduce.shuffle.transfer.buffer.size=131072
mapreduce.task.combine.progress.records=10000
mapreduce.task.files.preserve.failedtasks=false
mapreduce.task.io.sort.factor=10
mapreduce.task.io.sort.mb=100
mapreduce.task.merge.progress.records=10000
mapreduce.task.profile=false
mapreduce.task.profile.map.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.maps=0-2
mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.reduce.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.reduces=0-2
mapreduce.task.skip.start.attempts=2
mapreduce.task.timeout=600000
mapreduce.task.userlog.limit.kb=0
mapreduce.tasktracker.dns.interface=default
mapreduce.tasktracker.dns.nameserver=default
mapreduce.tasktracker.healthchecker.interval=60000
mapreduce.tasktracker.healthchecker.script.timeout=600000
mapreduce.tasktracker.http.address=0.0.0.0:50060
mapreduce.tasktracker.http.threads=40
mapreduce.tasktracker.indexcache.mb=10
mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapreduce.tasktracker.local.dir.minspacekill=0
mapreduce.tasktracker.local.dir.minspacestart=0
mapreduce.tasktracker.map.tasks.maximum=2
mapreduce.tasktracker.outofband.heartbeat=false
mapreduce.tasktracker.reduce.tasks.maximum=2
mapreduce.tasktracker.report.address=127.0.0.1:0
mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
metastore.metadata.transformer.class=  
net.topology.impl=org.apache.hadoop.net.NetworkTopology
net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
net.topology.script.number.args=100
nfs.exports.allowed.hosts=* rw
parquet.memory.pool.ratio=0.5
rpc.metrics.quantile.enable=false
s3.blocksize=67108864
s3.bytes-per-checksum=512
s3.client-write-packet-size=65536
s3.replication=3
s3.stream-buffer-size=4096
s3native.blocksize=67108864
s3native.bytes-per-checksum=512
s3native.client-write-packet-size=65536
s3native.replication=3
s3native.stream-buffer-size=4096
stream.stderr.reporter.enabled=true
stream.stderr.reporter.prefix=reporter:
test.data.files=${hive.root}/data/files
test.data.scripts=${hive.root}/data/scripts
test.log.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/log/
test.property1=value1
test.var.hiveconf.property=__HIVE_DEFAULT_PARTITION__
tfile.fs.input.buffer.size=262144
tfile.fs.output.buffer.size=262144
tfile.io.chunk.size=1048576
yarn.acl.enable=false
yarn.admin.acl=*
yarn.am.liveness-monitor.expiry-interval-ms=600000
yarn.app.mapreduce.am.command-opts=-Xmx1024m
yarn.app.mapreduce.am.container.log.backups=0
yarn.app.mapreduce.am.container.log.limit.kb=0
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
yarn.app.mapreduce.am.hard-kill-timeout-ms=10000
yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
yarn.app.mapreduce.am.job.committer.commit-window=10000
yarn.app.mapreduce.am.job.task.listener.thread-count=30
yarn.app.mapreduce.am.resource.cpu-vcores=1
yarn.app.mapreduce.am.resource.mb=1536
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
yarn.app.mapreduce.am.staging-dir=/tmp/hadoop-yarn/staging
yarn.app.mapreduce.client-am.ipc.max-retries=3
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
yarn.app.mapreduce.client.job.max-retries=0
yarn.app.mapreduce.client.job.retry-interval=2000
yarn.app.mapreduce.client.max-retries=3
yarn.app.mapreduce.shuffle.log.backups=0
yarn.app.mapreduce.shuffle.log.limit.kb=0
yarn.app.mapreduce.shuffle.log.separate=true
yarn.app.mapreduce.task.container.log.backups=0
yarn.bin.path=
    yarn:
yarn.client.application-client-protocol.poll-interval-ms=200
yarn.client.failover-proxy-provider=org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
yarn.client.failover-retries=0
yarn.client.failover-retries-on-socket-timeouts=0
yarn.client.max-cached-nodemanagers-proxies=0
yarn.client.nodemanager-client-async.thread-pool-max-size=500
yarn.client.nodemanager-connect.max-wait-ms=180000
yarn.client.nodemanager-connect.retry-interval-ms=10000
yarn.dispatcher.drain-events.timeout=300000
yarn.fail-fast=false
yarn.http.policy=HTTP_ONLY
yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
yarn.log-aggregation-enable=false
yarn.log-aggregation.retain-check-interval-seconds=-1
yarn.log-aggregation.retain-seconds=-1
yarn.nm.liveness-monitor.expiry-interval-ms=600000
yarn.nodemanager.address=0.0.0.0:0
yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
yarn.nodemanager.container-manager.thread-count=20
yarn.nodemanager.container-metrics.unregister-delay-ms=10000
yarn.nodemanager.container-monitor.interval-ms=3000
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled=false
yarn.nodemanager.delete.debug-delay-sec=0
yarn.nodemanager.delete.thread-count=4
yarn.nodemanager.disk-health-checker.interval-ms=120000
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=99
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb=0
yarn.nodemanager.disk-health-checker.min-healthy-disks=0.25
yarn.nodemanager.docker-container-executor.exec-name=/usr/bin/docker
yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME
yarn.nodemanager.health-checker.interval-ms=600000
yarn.nodemanager.health-checker.script.timeout-ms=1200000
yarn.nodemanager.hostname=0.0.0.0
yarn.nodemanager.keytab=/etc/krb5.keytab
yarn.nodemanager.linux-container-executor.cgroups.hierarchy=/hadoop-yarn
yarn.nodemanager.linux-container-executor.cgroups.mount=false
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage=false
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users=true
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user=nobody
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern=^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
yarn.nodemanager.linux-container-executor.resources-handler.class=org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
yarn.nodemanager.local-cache.max-files-per-directory=8192
yarn.nodemanager.local-dirs=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/nm-local-dir
yarn.nodemanager.localizer.address=0.0.0.0:8040
yarn.nodemanager.localizer.cache.cleanup.interval-ms=600000
yarn.nodemanager.localizer.cache.target-size-mb=10240
yarn.nodemanager.localizer.client.thread-count=5
yarn.nodemanager.localizer.fetch.thread-count=4
yarn.nodemanager.log-aggregation.compression-type=none
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds=-1
yarn.nodemanager.log-dirs=${yarn.log.dir}/userlogs
yarn.nodemanager.log.retain-seconds=10800
yarn.nodemanager.pmem-check-enabled=true
yarn.nodemanager.process-kill-wait.ms=2000
yarn.nodemanager.recovery.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn-nm-recovery
yarn.nodemanager.recovery.enabled=false
yarn.nodemanager.remote-app-log-dir=/tmp/logs
yarn.nodemanager.remote-app-log-dir-suffix=logs
yarn.nodemanager.resource.cpu-vcores=8
yarn.nodemanager.resource.memory-mb=8192
yarn.nodemanager.resource.percentage-physical-cpu-limit=100
yarn.nodemanager.resourcemanager.minimum.version=NONE
yarn.nodemanager.sleep-delay-before-sigkill.ms=250
yarn.nodemanager.vmem-check-enabled=true
yarn.nodemanager.vmem-pmem-ratio=2.1
yarn.nodemanager.webapp.address=0.0.0.0:8042
yarn.nodemanager.webapp.cross-origin.enabled=false
yarn.nodemanager.windows-container.cpu-limit.enabled=false
yarn.nodemanager.windows-container.memory-limit.enabled=false
yarn.resourcemanager.address=0.0.0.0:8032
yarn.resourcemanager.admin.address=0.0.0.0:8033
yarn.resourcemanager.admin.client.thread-count=1
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.am.max-attempts=2
yarn.resourcemanager.amlauncher.thread-count=50
yarn.resourcemanager.client.thread-count=50
yarn.resourcemanager.configuration.provider-class=org.apache.hadoop.yarn.LocalConfigurationProvider
yarn.resourcemanager.connect.max-wait.ms=900000
yarn.resourcemanager.connect.retry-interval.ms=30000
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.container.liveness-monitor.interval-ms=600000
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000
yarn.resourcemanager.fail-fast=false
yarn.resourcemanager.fs.state-store.num-retries=0
yarn.resourcemanager.fs.state-store.retry-interval-ms=1000
yarn.resourcemanager.fs.state-store.retry-policy-spec=2000, 500
yarn.resourcemanager.fs.state-store.uri=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/system/rmstore
yarn.resourcemanager.ha.automatic-failover.embedded=true
yarn.resourcemanager.ha.automatic-failover.enabled=true
yarn.resourcemanager.ha.automatic-failover.zk-base-path=
    /yarn-leader-election:
yarn.resourcemanager.ha.enabled=false
yarn.resourcemanager.hostname=0.0.0.0
yarn.resourcemanager.keytab=/etc/krb5.keytab
yarn.resourcemanager.leveldb-state-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/system/rmstore:
yarn.resourcemanager.max-completed-applications=10000
yarn.resourcemanager.nodemanager-connect-retries=10
yarn.resourcemanager.nodemanager.minimum.version=NONE
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms=1000
yarn.resourcemanager.proxy-user-privileges.enabled=false
yarn.resourcemanager.recovery.enabled=false
yarn.resourcemanager.resource-tracker.address=0.0.0.0:8031
yarn.resourcemanager.resource-tracker.client.thread-count=50
yarn.resourcemanager.scheduler.address=0.0.0.0:8030
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.resourcemanager.scheduler.client.thread-count=50
yarn.resourcemanager.scheduler.monitor.enable=false
yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.state-store.max-completed-applications=10000
yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size=10
yarn.resourcemanager.system-metrics-publisher.enabled=false
yarn.resourcemanager.webapp.address=0.0.0.0:8088
yarn.resourcemanager.webapp.cross-origin.enabled=false
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled=true
yarn.resourcemanager.webapp.https.address=0.0.0.0:8090
yarn.resourcemanager.work-preserving-recovery.enabled=true
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms=10000
yarn.resourcemanager.zk-acl=world:anyone:rwcda
yarn.resourcemanager.zk-num-retries=1000
yarn.resourcemanager.zk-retry-interval-ms=1000
yarn.resourcemanager.zk-state-store.parent-path=
    /rmstore:
yarn.resourcemanager.zk-timeout-ms=10000
yarn.scheduler.maximum-allocation-mb=8192
yarn.scheduler.maximum-allocation-vcores=32
yarn.scheduler.minimum-allocation-mb=1024
yarn.scheduler.minimum-allocation-vcores=1
yarn.sharedcache.admin.address=0.0.0.0:8047
yarn.sharedcache.admin.thread-count=1
yarn.sharedcache.app-checker.class=org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
yarn.sharedcache.checksum.algo.impl=org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
yarn.sharedcache.cleaner.initial-delay-mins=10
yarn.sharedcache.cleaner.period-mins=1440
yarn.sharedcache.cleaner.resource-sleep-ms=0
yarn.sharedcache.client-server.address=0.0.0.0:8045
yarn.sharedcache.client-server.thread-count=50
yarn.sharedcache.enabled=false
yarn.sharedcache.nested-level=3
yarn.sharedcache.nm.uploader.replication.factor=10
yarn.sharedcache.nm.uploader.thread-count=20
yarn.sharedcache.root-dir=/sharedcache
yarn.sharedcache.store.class=org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
yarn.sharedcache.store.in-memory.check-period-mins=720
yarn.sharedcache.store.in-memory.initial-delay-mins=10
yarn.sharedcache.store.in-memory.staleness-period-mins=10080
yarn.sharedcache.uploader.server.address=0.0.0.0:8046
yarn.sharedcache.uploader.server.thread-count=50
yarn.sharedcache.webapp.address=0.0.0.0:8788
yarn.timeline-service.address=0.0.0.0:10200
yarn.timeline-service.client.best-effort=false
yarn.timeline-service.client.max-retries=30
yarn.timeline-service.client.retry-interval-ms=1000
yarn.timeline-service.enabled=false
yarn.timeline-service.generic-application-history.max-applications=10000
yarn.timeline-service.handler-thread-count=10
yarn.timeline-service.hostname=0.0.0.0
yarn.timeline-service.http-authentication.simple.anonymous.allowed=true
yarn.timeline-service.http-authentication.type=simple
yarn.timeline-service.keytab=/etc/krb5.keytab
yarn.timeline-service.leveldb-state-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/timeline:
yarn.timeline-service.leveldb-timeline-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/timeline:
yarn.timeline-service.leveldb-timeline-store.read-cache-size=104857600
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
yarn.timeline-service.recovery.enabled=false
yarn.timeline-service.state-store-class=org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
yarn.timeline-service.ttl-enable=true
yarn.timeline-service.ttl-ms=604800000
yarn.timeline-service.webapp.address=0.0.0.0:8188
yarn.timeline-service.webapp.https.address=0.0.0.0:8190
END========"new HiveConf()"========

2024-04-24T20:42:45,286  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:42:45,287  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:45,287  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): create table TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:42:45,288  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:45,427  INFO [main] exec.DDLTask: creating table default.TExternal on null
2024-04-24T20:42:45,440  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExternal, dbName:default, owner:alex, createTime:1713987765, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, numRows=0, rawDataSize=0, numFiles=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:45,440  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExternal, dbName:default, owner:alex, createTime:1713987765, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, numRows=0, rawDataSize=0, numFiles=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:45,440  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:42:45,452  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal
2024-04-24T20:42:45,667  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:45,668  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 0.38 seconds
OK
2024-04-24T20:42:45,668  INFO [main] ql.Driver: OK
2024-04-24T20:42:45,668  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:45,668  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d txnid:0]
2024-04-24T20:42:45,676  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): insert into TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:42:45,679  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:45,681  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:45,682  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:45,778  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:45,810  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:42:45,810  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:45,811  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:45,811  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:45,812  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:45,812  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:45,831  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:42:46,539  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:42:46,539  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:42:46,546  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:42:46,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:42:46,561  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:46,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:46,593  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:46,593  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:46,593  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:46,593  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:42:46,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:42:46,643  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1
2024-04-24T20:42:46,670  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:42:46,699  INFO [main] ppd.OpProcFactory: Processing for FS(3)
2024-04-24T20:42:46,700  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:42:46,700  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:42:46,700  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:42:46,757  INFO [main] optimizer.GenMRFileSink1: using CombineHiveInputformat for the merge job
2024-04-24T20:42:46,761  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:42:46,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:42:46,792  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:42:46,792  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:46,792  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:42:46,792  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:46,793  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 1.116 seconds
2024-04-24T20:42:46,793  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:46,793  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texternal, operationType:INSERT, isAcid:false, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d)
2024-04-24T20:42:46,810  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:42:46,810  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:46,810  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d): insert into TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:42:46,811  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:42:46,811  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:46,813  INFO [main] ql.Driver: Query ID = alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
Total jobs = 1
2024-04-24T20:42:46,813  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:42:46,823  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:42:46,825  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:42:46,825  INFO [main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:42:46,829  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:42:46,833  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:42:46,834  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:46,901  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:42:46,923  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,71KB
2024-04-24T20:42:46,937  INFO [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2024-04-24T20:42:46,944  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10001
2024-04-24T20:42:46,952  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:42:46,955  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10004/4c6effae-0425-4daa-bd92-5fe5db177b39/map.xml
2024-04-24T20:42:46,980  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:42:47,057  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10004/4c6effae-0425-4daa-bd92-5fe5db177b39/map.xml
2024-04-24T20:42:47,061  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:42:47,061  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:42:47,061  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:47,075  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:42:47,082  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:42:47,103  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:42:47,168  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local633889388_0001
2024-04-24T20:42:47,298  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T20:42:47,300  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T20:42:47,302  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:42:47,302  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:42:47,311  INFO [Thread-49] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:42:47,314  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local633889388_0001_m_000000_0
2024-04-24T20:42:47,344  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:47,348  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:47,351  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10004/4c6effae-0425-4daa-bd92-5fe5db177b39/map.xml
2024-04-24T20:42:47,352  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:42:47,373  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,71KB
2024-04-24T20:42:47,379  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T20:42:47,384  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:47,384  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:47,384  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10004/4c6effae-0425-4daa-bd92-5fe5db177b39/map.xml
2024-04-24T20:42:47,386  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:42:47,388  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:42:47,390  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:42:47,390  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:42:47,393  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:42:47,395  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing operator FS[3]
2024-04-24T20:42:47,396  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@233744de and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@4c631491
2024-04-24T20:42:47,398  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10004/4c6effae-0425-4daa-bd92-5fe5db177b39/map.xml
2024-04-24T20:42:47,401  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_tmp.-ext-10002/000000_0
2024-04-24T20:42:47,401  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T20:42:47,401  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_tmp.-ext-10002/000000_0
2024-04-24T20:42:47,413  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 1
2024-04-24T20:42:47,428  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:42:47,457  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing operator FS[3]
2024-04-24T20:42:47,458  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 3
2024-04-24T20:42:47,489  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_1_default.texternal:3, 
2024-04-24T20:42:47,491  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:42:47,492  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local633889388_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T20:42:47,496  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/810f17e8-32cd-48d9-8479-d8ce125c00af/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:47,496  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local633889388_0001_m_000000_0' done.
2024-04-24T20:42:47,496  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local633889388_0001_m_000000_0
2024-04-24T20:42:47,497  INFO [Thread-49] mapred.LocalJobRunner: map task executor complete.
2024-04-24 20:42:48,313 Stage-1 map = 100%,  reduce = 0%
2024-04-24T20:42:48,314  INFO [main] exec.Task: 2024-04-24 20:42:48,313 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local633889388_0001
2024-04-24T20:42:48,317  INFO [main] exec.Task: Ended Job = job_local633889388_0001
2024-04-24T20:42:48,319  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/_tmp.-ext-10002 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/-ext-10002
2024-04-24T20:42:48,320  INFO [main] ql.Driver: Starting task [Stage-7:CONDITIONAL] in serial mode
Stage-4 is selected by condition resolver.
2024-04-24T20:42:48,321  INFO [main] exec.Task: Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
2024-04-24T20:42:48,321  INFO [main] exec.Task: Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
2024-04-24T20:42:48,321  INFO [main] exec.Task: Stage-5 is filtered out by condition resolver.
2024-04-24T20:42:48,321  INFO [main] ql.Driver: Starting task [Stage-4:MOVE] in serial mode
2024-04-24T20:42:48,322  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:48,322  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:48,323  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:48,323  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/-ext-10000
2024-04-24T20:42:48,323  INFO [main] exec.Task: Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/-ext-10000 from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/-ext-10002
2024-04-24T20:42:48,324  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:48,324  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:48,339  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.texternal
2024-04-24T20:42:48,339  INFO [main] exec.Task: Loading data to table default.texternal from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal/.hive-staging_hive_2024-04-24_20-42-45_676_2664614220094132846-1/-ext-10000
2024-04-24T20:42:48,340  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:42:48,340  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,381  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,382  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,383  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,383  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:48,384  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:48,388  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:48,388  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:48,410  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:42:48,410  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:42:48,434  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:48,434  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:48,447  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=texternal newtbl=texternal
2024-04-24T20:42:48,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=texternal newtbl=texternal	
2024-04-24T20:42:48,504  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:42:48,504  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:42:48,504  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:48,504  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:48,505  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:48,505  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:48,507  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:42:48,507  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,544  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,545  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,546  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:48,547  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:48,549  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:48,549  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:48,569  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/810f17e8-32cd-48d9-8479-d8ce125c00af/hive_2024-04-24_20-42-45_676_2664614220094132846-1/-mr-10001
2024-04-24T20:42:48,571  INFO [main] fs.FSStatsAggregator: Read stats : {default.texternal/={numRows=3, rawDataSize=24}}
2024-04-24T20:42:48,571  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:42:48,571  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:42:48,592  INFO [main] fs.FSStatsAggregator: Read stats for : default.texternal/	numRows	3
2024-04-24T20:42:48,592  INFO [main] fs.FSStatsAggregator: Read stats for : default.texternal/	rawDataSize	24
2024-04-24T20:42:48,592  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:48,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:48,593  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:48,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:48,595  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=texternal newtbl=texternal
2024-04-24T20:42:48,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=texternal newtbl=texternal	
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,653  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:48,654  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:48,656  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:48,657  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:48,684  INFO [main] hive.log: Updating table stats fast for texternal
2024-04-24T20:42:48,684  INFO [main] hive.log: Updated size of table texternal to 244
2024-04-24T20:42:48,696  INFO [main] exec.StatsTask: Table default.texternal stats: [numFiles=1, numRows=3, totalSize=244, rawDataSize=24]
2024-04-24T20:42:48,696  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:42:48,696  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:42:48,697  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:48,697  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:48,697  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d); Time taken: 1.886 seconds
OK
2024-04-24T20:42:48,697  INFO [main] ql.Driver: OK
2024-04-24T20:42:48,697  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d
2024-04-24T20:42:48,697  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204244_3e287b65-7d4b-4f05-9998-c2710c890e5d txnid:0]
2024-04-24T20:42:48,710  INFO [main] acid.PreUpgradeTool: Starting with RunOptions{outputDir='/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179', execute=true, dbRegex='.*', tableRegex='.*', tableType=null, tablePoolSize=8}
2024-04-24T20:42:48,710  INFO [main] acid.PreUpgradeTool: Using Hive Version: 2.3.3 build: 2.3.3 from 8a511e3f79b43d4be41cd231cf5c99e43b248383 by daijy source checksum fb9b95d9baaf3f968c457dee42d015d4
2024-04-24T20:42:48,712  INFO [main] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:42:48,714  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:48,716  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:48,716  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:48,720  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=810f17e8-32cd-48d9-8479-d8ce125c00af, clientType=HIVECLI]
2024-04-24T20:42:48,721  INFO [main] metastore.HiveMetaStore: 0: get_databases: .*
2024-04-24T20:42:48,721  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: .*	
2024-04-24T20:42:48,726  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
2024-04-24T20:42:48,726  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
2024-04-24T20:42:48,731  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:42:48,732  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:42:48,735  INFO [Table-ForkJoinPool-1-worker-1] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:42:48,741  INFO [Table-ForkJoinPool-1-worker-1] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=810f17e8-32cd-48d9-8479-d8ce125c00af, clientType=HIVECLI]
2024-04-24T20:42:48,742  INFO [Table-ForkJoinPool-1-worker-1] metastore.HiveMetaStore: 1: get_table : db=test tbl=texternal
2024-04-24T20:42:48,742  INFO [Table-ForkJoinPool-1-worker-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:42:48,805  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,805  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:48,805  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,807  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,807  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,807  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,807  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,807  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,808  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,809  INFO [Table-ForkJoinPool-1-worker-1] metastore.HiveMetaStore: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:48,810  INFO [Table-ForkJoinPool-1-worker-1] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:48,814  INFO [Table-ForkJoinPool-1-worker-1] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:48,814  INFO [Table-ForkJoinPool-1-worker-1] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:48,830  INFO [Table-ForkJoinPool-1-worker-1] metadata.HiveUtils: Adding metastore authorization provider: org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
2024-04-24T20:42:48,833  INFO [Table-ForkJoinPool-1-worker-1] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,867  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,868  WARN [Table-ForkJoinPool-1-worker-1] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,888  INFO [main] acid.PreUpgradeTool: No compaction is necessary
2024-04-24T20:42:48,889  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:48,889  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:48,889  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:48,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
]]></system-err>
  </testcase>
  <testcase name="testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.32">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TInclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
]]></error>
    <system-err><![CDATA[2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,931  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,932  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:48,961  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:48,962  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:49,103  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:49,104  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:49,104  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:49,104  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:49,263  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181
2024-04-24T20:42:49,265  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181
2024-04-24T20:42:49,267  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181/_tmp_space.db
2024-04-24T20:42:49,268  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=239b885e-f5d6-4106-bedb-01c974371181, clientType=HIVECLI]
2024-04-24T20:42:49,268  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:42:49,268  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TInclude
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:49,310  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:49,311  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:49,311  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:49,312  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:49,314  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:49,314  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:49,314  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,314  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,316  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:49,316  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:49,316  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:49,317  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.048 seconds
2024-04-24T20:42:49,317  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,317  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TInclude
2024-04-24T20:42:49,317  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:49,318  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,318  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,320 ERROR [main] metadata.Hive: Table TInclude not found: default.TInclude table not found
2024-04-24T20:42:49,320  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,320  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,322  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:49,323  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.005 seconds
OK
2024-04-24T20:42:49,323  INFO [main] ql.Driver: OK
2024-04-24T20:42:49,323  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:49,323  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TExclude
2024-04-24T20:42:49,324  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:49,325  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:49,327  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:49,327  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:49,327  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:49,327  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.004 seconds
2024-04-24T20:42:49,327  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,328  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TExclude
2024-04-24T20:42:49,328  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:49,328  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:49,328  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:49,330 ERROR [main] metadata.Hive: Table TExclude not found: default.TExclude table not found
2024-04-24T20:42:49,330  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:49,330  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:49,333  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:49,333  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.005 seconds
OK
2024-04-24T20:42:49,333  INFO [main] ql.Driver: OK
2024-04-24T20:42:49,333  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:49,334  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:49,336  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:49,336  INFO [main] parse.CalcitePlanner: Creating table default.TInclude position=13
2024-04-24T20:42:49,336  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:49,336  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:49,340  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:49,340  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:49,340  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:49,341  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.006 seconds
2024-04-24T20:42:49,341  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,342  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a)
2024-04-24T20:42:49,365  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:42:49,365  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,365  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:49,365  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:49,366  INFO [main] exec.DDLTask: creating table default.TInclude on null
2024-04-24T20:42:49,367  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numRows=0, rawDataSize=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:49,367  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numRows=0, rawDataSize=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:49,375  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude
2024-04-24T20:42:49,409  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:49,410  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.044 seconds
OK
2024-04-24T20:42:49,410  INFO [main] ql.Driver: OK
2024-04-24T20:42:49,410  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,410  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a txnid:0]
2024-04-24T20:42:49,414  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:49,415  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:49,416  INFO [main] parse.CalcitePlanner: Creating table default.TExclude position=13
2024-04-24T20:42:49,416  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:49,416  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:49,421  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:49,421  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:49,421  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:49,422  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.007 seconds
2024-04-24T20:42:49,422  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,422  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a)
2024-04-24T20:42:49,437  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:42:49,438  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,438  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:49,438  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:49,439  INFO [main] exec.DDLTask: creating table default.TExclude on null
2024-04-24T20:42:49,440  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, transactional=true, numFiles=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:49,440  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, transactional=true, numFiles=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:49,449  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texclude
2024-04-24T20:42:49,476  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:49,476  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.038 seconds
OK
2024-04-24T20:42:49,476  INFO [main] ql.Driver: OK
2024-04-24T20:42:49,476  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,476  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a txnid:0]
2024-04-24T20:42:49,480  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:42:49,482  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:49,482  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,499  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:49,504  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:42:49,504  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:49,504  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:49,504  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:49,504  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,504  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,518  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:42:49,581  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:42:49,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:42:49,583  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:42:49,583  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:42:49,587  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:49,587  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:49,603  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:49,603  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:49,603  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:49,603  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:49,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:49,623  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1
2024-04-24T20:42:49,640  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:42:49,641  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:42:49,642  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:42:49,643  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:42:49,643  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tinclude
2024-04-24T20:42:49,652  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:42:49,652  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:49,652  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:42:49,653  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:49,653  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.172 seconds
2024-04-24T20:42:49,655  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:49,684  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:49,685  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:49,697  INFO [main] compactor.HouseKeeperServiceBase: Started org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService with delay/interval = 100/1000 MILLISECONDS
2024-04-24T20:42:49,706  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:42:49,706  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,706  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a)
2024-04-24T20:42:49,729  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:42:49,735  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:42:49,735  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:42:49,735  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:49,735  INFO [main] ql.Driver: Query ID = alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
Total jobs = 1
2024-04-24T20:42:49,735  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:42:49,735  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:42:49,736  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:42:49,736  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:42:49,736  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:42:49,736  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:42:49,736  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:42:49,736  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:42:49,736  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:42:49,736  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:42:49,737  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:42:49,737  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:42:49,737  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:49,742  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:42:49,747  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,68KB
2024-04-24T20:42:49,751  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:42:49,757  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:42:49,758  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:42:49,759  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10001
2024-04-24T20:42:49,761  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:42:49,762  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/map.xml
2024-04-24T20:42:49,762  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/reduce.xml
2024-04-24T20:42:49,765  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:42:49,799  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.AcidOpenTxnsCounterService: OpenTxnsCounter ran for 0seconds.  isAliveCounter=-2147483647
2024-04-24T20:42:49,846  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/map.xml
2024-04-24T20:42:49,847  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:42:49,848  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:42:49,848  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:49,852  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:42:49,852  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:42:49,866  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:42:49,879  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local419275395_0002
2024-04-24T20:42:49,928  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:42:49,928  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:42:49,928  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:42:49,929  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:42:49,930  INFO [Thread-127] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:42:49,931  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local419275395_0002_m_000000_0
2024-04-24T20:42:49,934  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:49,935  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:49,937  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/map.xml
2024-04-24T20:42:49,938  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:42:49,941  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,68KB
2024-04-24T20:42:49,943  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:42:49,963  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:42:49,963  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:42:49,963  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:42:49,963  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:42:49,963  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:42:49,966  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:42:49,966  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:49,967  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:49,967  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/map.xml
2024-04-24T20:42:49,967  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:42:49,968  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:42:49,968  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:42:49,968  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:42:49,968  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:42:49,968  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:42:49,969  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:42:49,978  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/map.xml
2024-04-24T20:42:49,978  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:42:49,979  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:42:49,979  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:42:49,980  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:42:49,981  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:42:49,981  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:42:49,981  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:42:49,981  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:42:49,982  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:42:49,986  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:42:49,988  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local419275395_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T20:42:49,991  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/239b885e-f5d6-4106-bedb-01c974371181/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:49,991  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local419275395_0002_m_000000_0' done.
2024-04-24T20:42:49,991  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local419275395_0002_m_000000_0
2024-04-24T20:42:49,992  INFO [Thread-127] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:42:49,994  INFO [Thread-127] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:42:49,994  INFO [pool-20-thread-1] mapred.LocalJobRunner: Starting task: attempt_local419275395_0002_r_000000_0
2024-04-24T20:42:50,000  INFO [pool-20-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:50,002  INFO [pool-20-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49dd8b43
2024-04-24T20:42:50,012  INFO [pool-20-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:42:50,014  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local419275395_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:42:50,030  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local419275395_0002_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:42:50,032  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local419275395_0002_m_000000_0
2024-04-24T20:42:50,033  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:42:50,034  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:42:50,035  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:50,035  INFO [pool-20-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:42:50,040  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:50,040  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:42:50,041  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:42:50,041  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:42:50,042  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:42:50,042  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:50,042  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:42:50,042  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:50,044  INFO [pool-20-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:50,044  INFO [pool-20-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:50,044  INFO [pool-20-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/reduce.xml
2024-04-24T20:42:50,045  INFO [pool-20-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:42:50,050  INFO [pool-20-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:42:50,051  INFO [pool-20-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:42:50,051  INFO [pool-20-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:42:50,051  INFO [pool-20-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:42:50,052  INFO [pool-20-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:42:50,053  INFO [pool-20-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@79579610 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@509e0c7
2024-04-24T20:42:50,055  INFO [pool-20-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_tmp.-ext-10000/000000_0
2024-04-24T20:42:50,056  INFO [pool-20-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:42:50,056  INFO [pool-20-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_tmp.-ext-10000/000000_0
2024-04-24T20:42:50,066  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:42:50,066  INFO [pool-20-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:50,071  INFO [pool-20-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:50,072  INFO [pool-20-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:42:50,072  INFO [pool-20-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:42:50,072  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:42:50,081  INFO [pool-20-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:3, 
2024-04-24T20:42:50,081  INFO [pool-20-thread-1] mapred.Task: Task:attempt_local419275395_0002_r_000000_0 is done. And is in the process of committing
2024-04-24T20:42:50,082  INFO [pool-20-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:42:50,082  INFO [pool-20-thread-1] mapred.Task: Task 'attempt_local419275395_0002_r_000000_0' done.
2024-04-24T20:42:50,082  INFO [pool-20-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local419275395_0002_r_000000_0
2024-04-24T20:42:50,082  INFO [pool-20-thread-1] mapred.LocalJobRunner: Starting task: attempt_local419275395_0002_r_000001_0
2024-04-24T20:42:50,084  INFO [pool-20-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:50,084  INFO [pool-20-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@39d95094
2024-04-24T20:42:50,084  INFO [pool-20-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:42:50,085  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local419275395_0002_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:42:50,086  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local419275395_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:42:50,086  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local419275395_0002_m_000000_0
2024-04-24T20:42:50,086  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:42:50,087  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:42:50,087  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:50,087  INFO [pool-20-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:42:50,088  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:50,088  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:50,089  INFO [pool-20-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10003/2daf59e2-8c9e-4f24-b1b2-f0e03ff5336e/reduce.xml
2024-04-24T20:42:50,090  INFO [pool-20-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:42:50,093  INFO [pool-20-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:42:50,093  INFO [pool-20-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:42:50,093  INFO [pool-20-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:42:50,094  INFO [pool-20-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:42:50,094  INFO [pool-20-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@6865e7cb and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@c2076f6
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_tmp.-ext-10000/000001_0
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:42:50,095  INFO [pool-20-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_tmp.-ext-10000/000001_0
2024-04-24T20:42:50,101  INFO [pool-20-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:50,106  INFO [pool-20-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:50,111  INFO [pool-20-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:0, 
2024-04-24T20:42:50,112  INFO [pool-20-thread-1] mapred.Task: Task:attempt_local419275395_0002_r_000001_0 is done. And is in the process of committing
2024-04-24T20:42:50,112  INFO [pool-20-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:42:50,112  INFO [pool-20-thread-1] mapred.Task: Task 'attempt_local419275395_0002_r_000001_0' done.
2024-04-24T20:42:50,112  INFO [pool-20-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local419275395_0002_r_000001_0
2024-04-24T20:42:50,113  INFO [Thread-127] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:42:50,940 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:42:50,940  INFO [main] exec.Task: 2024-04-24 20:42:50,940 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local419275395_0002
2024-04-24T20:42:50,942  INFO [main] exec.Task: Ended Job = job_local419275395_0002
2024-04-24T20:42:50,944  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/-ext-10000
2024-04-24T20:42:50,944  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:42:50,944  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:50,944  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:50,945  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:50,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tinclude
2024-04-24T20:42:50,945  INFO [main] exec.Task: Loading data to table default.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/-ext-10000
2024-04-24T20:42:50,946  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:42:50,946  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:50,974  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:50,975  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:50,975  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:50,977  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:50,979  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:50,979  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:50,992  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:42:50,992  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:42:51,008  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:42:51,009  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-49_481_5712770104950219783-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:42:51,010  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:42:51,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:42:51,045  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:42:51,045  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:42:51,045  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:51,045  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:51,045  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:51,045  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:51,047  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:42:51,047  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:51,072  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:51,074  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:51,075  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:51,078  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:51,078  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:51,091  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/239b885e-f5d6-4106-bedb-01c974371181/hive_2024-04-24_20-42-49_481_5712770104950219783-1/-mr-10001
2024-04-24T20:42:51,092  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={numRows=3, rawDataSize=0}}
2024-04-24T20:42:51,092  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={}}
2024-04-24T20:42:51,092  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:42:51,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:42:51,107  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:51,107  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:51,108  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:51,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:51,109  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:42:51,109  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:51,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:51,136  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:51,136  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:51,138  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:51,141  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:51,141  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:51,165  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:42:51,165  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:42:51,178  INFO [main] exec.StatsTask: Table default.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:42:51,178  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:42:51,179  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:42:51,179  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:51,179  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:51,179  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 1.443 seconds
OK
2024-04-24T20:42:51,179  INFO [main] ql.Driver: OK
2024-04-24T20:42:51,179  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:51,193  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): update TInclude set a = 1 where b = 2
2024-04-24T20:42:51,197  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,197  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,210  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `default`.`TInclude` select ROW__ID,`a`,`b` from `default`.`TInclude` sort by ROW__ID >
2024-04-24T20:42:51,213  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:42:51,213  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,213  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,226  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:51,226  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:42:51,226  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:42:51,227  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:42:51,227  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:42:51,240  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:42:51,240  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:42:51,240  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,240  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,257  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:42:51,283  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-42-51_210_7066991763152184162-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:42:51,295 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:42:51,295  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:51,295  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.103 seconds
2024-04-24T20:42:51,295  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:51,296  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TInclude
2024-04-24T20:42:51,297  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,297  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,309  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:51,309  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:51,309  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:51,310  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.013 seconds
2024-04-24T20:42:51,310  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:51,310  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tinclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a)
2024-04-24T20:42:51,325  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:42:51,325  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:51,325  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TInclude
2024-04-24T20:42:51,325  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:51,325  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,325  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,339  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:42:51,339  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:42:51,352  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TInclude
2024-04-24T20:42:51,352  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TInclude	
2024-04-24T20:42:51,972  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:51,973  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:52,015  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:52,016  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:52,017  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:52,039  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,040  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.714 seconds
OK
2024-04-24T20:42:52,040  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,040  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:52,040  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a txnid:0]
2024-04-24T20:42:52,045  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TExclude
2024-04-24T20:42:52,046  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:52,046  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:52,062  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,062  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,062  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,062  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.017 seconds
2024-04-24T20:42:52,063  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:52,063  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a)
2024-04-24T20:42:52,077  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:42:52,077  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:52,077  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a): drop table if exists TExclude
2024-04-24T20:42:52,078  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,078  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:52,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:52,091  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:42:52,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:42:52,106  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExclude
2024-04-24T20:42:52,106  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExclude	
2024-04-24T20:42:52,160  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:52,160  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:52,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:52,192  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:52,192  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:52,192  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:52,214  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,215  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a); Time taken: 0.137 seconds
OK
2024-04-24T20:42:52,215  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,215  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a
2024-04-24T20:42:52,215  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:5 queryId=alex_20240424204249_0151ed0b-fbc1-4ef2-97b7-2477d48a2d9a txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgrade" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.264">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TAcid set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
]]></error>
    <system-err><![CDATA[2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:52,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:52,250  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:52,277  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:52,278  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:52,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:52,445  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:52,446  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:52,446  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:52,446  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:52,606  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9
2024-04-24T20:42:52,610  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9
2024-04-24T20:42:52,613  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/_tmp_space.db
2024-04-24T20:42:52,613  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9, clientType=HIVECLI]
2024-04-24T20:42:52,613  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:42:52,614  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcid
2024-04-24T20:42:52,615  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:52,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:52,618  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,618  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,618  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,618  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.004 seconds
2024-04-24T20:42:52,619  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,619  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcid
2024-04-24T20:42:52,619  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,619  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:52,619  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:52,622 ERROR [main] metadata.Hive: Table TAcid not found: default.TAcid table not found
2024-04-24T20:42:52,622  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:52,622  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:52,625  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,626  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.006 seconds
OK
2024-04-24T20:42:52,626  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,626  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:52,626  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcidPart
2024-04-24T20:42:52,627  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:52,627  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:52,630  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,630  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,630  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,631  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.004 seconds
2024-04-24T20:42:52,631  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,631  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcidPart
2024-04-24T20:42:52,631  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,632  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:52,632  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:52,634 ERROR [main] metadata.Hive: Table TAcidPart not found: default.TAcidPart table not found
2024-04-24T20:42:52,634  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:52,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:52,637  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,637  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.006 seconds
OK
2024-04-24T20:42:52,637  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,637  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:52,638  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlat
2024-04-24T20:42:52,639  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:52,639  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:52,641  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,641  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,641  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,641  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.003 seconds
2024-04-24T20:42:52,642  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,642  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlat
2024-04-24T20:42:52,642  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,642  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:52,642  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:52,644 ERROR [main] metadata.Hive: Table TFlat not found: default.TFlat table not found
2024-04-24T20:42:52,644  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:52,644  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:52,646  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,646  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.004 seconds
OK
2024-04-24T20:42:52,646  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,646  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:52,647  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlatText
2024-04-24T20:42:52,647  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:52,648  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:52,649  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,649  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,649  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,650  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.002 seconds
2024-04-24T20:42:52,650  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,650  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlatText
2024-04-24T20:42:52,650  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,650  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:52,650  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:52,652 ERROR [main] metadata.Hive: Table TFlatText not found: default.TFlatText table not found
2024-04-24T20:42:52,652  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:52,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:52,654  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,654  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.004 seconds
OK
2024-04-24T20:42:52,655  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,655  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:52,655  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:52,657  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:52,657  INFO [main] parse.CalcitePlanner: Creating table default.TAcid position=13
2024-04-24T20:42:52,657  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:52,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:52,662  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,662  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,663  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,663  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.007 seconds
2024-04-24T20:42:52,663  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,663  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:52,684  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:42:52,684  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,684  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:52,685  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,686  INFO [main] exec.DDLTask: creating table default.TAcid on null
2024-04-24T20:42:52,686  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numFiles=0, numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:52,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numFiles=0, numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:52,695  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid
2024-04-24T20:42:52,756  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,756  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.072 seconds
OK
2024-04-24T20:42:52,756  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,756  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,756  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:52,760  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:52,762  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:52,762  INFO [main] parse.CalcitePlanner: Creating table default.TAcidPart position=13
2024-04-24T20:42:52,762  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:52,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:52,767  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,767  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,767  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,767  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.007 seconds
2024-04-24T20:42:52,767  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,768  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:52,782  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:42:52,782  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,782  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:42:52,782  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,784  INFO [main] exec.DDLTask: creating table default.TAcidPart on null
2024-04-24T20:42:52,784  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:52,784  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:52,793  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacidpart
2024-04-24T20:42:52,820  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,821  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.038 seconds
OK
2024-04-24T20:42:52,821  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,821  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,821  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:52,826  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:42:52,827  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:52,827  INFO [main] parse.CalcitePlanner: Creating table default.TFlat position=13
2024-04-24T20:42:52,827  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:52,827  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:52,832  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,832  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,832  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,832  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.006 seconds
2024-04-24T20:42:52,832  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,832  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:52,848  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:42:52,848  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,848  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:42:52,848  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,850  INFO [main] exec.DDLTask: creating table default.TFlat on null
2024-04-24T20:42:52,850  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numFiles=0, transactional=false, numRows=0, rawDataSize=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:52,850  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numFiles=0, transactional=false, numRows=0, rawDataSize=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:52,851  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:42:52,861  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tflat
2024-04-24T20:42:52,893  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,894  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.045 seconds
OK
2024-04-24T20:42:52,894  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,894  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,894  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:52,898  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:42:52,899  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:52,899  INFO [main] parse.CalcitePlanner: Creating table default.TFlatText position=13
2024-04-24T20:42:52,899  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:42:52,900  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:42:52,914  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:52,914  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:52,914  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:52,914  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.016 seconds
2024-04-24T20:42:52,915  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,915  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:52,928  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:42:52,928  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,928  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:42:52,928  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:52,930  INFO [main] exec.DDLTask: creating table default.TFlatText on null
2024-04-24T20:42:52,930  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, transactional=false, totalSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:42:52,930  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, transactional=false, totalSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:42:52,931  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:42:52,939  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tflattext
2024-04-24T20:42:52,970  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:52,971  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.042 seconds
OK
2024-04-24T20:42:52,971  INFO [main] ql.Driver: OK
2024-04-24T20:42:52,971  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:52,971  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:52,975  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:42:52,976  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:42:52,976  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:52,977  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:53,041  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:53,046  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:42:53,046  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:53,046  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:53,046  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:53,047  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:53,047  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:53,059  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:42:53,132  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:42:53,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:42:53,135  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:42:53,135  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:42:53,142  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:53,142  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:53,159  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:42:53,159  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:42:53,159  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:42:53,159  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:53,159  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:53,173  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1
2024-04-24T20:42:53,187  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:42:53,187  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:42:53,188  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:42:53,188  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:42:53,189  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tacid
2024-04-24T20:42:53,207  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:42:53,207  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:53,207  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:42:53,207  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:53,207  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.232 seconds
2024-04-24T20:42:53,214  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:42:53,214  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:53,214  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tacid, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:53,232  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:42:53,236  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:42:53,236  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:42:53,236  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:53,236  INFO [main] ql.Driver: Query ID = alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
Total jobs = 1
2024-04-24T20:42:53,236  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:42:53,236  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:42:53,237  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:42:53,237  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:42:53,237  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:42:53,237  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:42:53,237  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:42:53,237  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:42:53,237  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:42:53,237  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:42:53,237  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:42:53,237  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:42:53,237  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:53,243  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:42:53,245  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:42:53,249  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:42:53,253  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:42:53,254  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:42:53,254  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10001
2024-04-24T20:42:53,256  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:42:53,257  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/map.xml
2024-04-24T20:42:53,257  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/reduce.xml
2024-04-24T20:42:53,260  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:42:53,321  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/map.xml
2024-04-24T20:42:53,322  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:42:53,322  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:42:53,322  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:42:53,326  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:42:53,326  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:42:53,339  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:42:53,352  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1773842451_0003
2024-04-24T20:42:53,393  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:42:53,393  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:42:53,393  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:42:53,394  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:42:53,395  INFO [Thread-243] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:42:53,395  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1773842451_0003_m_000000_0
2024-04-24T20:42:53,398  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:53,399  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:53,401  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/map.xml
2024-04-24T20:42:53,402  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:42:53,404  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:42:53,405  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:42:53,410  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:42:53,410  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:42:53,410  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:42:53,410  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:42:53,410  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:42:53,411  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:42:53,412  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,412  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,412  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/map.xml
2024-04-24T20:42:53,412  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:42:53,413  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:42:53,414  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/map.xml
2024-04-24T20:42:53,415  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:42:53,415  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:42:53,415  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:42:53,415  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:42:53,416  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:42:53,417  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:42:53,417  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:42:53,417  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:42:53,417  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:42:53,417  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:42:53,418  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:42:53,418  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1773842451_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T20:42:53,420  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:42:53,420  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1773842451_0003_m_000000_0' done.
2024-04-24T20:42:53,420  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1773842451_0003_m_000000_0
2024-04-24T20:42:53,420  INFO [Thread-243] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:42:53,421  INFO [Thread-243] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:42:53,422  INFO [pool-26-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1773842451_0003_r_000000_0
2024-04-24T20:42:53,424  INFO [pool-26-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:53,424  INFO [pool-26-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d1ae1d1
2024-04-24T20:42:53,424  INFO [pool-26-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:42:53,425  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1773842451_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:42:53,427  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1773842451_0003_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:42:53,428  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local1773842451_0003_m_000000_0
2024-04-24T20:42:53,428  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:42:53,428  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:42:53,429  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:53,429  INFO [pool-26-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:53,430  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:42:53,431  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:53,431  INFO [pool-26-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,431  INFO [pool-26-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,431  INFO [pool-26-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/reduce.xml
2024-04-24T20:42:53,432  INFO [pool-26-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:42:53,435  INFO [pool-26-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:42:53,436  INFO [pool-26-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:42:53,436  INFO [pool-26-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:42:53,436  INFO [pool-26-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:42:53,437  INFO [pool-26-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:42:53,437  INFO [pool-26-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@799ad170 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@23d4a3fb
2024-04-24T20:42:53,438  INFO [pool-26-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_tmp.-ext-10000/000000_0
2024-04-24T20:42:53,438  INFO [pool-26-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:42:53,438  INFO [pool-26-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_tmp.-ext-10000/000000_0
2024-04-24T20:42:53,443  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:42:53,443  INFO [pool-26-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:53,448  INFO [pool-26-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:53,448  INFO [pool-26-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:42:53,448  INFO [pool-26-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:42:53,448  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:42:53,456  INFO [pool-26-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:3, 
2024-04-24T20:42:53,456  INFO [pool-26-thread-1] mapred.Task: Task:attempt_local1773842451_0003_r_000000_0 is done. And is in the process of committing
2024-04-24T20:42:53,457  INFO [pool-26-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:42:53,457  INFO [pool-26-thread-1] mapred.Task: Task 'attempt_local1773842451_0003_r_000000_0' done.
2024-04-24T20:42:53,457  INFO [pool-26-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1773842451_0003_r_000000_0
2024-04-24T20:42:53,457  INFO [pool-26-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1773842451_0003_r_000001_0
2024-04-24T20:42:53,458  INFO [pool-26-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:42:53,458  INFO [pool-26-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@270da4c0
2024-04-24T20:42:53,459  INFO [pool-26-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:42:53,460  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1773842451_0003_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:42:53,461  INFO [localfetcher#4] reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1773842451_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:42:53,461  INFO [localfetcher#4] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1773842451_0003_m_000000_0
2024-04-24T20:42:53,461  INFO [localfetcher#4] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:42:53,461  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:42:53,462  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:53,462  INFO [pool-26-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:42:53,463  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:53,463  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:42:53,464  INFO [pool-26-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10003/f95386a5-24a9-48a4-8f69-14df6fe0ed4e/reduce.xml
2024-04-24T20:42:53,465  INFO [pool-26-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:42:53,468  INFO [pool-26-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:42:53,469  INFO [pool-26-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:42:53,469  INFO [pool-26-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:42:53,469  INFO [pool-26-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:42:53,470  INFO [pool-26-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:42:53,470  INFO [pool-26-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@609c3cd and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@889a0ad
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_tmp.-ext-10000/000001_0
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:42:53,471  INFO [pool-26-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_tmp.-ext-10000/000001_0
2024-04-24T20:42:53,476  INFO [pool-26-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:53,481  INFO [pool-26-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:42:53,486  INFO [pool-26-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:0, 
2024-04-24T20:42:53,486  INFO [pool-26-thread-1] mapred.Task: Task:attempt_local1773842451_0003_r_000001_0 is done. And is in the process of committing
2024-04-24T20:42:53,487  INFO [pool-26-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:42:53,487  INFO [pool-26-thread-1] mapred.Task: Task 'attempt_local1773842451_0003_r_000001_0' done.
2024-04-24T20:42:53,487  INFO [pool-26-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1773842451_0003_r_000001_0
2024-04-24T20:42:53,487  INFO [Thread-243] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:42:54,406 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:42:54,406  INFO [main] exec.Task: 2024-04-24 20:42:54,406 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1773842451_0003
2024-04-24T20:42:54,408  INFO [main] exec.Task: Ended Job = job_local1773842451_0003
2024-04-24T20:42:54,410  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/-ext-10000
2024-04-24T20:42:54,410  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:42:54,410  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:54,410  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:54,411  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:54,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tacid
2024-04-24T20:42:54,411  INFO [main] exec.Task: Loading data to table default.tacid from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/-ext-10000
2024-04-24T20:42:54,413  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:42:54,413  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:54,446  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:54,447  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:54,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:54,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:54,447  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:54,447  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:54,447  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:54,447  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:54,458  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:54,458  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:54,469  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:42:54,470  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:42:54,482  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:42:54,483  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-52_976_8114049074026371370-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:42:54,484  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:42:54,484  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:42:54,518  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:42:54,518  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:42:54,518  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:54,518  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:54,519  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:54,519  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:54,521  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:42:54,521  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:42:54,551  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:54,552  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:54,553  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:54,553  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:54,555  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:54,555  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:54,568  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/ba6ce9fe-f3e6-4763-a9b6-7adfd2e691a9/hive_2024-04-24_20-42-52_976_8114049074026371370-1/-mr-10001
2024-04-24T20:42:54,568  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={}}
2024-04-24T20:42:54,569  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={numRows=3, rawDataSize=0}}
2024-04-24T20:42:54,569  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:42:54,569  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:42:54,586  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:42:54,586  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:42:54,587  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:42:54,587  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:42:54,588  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:42:54,589  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:54,625  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:54,626  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:54,626  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:42:54,627  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:42:54,628  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:42:54,628  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:42:54,648  INFO [main] hive.log: Updating table stats fast for tacid
2024-04-24T20:42:54,648  INFO [main] hive.log: Updated size of table tacid to 802
2024-04-24T20:42:54,660  INFO [main] exec.StatsTask: Table default.tacid stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:42:54,660  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:42:54,661  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:42:54,661  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:54,661  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:42:54,661  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 1.424 seconds
OK
2024-04-24T20:42:54,661  INFO [main] ql.Driver: OK
2024-04-24T20:42:54,661  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:54,674  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): update TAcid set a = 1 where b = 2
2024-04-24T20:42:54,675  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,675  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,687  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TAcid set a = 1 where b = 2> as 
<insert into table `default`.`TAcid` select ROW__ID,`a`,`b` from `default`.`TAcid` sort by ROW__ID >
2024-04-24T20:42:54,687  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:42:54,688  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,700  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:42:54,700  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:42:54,700  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:42:54,700  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:42:54,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:42:54,712  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:42:54,712  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:42:54,712  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,724  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:42:54,726  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/tacid/.hive-staging_hive_2024-04-24_20-42-54_687_7830545418790754334-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:42:54,735 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:42:54,736  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:54,736  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.063 seconds
2024-04-24T20:42:54,736  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:42:54,736  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcid
2024-04-24T20:42:54,737  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,737  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,753  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:54,753  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:54,753  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:54,753  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.017 seconds
2024-04-24T20:42:54,753  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:54,754  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacid, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:54,766  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T20:42:54,766  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:54,766  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcid
2024-04-24T20:42:54,766  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:54,767  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,778  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:42:54,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:42:54,790  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcid
2024-04-24T20:42:54,790  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcid	
2024-04-24T20:42:55,062  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:55,062  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:55,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:55,094  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:55,117  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:55,117  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.351 seconds
OK
2024-04-24T20:42:55,117  INFO [main] ql.Driver: OK
2024-04-24T20:42:55,117  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,117  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:6 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:55,122  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcidPart
2024-04-24T20:42:55,122  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:55,122  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:55,135  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:55,135  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:55,135  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:55,135  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.013 seconds
2024-04-24T20:42:55,135  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,136  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacidpart, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:55,149  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T20:42:55,149  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,149  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TAcidPart
2024-04-24T20:42:55,150  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:55,150  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:55,150  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:55,162  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:42:55,162  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:42:55,178  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcidPart
2024-04-24T20:42:55,178  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcidPart	
2024-04-24T20:42:55,228  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:55,229  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:55,254  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:55,274  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:55,275  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.125 seconds
OK
2024-04-24T20:42:55,275  INFO [main] ql.Driver: OK
2024-04-24T20:42:55,275  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,275  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:7 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:55,279  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlat
2024-04-24T20:42:55,279  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:55,279  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:55,291  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:55,291  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:55,291  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:55,291  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.012 seconds
2024-04-24T20:42:55,291  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,292  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflat, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:55,304  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T20:42:55,304  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,304  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlat
2024-04-24T20:42:55,305  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:55,305  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:55,305  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:55,317  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:42:55,317  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:42:55,329  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlat
2024-04-24T20:42:55,329  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlat	
2024-04-24T20:42:55,377  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:55,378  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:55,378  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.074 seconds
OK
2024-04-24T20:42:55,378  INFO [main] ql.Driver: OK
2024-04-24T20:42:55,378  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,378  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:8 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
2024-04-24T20:42:55,382  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlatText
2024-04-24T20:42:55,382  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:55,382  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:55,395  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:55,395  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:55,395  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:55,395  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.013 seconds
2024-04-24T20:42:55,395  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,395  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflattext, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f)
2024-04-24T20:42:55,408  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T20:42:55,408  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,408  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f): drop table if exists TFlatText
2024-04-24T20:42:55,408  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:55,409  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:55,409  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:55,421  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:42:55,421  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:42:55,432  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlatText
2024-04-24T20:42:55,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlatText	
2024-04-24T20:42:55,478  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:42:55,479  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:42:55,479  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f); Time taken: 0.071 seconds
OK
2024-04-24T20:42:55,479  INFO [main] ql.Driver: OK
2024-04-24T20:42:55,479  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f
2024-04-24T20:42:55,479  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:9 queryId=alex_20240424204252_c91ef9b4-cc9d-4360-af08-7dbdf1cc294f txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgradeExternalTableNoReadPermissionForDatabase" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="6.64">
    <failure type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:303)
]]></failure>
    <system-err><![CDATA[2024-04-24T20:42:55,519  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:55,519  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:55,519  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:55,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:55,555  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:55,698  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:55,855  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5
2024-04-24T20:42:55,857  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5
2024-04-24T20:42:55,860  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/_tmp_space.db
2024-04-24T20:42:55,860  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4333c72d-aa9b-4b99-a397-05a2baf4e8c5, clientType=HIVECLI]
2024-04-24T20:42:55,860  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:42:55,861  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): drop database if exists test cascade
2024-04-24T20:42:55,862  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:42:55,862  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:42:55,867  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:42:55,867  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:42:55,875  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:42:55,875  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:42:55,875  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:42:55,875  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.014 seconds
2024-04-24T20:42:55,875  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:42:55,876  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a)
2024-04-24T20:42:55,892  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:42:55,892  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:42:55,892  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): drop database if exists test cascade
2024-04-24T20:42:55,892  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:42:55,892  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:42:55,892  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:42:55,897  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:55,897  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:55,899  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:42:55,899  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:42:55,901  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:55,901  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:55,903  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:42:55,903  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:42:55,908  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:42:55,991  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:56,021  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:56,021  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:56,021  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:56,022  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:56,042 ERROR [main] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:171)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.derby.impl.jdbc.Util.newBatchUpdateException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:424)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:676)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:644)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:731)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:89)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:450)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:210)
	at org.datanucleus.TransactionImpl.commit(TransactionImpl.java:274)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:107)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: java.sql.SQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 95 more
Caused by: java.sql.SQLException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
	... 103 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 97 more

2024-04-24T20:42:58,043  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:42:58,043  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:42:58,046  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:42:58,046  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:42:58,049  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:42:58,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:42:58,051  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:42:58,053  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:42:58,080  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:42:58,081  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:42:58,091 ERROR [main] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:171)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.derby.impl.jdbc.Util.newBatchUpdateException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:424)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:676)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:644)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:731)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:89)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:450)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:210)
	at org.datanucleus.TransactionImpl.commit(TransactionImpl.java:274)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:107)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: java.sql.SQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 95 more
Caused by: java.sql.SQLException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
	... 103 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 97 more

2024-04-24T20:43:00,092  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:43:00,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:43:00,097  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:00,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:00,106  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:43:00,106  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:43:00,178  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=test tbl=texternal
2024-04-24T20:43:00,178  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=test tbl=texternal	
2024-04-24T20:43:00,279  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:43:00,286  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987673811/warehouse/test.db does not exist; Force to delete it.
2024-04-24T20:43:00,287 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987673811/warehouse/test.db
2024-04-24T20:43:00,287  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:00,313  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:00,323  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:00,323  INFO [main] metadata.Hive: Total time spent in this metastore function was greater than 1000ms : dropDatabase_(String, boolean, boolean, boolean, )=4431
2024-04-24T20:43:00,323  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 4.431 seconds
OK
2024-04-24T20:43:00,323  INFO [main] ql.Driver: OK
2024-04-24T20:43:00,323  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,324  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a txnid:0]
2024-04-24T20:43:00,328  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): drop table if exists TExternal
2024-04-24T20:43:00,329  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:00,329  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:00,345  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:00,345  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:00,345  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:00,345  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.017 seconds
2024-04-24T20:43:00,346  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,346  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texternal, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a)
2024-04-24T20:43:00,358  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:43:00,358  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,359  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): drop table if exists TExternal
2024-04-24T20:43:00,359  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:00,359  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:00,359  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:00,370  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:00,370  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:00,381  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExternal
2024-04-24T20:43:00,381  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExternal	
2024-04-24T20:43:00,424  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal does not exist; Force to delete it.
2024-04-24T20:43:00,424 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/texternal
2024-04-24T20:43:00,424  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:00,425  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.066 seconds
OK
2024-04-24T20:43:00,425  INFO [main] ql.Driver: OK
2024-04-24T20:43:00,425  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,425  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a txnid:0]
2024-04-24T20:43:00,429  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): create database test
2024-04-24T20:43:00,430  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:00,430  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:00,430  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:00,431  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.001 seconds
2024-04-24T20:43:00,431  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,431  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): create database test
2024-04-24T20:43:00,431  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:00,432  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:43:00,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:43:00,433  WARN [main] metastore.ObjectStore: Failed to get database test, returning NoSuchObjectException
2024-04-24T20:43:00,436  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db
2024-04-24T20:43:00,459  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:00,459  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.028 seconds
OK
2024-04-24T20:43:00,459  INFO [main] ql.Driver: OK
2024-04-24T20:43:00,459  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:00,459  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:00,460  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:00,460  INFO [main] parse.CalcitePlanner: Creating table test.TExternal position=13
2024-04-24T20:43:00,460  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:43:00,460  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:43:00,464  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:00,464  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:00,465  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:00,465  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.005 seconds
2024-04-24T20:43:00,465  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,465  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a)
2024-04-24T20:43:00,477  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:43:00,477  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,477  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:00,477  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:00,479  INFO [main] exec.DDLTask: creating table test.TExternal on null
2024-04-24T20:43:00,479  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987780, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, transactional=false, totalSize=0, numFiles=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:00,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987780, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, transactional=false, totalSize=0, numFiles=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:00,480  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:43:00,487  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal
2024-04-24T20:43:00,529  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:00,529  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.052 seconds
OK
2024-04-24T20:43:00,529  INFO [main] ql.Driver: OK
2024-04-24T20:43:00,529  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,529  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a txnid:0]
2024-04-24T20:43:00,533  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:43:00,534  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:00,534  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:43:00,534  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:43:00,545  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:00,550  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:00,550  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:00,550  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:00,551  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:00,551  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:43:00,551  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:43:00,562  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:00,619  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:43:00,619  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:43:00,622  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:43:00,622  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:43:00,627  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:00,627  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:00,642  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:00,642  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:00,642  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:00,642  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:43:00,642  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:43:00,654  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1
2024-04-24T20:43:00,669  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:43:00,669  INFO [main] ppd.OpProcFactory: Processing for FS(3)
2024-04-24T20:43:00,669  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:43:00,669  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:43:00,669  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:43:00,678  INFO [main] optimizer.GenMRFileSink1: using CombineHiveInputformat for the merge job
2024-04-24T20:43:00,679  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:43:00,679  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:43:00,691  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:43:00,692  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:00,692  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:43:00,692  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:00,692  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 0.159 seconds
2024-04-24T20:43:00,692  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,692  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:test, tablename:texternal, operationType:INSERT, isAcid:false, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a)
2024-04-24T20:43:00,705  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:43:00,705  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,705  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:43:00,705  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:43:00,705  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:00,705  INFO [main] ql.Driver: Query ID = alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
Total jobs = 1
2024-04-24T20:43:00,705  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:43:00,705  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:43:00,706  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:43:00,706  INFO [main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:43:00,707  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:43:00,707  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:43:00,707  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:00,711  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:43:00,713  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:43:00,715  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:00,715  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10001
2024-04-24T20:43:00,717  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:00,717  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10004/22083b2c-16f6-4a93-98ec-0b455a488a12/map.xml
2024-04-24T20:43:00,721  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:43:00,784  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10004/22083b2c-16f6-4a93-98ec-0b455a488a12/map.xml
2024-04-24T20:43:00,785  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:43:00,785  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:43:00,785  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:00,788  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:43:00,789  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:43:00,801  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:43:00,814  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local268892293_0004
2024-04-24T20:43:00,857  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:43:00,857  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:43:00,857  INFO [Thread-364] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:00,858  INFO [Thread-364] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:00,859  INFO [Thread-364] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:43:00,859  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local268892293_0004_m_000000_0
2024-04-24T20:43:00,862  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:00,863  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:00,864  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10004/22083b2c-16f6-4a93-98ec-0b455a488a12/map.xml
2024-04-24T20:43:00,864  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:43:00,866  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:43:00,867  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T20:43:00,869  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:00,869  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:00,869  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10004/22083b2c-16f6-4a93-98ec-0b455a488a12/map.xml
2024-04-24T20:43:00,869  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:43:00,870  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:43:00,870  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:43:00,870  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:43:00,870  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:43:00,871  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing operator FS[3]
2024-04-24T20:43:00,872  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@776d281c and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@3ed869c5
2024-04-24T20:43:00,872  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10004/22083b2c-16f6-4a93-98ec-0b455a488a12/map.xml
2024-04-24T20:43:00,872  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_tmp.-ext-10002/000000_0
2024-04-24T20:43:00,872  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T20:43:00,872  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_tmp.-ext-10002/000000_0
2024-04-24T20:43:00,874  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 1
2024-04-24T20:43:00,874  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:43:00,879  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:43:00,879  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:43:00,879  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:43:00,879  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:43:00,880  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:43:00,880  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:43:00,880  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing operator FS[3]
2024-04-24T20:43:00,880  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 3
2024-04-24T20:43:00,889  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_1_test.texternal:3, 
2024-04-24T20:43:00,889  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:43:00,890  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local268892293_0004_m_000000_0 is done. And is in the process of committing
2024-04-24T20:43:00,892  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:00,892  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local268892293_0004_m_000000_0' done.
2024-04-24T20:43:00,892  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local268892293_0004_m_000000_0
2024-04-24T20:43:00,892  INFO [Thread-364] mapred.LocalJobRunner: map task executor complete.
2024-04-24 20:43:01,862 Stage-1 map = 100%,  reduce = 0%
2024-04-24T20:43:01,862  INFO [main] exec.Task: 2024-04-24 20:43:01,862 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local268892293_0004
2024-04-24T20:43:01,864  INFO [main] exec.Task: Ended Job = job_local268892293_0004
2024-04-24T20:43:01,866  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/_tmp.-ext-10002 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/-ext-10002
2024-04-24T20:43:01,866  INFO [main] ql.Driver: Starting task [Stage-7:CONDITIONAL] in serial mode
Stage-4 is selected by condition resolver.
2024-04-24T20:43:01,866  INFO [main] exec.Task: Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
2024-04-24T20:43:01,866  INFO [main] exec.Task: Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
2024-04-24T20:43:01,867  INFO [main] exec.Task: Stage-5 is filtered out by condition resolver.
2024-04-24T20:43:01,867  INFO [main] ql.Driver: Starting task [Stage-4:MOVE] in serial mode
2024-04-24T20:43:01,867  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:01,867  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:01,867  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:01,867  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/-ext-10000
2024-04-24T20:43:01,867  INFO [main] exec.Task: Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/-ext-10000 from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/-ext-10002
2024-04-24T20:43:01,868  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:01,868  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:01,889  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table test.texternal
2024-04-24T20:43:01,889  INFO [main] exec.Task: Loading data to table test.texternal from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-43-00_533_2362279241459429201-1/-ext-10000
2024-04-24T20:43:01,890  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:43:01,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:01,917  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:01,917  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:01,918  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:01,926  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:01,926  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:01,937  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:43:01,937  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:43:01,948  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:01,948  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:01,956  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:43:01,956  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:43:01,984  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:43:01,984  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:43:01,984  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:01,984  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:01,984  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:01,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:01,985  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:43:01,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:02,010  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:02,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:02,011  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:02,012  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:02,013  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:02,014  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:02,025  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/4333c72d-aa9b-4b99-a397-05a2baf4e8c5/hive_2024-04-24_20-43-00_533_2362279241459429201-1/-mr-10001
2024-04-24T20:43:02,026  INFO [main] fs.FSStatsAggregator: Read stats : {test.texternal/={rawDataSize=24, numRows=3}}
2024-04-24T20:43:02,026  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:43:02,026  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:43:02,039  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	numRows	3
2024-04-24T20:43:02,039  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	rawDataSize	24
2024-04-24T20:43:02,039  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:02,040  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:02,040  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:02,040  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:02,042  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:43:02,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:43:02,068  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:02,069  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:02,069  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:02,070  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:02,071  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:02,071  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:02,090  INFO [main] hive.log: Updating table stats fast for texternal
2024-04-24T20:43:02,090  INFO [main] hive.log: Updated size of table texternal to 244
2024-04-24T20:43:02,101  INFO [main] exec.StatsTask: Table test.texternal stats: [numFiles=1, numRows=3, totalSize=244, rawDataSize=24]
2024-04-24T20:43:02,101  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:43:02,101  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:43:02,101  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:02,101  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:02,101  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a); Time taken: 1.396 seconds
OK
2024-04-24T20:43:02,101  INFO [main] ql.Driver: OK
2024-04-24T20:43:02,101  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a
2024-04-24T20:43:02,102  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204255_98f5b4ac-e741-4763-96ee-9fc214d72e4a txnid:0]
2024-04-24T20:43:02,105  INFO [main] acid.PreUpgradeTool: Starting with RunOptions{outputDir='/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179', execute=true, dbRegex='.*', tableRegex='.*', tableType=null, tablePoolSize=8}
2024-04-24T20:43:02,105  INFO [main] acid.PreUpgradeTool: Using Hive Version: 2.3.3 build: 2.3.3 from 8a511e3f79b43d4be41cd231cf5c99e43b248383 by daijy source checksum fb9b95d9baaf3f968c457dee42d015d4
2024-04-24T20:43:02,105  INFO [main] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:43:02,107  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:02,108  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:02,108  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:02,113  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4333c72d-aa9b-4b99-a397-05a2baf4e8c5, clientType=HIVECLI]
2024-04-24T20:43:02,113  INFO [main] metastore.HiveMetaStore: 0: get_databases: .*
2024-04-24T20:43:02,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: .*	
2024-04-24T20:43:02,117  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
2024-04-24T20:43:02,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
2024-04-24T20:43:02,120  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:43:02,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:43:02,122  INFO [main] acid.PreUpgradeTool: No compaction is necessary
2024-04-24T20:43:02,122  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:02,122  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:02,123  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:02,123  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
]]></system-err>
  </testcase>
  <testcase name="testConcurrency" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="35.381"/>
  <testcase name="testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="2.485">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TInclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:179)
]]></error>
    <system-err><![CDATA[2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:37,531  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:37,555  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:37,736  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:37,737  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:37,737  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:37,737  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:37,737  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:37,737  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:37,927  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4
2024-04-24T20:43:37,932  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4
2024-04-24T20:43:37,938  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/_tmp_space.db
2024-04-24T20:43:37,939  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4, clientType=HIVECLI]
2024-04-24T20:43:37,939  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:43:37,940  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DInclude cascade
2024-04-24T20:43:37,941  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:37,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:37,943  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:43:37,943  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:37,943  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:37,944  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:37,944  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.004 seconds
2024-04-24T20:43:37,945  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:37,945  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DInclude cascade
2024-04-24T20:43:37,945  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:37,946  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.0 seconds
OK
2024-04-24T20:43:37,946  INFO [main] ql.Driver: OK
2024-04-24T20:43:37,946  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:37,947  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DExclude cascade
2024-04-24T20:43:37,948  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:43:37,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:43:37,950  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:43:37,950  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:37,950  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:37,950  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:37,951  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.003 seconds
2024-04-24T20:43:37,951  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:37,952  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DExclude cascade
2024-04-24T20:43:37,952  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:37,953  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.001 seconds
OK
2024-04-24T20:43:37,953  INFO [main] ql.Driver: OK
2024-04-24T20:43:37,953  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:37,953  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): create database DInclude
2024-04-24T20:43:37,954  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:37,954  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:37,954  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:37,955  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.001 seconds
2024-04-24T20:43:37,956  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:37,956  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): create database DInclude
2024-04-24T20:43:37,956  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:37,958  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:43:37,959  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:43:37,960  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:43:37,966  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db
2024-04-24T20:43:37,991  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:37,992  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.035 seconds
OK
2024-04-24T20:43:37,992  INFO [main] ql.Driver: OK
2024-04-24T20:43:37,992  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:37,992  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): use DInclude
2024-04-24T20:43:37,993  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:37,993  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:38,001  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:38,001  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:38,001  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:38,002  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.009 seconds
2024-04-24T20:43:38,002  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,002  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): use DInclude
2024-04-24T20:43:38,003  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:38,003  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:38,003  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:38,009  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:38,009  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:38,014  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:38,014  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.012 seconds
OK
2024-04-24T20:43:38,014  INFO [main] ql.Driver: OK
2024-04-24T20:43:38,014  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:38,014  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:38,015  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:38,015  INFO [main] parse.CalcitePlanner: Creating table DInclude.TInclude position=13
2024-04-24T20:43:38,015  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:38,015  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:38,020  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:38,020  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:38,020  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:38,020  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.006 seconds
2024-04-24T20:43:38,020  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,020  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e)
2024-04-24T20:43:38,036  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:43:38,036  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,036  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:38,036  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:38,037  INFO [main] exec.DDLTask: creating table DInclude.TInclude on null
2024-04-24T20:43:38,038  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987818, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, numRows=0, rawDataSize=0, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:38,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987818, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, numRows=0, rawDataSize=0, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:38,045  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude
2024-04-24T20:43:38,087  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:38,087  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.051 seconds
OK
2024-04-24T20:43:38,087  INFO [main] ql.Driver: OK
2024-04-24T20:43:38,087  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,087  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e txnid:0]
2024-04-24T20:43:38,090  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:43:38,091  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:38,091  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:38,091  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:38,126  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:38,131  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:38,131  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:38,131  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:38,131  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:38,131  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:38,131  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:38,141  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:38,185  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:43:38,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:43:38,187  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:43:38,187  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:43:38,192  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:43:38,192  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:43:38,194  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:38,194  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:38,207  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:38,207  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:38,207  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:38,207  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:38,207  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:38,217  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1
2024-04-24T20:43:38,229  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:43:38,229  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:43:38,230  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:43:38,230  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:43:38,230  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) dinclude.tinclude
2024-04-24T20:43:38,247  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:43:38,247  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:38,247  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:43:38,247  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:38,247  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.157 seconds
2024-04-24T20:43:38,253  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:43:38,253  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,253  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:dinclude, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e)
2024-04-24T20:43:38,267  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:43:38,271  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:43:38,271  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:43:38,271  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:38,271  INFO [main] ql.Driver: Query ID = alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
Total jobs = 1
2024-04-24T20:43:38,271  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:43:38,271  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:43:38,272  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:43:38,272  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:43:38,272  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:43:38,272  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:43:38,272  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:43:38,272  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:43:38,272  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:43:38,272  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:43:38,272  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:43:38,272  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:43:38,272  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:38,277  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:43:38,279  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:38,283  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:43:38,285  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:43:38,286  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:38,287  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10001
2024-04-24T20:43:38,288  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:38,289  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/map.xml
2024-04-24T20:43:38,289  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/reduce.xml
2024-04-24T20:43:38,292  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:43:38,365  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/map.xml
2024-04-24T20:43:38,366  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:43:38,366  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:43:38,366  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:38,369  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:43:38,369  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:43:38,382  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:43:38,393  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local85810386_0025
2024-04-24T20:43:38,431  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:43:38,431  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:43:38,431  INFO [Thread-3793] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:38,432  INFO [Thread-3793] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:38,433  INFO [Thread-3793] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:43:38,433  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local85810386_0025_m_000000_0
2024-04-24T20:43:38,436  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:38,436  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:38,438  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/map.xml
2024-04-24T20:43:38,438  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:43:38,439  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:38,440  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:43:38,445  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:43:38,446  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,446  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,446  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/map.xml
2024-04-24T20:43:38,446  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:43:38,446  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:43:38,447  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/map.xml
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:43:38,448  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:43:38,450  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:43:38,451  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local85810386_0025_m_000000_0 is done. And is in the process of committing
2024-04-24T20:43:38,452  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:38,453  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local85810386_0025_m_000000_0' done.
2024-04-24T20:43:38,453  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local85810386_0025_m_000000_0
2024-04-24T20:43:38,453  INFO [Thread-3793] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:43:38,454  INFO [Thread-3793] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:43:38,454  INFO [pool-168-thread-1] mapred.LocalJobRunner: Starting task: attempt_local85810386_0025_r_000000_0
2024-04-24T20:43:38,456  INFO [pool-168-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:38,456  INFO [pool-168-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6552280e
2024-04-24T20:43:38,456  INFO [pool-168-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:38,457  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local85810386_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:38,459  INFO [localfetcher#205] reduce.LocalFetcher: localfetcher#205 about to shuffle output of map attempt_local85810386_0025_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:43:38,459  INFO [localfetcher#205] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local85810386_0025_m_000000_0
2024-04-24T20:43:38,459  INFO [localfetcher#205] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:43:38,459  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:38,459  INFO [pool-168-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:38,459  INFO [pool-168-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:38,460  INFO [pool-168-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:38,461  INFO [pool-168-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,461  INFO [pool-168-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,461  INFO [pool-168-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/reduce.xml
2024-04-24T20:43:38,461  INFO [pool-168-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:38,463  INFO [pool-168-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:43:38,463  INFO [pool-168-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:38,463  INFO [pool-168-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@11ba3d2f and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@65dc754e
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:43:38,464  INFO [pool-168-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:38,469  INFO [pool-168-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:43:38,469  INFO [pool-168-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:38,473  INFO [pool-168-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:38,474  INFO [pool-168-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:38,474  INFO [pool-168-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:38,474  INFO [pool-168-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:43:38,480  INFO [pool-168-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:3, 
2024-04-24T20:43:38,480  INFO [pool-168-thread-1] mapred.Task: Task:attempt_local85810386_0025_r_000000_0 is done. And is in the process of committing
2024-04-24T20:43:38,481  INFO [pool-168-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:38,481  INFO [pool-168-thread-1] mapred.Task: Task 'attempt_local85810386_0025_r_000000_0' done.
2024-04-24T20:43:38,481  INFO [pool-168-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local85810386_0025_r_000000_0
2024-04-24T20:43:38,481  INFO [pool-168-thread-1] mapred.LocalJobRunner: Starting task: attempt_local85810386_0025_r_000001_0
2024-04-24T20:43:38,481  INFO [pool-168-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:38,482  INFO [pool-168-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27410f21
2024-04-24T20:43:38,482  INFO [pool-168-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:38,482  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local85810386_0025_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:38,483  INFO [localfetcher#206] reduce.LocalFetcher: localfetcher#206 about to shuffle output of map attempt_local85810386_0025_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:43:38,483  INFO [localfetcher#206] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local85810386_0025_m_000000_0
2024-04-24T20:43:38,483  INFO [localfetcher#206] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:43:38,483  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:38,484  INFO [pool-168-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:38,484  INFO [pool-168-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:38,484  INFO [pool-168-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:38,484  INFO [pool-168-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:38,484  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter3244372903204824257.jar]
2024-04-24T20:43:38,485  INFO [pool-168-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10003/e48522c7-f9ae-47a5-83cb-cfc82a6d3c40/reduce.xml
2024-04-24T20:43:38,486  INFO [pool-168-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:38,487  INFO [pool-168-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:43:38,488  INFO [pool-168-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:38,488  INFO [pool-168-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:38,488  INFO [pool-168-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:38,488  INFO [pool-168-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@6d625837 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@42756abd
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:43:38,489  INFO [pool-168-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:38,494  INFO [pool-168-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:38,499  INFO [pool-168-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:38,504  INFO [pool-168-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:0, 
2024-04-24T20:43:38,504  INFO [pool-168-thread-1] mapred.Task: Task:attempt_local85810386_0025_r_000001_0 is done. And is in the process of committing
2024-04-24T20:43:38,505  INFO [pool-168-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:38,505  INFO [pool-168-thread-1] mapred.Task: Task 'attempt_local85810386_0025_r_000001_0' done.
2024-04-24T20:43:38,505  INFO [pool-168-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local85810386_0025_r_000001_0
2024-04-24T20:43:38,505  INFO [Thread-3793] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:43:39,434 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:43:39,434  INFO [main] exec.Task: 2024-04-24 20:43:39,434 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local85810386_0025
2024-04-24T20:43:39,436  INFO [main] exec.Task: Ended Job = job_local85810386_0025
2024-04-24T20:43:39,438  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/-ext-10000
2024-04-24T20:43:39,439  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:43:39,439  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:39,440  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:39,440  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:39,441  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table dinclude.tinclude
2024-04-24T20:43:39,441  INFO [main] exec.Task: Loading data to table dinclude.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/-ext-10000
2024-04-24T20:43:39,443  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:43:39,443  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:39,493  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:39,493  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:39,494  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:39,501  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:39,501  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:39,511  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:43:39,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:43:39,521  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:43:39,521  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-38_090_7700554035838589315-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:43:39,522  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:43:39,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:43:39,546  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:43:39,546  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:43:39,546  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:39,546  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:39,547  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:39,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:39,547  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:43:39,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:43:39,572  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:39,572  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:39,572  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:39,572  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:39,572  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:39,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:39,573  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:39,573  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:39,574  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:39,574  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:39,584  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c4ae890-f4b1-4918-a5cd-2d7b1bbd79d4/hive_2024-04-24_20-43-38_090_7700554035838589315-1/-mr-10001
2024-04-24T20:43:39,584  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={rawDataSize=0, numRows=3}}
2024-04-24T20:43:39,585  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={}}
2024-04-24T20:43:39,585  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:43:39,585  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:43:39,595  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:39,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:39,595  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:39,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:39,596  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:43:39,597  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:39,621  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:39,621  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:39,622  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:39,623  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:39,623  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:39,638  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:43:39,638  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:43:39,647  INFO [main] exec.StatsTask: Table dinclude.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:43:39,647  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:43:39,648  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:43:39,648  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:39,648  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:39,648  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 1.376 seconds
OK
2024-04-24T20:43:39,648  INFO [main] ql.Driver: OK
2024-04-24T20:43:39,648  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:39,658  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): update TInclude set a = 1 where b = 2
2024-04-24T20:43:39,659  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:39,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:39,668  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `DInclude`.`TInclude` select ROW__ID,`a`,`b` from `DInclude`.`TInclude` sort by ROW__ID >
2024-04-24T20:43:39,669  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:43:39,669  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:39,669  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:39,679  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:39,679  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:39,679  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:43:39,679  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:43:39,679  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:43:39,689  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:43:39,689  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:43:39,689  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:43:39,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:43:39,699  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:39,700  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-43-39_668_3036362936121564786-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:43:39,710 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:43:39,710  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:39,710  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.053 seconds
2024-04-24T20:43:39,710  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:39,710  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DInclude cascade
2024-04-24T20:43:39,711  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:39,711  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:39,715  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=DInclude pat=.*
2024-04-24T20:43:39,715  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=DInclude pat=.*	
2024-04-24T20:43:39,717  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:39,717  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:39,717  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:39,718  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.007 seconds
2024-04-24T20:43:39,718  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:39,718  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e)
2024-04-24T20:43:39,727  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:43:39,727  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:39,727  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DInclude cascade
2024-04-24T20:43:39,727  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:39,727  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:43:39,728  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:43:39,731  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=DInclude
2024-04-24T20:43:39,731  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=DInclude	
2024-04-24T20:43:39,734  INFO [main] metastore.HiveMetaStore: 0: drop_database: DInclude
2024-04-24T20:43:39,734  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: DInclude	
2024-04-24T20:43:39,739  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:43:39,739  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:43:39,741  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=dinclude pat=*
2024-04-24T20:43:39,741  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=dinclude pat=*	
2024-04-24T20:43:39,774  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=DInclude tbl=tinclude
2024-04-24T20:43:39,774  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=DInclude tbl=tinclude	
2024-04-24T20:43:39,877  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:39,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:39,924  INFO [main] metastore.ObjectStore: Dropping database DInclude along with all tables
2024-04-24T20:43:39,939  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:43:39,939  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:39,965  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:39,966  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:39,982  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:39,982  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.255 seconds
OK
2024-04-24T20:43:39,982  INFO [main] ql.Driver: OK
2024-04-24T20:43:39,982  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:39,982  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e txnid:0]
2024-04-24T20:43:39,986  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DExclude cascade
2024-04-24T20:43:39,986  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:43:39,986  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:43:39,988  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:43:39,989  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:39,989  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:39,989  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:39,989  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.003 seconds
2024-04-24T20:43:39,989  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e
2024-04-24T20:43:39,989  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e): drop database if exists DExclude cascade
2024-04-24T20:43:39,989  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:39,990  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204337_3aeae80d-5559-4af8-8ecc-7544920d715e); Time taken: 0.0 seconds
OK
2024-04-24T20:43:39,990  INFO [main] ql.Driver: OK
2024-04-24T20:43:39,990  INFO [main] lockmgr.DbLockManager: releaseLocks: []
]]></system-err>
  </testcase>
</testsuite>