SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,098718 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@367ffa75]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@367ffa75) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@66d18979
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,019012 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", alwaysWriteExceptions="null", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, header="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", disableAnsi="null", noConsoleNoAnsi="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", target="SYSTEM_ERR", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", Configuration(HiveLog4j2Test), name="console", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", footer="null", alwaysWriteExceptions="null", header="null", noConsoleNoAnsi="null", disableAnsi="null", Replace=null, pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(modulate="true", interval="1", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(min="null", compressionLevel="null", max="30", fileIndex="null", ={}, tempCompressedFilePattern="null", stopCustomActionsOnError="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), fileGroup="null", filePermissions="null", advertise="null", fileOwner="null", advertiseURI="null", filePattern="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log.%d{yyyy-MM-dd}", fileName="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log", append="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), immediateFlush="null", bufferSize="null", bufferedIo="null", name="DRFA", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), ignoreExceptions="null", Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log seek to 542251257
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T11:01:13.166-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-11:01:14.775, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-11:01:14.776, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@475e586c...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@475e586c OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@1f53a5dc
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@367ffa75
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@367ffa75) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@367ffa75] started OK.
2024-04-24T11:01:14,875  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T11:01:15,251  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T11:01:15,302  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:15,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:15,303  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:15,303  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:15,303  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:15,304  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:15,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:15,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:15,304  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:15,305  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:15,305  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
Hive Session ID = cb8f465c-9276-4dbb-94af-fda0f87644f9
2024-04-24T11:01:15,450  INFO [main] SessionState: Hive Session ID = cb8f465c-9276-4dbb-94af-fda0f87644f9
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T11:01:15,462  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@16423501.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@16423501.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T11:01:15,632  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/cb8f465c-9276-4dbb-94af-fda0f87644f9
2024-04-24T11:01:15,635  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/cb8f465c-9276-4dbb-94af-fda0f87644f9
2024-04-24T11:01:15,638  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/cb8f465c-9276-4dbb-94af-fda0f87644f9/_tmp_space.db
2024-04-24T11:01:15,693  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:17,090  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,108  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,114  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,117  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,118  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,118  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,119  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:01:17,221  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:01:17,437  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:01:17,464  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:01:17,470  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T11:01:17,470  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T11:01:17,485  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:01:17,490  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T11:01:18,189  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:01:18,194  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T11:01:18,987  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T11:01:18,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: null will be shutdown
2024-04-24T11:01:19,017  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4397a639 created in the thread with id: 1
2024-04-24T11:01:21,520  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T11:01:21,520  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T11:01:21,520  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445 from thread id: 1
2024-04-24T11:01:21,664  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T11:01:21,699  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T11:01:21,736  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T11:01:21,739  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T11:01:21,859  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T11:01:21,866  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T11:01:21,892  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:01:21,894  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T11:01:21,896  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:01:21,897  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T11:01:21,899  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:01:21,901  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T11:01:21,903  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:01:21,903  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T11:01:21,908  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T11:01:21,909  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T11:01:21,910  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T11:01:21,913  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T11:01:21,913  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T11:01:21,915  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:01:22,111  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:01:22,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T11:01:22,439  INFO [main] reflections.Reflections: Reflections took 208 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:01:22,615  INFO [main] reflections.Reflections: Reflections took 138 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:01:22,746  INFO [main] reflections.Reflections: Reflections took 124 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:01:22,754  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:22,898  INFO [main] reflections.Reflections: Reflections took 128 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:01:22,948  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:22,951  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:22,954  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:22,954  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=13, flushCache_()=0, getAllFunctions_()=50, isCompatibleWith_(Configuration)=0}
2024-04-24T11:01:22,954  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 7.262 seconds
2024-04-24T11:01:22,955  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:22,955  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:22,958  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:22,961  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:22,962  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:22,965  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:22,969  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:22,969  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=6}
2024-04-24T11:01:22,969  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.011 seconds
2024-04-24T11:01:22,970  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table inpy(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as textfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,052  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,054  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:01:23,073  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=cb8f465c-9276-4dbb-94af-fda0f87644f9, clientType=HIVECLI]
2024-04-24T11:01:23,075  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T11:01:23,077  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T11:01:23,077  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4397a639 will be shutdown
2024-04-24T11:01:23,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:01:23,078  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T11:01:23,079  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:01:23,081  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:01:23,081  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:01:23,082  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081, with PersistenceManager: null will be shutdown
2024-04-24T11:01:23,083  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401e02b4 created in the thread with id: 1
2024-04-24T11:01:23,100  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081 from thread id: 1
2024-04-24T11:01:23,100  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:01:23,101  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:01:23,109  INFO [main] parse.CalcitePlanner: Creating table default.inpy position=13
2024-04-24T11:01:23,122  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:01:23,122  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:01:23,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@401e02b4 will be shutdown
2024-04-24T11:01:23,124  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@370c7cc5 created in the thread with id: 1
2024-04-24T11:01:23,128  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:01:23,129  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:01:23,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,144  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,144  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,144  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,145  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,145  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T11:01:23,146  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.175 seconds
2024-04-24T11:01:23,146  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,146  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,146  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table inpy(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as textfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,146  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:23,147  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T11:01:23,147  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T11:01:23,147  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@760f1081, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@370c7cc5 will be shutdown
2024-04-24T11:01:23,148  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:01:23,148  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T11:01:23,253  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:01:23,255  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:01:23,255  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:01:23,256  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cba0321, with PersistenceManager: null will be shutdown
2024-04-24T11:01:23,256  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cba0321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66d3b881 created in the thread with id: 1
2024-04-24T11:01:23,260  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cba0321 from thread id: 1
2024-04-24T11:01:23,261  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:01:23,261  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:01:23,262  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:inpy, dbName:default, owner:alex, createTime:1713981683, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFilesErasureCoded=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}, numRows=0, bucketing_version=2, rawDataSize=0, transactional=false, numFiles=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:01:23,281  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/inpy
2024-04-24T11:01:23,424  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,425  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=163}
2024-04-24T11:01:23,425  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.278 seconds
2024-04-24T11:01:23,426  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:23,426  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,429  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,429  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,429  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,429  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, getDatabase_(String)=3}
2024-04-24T11:01:23,430  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.003 seconds
2024-04-24T11:01:23,430  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,430  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,430  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:23,430  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:23,431  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,433  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,436  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,436  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=6}
2024-04-24T11:01:23,436  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.006 seconds
2024-04-24T11:01:23,437  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table rc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as rcfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,439  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,439  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:01:23,439  INFO [main] parse.CalcitePlanner: Creating table default.rc5318 position=13
2024-04-24T11:01:23,442  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,445  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,445  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,445  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,445  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,445  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getDatabase_(String)=2, isCompatibleWith_(Configuration)=0}
2024-04-24T11:01:23,445  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.008 seconds
2024-04-24T11:01:23,445  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,446  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,446  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table rc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as rcfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,446  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:23,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:rc5318, dbName:default, owner:alex, createTime:1713981683, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, numFilesErasureCoded=0, transactional=false, numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}, rawDataSize=0, bucketing_version=2, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:01:23,466  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/rc5318
2024-04-24T11:01:23,501  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,501  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=49}
2024-04-24T11:01:23,501  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.055 seconds
2024-04-24T11:01:23,502  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:23,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,506  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,506  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,506  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,506  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=3, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T11:01:23,506  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.004 seconds
2024-04-24T11:01:23,506  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,507  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,507  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): use default
2024-04-24T11:01:23,507  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:23,507  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,509  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,513  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,513  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=5}
2024-04-24T11:01:23,513  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.006 seconds
2024-04-24T11:01:23,514  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table orc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,516  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,516  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:01:23,516  INFO [main] parse.CalcitePlanner: Creating table default.orc5318 position=13
2024-04-24T11:01:23,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,525  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,525  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,525  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,525  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,525  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=3, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T11:01:23,526  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.011 seconds
2024-04-24T11:01:23,526  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,526  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,526  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): create table orc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T11:01:23,526  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:23,532  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:orc5318, dbName:default, owner:alex, createTime:1713981683, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numFilesErasureCoded=0, transactional=false, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}, bucketing_version=2, numRows=0, rawDataSize=0, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:01:23,540  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/orc5318
2024-04-24T11:01:23,581  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,581  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=50, isCompatibleWith_(Configuration)=0}
2024-04-24T11:01:23,582  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.055 seconds
2024-04-24T11:01:23,582  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/textfile' OVERWRITE INTO TABLE inpy
2024-04-24T11:01:23,585  INFO [main] parse.LoadSemanticAnalyzer: Starting caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:23,677  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:23,723  INFO [main] parse.LoadSemanticAnalyzer: Ending caching scope for: alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f
2024-04-24T11:01:23,723  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:23,723  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:23,723  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:23,724  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=1, getTable_(GetTableRequest)=89, isCompatibleWith_(Configuration)=1}
2024-04-24T11:01:23,724  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.141 seconds
2024-04-24T11:01:23,724  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:23,724  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:23,724  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/textfile' OVERWRITE INTO TABLE inpy
2024-04-24T11:01:23,725  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.inpy
2024-04-24T11:01:23,726  INFO [main] exec.Task: Loading data to table default.inpy from file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/textfile
2024-04-24T11:01:23,726  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:23,748  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:23,752  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:23,770  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:23,771  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:01:23,775  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/inpy
2024-04-24T11:01:23,788  WARN [main] metadata.Hive: Cannot get a table snapshot for inpy
2024-04-24T11:01:23,789  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.inpy newtbl=inpy	
2024-04-24T11:01:23,856  INFO [main] ql.Driver: Starting task [Stage-1:STATS] in serial mode
2024-04-24T11:01:23,857  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:23,874  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:23,874  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T11:01:23,874  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:23,892  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:23,895  WARN [main] metadata.Hive: Cannot get a table snapshot for inpy
2024-04-24T11:01:23,895  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.inpy newtbl=inpy	
2024-04-24T11:01:23,947  INFO [main] stats.BasicStatsTask: Table default.inpy stats: [numFiles=1, numRows=0, totalSize=83, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T11:01:23,948  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:23,948  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=2, alter_table_(String, String, String, Table, EnvironmentContext, String)=117, getTable_(GetTableRequest)=79}
2024-04-24T11:01:23,948  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.224 seconds
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,024  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,024  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,024  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,025  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:24,026  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:24,038  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T11:01:24,050  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:01:24,050  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:01:24,051  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cba0321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66d3b881 will be shutdown
2024-04-24T11:01:24,051  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1cba0321, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58636b50 created in the thread with id: 1
2024-04-24T11:01:24,060  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:01:24,061  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:01:24,098  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,110  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:24,126  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,215  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,216  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,216  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,216  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,216  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,216  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,217  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:24,219  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:24,223  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:24,244  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
HCatContext INSTANCE is present : false
Copying from [inpy] to [rc5318] with schema : ti:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@6906be0f[fieldName=ti,comment=<null>,type=tinyint,category=PRIMITIVE],si:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@7a62d697[fieldName=si,comment=<null>,type=smallint,category=PRIMITIVE],i:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@edbc2bf[fieldName=i,comment=<null>,type=int,category=PRIMITIVE],bi:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@3e01796a[fieldName=bi,comment=<null>,type=bigint,category=PRIMITIVE],f:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@62ab5e63[fieldName=f,comment=<null>,type=float,category=PRIMITIVE],d:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@e91facf[fieldName=d,comment=<null>,type=double,category=PRIMITIVE],b:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@5e8f0f98[fieldName=b,comment=<null>,type=boolean,category=PRIMITIVE]
2024-04-24T11:01:24,363  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,364  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,366  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:24,367  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,404  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,404  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,422  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,422  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,446  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.client.cache.enabled=true, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.warehouse.dir=${test.warehouse.dir}, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.min=32768, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, datanucleus.connectionPool.maxPoolSize=4, hive.metastore.schema.verification=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.stats.column.autogather=true, hive.in.test=true, hive.scheduled.queries.executor.enabled=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.llap.io.use.lrfu=true, hive.metastore.client.cache.maxSize=10Mb, hive.stats.key.prefix.reserve.length=0, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.query.reexecution.stats.persist.scope=query, hive.ignore.mapjoin.hint=false, test.log.dir=${test.tmp.dir}/log/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.querylog.location=${test.tmp.dir}/tmp, test.data.files=${hive.root}/data/files, hive.users.in.admin.role=hive_admin_user, hive.support.concurrency=true, hive.auto.convert.join=false, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.allocator.direct=false, hive.llap.cache.allow.synthetic.fileid=true, test.data.scripts=${hive.root}/data/scripts, hive.strict.timestamp.conversion=false, hive.test.dummystats.aggregator=value2, hive.llap.io.cache.orc.size=8388608, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.materializedview.rewriting=true, test.property1=value1, hive.mapjoin.max.gc.time.percentage=0.99, hive.exec.submit.local.task.via.child=false, hive.query.results.cache.enabled=false, hive.conf.restricted.list=dummy.config.value, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.cbo.fallback.strategy=TEST, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, hive.llap.io.cache.orc.arena.size=8388608, iceberg.hive.keep.stats=true, hive.stats.fetch.bitvector=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.client.cache.recordStats=true, hive.exec.mode.local.auto=false, javax.jdo.option.ConnectionPassword=mine, datanucleus.schema.autoCreateAll=true, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat}
2024-04-24T11:01:24,473  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:24,494  INFO [main] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713981683}
2024-04-24T11:01:24,503  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,503  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,509  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,510  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,516  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,516  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,562  INFO [main] io.RCFile: Column#0 : Plain Total Column Value Length: 3,  Compr Total Column Value Length: 3
2024-04-24T11:01:24,562  INFO [main] io.RCFile: Column#1 : Plain Total Column Value Length: 5,  Compr Total Column Value Length: 5
2024-04-24T11:01:24,563  INFO [main] io.RCFile: Column#2 : Plain Total Column Value Length: 6,  Compr Total Column Value Length: 6
2024-04-24T11:01:24,563  INFO [main] io.RCFile: Column#3 : Plain Total Column Value Length: 11,  Compr Total Column Value Length: 11
2024-04-24T11:01:24,563  INFO [main] io.RCFile: Column#4 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T11:01:24,563  INFO [main] io.RCFile: Column#5 : Plain Total Column Value Length: 23,  Compr Total Column Value Length: 23
2024-04-24T11:01:24,563  INFO [main] io.RCFile: Column#6 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T11:01:24,564  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:24,565  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:24,572  INFO [main] output.FileOutputCommitter: Saved output of task 'attempt_200908190029_0001_r_000001_1' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/rc5318/_SCRATCH0,8972776518086744
2024-04-24T11:01:24,630  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,630  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,630  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,630  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,630  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,631  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,631  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,631  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,631  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,632  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,632  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:24,633  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,640  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.rc5318 newtbl=rc5318	
2024-04-24T11:01:24,694  INFO [main] utils.MetaStoreServerUtils: Updating table stats for rc5318
2024-04-24T11:01:24,695  INFO [main] utils.MetaStoreServerUtils: Updated size of table rc5318 to 170
2024-04-24T11:01:24,714  INFO [main] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T11:01:24,771  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,771  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,771  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,771  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,779  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,780  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:24,781  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,786  INFO [main] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,855  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:24,857  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:24,882  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,887  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:24,910  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:24,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:24,958  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:24,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:24,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:24,959  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:24,959  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:24,960  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:24,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:24,964  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:24,978  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
HCatContext INSTANCE is present : false
Copying from [inpy] to [orc5318] with schema : ti:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@3412a3fd[fieldName=ti,comment=<null>,type=tinyint,category=PRIMITIVE],si:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@36ecf9f6[fieldName=si,comment=<null>,type=smallint,category=PRIMITIVE],i:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@104bc677[fieldName=i,comment=<null>,type=int,category=PRIMITIVE],bi:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@3bda1f0[fieldName=bi,comment=<null>,type=bigint,category=PRIMITIVE],f:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@2211e731[fieldName=f,comment=<null>,type=float,category=PRIMITIVE],d:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@73e399cc[fieldName=d,comment=<null>,type=double,category=PRIMITIVE],b:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@3dd591b9[fieldName=b,comment=<null>,type=boolean,category=PRIMITIVE]
2024-04-24T11:01:25,028  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:25,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:25,030  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:25,030  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:25,030  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:25,031  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:25,042  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,042  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,045  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,045  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,056  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.client.cache.enabled=true, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.warehouse.dir=${test.warehouse.dir}, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.min=32768, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, datanucleus.connectionPool.maxPoolSize=4, hive.metastore.schema.verification=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.stats.column.autogather=true, hive.in.test=true, hive.scheduled.queries.executor.enabled=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.llap.io.use.lrfu=true, hive.metastore.client.cache.maxSize=10Mb, hive.stats.key.prefix.reserve.length=0, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.query.reexecution.stats.persist.scope=query, hive.ignore.mapjoin.hint=false, test.log.dir=${test.tmp.dir}/log/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.querylog.location=${test.tmp.dir}/tmp, test.data.files=${hive.root}/data/files, hive.users.in.admin.role=hive_admin_user, hive.support.concurrency=true, hive.auto.convert.join=false, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.allocator.direct=false, hive.llap.cache.allow.synthetic.fileid=true, test.data.scripts=${hive.root}/data/scripts, hive.strict.timestamp.conversion=false, hive.test.dummystats.aggregator=value2, hive.llap.io.cache.orc.size=8388608, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.materializedview.rewriting=true, test.property1=value1, hive.mapjoin.max.gc.time.percentage=0.99, hive.exec.submit.local.task.via.child=false, hive.query.results.cache.enabled=false, hive.conf.restricted.list=dummy.config.value, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.cbo.fallback.strategy=TEST, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, hive.llap.io.cache.orc.arena.size=8388608, iceberg.hive.keep.stats=true, hive.stats.fetch.bitvector=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.client.cache.recordStats=true, hive.exec.mode.local.auto=false, javax.jdo.option.ConnectionPassword=mine, datanucleus.schema.autoCreateAll=true, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat}
2024-04-24T11:01:25,063  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:25,067  INFO [main] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713981683}
2024-04-24T11:01:25,072  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,072  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,076  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,076  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,081  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,081  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,124  INFO [main] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-24T11:01:25,133  INFO [main] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/orc5318/_SCRATCH0,43473648277104615/_temporary/0/_temporary/attempt_200908190029_0001_r_000001_1/part-m-00001 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-24T11:01:25,220  INFO [main] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/orc5318/_SCRATCH0,43473648277104615/_temporary/0/_temporary/attempt_200908190029_0001_r_000001_1/part-m-00001 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-24T11:01:25,365  INFO [Finalizer] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:01:25,365  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T11:01:25,386  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:25,386  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:25,388  INFO [main] output.FileOutputCommitter: Saved output of task 'attempt_200908190029_0001_r_000001_1' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/orc5318/_SCRATCH0,43473648277104615
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:25,429  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:25,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:25,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:25,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:25,430  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:25,431  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:25,435  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.orc5318 newtbl=orc5318	
2024-04-24T11:01:25,468  INFO [main] utils.MetaStoreServerUtils: Updating table stats for orc5318
2024-04-24T11:01:25,469  INFO [main] utils.MetaStoreServerUtils: Updated size of table orc5318 to 710
2024-04-24T11:01:25,484  INFO [main] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T11:01:25,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:25,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:25,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:25,521  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:25,521  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:01:25,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:25,524  INFO [main] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T11:01:25,574  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:01:25,584  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-702407f1-3598-4c7d-bd57-c2311eb1bb08
===
inpy:
2024-04-24T11:01:25,850  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:25,850  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:25,851  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:25,852  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:25,852  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:25,857  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:25,877  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:25,929  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:25,929  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:25,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:25,931  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:25,935  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:25,956  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:25,976  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:01:26,011  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:01:26,046  INFO [main] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:01:26,070  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:01:26,082  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:01:26,083  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:01:26,185  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T11:01:26,194  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T11:01:26,207  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T11:01:26,207  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T11:01:26,226  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:01:26,229  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:26,244  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:26,245  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:26,245  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:26,245  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:26,245  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:26,245  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:26,246  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T11:01:26,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:26,250  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:26,264  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:26,276  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:01:26,297  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:01:26,303  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,346  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:01:26,353  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:01:26,366  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:01:26,372  INFO [JobControl] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:26,374  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:01:26,406  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:01:26,433  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local1173190176_0001
2024-04-24T11:01:26,433  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:01:26,530  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:01:26,531  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:01:26,542  INFO [Thread-86] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:26,542  INFO [Thread-86] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:26,542  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:01:26,561  INFO [Thread-86] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:01:26,561  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1173190176_0001_m_000000_0
2024-04-24T11:01:26,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:26,584  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:26,597  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:01:26,600  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 83
Input split[0]:
   Length = 83
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:01:26,609  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@695b3c13
2024-04-24T11:01:26,613  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:26,613  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:26,630  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713981683}
2024-04-24T11:01:26,631  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:01:26,632  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:01:26,635  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:01:26,641  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:26,646  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1173190176_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T11:01:26,649  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:26,649  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1173190176_0001_m_000000_0 is allowed to commit now
2024-04-24T11:01:26,652  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1173190176_0001_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp273836497
2024-04-24T11:01:26,653  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/inpy/textfile:0+83
2024-04-24T11:01:26,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1173190176_0001_m_000000_0' done.
2024-04-24T11:01:26,655  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1173190176_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2737
		FILE: Number of bytes written=566603
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2121
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=891813888
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:01:26,655  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1173190176_0001_m_000000_0
2024-04-24T11:01:26,655  INFO [Thread-86] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:01:26,799  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local1173190176_0001
2024-04-24T11:01:26,799  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:01:26,799  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:01:26,802  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,805  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,808  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,826  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:01:26,827  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:01:26	2024-04-24 11:01:26	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local1173190176_0001	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp273836497,

Input(s):
Successfully read 2 records from: "inpy"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp273836497"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local1173190176_0001


2024-04-24T11:01:26,828  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,831  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,833  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:01:26,835  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:01:26,845  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:26,845  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:01:26,871  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:01:26,872  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-702407f1-3598-4c7d-bd57-c2311eb1bb08
===
rc5318:
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:26,902  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:26,903  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:26,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:26,925  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:26,945  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:26,946  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:26,946  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:26,946  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:26,946  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:26,949  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:26,965  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:26,967  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:01:26,977  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:01:26,978  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:01:26,979  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:01:26,980  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:01:26,980  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:01:26,987  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:26,989  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:01:26,989  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:01:27,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:27,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:27,012  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:27,012  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:27,012  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:27,012  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:27,013  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:27,015  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:27,019  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:27,036  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:27,044  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:01:27,053  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:01:27,056  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,074  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:01:27,079  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:01:27,082  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:01:27,088  INFO [JobControl] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:27,088  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:01:27,109  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:01:27,127  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local2101710246_0002
2024-04-24T11:01:27,127  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:01:27,224  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:01:27,225  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:01:27,229  INFO [Thread-127] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,229  INFO [Thread-127] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,229  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:01:27,240  INFO [Thread-127] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:01:27,240  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2101710246_0002_m_000000_0
2024-04-24T11:01:27,246  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,246  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,248  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:01:27,249  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 170
Input split[0]:
   Length = 170
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:01:27,253  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@352524c2
2024-04-24T11:01:27,255  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,255  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,272  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe with properties {name=default.rc5318, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, totalSize=170, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713981683}
2024-04-24T11:01:27,273  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:01:27,273  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:01:27,273  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:01:27,274  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:27,275  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2101710246_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T11:01:27,277  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:27,277  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2101710246_0002_m_000000_0 is allowed to commit now
2024-04-24T11:01:27,279  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2101710246_0002_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp380600348
2024-04-24T11:01:27,280  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/rc5318/part-m-00001:0+170
2024-04-24T11:01:27,280  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2101710246_0002_m_000000_0' done.
2024-04-24T11:01:27,280  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2101710246_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5198
		FILE: Number of bytes written=1132326
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2131
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=894435328
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:01:27,280  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2101710246_0002_m_000000_0
2024-04-24T11:01:27,280  INFO [Thread-127] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:01:27,426  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local2101710246_0002
2024-04-24T11:01:27,426  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:01:27,426  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:01:27,430  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,434  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,438  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,443  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:01:27,443  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:01:26	2024-04-24 11:01:27	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local2101710246_0002	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp380600348,

Input(s):
Successfully read 2 records from: "rc5318"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp380600348"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local2101710246_0002


2024-04-24T11:01:27,446  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,449  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,452  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:01:27,453  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:01:27,464  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:27,464  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:01:27,492  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:01:27,493  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-702407f1-3598-4c7d-bd57-c2311eb1bb08
===
orc5318:
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:27,515  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:27,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:27,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:27,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:27,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:27,516  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:27,519  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:27,532  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:27,546  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:27,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:27,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:27,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:27,550  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:27,562  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:27,564  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:01:27,571  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:01:27,571  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:01:27,572  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:01:27,573  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:01:27,573  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:01:27,579  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,581  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:01:27,581  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:01:27,595  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:01:27,596  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:01:27,596  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:01:27,597  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:01:27,600  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:27,612  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:27,617  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:01:27,622  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:01:27,624  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:27,640  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:01:27,645  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:01:27,648  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:01:27,649  INFO [JobControl] orc.OrcInputFormat: getSplits started
2024-04-24T11:01:27,654  INFO [JobControl] orc.OrcInputFormat: Context:: isAcid: false isVectorMode: false sarg: null minSplitSize: 0 maxSplitSize: 268435456 splitStrategy: HYBRID footerInSplits: false numBuckets: 0 numThreads: 10 cacheMemSize: 268435456 cacheStripeDetails: true useSoftReference: false writeIdList: null:9223372036854775807:9223372036854775807:: isTransactionalTable: false txnProperties: null 
2024-04-24T11:01:27,654  INFO [JobControl] orc.OrcInputFormat: ORC pushdown predicate: null
2024-04-24T11:01:27,702  INFO [JobControl] orc.OrcInputFormat: FooterCacheHitRatio: 0/1
2024-04-24T11:01:27,704  INFO [JobControl] orc.OrcInputFormat: getSplits finished (#splits: 1). duration: 55 ms
2024-04-24T11:01:27,704  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:01:27,725  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:01:27,739  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local1827145916_0003
2024-04-24T11:01:27,739  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:01:27,798  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:01:27,798  INFO [Thread-166] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:01:27,803  INFO [Thread-166] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,803  INFO [Thread-166] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,803  INFO [Thread-166] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:01:27,814  INFO [Thread-166] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:01:27,814  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1827145916_0003_m_000000_0
2024-04-24T11:01:27,820  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,820  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:01:27,823  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 361
Input split[0]:
   Length = 361
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:01:27,827  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@52076c12
2024-04-24T11:01:27,829  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:01:27,829  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:01:27,844  INFO [LocalJobRunner Map Task Executor #0] orc.ReaderImpl: Reading ORC rows from file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713981673968/warehouse/orc5318/part-m-00001 with {include: null, offset: 3, length: 361, schema: struct<ti:tinyint,si:smallint,i:int,bi:bigint,f:float,d:double,b:boolean>, includeAcidColumns: true}
2024-04-24T11:01:27,870  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.ql.io.orc.OrcSerde with properties {name=default.orc5318, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, totalSize=710, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713981683}
2024-04-24T11:01:27,871  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:01:27,871  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:01:27,871  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:01:27,873  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:27,873  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1827145916_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T11:01:27,875  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:01:27,875  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1827145916_0003_m_000000_0 is allowed to commit now
2024-04-24T11:01:27,878  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1827145916_0003_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp-1869331902
2024-04-24T11:01:27,878  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T11:01:27,878  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1827145916_0003_m_000000_0' done.
2024-04-24T11:01:27,879  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1827145916_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=11345
		FILE: Number of bytes written=1698257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2336
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=894435328
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:01:27,879  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1827145916_0003_m_000000_0
2024-04-24T11:01:27,879  INFO [Thread-166] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:01:27,999  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local1827145916_0003
2024-04-24T11:01:27,999  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:01:27,999  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:01:28,007  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:28,014  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:28,020  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:28,028  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:01:28,029  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:01:27	2024-04-24 11:01:28	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local1827145916_0003	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp-1869331902,

Input(s):
Successfully read 2 records from: "orc5318"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713981685524/pig/temp/temp-727795839/tmp-1869331902"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local1827145916_0003


2024-04-24T11:01:28,034  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:28,039  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:01:28,041  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:01:28,042  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:01:28,052  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:01:28,052  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:01:28,054  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table inpy
2024-04-24T11:01:28,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:28,069  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,069  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:28,069  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:28,069  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:28,070  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13}
2024-04-24T11:01:28,070  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.016 seconds
2024-04-24T11:01:28,070  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:28,070  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:28,070  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table inpy
2024-04-24T11:01:28,071  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:28,071  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:28,084  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,085  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:01:28,097  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.inpy	
2024-04-24T11:01:28,330  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:28,330  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=245, getTable_(GetTableRequest)=13}
2024-04-24T11:01:28,330  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.26 seconds
2024-04-24T11:01:28,331  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table rc5318
2024-04-24T11:01:28,332  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:28,383  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,383  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:28,383  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:28,384  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:28,384  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=51, isCompatibleWith_(Configuration)=1, flushCache_()=0}
2024-04-24T11:01:28,384  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.052 seconds
2024-04-24T11:01:28,384  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:28,384  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:28,384  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table rc5318
2024-04-24T11:01:28,384  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:28,385  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:28,398  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,398  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:01:28,411  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.rc5318	
2024-04-24T11:01:28,481  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:28,481  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=13, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=83}
2024-04-24T11:01:28,481  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.097 seconds
2024-04-24T11:01:28,482  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table orc5318
2024-04-24T11:01:28,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:28,495  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,495  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:01:28,496  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:01:28,496  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:01:28,496  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=13, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T11:01:28,496  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.014 seconds
2024-04-24T11:01:28,496  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:01:28,496  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:01:28,496  INFO [main] ql.Driver: Executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f): drop table orc5318
2024-04-24T11:01:28,496  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:01:28,497  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:28,509  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,510  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:01:28,522  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:01:28,522  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.orc5318	
2024-04-24T11:01:28,567  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:01:28,567  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, dropTable_(String, String, boolean, boolean, boolean)=56, getTable_(GetTableRequest)=13}
2024-04-24T11:01:28,567  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424110115_59518e7a-9557-4cd2-9776-3d2357fae02f); Time taken: 0.071 seconds
2024-04-24T11:01:28,583  INFO [pool-2-thread-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:01:28,583  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
