SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,098245 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@30c15d8b]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@30c15d8b) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@662ac478
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7bedc48a
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,016181 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log seek to 197838196
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T10:02:05.686-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-10:02:07.291, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-10:02:07.292, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7bedc48a initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7bedc48a
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7bedc48a OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@1a38c59b...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@1a38c59b OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7ceb3185
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@30c15d8b
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@30c15d8b) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@30c15d8b] started OK.
2024-04-24T10:02:07,460  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/warehouse
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T10:02:07,481  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-site.xml
2024-04-24T10:02:07,753  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T10:02:07,801  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:07,801  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:07,802  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:07,802  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:07,802  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:07,802  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:07,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:07,803  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:07,803  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:07,803  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:07,803  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:07,983  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:08,198  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T10:02:08,231  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:08,237  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T10:02:08,238  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T10:02:08,258  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T10:02:08,263  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T10:02:09,029  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T10:02:09,032  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
log4j: Trying to find [log4j.xml] using context classloader sun.misc.Launcher$AppClassLoader@7f31245a.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@7f31245a class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader sun.misc.Launcher$AppClassLoader@7f31245a.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@7f31245a class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (DataNucleus.General).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T10:02:09,733  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T10:02:09,733  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134, with PersistenceManager: null will be shutdown
2024-04-24T10:02:09,757  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@670ce331 created in the thread with id: 1
2024-04-24T10:02:12,106  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T10:02:12,106  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T10:02:12,106  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134 from thread id: 1
2024-04-24T10:02:12,313  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T10:02:12,344  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T10:02:12,371  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T10:02:12,372  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T10:02:12,469  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T10:02:12,476  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T10:02:12,477  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T10:02:12,479  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T10:02:12,503  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T10:02:12,506  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T10:02:12,507  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T10:02:12,508  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T10:02:12,510  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T10:02:12,512  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T10:02:12,513  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T10:02:12,514  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T10:02:12,520  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T10:02:12,521  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T10:02:12,522  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T10:02:12,525  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 405a86b3-5dab-47c3-a915-6063bdd09338
2024-04-24T10:02:12,725  INFO [main] SessionState: Hive Session ID = 405a86b3-5dab-47c3-a915-6063bdd09338
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T10:02:12,737  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T10:02:12,799  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/405a86b3-5dab-47c3-a915-6063bdd09338
2024-04-24T10:02:12,803  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/405a86b3-5dab-47c3-a915-6063bdd09338
2024-04-24T10:02:12,806  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/405a86b3-5dab-47c3-a915-6063bdd09338/_tmp_space.db
2024-04-24T10:02:12,851  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): drop table junit_external
2024-04-24T10:02:14,027  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,031  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,035  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,036  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,036  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,037  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,037  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T10:02:14,091  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:14,091  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:14,092  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@670ce331 will be shutdown
2024-04-24T10:02:14,093  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21f7e537 created in the thread with id: 1
2024-04-24T10:02:14,107  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:14,108  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:14,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T10:02:14,338  INFO [main] reflections.Reflections: Reflections took 133 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T10:02:14,442  INFO [main] reflections.Reflections: Reflections took 72 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T10:02:14,532  INFO [main] reflections.Reflections: Reflections took 85 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T10:02:14,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:14,630  INFO [main] reflections.Reflections: Reflections took 67 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T10:02:14,680  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T10:02:14,683  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T10:02:14,686  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T10:02:14,686  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, getAllFunctions_()=44}
2024-04-24T10:02:14,686  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 1.837 seconds
2024-04-24T10:02:14,687  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T10:02:14,687  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T10:02:14,690  INFO [main] ql.Driver: Executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): drop table junit_external
2024-04-24T10:02:14,693  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T10:02:14,695  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:14,714  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T10:02:14,714  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1}
2024-04-24T10:02:14,714  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.024 seconds
2024-04-24T10:02:14,716  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): create external table junit_external(a int, b string) partitioned by (c string) stored as RCFILE
2024-04-24T10:02:14,791  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73
2024-04-24T10:02:14,793  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T10:02:14,810  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=405a86b3-5dab-47c3-a915-6063bdd09338, clientType=HIVECLI]
2024-04-24T10:02:14,813  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T10:02:14,814  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T10:02:14,814  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@8b91134, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21f7e537 will be shutdown
2024-04-24T10:02:14,814  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:14,815  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T10:02:14,816  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:14,816  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T10:02:14,816  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:14,818  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8, with PersistenceManager: null will be shutdown
2024-04-24T10:02:14,819  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3cc3f13e created in the thread with id: 1
2024-04-24T10:02:14,828  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8 from thread id: 1
2024-04-24T10:02:14,829  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:14,829  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:14,836  INFO [main] parse.CalcitePlanner: Creating table default.junit_external position=22
2024-04-24T10:02:14,850  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:14,850  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:14,851  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3cc3f13e will be shutdown
2024-04-24T10:02:14,852  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13e00016 created in the thread with id: 1
2024-04-24T10:02:14,857  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:14,858  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:14,862  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T10:02:14,875  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73
2024-04-24T10:02:14,875  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T10:02:14,875  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T10:02:14,875  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T10:02:14,875  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T10:02:14,876  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.16 seconds
2024-04-24T10:02:14,876  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T10:02:14,877  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T10:02:14,877  INFO [main] ql.Driver: Executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): create external table junit_external(a int, b string) partitioned by (c string) stored as RCFILE
2024-04-24T10:02:14,877  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T10:02:14,877  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T10:02:14,878  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T10:02:14,878  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@424f02b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13e00016 will be shutdown
2024-04-24T10:02:14,878  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:14,878  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T10:02:14,914  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:14,915  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T10:02:14,915  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:14,916  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac2e1b, with PersistenceManager: null will be shutdown
2024-04-24T10:02:14,917  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac2e1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cee2e10 created in the thread with id: 1
2024-04-24T10:02:14,921  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac2e1b from thread id: 1
2024-04-24T10:02:14,922  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:14,922  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:14,922  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:junit_external, dbName:default, owner:alex, createTime:1713978134, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:c, type:string, comment:null)], parameters:{EXTERNAL=TRUE, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T10:02:14,931  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/warehouse/junit_external
2024-04-24T10:02:15,065  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T10:02:15,065  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=142}
2024-04-24T10:02:15,065  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.188 seconds
2024-04-24T10:02:15,115  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T10:02:15,125  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-02a3b517-9df8-468f-8585-9594dd6bf6a1
2024-04-24T10:02:15,125  INFO [main] mapreduce.HCatBaseTest: Registering pig query: A = load '/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/input.data' as (a:int, b:chararray);
2024-04-24T10:02:15,385  INFO [main] mapreduce.HCatBaseTest: Registering pig query: store A into 'default.junit_external' using org.apache.hive.hcatalog.pig.HCatStorerWrapper('c=100','/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/0cff0cf6-5a08-4577-824e-9bdeae7fe16f');
2024-04-24T10:02:15,455  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:15,455  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:15,455  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:15,455  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:15,455  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:15,456  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:15,457  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T10:02:15,458  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T10:02:15,466  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T10:02:15,474  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:15,474  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:15,475  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac2e1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cee2e10 will be shutdown
2024-04-24T10:02:15,475  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac2e1b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2707c790 created in the thread with id: 1
2024-04-24T10:02:15,485  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:15,485  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:15,507  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T10:02:15,519  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:15,595  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T10:02:15,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:15,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:15,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:15,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:15,663  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:15,664  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T10:02:15,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T10:02:15,678  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T10:02:15,704  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T10:02:15,734  INFO [main] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T10:02:15,762  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T10:02:15,778  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T10:02:15,779  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T10:02:15,870  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T10:02:15,879  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T10:02:15,888  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T10:02:15,888  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T10:02:15,904  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T10:02:15,906  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T10:02:15,912  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T10:02:15,920  INFO [main] data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2024-04-24T10:02:15,920  INFO [main] data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2024-04-24T10:02:15,920  INFO [main] data.SchemaTupleFrontend: Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/1713978135919-0
2024-04-24T10:02:15,939  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T10:02:15,945  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:15,982  WARN [JobControl] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:15,983  WARN [JobControl] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:15,983  WARN [JobControl] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:15,983  WARN [JobControl] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:15,983  WARN [JobControl] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:15,983  WARN [JobControl] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:15,983  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T10:02:15,984  INFO [JobControl] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:15,984  INFO [JobControl] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T10:02:15,984  INFO [JobControl] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:15,985  INFO [JobControl] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@697a042a, with PersistenceManager: null will be shutdown
2024-04-24T10:02:15,985  INFO [JobControl] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@697a042a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60dc45c6 created in the thread with id: 56
2024-04-24T10:02:15,992  INFO [JobControl] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@697a042a from thread id: 56
2024-04-24T10:02:15,992  INFO [JobControl] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:15,992  INFO [JobControl] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:15,993  INFO [JobControl] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T10:02:16,037  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T10:02:16,046  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T10:02:16,056  INFO [JobControl] builtin.PigStorage: Using PigTextInputFormat
2024-04-24T10:02:16,061  INFO [JobControl] input.FileInputFormat: Total input files to process : 1
2024-04-24T10:02:16,061  INFO [JobControl] util.MapRedUtil: Total input paths to process : 1
2024-04-24T10:02:16,075  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T10:02:16,116  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T10:02:16,144  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local1561379407_0001
2024-04-24T10:02:16,144  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T10:02:16,252  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T10:02:16,254  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T10:02:16,269  INFO [Thread-49] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,269  INFO [Thread-49] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,274  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T10:02:16,281  INFO [Thread-49] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,282  INFO [Thread-49] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,295  INFO [Thread-49] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T10:02:16,296  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1561379407_0001_m_000000_0
2024-04-24T10:02:16,435  INFO [Finalizer] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:16,436  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T10:02:16,441  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local1561379407_0001
2024-04-24T10:02:16,441  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases A
2024-04-24T10:02:16,441  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: A[1,4],A[-1,-1] C:  R: 
2024-04-24T10:02:16,443  INFO [main] mapReduceLayer.MapReduceLauncher: 0% complete
2024-04-24T10:02:16,443  INFO [main] mapReduceLayer.MapReduceLauncher: Running jobs are [job_local1561379407_0001]
2024-04-24T10:02:16,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,462  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,466  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,466  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,478  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T10:02:16,483  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 36
Input split[0]:
   Length = 36
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------

2024-04-24T10:02:16,489  INFO [LocalJobRunner Map Task Executor #0] builtin.PigStorage: Using PigTextInputFormat
2024-04-24T10:02:16,491  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/input.data:0+36
2024-04-24T10:02:16,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,498  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,524  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T10:02:16,525  INFO [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: Key [pig.schematuple] was not set... will not generate code.
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T10:02:16,530  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: A[1,4],A[-1,-1] C:  R: 
2024-04-24T10:02:16,544  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T10:02:16,545  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T10:02:16,545  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T10:02:16,551  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1561379407_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T10:02:16,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,553  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,554  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T10:02:16,554  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1561379407_0001_m_000000_0 is allowed to commit now
2024-04-24T10:02:16,556  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T10:02:16,556  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T10:02:16,558  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1561379407_0001_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/0cff0cf6-5a08-4577-824e-9bdeae7fe16f
2024-04-24T10:02:16,559  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T10:02:16,559  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1561379407_0001_m_000000_0' done.
2024-04-24T10:02:16,561  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1561379407_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=570
		FILE: Number of bytes written=572876
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Input split bytes=480
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=882376704
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T10:02:16,561  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1561379407_0001_m_000000_0
2024-04-24T10:02:16,562  INFO [Thread-49] mapred.LocalJobRunner: map task executor complete.
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:16,613  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:16,614  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:16,614  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:16,614  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:16,614  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:16,614  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:16,614  INFO [Thread-49] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T10:02:16,615  INFO [Thread-49] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T10:02:16,616  INFO [Thread-49] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T10:02:16,616  INFO [Thread-49] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T10:02:16,616  INFO [Thread-49] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b446ff, with PersistenceManager: null will be shutdown
2024-04-24T10:02:16,617  INFO [Thread-49] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b446ff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@686e2983 created in the thread with id: 76
2024-04-24T10:02:16,621  INFO [Thread-49] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23b446ff from thread id: 76
2024-04-24T10:02:16,621  INFO [Thread-49] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T10:02:16,621  INFO [Thread-49] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T10:02:16,621  INFO [Thread-49] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:16,669  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:16,670  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:16,670  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:16,670  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:16,670  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:16,670  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:16,671  INFO [Thread-49] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table junit_external has new partitions [{c=100}].
2024-04-24T10:02:16,672  INFO [Thread-49] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partition : tbl=hive.default.junit_external[100]	
2024-04-24T10:02:16,693  INFO [Thread-49] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=add_partition	
2024-04-24T10:02:16,693  INFO [Thread-49] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=add_partitions	
2024-04-24T10:02:16,708  INFO [HMSHandler #0] utils.MetaStoreServerUtils: Updating partition stats fast for: junit_external
2024-04-24T10:02:16,708  INFO [HMSHandler #0] utils.MetaStoreServerUtils: Updated size to 97
2024-04-24T10:02:16,792  INFO [Thread-49] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T10:02:16,834  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T10:02:16,834  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T10:02:16,834  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T10:02:16,835  WARN [Thread-49] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T10:02:16,835  INFO [Thread-49] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T10:02:16,836  INFO [Thread-49] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T10:02:16,837  INFO [Thread-49] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T10:02:16,943  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:16,945  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:16,946  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:16,964  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T10:02:16,965  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 10:02:15	2024-04-24 10:02:16	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local1561379407_0001	1	0	n/a	n/a	n/a	n/a	0	0	0	0	A	MAP_ONLY	default.junit_external,

Input(s):
Successfully read 9 records from: "/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713978127360/input.data"

Output(s):
Successfully stored 9 records in: "default.junit_external"

Counters:
Total records written : 9
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local1561379407_0001


2024-04-24T10:02:16,966  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:16,967  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T10:02:16,968  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T10:02:16,969  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): select * from junit_external
2024-04-24T10:02:16,972  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73
2024-04-24T10:02:16,973  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T10:02:16,975  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T10:02:16,975  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T10:02:16,977  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:16,988  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T10:02:16,991  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T10:02:16,991  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T10:02:16,995  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T10:02:18,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.junit_external	
2024-04-24T10:02:18,600  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.junit_external, projIndxSet: [0, 1, 2], allowMissingStats: true
2024-04-24T10:02:18,602  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions : tbl=hive.default.junit_external	
2024-04-24T10:02:18,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_aggr_stats_for: table=hive.default.junit_external	
2024-04-24T10:02:18,689  WARN [main] calcite.RelOptHiveTable: No Stats for default@junit_external, Columns: a, b
No Stats for default@junit_external, Columns: a, b
2024-04-24T10:02:18,689  INFO [main] SessionState: No Stats for default@junit_external, Columns: a, b
2024-04-24T10:02:18,786  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T10:02:18,786  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T10:02:18,786  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T10:02:18,826  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/405a86b3-5dab-47c3-a915-6063bdd09338/hive_2024-04-24_10-02-16_969_6911118483663606871-1/-mr-10001/.hive-staging_hive_2024-04-24_10-02-16_969_6911118483663606871-1
2024-04-24T10:02:18,843  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T10:02:18,897  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T10:02:18,916  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T10:02:18,916  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73
2024-04-24T10:02:18,916  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T10:02:18,916  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:junit_external.a, type:int, comment:null), FieldSchema(name:junit_external.b, type:string, comment:null), FieldSchema(name:junit_external.c, type:string, comment:null)], properties:null)
2024-04-24T10:02:18,929  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T10:02:18,929  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T10:02:18,934  INFO [main] exec.SelectOperator: SELECT struct<a:int,b:string,c:string>
2024-04-24T10:02:18,934  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T10:02:18,938  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T10:02:18,938  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, listPartitions_(String, String, short)=44, getAllTableConstraints_(AllTableConstraintsRequest)=61, getTable_(GetTableRequest)=13, flushCache_()=0, getAggrColStatsFor_(String, String, List, List, String, String)=32}
2024-04-24T10:02:18,938  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 1.969 seconds
2024-04-24T10:02:18,938  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T10:02:18,938  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T10:02:18,938  INFO [main] ql.Driver: Executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): select * from junit_external
2024-04-24T10:02:18,939  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T10:02:18,939  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T10:02:18,939  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.001 seconds
2024-04-24T10:02:18,947  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T10:02:18,958  INFO [main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T10:02:18,958  INFO [main] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:9, 
2024-04-24T10:02:18,958  INFO [main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T10:02:18,958  INFO [main] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:9, 
2024-04-24T10:02:18,958  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T10:02:18,959  INFO [main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:9, 
2024-04-24T10:02:18,959  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/405a86b3-5dab-47c3-a915-6063bdd09338/hive_2024-04-24_10-02-16_969_6911118483663606871-1
2024-04-24T10:02:18,959  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/405a86b3-5dab-47c3-a915-6063bdd09338/hive_2024-04-24_10-02-16_969_6911118483663606871-1 on fs with scheme file
2024-04-24T10:02:18,960  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): drop table junit_external
2024-04-24T10:02:18,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:18,977  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T10:02:18,978  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T10:02:18,978  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getTable_(GetTableRequest)=17, flushCache_()=0}
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.018 seconds
2024-04-24T10:02:18,978  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73): drop table junit_external
2024-04-24T10:02:18,978  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T10:02:18,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:18,992  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T10:02:18,992  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.junit_external	
2024-04-24T10:02:19,006  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T10:02:19,006  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.junit_external	
2024-04-24T10:02:19,314  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T10:02:19,314  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, dropTable_(String, String, boolean, boolean, boolean)=321, getTable_(GetTableRequest)=13}
2024-04-24T10:02:19,314  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424100207_34ea984a-57c1-419f-8e10-1d38e6274a73); Time taken: 0.336 seconds
2024-04-24T10:02:19,328  INFO [pool-3-thread-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:19,328  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-04-24T10:02:19,328  INFO [pool-3-thread-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:19,328  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T10:02:19,329  INFO [pool-3-thread-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T10:02:19,329  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
