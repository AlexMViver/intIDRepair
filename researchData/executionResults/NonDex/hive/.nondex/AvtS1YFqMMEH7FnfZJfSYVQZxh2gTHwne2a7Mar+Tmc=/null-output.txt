DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
DEBUG StatusLogger Took 0,076473 seconds to load 240 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@20ce78ec]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@20ce78ec) with optional ClassLoader: null
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
DEBUG StatusLogger Missing dependencies for Yaml support, ConfigurationFactory org.apache.logging.log4j.core.config.yaml.YamlConfigurationFactory is inactive
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4f18837a
TRACE StatusLogger Trying to find [log4j2-test330bedb4.properties] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.properties] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yaml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.yaml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test330bedb4.json] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.json] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test330bedb4.jsn] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.jsn] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test330bedb4.xml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test330bedb4.xml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.properties] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.properties] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.yml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.yml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.yaml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.yaml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.json] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.json] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.jsn] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.jsn] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2-test.xml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2-test.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2-test.xml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.properties] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.properties] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.yml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.yml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.yml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.yaml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.yaml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.yaml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.json] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.json] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.json] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.jsn] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.jsn] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.jsn] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2330bedb4.xml] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
TRACE StatusLogger Trying to find [log4j2330bedb4.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
TRACE StatusLogger Trying to find [log4j2330bedb4.xml] using ClassLoader.getSystemResource().
TRACE StatusLogger Trying to find [log4j2.properties] using context class loader sun.misc.Launcher$AppClassLoader@330bedb4.
INFO StatusLogger Log4j appears to be running in a Servlet environment, but there's no log4j-web module available. If you want better web container support, please add the log4j-web JAR to your web archive or server lib directory.
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@9597028
DEBUG StatusLogger Installed 1 script engine
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger PluginManager 'Core' found 124 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="filename", value="logs")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={filename=logs}, Configuration(PropertiesConfig))
DEBUG StatusLogger PluginManager 'Lookup' found 16 plugins
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="STDOUT", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="CAPTURED", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={STDOUT, CAPTURED}, ={}, Configuration(PropertiesConfig), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Configuration(PropertiesConfig), Replace=null, charset="null", footer="null", disableAnsi="null", alwaysWriteExceptions="null", noConsoleNoAnsi="null", PatternSelector=null, header="null", pattern="[%-5level] %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %c{1} - %msg%n")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(direct="null", follow="null", target="null", immediateFlush="null", bufferedIo="null", bufferSize="null", PatternLayout([%-5level] %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %c{1} - %msg%n), Configuration(PropertiesConfig), ignoreExceptions="null", name="STDOUT", ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.metastore.testutils.CapturingLogAppender].
DEBUG StatusLogger createAppender(name="CAPTURED")
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={STDOUT, CAPTURED})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@9597028 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@9597028
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@9597028 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@1da51a35...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@1da51a35 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@2ad48653
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@20ce78ec
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=STDOUT
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=CAPTURED
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes/log4j2.properties (org.apache.logging.log4j.core.LoggerContext@20ce78ec) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@20ce78ec] started OK.
[INFO ] 2024-04-23 23:33:08.734 [main] MetastoreConf - Unable to find config file: hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
[INFO ] 2024-04-23 23:33:08.739 [main] MetastoreConf - Unable to find config file: hivemetastore-site.xml
[INFO ] 2024-04-23 23:33:08.740 [main] MetastoreConf - Unable to find config file: metastore-site.xml
[DEBUG] 2024-04-23 23:33:08.740 [main] MetastoreConf - Setting conf value datanucleus.schema.autoCreateAll using value true
[DEBUG] 2024-04-23 23:33:08.775 [main] MetastoreConf - Setting conf value javax.jdo.option.ConnectionURL using value jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true
[DEBUG] 2024-04-23 23:33:08.775 [main] MetastoreConf - Setting conf value metastore.schema.verification using value false
[DEBUG] 2024-04-23 23:33:08.775 [main] MetastoreConf - Setting conf value metastore.warehouse.dir using value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse
[DEBUG] 2024-04-23 23:33:08.776 [main] MetastoreConf - Picking up system property hive.metastore.warehouse.external.dir with value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/external
[DEBUG] 2024-04-23 23:33:08.778 [main] MetastoreConf - MetastoreConf object:
Key: <metastore.acid.housekeeper.interval> old hive key: <hive.metastore.acid.housekeeper.interval>  value: <60s>
Key: <metastore.acid.housekeeper.start> old hive key: <hive.metastore.acid.housekeeper.start>  value: <60s>
Key: <metastore.acid.txn.cleaner.interval> old hive key: <hive.metastore.acid.txn.cleaner.interval>  value: <10s>
Key: <metastore.added.jars.path> old hive key: <hive.added.jars.path>  value: <>
Key: <metastore.aggregate.stats.cache.clean.until> old hive key: <hive.metastore.aggregate.stats.cache.clean.until>  value: <0.8>
Key: <metastore.aggregate.stats.cache.enabled> old hive key: <hive.metastore.aggregate.stats.cache.enabled>  value: <false>
Key: <metastore.aggregate.stats.cache.fpp> old hive key: <hive.metastore.aggregate.stats.cache.fpp>  value: <0.01>
Key: <metastore.aggregate.stats.cache.max.full> old hive key: <hive.metastore.aggregate.stats.cache.max.full>  value: <0.9>
Key: <metastore.aggregate.stats.cache.max.partitions> old hive key: <hive.metastore.aggregate.stats.cache.max.partitions>  value: <10000>
Key: <metastore.aggregate.stats.cache.max.reader.wait> old hive key: <hive.metastore.aggregate.stats.cache.max.reader.wait>  value: <1000ms>
Key: <metastore.aggregate.stats.cache.max.variance> old hive key: <hive.metastore.aggregate.stats.cache.max.variance>  value: <0.01>
Key: <metastore.aggregate.stats.cache.max.writer.wait> old hive key: <hive.metastore.aggregate.stats.cache.max.writer.wait>  value: <5000ms>
Key: <metastore.aggregate.stats.cache.size> old hive key: <hive.metastore.aggregate.stats.cache.size>  value: <10000>
Key: <metastore.aggregate.stats.cache.ttl> old hive key: <hive.metastore.aggregate.stats.cache.ttl>  value: <600s>
Key: <metastore.warehouse.tenant.colocation> old hive key: <hive.metastore.warehouse.tenant.colocation>  value: <false>
Key: <metastore.alter.handler> old hive key: <hive.metastore.alter.impl>  value: <org.apache.hadoop.hive.metastore.HiveAlterHandler>
Key: <metastore.async.log.enabled> old hive key: <hive.async.log.enabled>  value: <true>
Key: <metastore.authorization.storage.checks> old hive key: <hive.metastore.authorization.storage.checks>  value: <false>
Key: <datanucleus.schema.autoCreateAll> old hive key: <datanucleus.schema.autoCreateAll>  value: <true>
Key: <metastore.batch.retrieve.max> old hive key: <hive.metastore.batch.retrieve.max>  value: <300>
Key: <metastore.batch.retrieve.table.partition.max> old hive key: <hive.metastore.batch.retrieve.table.partition.max>  value: <1000>
Key: <metastore.cache.pinobjtypes> old hive key: <hive.metastore.cache.pinobjtypes>  value: <Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order>
Key: <metastore.cached.rawstore.impl> old hive key: <hive.metastore.cached.rawstore.impl>  value: <org.apache.hadoop.hive.metastore.ObjectStore>
Key: <metastore.cached.rawstore.cache.update.frequency> old hive key: <hive.metastore.cached.rawstore.cache.update.frequency>  value: <60s>
Key: <metastore.cached.rawstore.cached.object.whitelist> old hive key: <hive.metastore.cached.rawstore.cached.object.whitelist>  value: <.*>
Key: <metastore.cached.rawstore.cached.object.blacklist> old hive key: <hive.metastore.cached.rawstore.cached.object.blacklist>  value: <>
Key: <metastore.cached.rawstore.max.cache.memory> old hive key: <hive.metastore.cached.rawstore.max.cache.memory>  value: <1Gb>
Key: <metastore.client.capability.check> old hive key: <hive.metastore.client.capability.check>  value: <true>
Key: <metastore.catalog.default> old hive key: <metastore.catalog.default>  value: <hive>
Key: <metastore.cached.rawstore.catalogs> old hive key: <metastore.cached.rawstore.catalogs>  value: <hive>
Key: <metastore.client.connect.retry.delay> old hive key: <hive.metastore.client.connect.retry.delay>  value: <1s>
Key: <metastore.client.kerberos.principal> old hive key: <hive.metastore.client.kerberos.principal>  value: <>
Key: <metastore.client.socket.lifetime> old hive key: <hive.metastore.client.socket.lifetime>  value: <0s>
Key: <metastore.client.socket.timeout> old hive key: <hive.metastore.client.socket.timeout>  value: <600s>
Key: <metastore.compactor.history.retention.did.not.initiate> old hive key: <hive.compactor.history.retention.did.not.initiate>  value: <2>
Key: <metastore.compactor.history.retention.failed> old hive key: <hive.compactor.history.retention.failed>  value: <3>
Key: <metastore.compactor.history.retention.succeeded> old hive key: <hive.compactor.history.retention.succeeded>  value: <3>
Key: <metastore.compactor.history.retention.timeout> old hive key: <hive.compactor.history.retention.timeout>  value: <7d>
Key: <metastore.compactor.initiator.failed.compacts.threshold> old hive key: <hive.compactor.initiator.failed.compacts.threshold>  value: <2>
Key: <metastore.compactor.initiator.failed.retry.time> old hive key: <hive.compactor.initiator.failed.retry.time>  value: <7d>
Key: <metastore.compactor.run.as.user> old hive key: <hive.compactor.run.as.user>  value: <>
Key: <metastore.compactor.oldest.replication.open.txn.threshold.warning> old hive key: <hive.compactor.oldest.replication.open.txn.threshold.warning>  value: <14d>
Key: <metastore.compactor.oldest.replication.open.txn.threshold.error> old hive key: <hive.compactor.oldest.replication.open.txn.threshold.error>  value: <21d>
Key: <metastore.compactor.oldest.open.txn.threshold.warning> old hive key: <hive.compactor.oldest.open.txn.threshold.warning>  value: <24h>
Key: <metastore.compactor.oldest.open.txn.threshold.error> old hive key: <hive.compactor.oldest.open.txn.threshold.error>  value: <72h>
Key: <metastore.compactor.oldest.uncleaned.aborted.txn.time.threshold.warning> old hive key: <hive.compactor.oldest.uncleaned.aborted.txn.time.threshold.warning>  value: <24h>
Key: <metastore.compactor.oldest.uncleaned.aborted.txn.time.threshold.error> old hive key: <hive.compactor.oldest.uncleaned.aborted.txn.time.threshold.error>  value: <48h>
Key: <metastore.compactor.tables.with.aborted.txn.threshold> old hive key: <hive.compactor.tables.with.aborted.txn.threshold>  value: <1>
Key: <metastore.compactor.oldest.uncleaned.compaction.time.threshold> old hive key: <hive.compactor.oldest.uncleaned.compaction.time.threshold>  value: <24h>
Key: <metastore.compactor.failed.compaction.ratio.threshold> old hive key: <hive.compactor.failed.compaction.ratio.threshold>  value: <0.01>
Key: <metastore.compactor.oldest.initiated.compaction.time.threshold.warning> old hive key: <hive.compactor.oldest.initiated.compaction.time.threshold.warning>  value: <1h>
Key: <metastore.compactor.oldest.initiated.compaction.time.threshold.error> old hive key: <hive.compactor.oldest.initiated.compaction.time.threshold.error>  value: <12h>
Key: <metastore.compactor.completed.txn.components.record.threshold.warning> old hive key: <hive.compactor.completed.txn.components.record.threshold.warning>  value: <500000>
Key: <metastore.compactor.completed.txn.components.record.threshold.error> old hive key: <hive.compactor.completed.txn.components.record.threshold.error>  value: <1000000>
Key: <metastore.compactor.txn.to.writeid.record.threshold.warning> old hive key: <hive.compactor.txn.to.writeid.record.threshold.warning>  value: <500000>
Key: <metastore.compactor.txn.to.writeid.record.threshold.error> old hive key: <hive.compactor.txn.to.writeid.record.threshold.error>  value: <1000000>
Key: <metastore.compactor.number.of.disabled.compaction.tables.threshold> old hive key: <hive.compactor.number.of.disabled.compaction.tables.threshold>  value: <1>
Key: <metastore.compactor.acid.metrics.logger.frequency> old hive key: <hive.compactor.acid.metrics.logger.frequency>  value: <360m>
Key: <metastore.housekeeping.leader.hostname> old hive key: <hive.metastore.housekeeping.leader.hostname>  value: <>
Key: <metastore.housekeeping.threads.on> old hive key: <hive.metastore.housekeeping.threads.on>  value: <false>
Key: <metastore.acidmetrics.thread.on> old hive key: <hive.metastore.acidmetrics.thread.on>  value: <true>
Key: <metastore.acidmetrics.check.interval> old hive key: <hive.metastore.acidmetrics.check.interval>  value: <300s>
Key: <metastore.acidmetrics.ext.on> old hive key: <hive.metastore.acidmetrics.ext.on>  value: <true>
Key: <metastore.acidmetrics.table.aborted.txns.threshold> old hive key: <hive.metastore.acidmetrics.table.aborted.txns.threshold>  value: <1500>
Key: <metastore.compactor.initiator.on> old hive key: <hive.compactor.initiator.on>  value: <false>
Key: <metastore.compactor.worker.threads> old hive key: <hive.compactor.worker.threads>  value: <0>
Key: <metastore.compactor.worker.detect.multiple.versions.threshold> old hive key: <hive.metastore.compactor.worker.detect.multiple.versions.threshold>  value: <24h>
Key: <metastore.compactor.enable.stats.compression> old hive key: <metastore.compactor.enable.stats.compression>  value: <true>
Key: <javax.jdo.option.ConnectionDriverName> old hive key: <javax.jdo.option.ConnectionDriverName>  value: <org.apache.derby.jdbc.EmbeddedDriver>
Key: <datanucleus.connectionPool.maxPoolSize> old hive key: <datanucleus.connectionPool.maxPoolSize>  value: <10>
Key: <metastore.ds.connection.url.hook> old hive key: <hive.metastore.ds.connection.url.hook>  value: <>
Key: <javax.jdo.option.ConnectionURL> old hive key: <javax.jdo.option.ConnectionURL>  value: <jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true>
Key: <datanucleus.connectionPoolingType> old hive key: <datanucleus.connectionPoolingType>  value: <HikariCP>
Key: <javax.jdo.option.ConnectionUserName> old hive key: <javax.jdo.option.ConnectionUserName>  value: <APP>
Key: <metastore.create.as.acid> old hive key: <hive.create.as.acid>  value: <false>
Key: <metastore.count.open.txns.interval> old hive key: <hive.count.open.txns.interval>  value: <1s>
Key: <datanucleus.autoStartMechanismMode> old hive key: <datanucleus.autoStartMechanismMode>  value: <ignored>
Key: <datanucleus.cache.level2> old hive key: <datanucleus.cache.level2>  value: <false>
Key: <datanucleus.cache.level2.type> old hive key: <datanucleus.cache.level2.type>  value: <none>
Key: <datanucleus.rdbms.initializeColumnInfo> old hive key: <datanucleus.rdbms.initializeColumnInfo>  value: <NONE>
Key: <datanucleus.plugin.pluginRegistryBundleCheck> old hive key: <datanucleus.plugin.pluginRegistryBundleCheck>  value: <LOG>
Key: <datanucleus.transactionIsolation> old hive key: <datanucleus.transactionIsolation>  value: <read-committed>
Key: <datanucleus.rdbms.useLegacyNativeValueStrategy> old hive key: <datanucleus.rdbms.useLegacyNativeValueStrategy>  value: <true>
Key: <metastore.dbaccess.ssl.truststore.path> old hive key: <hive.metastore.dbaccess.ssl.truststore.path>  value: <>
Key: <metastore.dbaccess.ssl.truststore.type> old hive key: <hive.metastore.dbaccess.ssl.truststore.type>  value: <jks>
Key: <metastore.dbaccess.ssl.use.SSL> old hive key: <hive.metastore.dbaccess.ssl.use.SSL>  value: <false>
Key: <metastore.default.partition.name> old hive key: <hive.exec.default.partition.name>  value: <__HIVE_DEFAULT_PARTITION__>
Key: <metastore.cluster.delegation.key.update-interval> old hive key: <hive.cluster.delegation.key.update-interval>  value: <1d>
Key: <metastore.cluster.delegation.token.gc-interval> old hive key: <hive.cluster.delegation.token.gc-interval>  value: <15m>
Key: <metastore.cluster.delegation.token.max-lifetime> old hive key: <hive.cluster.delegation.token.max-lifetime>  value: <7d>
Key: <metastore.cluster.delegation.token.renew-interval> old hive key: <hive.cluster.delegation.token.renew-interval>  value: <1d>
Key: <metastore.cluster.delegation.token.store.class> old hive key: <hive.cluster.delegation.token.store.class>  value: <org.apache.hadoop.hive.metastore.security.MetastoreDelegationTokenManager>
Key: <javax.jdo.option.DetachAllOnCommit> old hive key: <javax.jdo.option.DetachAllOnCommit>  value: <true>
Key: <metastore.direct.sql.max.elements.in.clause> old hive key: <hive.direct.sql.max.elements.in.clause>  value: <1000>
Key: <metastore.direct.sql.max.elements.values.clause> old hive key: <hive.direct.sql.max.elements.values.clause>  value: <1000>
Key: <metastore.direct.sql.max.parameters> old hive key: <hive.direct.sql.max.parameters>  value: <1000>
Key: <metastore.direct.sql.max.query.length> old hive key: <hive.direct.sql.max.query.length>  value: <100>
Key: <metastore.direct.sql.batch.size> old hive key: <hive.metastore.direct.sql.batch.size>  value: <0>
Key: <metastore.disallow.incompatible.col.type.changes> old hive key: <hive.metastore.disallow.incompatible.col.type.changes>  value: <true>
Key: <metastore.allow.incompatible.col.type.changes.serdes> old hive key: <hive.metastore.allow.incompatible.col.type.changes.serdes>  value: <org.apache.hadoop.hive.kudu.KuduSerDe,org.apache.iceberg.mr.hive.HiveIcebergSerDe>
Key: <metastore.dump.config.on.creation> old hive key: <metastore.dump.config.on.creation>  value: <true>
Key: <metastore.end.function.listeners> old hive key: <hive.metastore.end.function.listeners>  value: <>
Key: <metastore.event.clean.freq> old hive key: <hive.metastore.event.clean.freq>  value: <0s>
Key: <metastore.event.expiry.duration> old hive key: <hive.metastore.event.expiry.duration>  value: <0s>
Key: <metastore.event.listeners> old hive key: <hive.metastore.event.listeners>  value: <>
Key: <metastore.event.message.factory> old hive key: <hive.metastore.event.message.factory>  value: <org.apache.hadoop.hive.metastore.messaging.json.gzip.GzipJSONMessageEncoder>
Key: <metastore.repl.message.factory> old hive key: <hive.metastore.repl.message.factory>  value: <org.apache.hadoop.hive.metastore.messaging.json.gzip.GzipJSONMessageEncoder>
Key: <metastore.notification.parameters.exclude.patterns> old hive key: <hive.metastore.notification.parameters.exclude.patterns>  value: <>
Key: <metastore.event.db.listener.timetolive> old hive key: <hive.metastore.event.db.listener.timetolive>  value: <1d>
Key: <metastore.event.db.clean.maxevents> old hive key: <hive.metastore.event.db.clean.maxevents>  value: <10000>
Key: <metastore.event.db.listener.clean.interval> old hive key: <hive.metastore.event.db.listener.clean.interval>  value: <7200s>
Key: <metastore.event.db.listener.clean.startup.wait.interval> old hive key: <hive.metastore.event.db.listener.clean.startup.wait.interval>  value: <1d>
Key: <metastore.metastore.event.db.notification.api.auth> old hive key: <hive.metastore.event.db.notification.api.auth>  value: <true>
Key: <metastore.execute.setugi> old hive key: <hive.metastore.execute.setugi>  value: <true>
Key: <metastore.expression.proxy> old hive key: <hive.metastore.expression.proxy>  value: <org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore>
Key: <metastore.decode.filter.expression.tostring> old hive key: <hive.metastore.decode.filter.expression.tostring>  value: <false>
Key: <metastore.file.metadata.threads> old hive key: <hive.metastore.hbase.file.metadata.threads>  value: <1>
Key: <metastore.filter.hook> old hive key: <hive.metastore.filter.hook>  value: <org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl>
Key: <metastore.fs.handler.class> old hive key: <hive.metastore.fs.handler.class>  value: <org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl>
Key: <metastore.fshandler.threads> old hive key: <hive.metastore.fshandler.threads>  value: <15>
Key: <metastore.hmshandler.retry.attempts> old hive key: <hive.hmshandler.retry.attempts>  value: <10>
Key: <metastore.hmshandler.force.reload.conf> old hive key: <hive.hmshandler.force.reload.conf>  value: <false>
Key: <metastore.hmshandler.retry.interval> old hive key: <hive.hmshandler.retry.interval>  value: <2000ms>
Key: <datanucleus.identifierFactory> old hive key: <datanucleus.identifierFactory>  value: <datanucleus1>
Key: <metastore.init.hooks> old hive key: <hive.metastore.init.hooks>  value: <>
Key: <metastore.initial.metadata.count.enabled> old hive key: <hive.metastore.initial.metadata.count.enabled>  value: <true>
Key: <metastore.integral.jdo.pushdown> old hive key: <hive.metastore.integral.jdo.pushdown>  value: <false>
Key: <metastore.jdbc.max.batch.size> old hive key: <hive.metastore.jdbc.max.batch.size>  value: <1000>
Key: <metastore.kerberos.keytab.file> old hive key: <hive.metastore.kerberos.keytab.file>  value: <>
Key: <metastore.kerberos.principal> old hive key: <hive.metastore.kerberos.principal>  value: <hive-metastore/_HOST@EXAMPLE.COM>
Key: <metastore.authentication> old hive key: <hive.metastore.authentication>  value: <NOSASL>
Key: <metastore.custom.authentication.class> old hive key: <hive.metastore.custom.authentication.class>  value: <>
Key: <metastore.authentication.ldap.url> old hive key: <hive.metastore.authentication.ldap.url>  value: <>
Key: <metastore.authentication.ldap.baseDN> old hive key: <hive.metastore.authentication.ldap.baseDN>  value: <>
Key: <metastore.authentication.ldap.Domain> old hive key: <hive.metastore.authentication.ldap.Domain>  value: <>
Key: <metastore.authentication.ldap.groupDNPattern> old hive key: <hive.metastore.authentication.ldap.groupDNPattern>  value: <>
Key: <metastore.authentication.ldap.groupFilter> old hive key: <hive.metastore.authentication.ldap.groupFilter>  value: <>
Key: <metastore.authentication.ldap.userDNPattern> old hive key: <hive.metastore.authentication.ldap.userDNPattern>  value: <>
Key: <metastore.authentication.ldap.userFilter> old hive key: <hive.metastore.authentication.ldap.userFilter>  value: <>
Key: <metastore.authentication.ldap.guidKey> old hive key: <hive.metastore.authentication.ldap.guidKey>  value: <uid>
Key: <metastore.authentication.ldap.groupMembershipKey> old hive key: <hive.metastore.authentication.ldap.groupMembershipKey>  value: <member>
Key: <metastore.authentication.ldap.userMembershipKey> old hive key: <hive.metastore.authentication.ldap.userMembershipKey>  value: <>
Key: <metastore.authentication.ldap.groupClassKey> old hive key: <hive.metastore.authentication.ldap.groupClassKey>  value: <groupOfNames>
Key: <metastore.authentication.ldap.customLDAPQuery> old hive key: <hive.metastore.authentication.ldap.customLDAPQuery>  value: <>
Key: <metastore.authentication.ldap.binddn> old hive key: <hive.metastore.authentication.ldap.binddn>  value: <>
Key: <metastore.authentication.ldap.bindpw> old hive key: <hive.metastore.authentication.ldap.bindpw>  value: <>
Key: <metastore.limit.partition.request> old hive key: <hive.metastore.limit.partition.request>  value: <-1>
Key: <metastore.client.cache.v2.enabled> old hive key: <hive.metastore.client.cache.v2.enabled>  value: <true>
Key: <metastore.client.cache.v2.maxSize> old hive key: <hive.metastore.client.cache.v2.maxSize>  value: <1Gb>
Key: <metastore.client.cache.v2.recordStats> old hive key: <hive.metastore.client.cache.v2.recordStats>  value: <false>
Key: <metastore.log4j.file> old hive key: <hive.log4j.file>  value: <>
Key: <javax.jdo.PersistenceManagerFactoryClass> old hive key: <javax.jdo.PersistenceManagerFactoryClass>  value: <org.datanucleus.api.jdo.JDOPersistenceManagerFactory>
Key: <metastore.materializations.invalidation.impl> old hive key: <hive.metastore.materializations.invalidation.impl>  value: <DEFAULT>
Key: <metastore.materializations.invalidation.clean.frequency> old hive key: <hive.metastore.materializations.invalidation.clean.frequency>  value: <3600s>
Key: <metastore.materializations.invalidation.max.duration> old hive key: <hive.metastore.materializations.invalidation.max.duration>  value: <86400s>
Key: <metastore.runtime.stats.clean.frequency> old hive key: <hive.metastore.runtime.stats.clean.frequency>  value: <3600s>
Key: <metastore.runtime.stats.max.age> old hive key: <hive.metastore.runtime.stats.max.age>  value: <259200s>
Key: <metastore.scheduled.queries.enabled> old hive key: <hive.metastore.scheduled.queries.enabled>  value: <true>
Key: <metastore.scheduled.queries.execution.timeout> old hive key: <hive.metastore.scheduled.queries.progress.timeout>  value: <120s>
Key: <metastore.scheduled.queries.execution.maint.task.frequency> old hive key: <hive.metastore.scheduled.queries.execution.clean.frequency>  value: <60s>
Key: <metastore.scheduled.queries.execution.max.age> old hive key: <hive.metastore.scheduled.queries.execution.max.age>  value: <2592000s>
Key: <metastore.scheduled.queries.autodisable.count> old hive key: <metastore.scheduled.queries.autodisable.count>  value: <0>
Key: <metastore.scheduled.queries.skip.opportunities.after.failures> old hive key: <metastore.scheduled.queries.skip.opportunities.after.failures>  value: <0>
Key: <metastore.metadata.export.location> old hive key: <hive.metadata.export.location>  value: <>
Key: <metastore.max.event.response> old hive key: <hive.metastore.max.event.response>  value: <1000000>
Key: <metastore.client.filter.enabled> old hive key: <hive.metastore.client.filter.enabled>  value: <true>
Key: <metastore.server.filter.enabled> old hive key: <hive.metastore.server.filter.enabled>  value: <false>
Key: <metastore.metadata.move.exported.metadata.to.trash> old hive key: <hive.metadata.move.exported.metadata.to.trash>  value: <true>
Key: <metastore.metrics.enabled> old hive key: <hive.metastore.metrics.enabled>  value: <false>
Key: <metastore.metrics.hadoop2.component> old hive key: <hive.service.metrics.hadoop2.component>  value: <hivemetastore>
Key: <metastore.metrics.file.frequency> old hive key: <hive.service.metrics.file.frequency>  value: <60000ms>
Key: <metastore.metrics.file.location> old hive key: <hive.service.metrics.file.location>  value: </tmp/report.json>
Key: <metastore.metrics.slf4j.frequency> old hive key: <hive.service.metrics.slf4j.frequency>  value: <5m>
Key: <metastore.metrics.slf4j.logging.level> old hive key: <hive.service.metrics.slf4j.logging.level>  value: <INFO>
Key: <metastore.metrics.reporters> old hive key: <metastore.metrics.reporters>  value: <json,jmx>
Key: <metastore.msck.path.validation> old hive key: <hive.msck.path.validation>  value: <throw>
Key: <metastore.msck.repair.batch.size> old hive key: <hive.msck.repair.batch.size>  value: <3000>
Key: <metastore.msck.repair.batch.max.retries> old hive key: <hive.msck.repair.batch.max.retries>  value: <4>
Key: <metastore.msck.repair.enable.partition.retention> old hive key: <metastore.msck.repair.enable.partition.retention>  value: <false>
Key: <metastore.partition.management.task.frequency> old hive key: <metastore.partition.management.task.frequency>  value: <300s>
Key: <metastore.partition.management.table.types> old hive key: <metastore.partition.management.table.types>  value: <MANAGED_TABLE,EXTERNAL_TABLE>
Key: <metastore.partition.management.task.thread.pool.size> old hive key: <metastore.partition.management.task.thread.pool.size>  value: <3>
Key: <metastore.partition.management.catalog.name> old hive key: <metastore.partition.management.catalog.name>  value: <hive>
Key: <metastore.partition.management.database.pattern> old hive key: <metastore.partition.management.database.pattern>  value: <*>
Key: <metastore.partition.management.table.pattern> old hive key: <metastore.partition.management.table.pattern>  value: <*>
Key: <metastore.metadata.transformer.class> old hive key: <metastore.metadata.transformer.class>  value: <org.apache.hadoop.hive.metastore.MetastoreDefaultTransformer>
Key: <metastore.metadata.transformer.translated.to.external.follows.renames> old hive key: <metastore.metadata.transformer.translated.to.external.follows.renames>  value: <true>
Key: <metastore.metadata.transformer.location.mode> old hive key: <metastore.metadata.transformer.location.mode>  value: <force>
Key: <javax.jdo.option.Multithreaded> old hive key: <javax.jdo.option.Multithreaded>  value: <true>
Key: <metastore.max.open.txns> old hive key: <hive.max.open.txns>  value: <100000>
Key: <javax.jdo.option.NonTransactionalRead> old hive key: <javax.jdo.option.NonTransactionalRead>  value: <true>
Key: <metastore.notification.sequence.lock.max.retries> old hive key: <hive.notification.sequence.lock.max.retries>  value: <10>
Key: <metastore.notification.sequence.lock.retry.sleep.interval> old hive key: <hive.notification.sequence.lock.retry.sleep.interval>  value: <10s>
Key: <metastore.orm.retrieveMapNullsAsEmptyStrings> old hive key: <hive.metastore.orm.retrieveMapNullsAsEmptyStrings>  value: <false>
Key: <metastore.partition.name.whitelist.pattern> old hive key: <hive.metastore.partition.name.whitelist.pattern>  value: <>
Key: <metastore.partition.inherit.table.properties> old hive key: <hive.metastore.partition.inherit.table.properties>  value: <>
Key: <metastore.pre.event.listeners> old hive key: <hive.metastore.pre.event.listeners>  value: <>
Key: <metastore.rawstore.impl> old hive key: <hive.metastore.rawstore.impl>  value: <org.apache.hadoop.hive.metastore.ObjectStore>
Key: <metastore.repl.cmrootdir> old hive key: <hive.repl.cmrootdir>  value: </user/${system:user.name}/cmroot/>
Key: <metastore.repl.cm.encryptionzone.rootdir> old hive key: <hive.repl.cm.encryptionzone.rootdir>  value: <.cmroot>
Key: <metastore.repl.cm.nonencryptionzone.rootdir> old hive key: <hive.repl.cm.nonencryptionzone.rootdir>  value: <>
Key: <metastore.repl.cm.retain> old hive key: <hive.repl.cm.retain>  value: <240h>
Key: <metastore.repl.cm.interval> old hive key: <hive.repl.cm.interval>  value: <3600s>
Key: <metastore.repl.cm.enabled> old hive key: <hive.repl.cm.enabled>  value: <false>
Key: <metastore.repl.rootdir> old hive key: <hive.repl.rootdir>  value: </user/${system:user.name}/repl/>
Key: <metastore.repl.copyfile.maxnumfiles> old hive key: <hive.exec.copyfile.maxnumfiles>  value: <1>
Key: <metastore.repl.copyfile.maxsize> old hive key: <hive.exec.copyfile.maxsize>  value: <33554432>
Key: <metastore.repl.event.db.listener.timetolive> old hive key: <hive.repl.event.db.listener.timetolive>  value: <10d>
Key: <metastore.repl.metrics.cache.maxsize> old hive key: <hive.repl.metrics.cache.maxsize>  value: <10000>
Key: <metastore.repl.metrics.update.frequency> old hive key: <hive.repl.metrics.update.frequency>  value: <1m>
Key: <metastore.repl.metrics.cleanup.frequency> old hive key: <hive.metastore.repl.metrics.cleanup.frequency>  value: <1d>
Key: <metastore.repl.metrics.max.age> old hive key: <hive.metastore.repl.metrics.max.age>  value: <7d>
Key: <metastore.repl.txn.timeout> old hive key: <hive.repl.txn.timeout>  value: <11d>
Key: <metastore.schema.info.class> old hive key: <hive.metastore.schema.info.class>  value: <org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo>
Key: <metastore.schema.verification> old hive key: <hive.metastore.schema.verification>  value: <false>
Key: <metastore.schema.verification.record.version> old hive key: <hive.metastore.schema.verification.record.version>  value: <false>
Key: <metastore.serdes.using.metastore.for.schema> old hive key: <hive.serdes.using.metastore.for.schema>  value: <org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe,org.apache.hadoop.hive.serde2.OpenCSVSerde>
Key: <metastore.server.max.message.size> old hive key: <hive.metastore.server.max.message.size>  value: <104857600>
Key: <metastore.server.max.threads> old hive key: <hive.metastore.server.max.threads>  value: <1000>
Key: <metastore.server.min.threads> old hive key: <hive.metastore.server.min.threads>  value: <200>
Key: <metastore.thrift.port> old hive key: <hive.metastore.port>  value: <9083>
Key: <metastore.keystore.path> old hive key: <hive.metastore.keystore.path>  value: <>
Key: <metastore.keystore.type> old hive key: <hive.metastore.keystore.type>  value: <>
Key: <metastore.keymanagerfactory.algorithm> old hive key: <hive.metastore.keymanagerfactory.algorithm>  value: <>
Key: <metastore.ssl.protocol.blacklist> old hive key: <hive.ssl.protocol.blacklist>  value: <SSLv2,SSLv3>
Key: <metastore.truststore.path> old hive key: <hive.metastore.truststore.path>  value: <>
Key: <metastore.truststore.type> old hive key: <hive.metastore.truststore.type>  value: <>
Key: <metastore.trustmanagerfactory.algorithm> old hive key: <hive.metastore.trustmanagerfactory.algorithm>  value: <>
Key: <metastore.stats.autogather> old hive key: <hive.stats.autogather>  value: <true>
Key: <metastore.stats.fetch.bitvector> old hive key: <hive.stats.fetch.bitvector>  value: <false>
Key: <metastore.stats.ndv.tuner> old hive key: <hive.metastore.stats.ndv.tuner>  value: <0.0>
Key: <metastore.stats.ndv.densityfunction> old hive key: <hive.metastore.stats.ndv.densityfunction>  value: <false>
Key: <metastore.stats.default.aggregator> old hive key: <hive.stats.default.aggregator>  value: <>
Key: <metastore.stats.default.publisher> old hive key: <hive.stats.default.publisher>  value: <>
Key: <metastore.stats.auto.analyze> old hive key: <hive.metastore.stats.auto.analyze>  value: <none>
Key: <metastore.stats.auto.analyze.noop.wait> old hive key: <hive.metastore.stats.auto.analyze.noop.wait>  value: <5m>
Key: <metastore.stats.auto.analyze.worker.count> old hive key: <hive.metastore.stats.auto.analyze.worker.count>  value: <1>
Key: <metastore.storage.schema.reader.impl> old hive key: <metastore.storage.schema.reader.impl>  value: <org.apache.hadoop.hive.metastore.DefaultStorageSchemaReader>
Key: <datanucleus.storeManagerType> old hive key: <datanucleus.storeManagerType>  value: <rdbms>
Key: <metastore.strict.managed.tables> old hive key: <hive.strict.managed.tables>  value: <false>
Key: <metastore.support.special.characters.tablename> old hive key: <hive.support.special.characters.tablename>  value: <true>
Key: <metastore.task.threads.always> old hive key: <metastore.task.threads.always>  value: <org.apache.hadoop.hive.metastore.events.EventCleanerTask,org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask,org.apache.hadoop.hive.metastore.metrics.AcidMetricService,org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask,org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask,org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask>
Key: <metastore.task.threads.remote> old hive key: <metastore.task.threads.remote>  value: <org.apache.hadoop.hive.metastore.txn.AcidHouseKeeperService,org.apache.hadoop.hive.metastore.txn.AcidTxnCleanerService,org.apache.hadoop.hive.metastore.txn.AcidOpenTxnsCounterService,org.apache.hadoop.hive.metastore.MaterializationsRebuildLockCleanerTask,org.apache.hadoop.hive.metastore.PartitionManagementTask>
Key: <metastore.server.tcp.keepalive> old hive key: <hive.metastore.server.tcp.keepalive>  value: <true>
Key: <metastore.thread.pool.size> old hive key: <no.such>  value: <10>
Key: <metastore.connect.retries> old hive key: <hive.metastore.connect.retries>  value: <3>
Key: <metastore.failure.retries> old hive key: <hive.metastore.failure.retries>  value: <1>
Key: <metastore.thrift.bind.host> old hive key: <hive.metastore.thrift.bind.host>  value: <>
Key: <metastore.thrift.uris> old hive key: <hive.metastore.uris>  value: <>
Key: <metastore.service.discovery.mode> old hive key: <hive.metastore.service.discovery.mode>  value: <>
Key: <metastore.zookeeper.kerberos.enabled> old hive key: <hive.zookeeper.kerberos.enabled>  value: <true>
Key: <metastore.zookeeper.client.port> old hive key: <hive.zookeeper.client.port>  value: <2181>
Key: <metastore.zookeeper.session.timeout> old hive key: <hive.zookeeper.session.timeout>  value: <120000ms>
Key: <metastore.zookeeper.connection.timeout> old hive key: <hive.zookeeper.connection.timeout>  value: <15s>
Key: <metastore.zookeeper.namespace> old hive key: <hive.zookeeper.namespace>  value: <hive_metastore>
Key: <metastore.zookeeper.connection.max.retries> old hive key: <hive.zookeeper.connection.max.retries>  value: <3>
Key: <metastore.zookeeper.connection.basesleeptime> old hive key: <hive.zookeeper.connection.basesleeptime>  value: <1000ms>
Key: <metastore.zookeeper.ssl.client.enable> old hive key: <hive.zookeeper.ssl.client.enable>  value: <false>
Key: <metastore.zookeeper.ssl.keystore.location> old hive key: <hive.zookeeper.ssl.keystore.location>  value: <>
Key: <metastore.zookeeper.ssl.truststore.location> old hive key: <hive.zookeeper.ssl.truststore.location>  value: <>
Key: <metastore.thrift.uri.selection> old hive key: <hive.metastore.uri.selection>  value: <RANDOM>
Key: <metastore.token.signature> old hive key: <hive.metastore.token.signature>  value: <>
Key: <metastore.cache.can.use.event> old hive key: <hive.metastore.cache.can.use.event>  value: <false>
Key: <metastore.transactional.event.listeners> old hive key: <hive.metastore.transactional.event.listeners>  value: <>
Key: <metastore.try.direct.sql> old hive key: <hive.metastore.try.direct.sql>  value: <true>
Key: <metastore.try.direct.sql.ddl> old hive key: <hive.metastore.try.direct.sql.ddl>  value: <true>
Key: <metastore.txn.max.open.batch> old hive key: <hive.txn.max.open.batch>  value: <1000>
Key: <metastore.txn.retryable.sqlex.regex> old hive key: <hive.txn.retryable.sqlex.regex>  value: <>
Key: <metastore.txn.store.impl> old hive key: <hive.metastore.txn.store.impl>  value: <org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler>
Key: <metastore.txn.timeout> old hive key: <hive.txn.timeout>  value: <300s>
Key: <metastore.txn.opentxn.timeout> old hive key: <hive.txn.opentxn.timeout>  value: <1000ms>
Key: <metastore.txn.use.minhistorylevel> old hive key: <hive.txn.use.minhistorylevel>  value: <true>
Key: <metastore.uri.resolver> old hive key: <hive.metastore.uri.resolver>  value: <>
Key: <metastore.users.in.admin.role> old hive key: <hive.users.in.admin.role>  value: <>
Key: <metastore.use.SSL> old hive key: <hive.metastore.use.SSL>  value: <false>
Key: <metastore.sasl.enabled> old hive key: <hive.metastore.sasl.enabled>  value: <false>
Key: <metastore.client.auth.mode> old hive key: <hive.metastore.client.auth.mode>  value: <NOSASL>
Key: <metastore.client.plain.username> old hive key: <hive.metastore.client.plain.username>  value: <>
Key: <metastore.authentication.config.username> old hive key: <hive.metastore.authentication.config.username>  value: <>
Key: <metastore.authentication.config.password> old hive key: <hive.metastore.authentication.config.password>  value: <>
Key: <metastore.thrift.framed.transport.enabled> old hive key: <hive.metastore.thrift.framed.transport.enabled>  value: <false>
Key: <metastore.thrift.compact.protocol.enabled> old hive key: <hive.metastore.thrift.compact.protocol.enabled>  value: <false>
Key: <datanucleus.schema.validateColumns> old hive key: <datanucleus.schema.validateColumns>  value: <false>
Key: <datanucleus.schema.validateConstraints> old hive key: <datanucleus.schema.validateConstraints>  value: <false>
Key: <datanucleus.schema.validateTables> old hive key: <datanucleus.schema.validateTables>  value: <false>
Key: <metastore.warehouse.dir> old hive key: <hive.metastore.warehouse.dir>  value: <file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse>
Key: <metastore.warehouse.external.dir> old hive key: <hive.metastore.warehouse.external.dir>  value: <file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/external>
Key: <metastore.wm.default.pool.size> old hive key: <hive.metastore.wm.default.pool.size>  value: <4>
Key: <metastore.rawstore.batch.size> old hive key: <metastore.rawstore.batch.size>  value: <-1>
Key: <hive.metastore.runworker.in> old hive key: <hive.metastore.runworker.in>  value: <metastore>
Key: <hive.in.test> old hive key: <hive.in.test>  value: <false>
Key: <hive.in.tez.test> old hive key: <hive.in.tez.test>  value: <false>
Key: <hive.in.iceberg.test> old hive key: <hive.in.iceberg.test>  value: <false>
Key: <hive.security.authorization.manager> old hive key: <hive.security.authorization.manager>  value: <org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory>
Key: <hive.security.metastore.authenticator.manager> old hive key: <hive.security.metastore.authenticator.manager>  value: <org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator>
Key: <hive.security.metastore.authorization.auth.reads> old hive key: <hive.security.metastore.authorization.auth.reads>  value: <true>
Key: <hive.txn.manager> old hive key: <hive.txn.manager>  value: <org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager>
Key: <hive.support.concurrency> old hive key: <hive.support.concurrency>  value: <false>
Key: <hive.txn.stats.enabled> old hive key: <hive.txn.stats.enabled>  value: <true>
Key: <metastore.use.custom.database.product> old hive key: <hive.metastore.use.custom.database.product>  value: <false>
Key: <metastore.custom.database.product.classname> old hive key: <hive.metastore.custom.database.product.classname>  value: <none>
Key: <hive.blobstore.supported.schemes> old hive key: <hive.blobstore.supported.schemes>  value: <s3,s3a,s3n>
Key: <hive.service.metrics.codahale.reporter.classes> old hive key: <hive.service.metrics.codahale.reporter.classes>  value: <>
Key: <hive.service.metrics.reporter> old hive key: <hive.service.metrics.reporter>  value: <>
Key: <metastore.dbaccess.ssl.properties> old hive key: <hive.metastore.dbaccess.ssl.properties>  value: <>
Key: <metastore.num.striped.table.locks> old hive key: <hive.metastore.num.striped.table.locks>  value: <32>
Key: <metastore.colstats.retain.on.column.removal> old hive key: <hive.metastore.colstats.retain.on.column.removal>  value: <true>
Key: <test.str> old hive key: <hive.test.str>  value: <defaultval>
Key: <test.str.set> old hive key: <hive.test.str.set>  value: <a>
Key: <test.str.list> old hive key: <hive.test.str.list>  value: <a,b,c>
Key: <test.long> old hive key: <hive.test.long>  value: <42>
Key: <test.double> old hive key: <hive.test.double>  value: <3.141592653589793>
Key: <test.time> old hive key: <hive.test.time>  value: <1s>
Key: <test.deprecated> old hive key: <hive.test.deprecated>  value: <0>
Key: <test.time.validator.inclusive> old hive key: <hive.test.time.validator.inclusive>  value: <1s>
Key: <test.time.validator.exclusive> old hive key: <hive.test.time.validator.exclusive>  value: <1s>
Key: <test.bool> old hive key: <hive.test.bool>  value: <true>
Key: <test.class> old hive key: <hive.test.class>  value: <>
Finished MetastoreConf object.

[INFO ] 2024-04-23 23:33:08.791 [main] MetastoreConf - Unable to find config file: hive-site.xml
[INFO ] 2024-04-23 23:33:08.792 [main] MetastoreConf - Unable to find config file: hivemetastore-site.xml
[INFO ] 2024-04-23 23:33:08.792 [main] MetastoreConf - Unable to find config file: metastore-site.xml
[DEBUG] 2024-04-23 23:33:08.792 [main] MetastoreConf - Setting conf value datanucleus.schema.autoCreateAll using value true
[DEBUG] 2024-04-23 23:33:08.799 [main] MetastoreConf - Setting conf value javax.jdo.option.ConnectionURL using value jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true
[DEBUG] 2024-04-23 23:33:08.799 [main] MetastoreConf - Setting conf value metastore.schema.verification using value false
[DEBUG] 2024-04-23 23:33:08.799 [main] MetastoreConf - Setting conf value metastore.warehouse.dir using value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse
[DEBUG] 2024-04-23 23:33:08.799 [main] MetastoreConf - Picking up system property hive.metastore.warehouse.external.dir with value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/external
[INFO ] 2024-04-23 23:33:08.802 [main] MetastoreConf - Unable to find config file: hive-site.xml
[INFO ] 2024-04-23 23:33:08.802 [main] MetastoreConf - Unable to find config file: hivemetastore-site.xml
[INFO ] 2024-04-23 23:33:08.803 [main] MetastoreConf - Unable to find config file: metastore-site.xml
[DEBUG] 2024-04-23 23:33:08.803 [main] MetastoreConf - Setting conf value datanucleus.schema.autoCreateAll using value true
[DEBUG] 2024-04-23 23:33:08.807 [main] MetastoreConf - Setting conf value javax.jdo.option.ConnectionURL using value jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true
[DEBUG] 2024-04-23 23:33:08.807 [main] MetastoreConf - Setting conf value metastore.schema.verification using value false
[DEBUG] 2024-04-23 23:33:08.807 [main] MetastoreConf - Setting conf value metastore.warehouse.dir using value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse
[DEBUG] 2024-04-23 23:33:08.807 [main] MetastoreConf - Picking up system property hive.metastore.warehouse.external.dir with value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/external
al

Check value null from jpox.properties with LOG
[DEBUG] 2024-04-23 23:43:08.654 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.transactionIsolation value null from jpox.properties with read-committed
[DEBUG] 2024-04-23 23:43:08.654 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.rdbms.useLegacyNativeValueStrategy value null from jpox.properties with true
[DEBUG] 2024-04-23 23:43:08.654 [Thread-2] PersistenceManagerProvider - Overriding javax.jdo.option.DetachAllOnCommit value null from jpox.properties with true
[DEBUG] 2024-04-23 23:43:08.654 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.identifierFactory value null from jpox.properties with datanucleus1
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding javax.jdo.PersistenceManagerFactoryClass value null from jpox.properties with org.datanucleus.api.jdo.JDOPersistenceManagerFactory
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding javax.jdo.option.Multithreaded value null from jpox.properties with true
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding javax.jdo.option.NonTransactionalRead value null from jpox.properties with true
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.storeManagerType value null from jpox.properties with rdbms
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.schema.validateColumns value null from jpox.properties with false
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.schema.validateConstraints value null from jpox.properties with false
[DEBUG] 2024-04-23 23:43:08.655 [Thread-2] PersistenceManagerProvider - Overriding datanucleus.schema.validateTables value null from jpox.properties with false
[DEBUG] 2024-04-23 23:43:08.662 [Thread-2] Shell - Failed to detect a valid hadoop home directory
java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:469) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.conf.Configuration.getStringCollection(Configuration.java:2170) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:65) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:2340) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.conf.Configuration.getPassword(Configuration.java:2278) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.conf.MetastoreConf.getPassword(MetastoreConf.java:2261) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.PersistenceManagerProvider.lambda$getDataSourceProps$1(PersistenceManagerProvider.java:457) ~[classes/:?]
	at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131) [guava-19.0.jar:?]
	at org.apache.hadoop.hive.metastore.PersistenceManagerProvider.getDataSourceProps(PersistenceManagerProvider.java:462) [classes/:?]
	at org.apache.hadoop.hive.metastore.PersistenceManagerProvider.updatePmfProperties(PersistenceManagerProvider.java:152) [classes/:?]
	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:357) [classes/:?]
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) [classes/:?]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.newRawStoreForConf(HMSHandler.java:727) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.getMSForConf(HMSHandler.java:695) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.getMS(HMSHandler.java:689) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.createDefaultDB(HMSHandler.java:783) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.init(HMSHandler.java:431) [classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:115) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:110) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:395) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:343) [classes/:?]
	at org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils$3.run(MetaStoreServerUtils.java:804) [classes/:?]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
[DEBUG] 2024-04-23 23:43:08.673 [Thread-2] Shell - setsid exited with exit code 0
[DEBUG] 2024-04-23 23:43:08.673 [Thread-2] PersistenceManagerProvider - datanucleus.schema.autoCreateAll = true
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.schema.validateTables = false
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.rdbms.useLegacyNativeValueStrategy = true
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.schema.validateColumns = false
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.connectionPool.maxPoolSize = 10
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.autoStartMechanismMode = ignored
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.rdbms.initializeColumnInfo = NONE
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - javax.jdo.option.Multithreaded = true
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.identifierFactory = datanucleus1
[DEBUG] 2024-04-23 23:43:08.674 [Thread-2] PersistenceManagerProvider - datanucleus.transactionIsolation = read-committed
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.option.ConnectionURL = jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.option.DetachAllOnCommit = true
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.option.NonTransactionalRead = true
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - datanucleus.schema.validateConstraints = false
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.EmbeddedDriver
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.option.ConnectionUserName = APP
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - datanucleus.cache.level2 = false
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - datanucleus.plugin.pluginRegistryBundleCheck = LOG
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - datanucleus.cache.level2.type = none
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - javax.jdo.PersistenceManagerFactoryClass = org.datanucleus.api.jdo.JDOPersistenceManagerFactory
[DEBUG] 2024-04-23 23:43:08.675 [Thread-2] PersistenceManagerProvider - datanucleus.storeManagerType = rdbms
[DEBUG] 2024-04-23 23:43:08.676 [Thread-2] PersistenceManagerProvider - datanucleus.connectionPoolingType = HikariCP
[INFO ] 2024-04-23 23:43:08.676 [Thread-2] PersistenceManagerProvider - Updating the pmf due to property change
[INFO ] 2024-04-23 23:43:08.676 [Thread-2] PersistenceManagerProvider - Current pmf properties are uninitialized
[DEBUG] 2024-04-23 23:43:08.685 [Thread-2] HikariCPDataSourceProvider - Creating Hikari connection pool for the MetaStore
[WARN ] 2024-04-23 23:43:08.694 [Thread-2] HikariConfig - HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
[DEBUG] 2024-04-23 23:43:08.695 [Thread-2] HikariConfig - HikariPool-1 - configuration:
[DEBUG] 2024-04-23 23:43:08.696 [Thread-2] HikariConfig - allowPoolSuspension.............false
[DEBUG] 2024-04-23 23:43:08.696 [Thread-2] HikariConfig - autoCommit......................true
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - catalog.........................none
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - connectionInitSql...............none
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - connectionTestQuery.............none
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - connectionTimeout...............30000
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - dataSource......................none
[DEBUG] 2024-04-23 23:43:08.697 [Thread-2] HikariConfig - dataSourceClassName.............none
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - dataSourceJNDI..................none
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - dataSourceProperties............{password=<masked>}
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - driverClassName.................none
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - healthCheckProperties...........{}
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - healthCheckRegistry.............none
[DEBUG] 2024-04-23 23:43:08.698 [Thread-2] HikariConfig - idleTimeout.....................600000
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - initializationFailFast..........true
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - initializationFailTimeout.......1
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - isolateInternalQueries..........false
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - jdbc4ConnectionTest.............false
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - jdbcUrl........................."jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true"
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - leakDetectionThreshold..........0
[DEBUG] 2024-04-23 23:43:08.699 [Thread-2] HikariConfig - maxLifetime.....................1800000
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - maximumPoolSize.................10
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - metricRegistry..................none
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - metricsTrackerFactory...........none
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - minimumIdle.....................10
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - password........................<masked>
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - poolName........................"HikariPool-1"
[DEBUG] 2024-04-23 23:43:08.700 [Thread-2] HikariConfig - readOnly........................false
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - registerMbeans..................false
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - scheduledExecutor...............none
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - scheduledExecutorService........internal
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - threadFactory...................internal
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - transactionIsolation............default
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - username........................"APP"
[DEBUG] 2024-04-23 23:43:08.701 [Thread-2] HikariConfig - validationTimeout...............5000
[INFO ] 2024-04-23 23:43:08.703 [Thread-2] HikariDataSource - HikariPool-1 - Starting...
[INFO ] 2024-04-23 23:43:09.142 [Thread-2] PoolBase - HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
[DEBUG] 2024-04-23 23:43:09.143 [Thread-2] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[INFO ] 2024-04-23 23:43:09.145 [Thread-2] HikariDataSource - HikariPool-1 - Start completed.
log4j: Trying to find [log4j.xml] using context classloader sun.misc.Launcher$AppClassLoader@330bedb4.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader sun.misc.Launcher$AppClassLoader@330bedb4.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (DataNucleus.General).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[DEBUG] 2024-04-23 23:43:09.245 [HikariPool-1 housekeeper] HikariPool - HikariPool-1 - Pool stats (total=1, active=0, idle=1, waiting=0)
[DEBUG] 2024-04-23 23:43:09.249 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@750036954 (XID = 168), (SESSIONID = 3), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.252 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@1837739489 (XID = 170), (SESSIONID = 5), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.253 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@1546561233 (XID = 172), (SESSIONID = 7), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.255 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@229003950 (XID = 174), (SESSIONID = 9), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.257 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@462117218 (XID = 176), (SESSIONID = 11), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.258 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@166210465 (XID = 178), (SESSIONID = 13), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.260 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@704443227 (XID = 180), (SESSIONID = 15), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.262 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@1989496942 (XID = 182), (SESSIONID = 17), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.264 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - Added connection org.apache.derby.impl.jdbc.EmbedConnection@1073529862 (XID = 184), (SESSIONID = 19), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.264 [HikariPool-1 connection adder] HikariPool - HikariPool-1 - After adding stats (total=10, active=0, idle=10, waiting=0)
[INFO ] 2024-04-23 23:43:09.767 [Thread-2] PersistenceManagerProvider - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
[INFO ] 2024-04-23 23:43:09.767 [Thread-2] ObjectStore - RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5169d290, with PersistenceManager: null will be shutdown
[DEBUG] 2024-04-23 23:43:09.767 [Thread-2] ObjectStore - ObjectStore, initialize called
[INFO ] 2024-04-23 23:43:09.786 [Thread-2] ObjectStore - RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5169d290, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fed9b72 created in the thread with id: 13
[DEBUG] 2024-04-23 23:43:09.794 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.795 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.796 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[WARN ] 2024-04-23 23:43:09.827 [Thread-2] MetaStoreDirectSql - Self-test query [select "DB_ID" from "DBS"] failed; direct SQL is disabled
javax.jdo.JDODataStoreException: Error executing SQL query "select "DB_ID" from "DBS"".
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542) ~[datanucleus-api-jdo-5.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:456) ~[datanucleus-api-jdo-5.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:263) ~[datanucleus-api-jdo-5.2.4.jar:?]
	at org.apache.hadoop.hive.metastore.QueryWrapper.execute(QueryWrapper.java:112) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.runTestQuery(MetaStoreDirectSql.java:326) [classes/:?]
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.<init>(MetaStoreDirectSql.java:214) [classes/:?]
	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:415) [classes/:?]
	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:370) [classes/:?]
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:59) [classes/:?]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.newRawStoreForConf(HMSHandler.java:727) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.getMSForConf(HMSHandler.java:695) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.getMS(HMSHandler.java:689) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.createDefaultDB(HMSHandler.java:783) [classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.init(HMSHandler.java:431) [classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:80) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:115) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:110) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:395) [classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:343) [classes/:?]
	at org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils$3.run(MetaStoreServerUtils.java:804) [classes/:?]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
Caused by: java.sql.SQLSyntaxErrorException: Table/View 'DBS' does not exist.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement42.<init>(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.jdbc.Driver42.newEmbedPreparedStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at com.zaxxer.hikari.pool.ProxyConnection.prepareStatement(ProxyConnection.java:325) ~[HikariCP-2.6.1.jar:?]
	at com.zaxxer.hikari.pool.HikariProxyConnection.prepareStatement(HikariProxyConnection.java) ~[HikariCP-2.6.1.jar:?]
	at org.datanucleus.store.rdbms.SQLController.getStatementForQuery(SQLController.java:349) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getPreparedStatementForQuery(RDBMSQueryUtils.java:224) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.performExecute(SQLQuery.java:652) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1975) ~[datanucleus-core-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.executeWithArray(SQLQuery.java:818) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.query.Query.execute(Query.java:1846) ~[datanucleus-core-5.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:439) ~[datanucleus-api-jdo-5.2.4.jar:?]
	... 29 more
Caused by: org.apache.derby.iapi.error.StandardException: Table/View 'DBS' does not exist.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.FromBaseTable.bindTableDescriptor(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.FromBaseTable.bindNonVTITables(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.FromList.bindTables(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.SelectNode.bindNonVTITables(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.DMLStatementNode.bindTables(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.DMLStatementNode.bind(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.compile.CursorNode.bindStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement42.<init>(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.jdbc.Driver42.newEmbedPreparedStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) ~[derby-10.14.1.0.jar:?]
	at com.zaxxer.hikari.pool.ProxyConnection.prepareStatement(ProxyConnection.java:325) ~[HikariCP-2.6.1.jar:?]
	at com.zaxxer.hikari.pool.HikariProxyConnection.prepareStatement(HikariProxyConnection.java) ~[HikariCP-2.6.1.jar:?]
	at org.datanucleus.store.rdbms.SQLController.getStatementForQuery(SQLController.java:349) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getPreparedStatementForQuery(RDBMSQueryUtils.java:224) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.performExecute(SQLQuery.java:652) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1975) ~[datanucleus-core-5.2.4.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.executeWithArray(SQLQuery.java:818) ~[datanucleus-rdbms-5.2.4.jar:?]
	at org.datanucleus.store.query.Query.execute(Query.java:1846) ~[datanucleus-core-5.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:439) ~[datanucleus-api-jdo-5.2.4.jar:?]
	... 29 more
[DEBUG] 2024-04-23 23:43:09.829 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:09.830 [Thread-2] ObjectStore - Initialized ObjectStore
[DEBUG] 2024-04-23 23:43:09.908 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:10.456 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit, isolation) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.506 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:10.506 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.508 [Thread-2] MetaStoreSchemaInfoFactory - HIVE_HOME is not set. Using current directory instead
[WARN ] 2024-04-23 23:43:10.512 [Thread-2] ObjectStore - Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
[WARN ] 2024-04-23 23:43:10.513 [Thread-2] ObjectStore - setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
[INFO ] 2024-04-23 23:43:10.513 [Thread-2] HMSHandler - Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5169d290 from thread id: 13
[DEBUG] 2024-04-23 23:43:10.513 [Thread-2] ObjectStore - Fetching catalog hive
[DEBUG] 2024-04-23 23:43:10.513 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:10.549 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit, isolation) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.558 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:10.558 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.597 [Thread-2] MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, valueName=Time, about=)
[DEBUG] 2024-04-23 23:43:10.601 [Thread-2] MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, value=[GetGroups], sampleName=Ops, about=, type=DEFAULT, valueName=Time)
[DEBUG] 2024-04-23 23:43:10.602 [Thread-2] MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, type=DEFAULT, always=false, valueName=Time, sampleName=Ops, value=[Renewal failures since last successful login])
[DEBUG] 2024-04-23 23:43:10.602 [Thread-2] MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, valueName=Time, value=[Renewal failures since startup], type=DEFAULT, sampleName=Ops)
[DEBUG] 2024-04-23 23:43:10.602 [Thread-2] MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, valueName=Time, about=)
[DEBUG] 2024-04-23 23:43:10.603 [Thread-2] MetricsSystemImpl - UgiMetrics, User and group related metrics
[DEBUG] 2024-04-23 23:43:10.615 [Thread-2] SecurityUtil - Setting hadoop.security.token.service.use_ip to true
[DEBUG] 2024-04-23 23:43:10.627 [Thread-2] Groups -  Creating new Groups object
[DEBUG] 2024-04-23 23:43:10.628 [Thread-2] NativeCodeLoader - Trying to load the custom-built native-hadoop library...
[DEBUG] 2024-04-23 23:43:10.628 [Thread-2] NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
[DEBUG] 2024-04-23 23:43:10.628 [Thread-2] NativeCodeLoader - java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[WARN ] 2024-04-23 23:43:10.628 [Thread-2] NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[DEBUG] 2024-04-23 23:43:10.628 [Thread-2] PerformanceAdvisory - Falling back to shell based
[DEBUG] 2024-04-23 23:43:10.629 [Thread-2] JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
[DEBUG] 2024-04-23 23:43:10.641 [Thread-2] Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[DEBUG] 2024-04-23 23:43:10.644 [Thread-2] UserGroupInformation - hadoop login
[DEBUG] 2024-04-23 23:43:10.644 [Thread-2] UserGroupInformation - hadoop login commit
[DEBUG] 2024-04-23 23:43:10.645 [Thread-2] UserGroupInformation - using local user:UnixPrincipal: alex
[DEBUG] 2024-04-23 23:43:10.645 [Thread-2] UserGroupInformation - Using user: "UnixPrincipal: alex" with name alex
[DEBUG] 2024-04-23 23:43:10.646 [Thread-2] UserGroupInformation - User entry: "alex"
[DEBUG] 2024-04-23 23:43:10.646 [Thread-2] UserGroupInformation - UGI loginUser:alex (auth:SIMPLE)
[DEBUG] 2024-04-23 23:43:10.680 [Thread-2] FileSystem - Loading filesystems
[DEBUG] 2024-04-23 23:43:10.686 [Thread-2] FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.689 [Thread-2] FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.690 [Thread-2] FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.691 [Thread-2] FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.692 [Thread-2] FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.698 [Thread-2] FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.816 [Thread-2] FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.816 [Thread-2] FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar
[DEBUG] 2024-04-23 23:43:10.817 [Thread-2] FileSystem - Looking for FS supporting file
[DEBUG] 2024-04-23 23:43:10.817 [Thread-2] FileSystem - looking for configuration option fs.file.impl
[DEBUG] 2024-04-23 23:43:10.826 [Thread-2] FileSystem - Looking in service filesystems for implementation class
[DEBUG] 2024-04-23 23:43:10.826 [Thread-2] FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
[DEBUG] 2024-04-23 23:43:10.831 [Thread-2] ObjectStore - Creating catalog Catalog(name:hive, description:Default catalog, for Hive, locationUri:file:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse, createTime:1713912190)
[DEBUG] 2024-04-23 23:43:10.831 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:10.892 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.902 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:10.906 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.916 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:10.916 [Thread-2] ObjectStore - Open transaction: count = 2, isActive = true
[DEBUG] 2024-04-23 23:43:10.916 [Thread-2] ObjectStore - Open transaction: count = 3, isActive = true
[DEBUG] 2024-04-23 23:43:10.971 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit, isolation) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.977 [Thread-2] ObjectStore - Commit transaction: count = 2, isactive true
[DEBUG] 2024-04-23 23:43:10.977 [Thread-2] ObjectStore - Rollback transaction, isActive: true
[DEBUG] 2024-04-23 23:43:10.978 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:10.978 [Thread-2] ObjectStore - rolling back transaction: no open transactions: 0
[INFO ] 2024-04-23 23:43:10.978 [Thread-2] HMSHandler - Started creating a default database with name: default
[DEBUG] 2024-04-23 23:43:10.978 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:10.994 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.006 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:11.008 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.021 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[INFO ] 2024-04-23 23:43:11.022 [Thread-2] HMSHandler - Successfully created a default database with name: default
[DEBUG] 2024-04-23 23:43:11.022 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:11.022 [Thread-2] ObjectStore - Open transaction: count = 2, isActive = true
[DEBUG] 2024-04-23 23:43:11.045 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit, isolation) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.051 [Thread-2] ObjectStore - Commit transaction: count = 1, isactive true
[DEBUG] 2024-04-23 23:43:11.060 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@750036954 (XID = 168), (SESSIONID = 3), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.063 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:11.065 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[INFO ] 2024-04-23 23:43:11.065 [Thread-2] HMSHandler - Added admin role in metastore
[DEBUG] 2024-04-23 23:43:11.066 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:11.066 [Thread-2] ObjectStore - Open transaction: count = 2, isActive = true
[DEBUG] 2024-04-23 23:43:11.067 [Thread-2] ObjectStore - Commit transaction: count = 1, isactive true
[DEBUG] 2024-04-23 23:43:11.068 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:11.069 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[INFO ] 2024-04-23 23:43:11.070 [Thread-2] HMSHandler - Added public role in metastore
[DEBUG] 2024-04-23 23:43:11.074 [Thread-2] ObjectStore - Open transaction: count = 1, isActive = true
[DEBUG] 2024-04-23 23:43:11.076 [Thread-2] ObjectStore - Open transaction: count = 2, isActive = true
[DEBUG] 2024-04-23 23:43:11.081 [Thread-2] ObjectStore - Commit transaction: count = 1, isactive true
[DEBUG] 2024-04-23 23:43:11.084 [Thread-2] ObjectStore - Open transaction: count = 2, isActive = true
[DEBUG] 2024-04-23 23:43:11.122 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit, isolation) on connection org.apache.derby.impl.jdbc.EmbedConnection@750036954 (XID = 168), (SESSIONID = 3), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.130 [Thread-2] ObjectStore - Commit transaction: count = 1, isactive true
[DEBUG] 2024-04-23 23:43:11.140 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@750036954 (XID = 168), (SESSIONID = 3), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[DEBUG] 2024-04-23 23:43:11.144 [Thread-2] ObjectStore - Commit transaction: count = 0, isactive true
[DEBUG] 2024-04-23 23:43:11.145 [Thread-2] PoolBase - HikariPool-1 - Reset (autoCommit) on connection org.apache.derby.impl.jdbc.EmbedConnection@478850993 (XID = 166), (SESSIONID = 1), (DATABASE = memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db), (DRDAID = null) 
[INFO ] 2024-04-23 23:43:11.146 [Thread-2] HMSHandler - No user is added in admin role, since config is empty
[INFO ] 2024-04-23 23:43:11.150 [Thread-2] HMSHandler - HMS server filtering is disabled by configuration
[DEBUG] 2024-04-23 23:43:11.152 [Thread-2] PerfLogger - </PERFLOG method=init start=1713912188558 end=1713912191152 duration=2594 from=org.apache.hadoop.hive.metastore.RetryingHMSHandler threadId=0 retryCount=0 error=false>
[INFO ] 2024-04-23 23:43:11.424 [Thread-2] HiveMetaStore - Starting DB backed MetaStore Server with SetUGI enabled
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - Started the new metaserver on port [34353]...
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - Options.minWorkerThreads = 200
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - Options.maxWorkerThreads = 1000
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - TCP keepalive = true
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - Enable SSL = false
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - Compaction HMS parameters:
[INFO ] 2024-04-23 23:43:11.427 [Thread-2] HiveMetaStore - metastore.compactor.initiator.on = false
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.worker.threads = 0
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - hive.metastore.runworker.in = metastore
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] deprecation - metastore.compactor.history.retention.did.not.initiate is deprecated. Instead, use metastore.compactor.history.retention.attempted
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] deprecation - hive.compactor.history.retention.did.not.initiate is deprecated. Instead, use hive.compactor.history.retention.attempted
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.history.retention.attempted = 2
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.history.retention.failed = 3
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.history.retention.succeeded = 3
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.initiator.failed.compacts.threshold = 2
[INFO ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - metastore.compactor.enable.stats.compression
[WARN ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - Compactor Initiator is turned Off. Automatic compaction will not be triggered.
[WARN ] 2024-04-23 23:43:11.428 [Thread-2] HiveMetaStore - Invalid number of Compactor Worker threads(0) on HMS
[INFO ] 2024-04-23 23:43:11.429 [Thread-2] HiveMetaStore - Direct SQL optimization = true
[INFO ] 2024-04-23 23:43:11.432 [main] MetastoreConf - Unable to find config file: hive-site.xml
[INFO ] 2024-04-23 23:43:11.432 [main] MetastoreConf - Unable to find config file: hivemetastore-site.xml
[INFO ] 2024-04-23 23:43:11.432 [main] MetastoreConf - Unable to find config file: metastore-site.xml
[DEBUG] 2024-04-23 23:43:11.432 [main] MetastoreConf - Setting conf value datanucleus.schema.autoCreateAll using value true
[DEBUG] 2024-04-23 23:43:11.436 [TThreadPoolServer WorkerProcess-%d] TThreadPoolServer - Error processing request
org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:181) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.security.TFilterTransport.readAll(TFilterTransport.java:63) ~[classes/:?]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:463) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:361) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:244) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[classes/:?]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248) [libthrift-0.14.1.jar:0.14.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
[DEBUG] 2024-04-23 23:43:11.437 [TThreadPoolServer WorkerProcess-%d] HMSHandler - 1: Done cleaning up thread local RawStore
[INFO ] 2024-04-23 23:43:11.437 [TThreadPoolServer WorkerProcess-%d] audit - ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
[DEBUG] 2024-04-23 23:43:11.443 [main] MetastoreConf - Setting conf value javax.jdo.option.ConnectionURL using value jdbc:derby:memory:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/tmp/junit_metastore_db;create=true
[DEBUG] 2024-04-23 23:43:11.443 [main] MetastoreConf - Setting conf value metastore.schema.verification using value false
[DEBUG] 2024-04-23 23:43:11.443 [main] MetastoreConf - Setting conf value metastore.warehouse.dir using value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/warehouse
[DEBUG] 2024-04-23 23:43:11.443 [main] MetastoreConf - Picking up system property hive.metastore.warehouse.external.dir with value file:///home/alex/Repositories/hive/standalone-metastore/metastore-server/target/external
