SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,099575 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@367ffa75]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@367ffa75) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@66d18979
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,021539 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(header="null", charset="null", Configuration(HiveLog4j2Test), PatternSelector=null, footer="null", alwaysWriteExceptions="null", disableAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", noConsoleNoAnsi="null", Replace=null)
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", name="console", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(header="null", charset="null", Replace=null, alwaysWriteExceptions="null", PatternSelector=null, footer="null", Configuration(HiveLog4j2Test), disableAnsi="null", noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(maxRandomDelay="null", interval="1", modulate="true")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(compressionLevel="null", ={}, stopCustomActionsOnError="null", Configuration(HiveLog4j2Test), max="30", tempCompressedFilePattern="null", fileIndex="null", min="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(filePattern="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log.%d{yyyy-MM-dd}", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), fileGroup="null", append="null", advertise="null", filePermissions="null", advertiseURI="null", fileOwner="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), fileName="/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log", bufferSize="null", bufferedIo="null", immediateFlush="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), name="DRFA", ignoreExceptions="null", Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log seek to 746789691
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T11:40:25.311-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-11:40:26.982, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-11:40:26.983, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@6e509ffa OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@475e586c...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@475e586c OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@1f53a5dc
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@367ffa75
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@367ffa75) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@367ffa75] started OK.
2024-04-24T11:40:27,089  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T11:40:27,478  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T11:40:27,540  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:27,540  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:27,541  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:27,541  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:27,541  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:27,541  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:27,541  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:27,542  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:27,542  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:27,542  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:27,543  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
Hive Session ID = 5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388
2024-04-24T11:40:27,696  INFO [main] SessionState: Hive Session ID = 5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T11:40:27,708  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@16423501.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@16423501.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T11:40:27,891  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388
2024-04-24T11:40:27,894  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/localscratchdir/5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388
2024-04-24T11:40:27,897  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/scratchdir/alex/5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388/_tmp_space.db
2024-04-24T11:40:27,953  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:29,298  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,304  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,304  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,306  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,306  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,309  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,312  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T11:40:29,422  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:40:29,633  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:40:29,660  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:40:29,665  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T11:40:29,665  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T11:40:29,680  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:40:29,685  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T11:40:30,406  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:40:30,410  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T11:40:31,180  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T11:40:31,180  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: null will be shutdown
2024-04-24T11:40:31,209  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4397a639 created in the thread with id: 1
2024-04-24T11:40:33,632  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T11:40:33,632  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T11:40:33,633  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445 from thread id: 1
2024-04-24T11:40:33,773  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T11:40:33,807  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T11:40:33,841  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T11:40:33,846  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T11:40:33,960  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T11:40:33,991  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:40:33,993  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T11:40:33,995  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:40:33,995  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T11:40:33,997  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T11:40:34,000  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T11:40:34,001  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T11:40:34,002  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T11:40:34,007  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T11:40:34,008  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T11:40:34,009  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T11:40:34,010  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T11:40:34,011  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T11:40:34,012  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T11:40:34,014  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:40:34,209  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:40:34,250  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T11:40:34,532  INFO [main] reflections.Reflections: Reflections took 199 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:40:34,714  INFO [main] reflections.Reflections: Reflections took 141 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:40:34,868  INFO [main] reflections.Reflections: Reflections took 148 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:40:34,876  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,019  INFO [main] reflections.Reflections: Reflections took 126 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T11:40:35,070  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,072  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,075  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,075  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getDatabase_(String)=14, isCompatibleWith_(Configuration)=1, getAllFunctions_()=50}
2024-04-24T11:40:35,076  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 7.124 seconds
2024-04-24T11:40:35,077  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,077  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,079  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:35,083  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,084  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,087  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,091  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,091  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=6}
2024-04-24T11:40:35,091  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.012 seconds
2024-04-24T11:40:35,092  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table inpy(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as textfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,172  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,175  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:40:35,195  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5f6d85ec-bf3e-43bb-a4b8-0de2bd8f1388, clientType=HIVECLI]
2024-04-24T11:40:35,198  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T11:40:35,200  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T11:40:35,200  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@21ba2445, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4397a639 will be shutdown
2024-04-24T11:40:35,201  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:40:35,202  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T11:40:35,203  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:40:35,205  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:40:35,205  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:40:35,206  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613, with PersistenceManager: null will be shutdown
2024-04-24T11:40:35,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52621501 created in the thread with id: 1
2024-04-24T11:40:35,231  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613 from thread id: 1
2024-04-24T11:40:35,231  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:40:35,232  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:40:35,241  INFO [main] parse.CalcitePlanner: Creating table default.inpy position=13
2024-04-24T11:40:35,258  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:40:35,258  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:40:35,259  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52621501 will be shutdown
2024-04-24T11:40:35,260  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e974b9e created in the thread with id: 1
2024-04-24T11:40:35,265  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:40:35,265  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:40:35,269  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,281  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,281  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,281  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,282  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,282  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T11:40:35,282  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.189 seconds
2024-04-24T11:40:35,283  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,283  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,283  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table inpy(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as textfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,283  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,284  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T11:40:35,284  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T11:40:35,284  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7a358613, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e974b9e will be shutdown
2024-04-24T11:40:35,284  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:40:35,285  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T11:40:35,395  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:40:35,396  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T11:40:35,396  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:40:35,397  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5940b14e, with PersistenceManager: null will be shutdown
2024-04-24T11:40:35,398  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5940b14e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@795f6681 created in the thread with id: 1
2024-04-24T11:40:35,402  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5940b14e from thread id: 1
2024-04-24T11:40:35,402  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:40:35,402  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:40:35,403  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:inpy, dbName:default, owner:alex, createTime:1713984035, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}, numFilesErasureCoded=0, numFiles=0, transactional=false, rawDataSize=0, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:40:35,423  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/inpy
2024-04-24T11:40:35,564  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,564  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=161}
2024-04-24T11:40:35,565  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.281 seconds
2024-04-24T11:40:35,565  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:35,566  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,569  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,569  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,569  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,570  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, getDatabase_(String)=3}
2024-04-24T11:40:35,570  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.004 seconds
2024-04-24T11:40:35,570  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,570  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,570  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:35,570  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,571  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,573  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,576  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,576  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=5}
2024-04-24T11:40:35,576  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.006 seconds
2024-04-24T11:40:35,577  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table rc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as rcfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,579  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,579  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:40:35,579  INFO [main] parse.CalcitePlanner: Creating table default.rc5318 position=13
2024-04-24T11:40:35,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,584  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,584  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,585  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,585  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,585  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getDatabase_(String)=2, isCompatibleWith_(Configuration)=0}
2024-04-24T11:40:35,585  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.008 seconds
2024-04-24T11:40:35,585  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,586  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,586  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table rc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as rcfile TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,586  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,594  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:rc5318, dbName:default, owner:alex, createTime:1713984035, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, numFilesErasureCoded=0, transactional=false, numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:40:35,613  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/rc5318
2024-04-24T11:40:35,656  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,656  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=63, isCompatibleWith_(Configuration)=0}
2024-04-24T11:40:35,656  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.07 seconds
2024-04-24T11:40:35,657  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:35,658  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,660  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,660  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,660  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,661  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=2, flushCache_()=0}
2024-04-24T11:40:35,661  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.003 seconds
2024-04-24T11:40:35,661  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,661  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,661  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): use default
2024-04-24T11:40:35,662  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,662  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,664  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,668  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,668  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=5}
2024-04-24T11:40:35,668  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.007 seconds
2024-04-24T11:40:35,669  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table orc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,671  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,671  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T11:40:35,671  INFO [main] parse.CalcitePlanner: Creating table default.orc5318 position=13
2024-04-24T11:40:35,677  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,680  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,680  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,680  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,680  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,680  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, flushCache_()=0, getDatabase_(String)=3}
2024-04-24T11:40:35,680  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.011 seconds
2024-04-24T11:40:35,680  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,680  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,680  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): create table orc5318(ti tinyint, si smallint,i int, bi bigint, f float, d double, b boolean) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T11:40:35,681  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:35,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:orc5318, dbName:default, owner:alex, createTime:1713984035, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:ti, type:tinyint, comment:null), FieldSchema(name:si, type:smallint, comment:null), FieldSchema(name:i, type:int, comment:null), FieldSchema(name:bi, type:bigint, comment:null), FieldSchema(name:f, type:float, comment:null), FieldSchema(name:d, type:double, comment:null), FieldSchema(name:b, type:boolean, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFilesErasureCoded=0, numFiles=0, transactional=false, numRows=0, rawDataSize=0, totalSize=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"b":"true","bi":"true","d":"true","f":"true","i":"true","si":"true","ti":"true"}}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T11:40:35,694  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/orc5318
2024-04-24T11:40:35,732  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:35,732  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=45}
2024-04-24T11:40:35,732  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.052 seconds
2024-04-24T11:40:35,733  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/textfile' OVERWRITE INTO TABLE inpy
2024-04-24T11:40:35,735  INFO [main] parse.LoadSemanticAnalyzer: Starting caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,742  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:35,822  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:35,883  INFO [main] parse.LoadSemanticAnalyzer: Ending caching scope for: alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159
2024-04-24T11:40:35,883  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:35,883  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:35,883  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:35,883  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getTable_(GetTableRequest)=84, isCompatibleWith_(Configuration)=0}
2024-04-24T11:40:35,884  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.15 seconds
2024-04-24T11:40:35,884  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:35,884  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:35,884  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/textfile' OVERWRITE INTO TABLE inpy
2024-04-24T11:40:35,885  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.inpy
2024-04-24T11:40:35,886  INFO [main] exec.Task: Loading data to table default.inpy from file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/textfile
2024-04-24T11:40:35,886  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:35,902  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:35,905  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:35,922  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:35,923  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T11:40:35,927  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/inpy
2024-04-24T11:40:35,941  WARN [main] metadata.Hive: Cannot get a table snapshot for inpy
2024-04-24T11:40:35,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.inpy newtbl=inpy	
2024-04-24T11:40:36,010  INFO [main] ql.Driver: Starting task [Stage-1:STATS] in serial mode
2024-04-24T11:40:36,010  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:36,027  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:36,028  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T11:40:36,028  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:36,046  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:36,049  WARN [main] metadata.Hive: Cannot get a table snapshot for inpy
2024-04-24T11:40:36,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.inpy newtbl=inpy	
2024-04-24T11:40:36,099  INFO [main] stats.BasicStatsTask: Table default.inpy stats: [numFiles=1, numRows=0, totalSize=83, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T11:40:36,100  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:36,100  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getDatabase_(String)=3, getTable_(GetTableRequest)=69, alter_table_(String, String, String, Table, EnvironmentContext, String)=116}
2024-04-24T11:40:36,100  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.216 seconds
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,201  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,202  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:36,204  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:40:36,222  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T11:40:36,235  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T11:40:36,235  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T11:40:36,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5940b14e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@795f6681 will be shutdown
2024-04-24T11:40:36,237  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5940b14e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67ceeffd created in the thread with id: 1
2024-04-24T11:40:36,250  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T11:40:36,251  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T11:40:36,294  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,307  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:36,324  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,434  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,435  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,435  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:36,436  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:40:36,441  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,444  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:36,462  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
HCatContext INSTANCE is present : false
Copying from [inpy] to [rc5318] with schema : ti:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@6bf0f70a[fieldName=ti,comment=<null>,type=tinyint,category=PRIMITIVE],si:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@5310e451[fieldName=si,comment=<null>,type=smallint,category=PRIMITIVE],i:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@52d63b7e[fieldName=i,comment=<null>,type=int,category=PRIMITIVE],bi:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@74830d73[fieldName=bi,comment=<null>,type=bigint,category=PRIMITIVE],f:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@1827fc4e[fieldName=f,comment=<null>,type=float,category=PRIMITIVE],d:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@4c41a177[fieldName=d,comment=<null>,type=double,category=PRIMITIVE],b:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@2faf6e4a[fieldName=b,comment=<null>,type=boolean,category=PRIMITIVE]
2024-04-24T11:40:36,538  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,538  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,538  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,538  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,540  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:36,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,563  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,563  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,571  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,571  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,587  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.client.cache.enabled=true, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.warehouse.dir=${test.warehouse.dir}, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.min=32768, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, datanucleus.connectionPool.maxPoolSize=4, hive.metastore.schema.verification=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.stats.column.autogather=true, hive.in.test=true, hive.scheduled.queries.executor.enabled=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.llap.io.use.lrfu=true, hive.metastore.client.cache.maxSize=10Mb, hive.stats.key.prefix.reserve.length=0, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.query.reexecution.stats.persist.scope=query, hive.ignore.mapjoin.hint=false, test.log.dir=${test.tmp.dir}/log/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.querylog.location=${test.tmp.dir}/tmp, test.data.files=${hive.root}/data/files, hive.users.in.admin.role=hive_admin_user, hive.support.concurrency=true, hive.auto.convert.join=false, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.allocator.direct=false, hive.llap.cache.allow.synthetic.fileid=true, test.data.scripts=${hive.root}/data/scripts, hive.strict.timestamp.conversion=false, hive.test.dummystats.aggregator=value2, hive.llap.io.cache.orc.size=8388608, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.materializedview.rewriting=true, test.property1=value1, hive.mapjoin.max.gc.time.percentage=0.99, hive.exec.submit.local.task.via.child=false, hive.query.results.cache.enabled=false, hive.conf.restricted.list=dummy.config.value, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.cbo.fallback.strategy=TEST, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, hive.llap.io.cache.orc.arena.size=8388608, iceberg.hive.keep.stats=true, hive.stats.fetch.bitvector=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.client.cache.recordStats=true, hive.exec.mode.local.auto=false, javax.jdo.option.ConnectionPassword=mine, datanucleus.schema.autoCreateAll=true, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat}
2024-04-24T11:40:36,605  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:36,625  INFO [main] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713984036}
2024-04-24T11:40:36,634  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,634  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,641  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,641  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,648  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,648  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#0 : Plain Total Column Value Length: 3,  Compr Total Column Value Length: 3
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#1 : Plain Total Column Value Length: 5,  Compr Total Column Value Length: 5
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#2 : Plain Total Column Value Length: 6,  Compr Total Column Value Length: 6
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#3 : Plain Total Column Value Length: 11,  Compr Total Column Value Length: 11
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#4 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#5 : Plain Total Column Value Length: 23,  Compr Total Column Value Length: 23
2024-04-24T11:40:36,680  INFO [main] io.RCFile: Column#6 : Plain Total Column Value Length: 9,  Compr Total Column Value Length: 9
2024-04-24T11:40:36,681  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:36,681  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:36,685  INFO [main] output.FileOutputCommitter: Saved output of task 'attempt_200908190029_0001_r_000001_1' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/rc5318/_SCRATCH0,5877537233576945
2024-04-24T11:40:36,733  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,733  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,733  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,734  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,741  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,741  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,741  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:36,742  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,747  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.rc5318 newtbl=rc5318	
2024-04-24T11:40:36,779  INFO [main] utils.MetaStoreServerUtils: Updating table stats for rc5318
2024-04-24T11:40:36,779  INFO [main] utils.MetaStoreServerUtils: Updated size of table rc5318 to 170
2024-04-24T11:40:36,797  INFO [main] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,845  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,846  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:36,847  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,850  INFO [main] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T11:40:36,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,903  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:36,904  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:40:36,908  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,911  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:36,930  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:36,973  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:36,973  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:36,973  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:36,973  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:36,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:36,974  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:36,975  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:40:36,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:36,982  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:37,000  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
HCatContext INSTANCE is present : false
Copying from [inpy] to [orc5318] with schema : ti:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@3dd591b9[fieldName=ti,comment=<null>,type=tinyint,category=PRIMITIVE],si:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@538905d2[fieldName=si,comment=<null>,type=smallint,category=PRIMITIVE],i:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@7e8c58fd[fieldName=i,comment=<null>,type=int,category=PRIMITIVE],bi:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@11ce9319[fieldName=bi,comment=<null>,type=bigint,category=PRIMITIVE],f:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@780c0[fieldName=f,comment=<null>,type=float,category=PRIMITIVE],d:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@1b3bb287[fieldName=d,comment=<null>,type=double,category=PRIMITIVE],b:org.apache.hive.hcatalog.data.schema.HCatFieldSchema@7ec5aad[fieldName=b,comment=<null>,type=boolean,category=PRIMITIVE]
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:37,055  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:37,056  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:37,056  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:37,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:37,066  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,066  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,069  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,069  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,080  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.client.cache.enabled=true, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.warehouse.dir=${test.warehouse.dir}, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.min=32768, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, datanucleus.connectionPool.maxPoolSize=4, hive.metastore.schema.verification=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.stats.column.autogather=true, hive.in.test=true, hive.scheduled.queries.executor.enabled=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.llap.io.use.lrfu=true, hive.metastore.client.cache.maxSize=10Mb, hive.stats.key.prefix.reserve.length=0, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.query.reexecution.stats.persist.scope=query, hive.ignore.mapjoin.hint=false, test.log.dir=${test.tmp.dir}/log/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.querylog.location=${test.tmp.dir}/tmp, test.data.files=${hive.root}/data/files, hive.users.in.admin.role=hive_admin_user, hive.support.concurrency=true, hive.auto.convert.join=false, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.allocator.direct=false, hive.llap.cache.allow.synthetic.fileid=true, test.data.scripts=${hive.root}/data/scripts, hive.strict.timestamp.conversion=false, hive.test.dummystats.aggregator=value2, hive.llap.io.cache.orc.size=8388608, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.materializedview.rewriting=true, test.property1=value1, hive.mapjoin.max.gc.time.percentage=0.99, hive.exec.submit.local.task.via.child=false, hive.query.results.cache.enabled=false, hive.conf.restricted.list=dummy.config.value, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.cbo.fallback.strategy=TEST, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, hive.llap.io.cache.orc.arena.size=8388608, iceberg.hive.keep.stats=true, hive.stats.fetch.bitvector=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.client.cache.recordStats=true, hive.exec.mode.local.auto=false, javax.jdo.option.ConnectionPassword=mine, datanucleus.schema.autoCreateAll=true, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat}
2024-04-24T11:40:37,088  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:37,093  INFO [main] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713984036}
2024-04-24T11:40:37,097  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,097  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,100  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,100  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,104  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,104  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,159  INFO [main] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-24T11:40:37,166  INFO [main] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/orc5318/_SCRATCH0,6352982269154873/_temporary/0/_temporary/attempt_200908190029_0001_r_000001_1/part-m-00001 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-24T11:40:37,238  INFO [main] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/orc5318/_SCRATCH0,6352982269154873/_temporary/0/_temporary/attempt_200908190029_0001_r_000001_1/part-m-00001 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-24T11:40:37,347  INFO [Finalizer] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:40:37,347  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T11:40:37,367  INFO [main] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:37,367  INFO [main] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:37,369  INFO [main] output.FileOutputCommitter: Saved output of task 'attempt_200908190029_0001_r_000001_1' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/orc5318/_SCRATCH0,6352982269154873
2024-04-24T11:40:37,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:37,404  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:37,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:37,405  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:37,406  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:37,406  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:37,411  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.orc5318 newtbl=orc5318	
2024-04-24T11:40:37,440  INFO [main] utils.MetaStoreServerUtils: Updating table stats for orc5318
2024-04-24T11:40:37,440  INFO [main] utils.MetaStoreServerUtils: Updated size of table orc5318 to 710
2024-04-24T11:40:37,451  INFO [main] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:37,479  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:37,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:37,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:37,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:37,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:37,481  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T11:40:37,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:37,484  INFO [main] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T11:40:37,534  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:40:37,543  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-8c8a3718-6883-4ac4-865d-da8da03447a1
===
inpy:
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:37,794  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:37,795  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:37,795  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:37,795  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:37,795  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:37,795  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:37,800  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:37,827  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:37,871  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:37,872  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:37,875  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:37,888  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:37,904  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:40:37,931  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:40:37,957  INFO [main] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:40:37,978  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:40:37,990  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:40:37,990  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:40:38,090  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T11:40:38,099  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T11:40:38,112  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T11:40:38,112  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T11:40:38,131  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:40:38,134  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:38,149  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:38,150  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:38,150  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:38,150  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:38,150  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:38,150  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:38,151  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T11:40:38,152  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:38,155  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:38,169  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:38,182  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:40:38,208  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:40:38,213  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,263  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:40:38,270  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:40:38,285  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:40:38,292  INFO [JobControl] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:38,293  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:40:38,323  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:40:38,349  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local1610735672_0001
2024-04-24T11:40:38,349  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:40:38,455  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:40:38,456  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:40:38,464  INFO [Thread-86] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:38,464  INFO [Thread-86] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:38,464  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:40:38,481  INFO [Thread-86] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:40:38,482  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1610735672_0001_m_000000_0
2024-04-24T11:40:38,507  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:38,507  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:38,520  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:40:38,524  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 83
Input split[0]:
   Length = 83
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:40:38,535  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@695b3c13
2024-04-24T11:40:38,539  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:38,539  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:38,557  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe with properties {name=default.inpy, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, totalSize=83, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713984036}
2024-04-24T11:40:38,558  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:40:38,559  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:40:38,563  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:40:38,569  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:38,575  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1610735672_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T11:40:38,579  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:38,579  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1610735672_0001_m_000000_0 is allowed to commit now
2024-04-24T11:40:38,582  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1610735672_0001_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp708325652
2024-04-24T11:40:38,583  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/inpy/textfile:0+83
2024-04-24T11:40:38,583  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1610735672_0001_m_000000_0' done.
2024-04-24T11:40:38,584  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1610735672_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2737
		FILE: Number of bytes written=566611
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2121
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=880803840
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:40:38,585  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1610735672_0001_m_000000_0
2024-04-24T11:40:38,585  INFO [Thread-86] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:40:38,710  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local1610735672_0001
2024-04-24T11:40:38,710  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:40:38,710  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:40:38,713  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,717  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,719  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,738  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:40:38,739  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:40:38	2024-04-24 11:40:38	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local1610735672_0001	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp708325652,

Input(s):
Successfully read 2 records from: "inpy"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp708325652"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local1610735672_0001


2024-04-24T11:40:38,740  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,743  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,744  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:40:38,747  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:40:38,756  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:38,756  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:40:38,783  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:40:38,784  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-8c8a3718-6883-4ac4-865d-da8da03447a1
===
rc5318:
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:38,815  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:38,816  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:38,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:38,839  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:38,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:38,860  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:38,860  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:38,863  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:38,879  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:38,880  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:40:38,890  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:40:38,890  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:40:38,891  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:40:38,892  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:40:38,892  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:40:38,900  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,902  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:40:38,902  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:40:38,922  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:38,922  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:38,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:38,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:38,924  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:38,924  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T11:40:38,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:38,929  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:38,947  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:38,952  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:40:38,959  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:40:38,961  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:38,978  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:40:38,983  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:40:38,988  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:40:38,994  INFO [JobControl] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:38,995  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:40:39,015  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:40:39,033  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local1200595025_0002
2024-04-24T11:40:39,034  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:40:39,132  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:40:39,132  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:40:39,136  INFO [Thread-127] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,136  INFO [Thread-127] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,137  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:40:39,147  INFO [Thread-127] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:40:39,148  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1200595025_0002_m_000000_0
2024-04-24T11:40:39,153  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,153  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,155  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:40:39,156  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 170
Input split[0]:
   Length = 170
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:40:39,161  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@4431dad6
2024-04-24T11:40:39,163  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,163  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,180  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe with properties {name=default.rc5318, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, totalSize=170, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713984035}
2024-04-24T11:40:39,180  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:40:39,180  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:40:39,181  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:40:39,182  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:39,182  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1200595025_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T11:40:39,185  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:39,185  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1200595025_0002_m_000000_0 is allowed to commit now
2024-04-24T11:40:39,188  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1200595025_0002_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp469075732
2024-04-24T11:40:39,189  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/rc5318/part-m-00001:0+170
2024-04-24T11:40:39,189  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1200595025_0002_m_000000_0' done.
2024-04-24T11:40:39,189  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1200595025_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5198
		FILE: Number of bytes written=1132366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2131
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883425280
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:40:39,189  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1200595025_0002_m_000000_0
2024-04-24T11:40:39,189  INFO [Thread-127] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:40:39,333  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local1200595025_0002
2024-04-24T11:40:39,333  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:40:39,333  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:40:39,339  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,345  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,351  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,358  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:40:39,358  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:40:38	2024-04-24 11:40:39	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local1200595025_0002	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp469075732,

Input(s):
Successfully read 2 records from: "rc5318"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp469075732"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local1200595025_0002


2024-04-24T11:40:39,362  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,368  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,371  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:40:39,373  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:40:39,390  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:39,390  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:40:39,424  INFO [main] executionengine.HExecutionEngine: Connecting to hadoop file system at: file:///
2024-04-24T11:40:39,425  INFO [main] pig.PigServer: Pig Script ID for the session: PIG-default-8c8a3718-6883-4ac4-865d-da8da03447a1
===
orc5318:
2024-04-24T11:40:39,447  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:39,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:39,448  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:39,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:39,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:39,465  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:39,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:39,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:39,484  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:39,496  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:39,498  INFO [main] pigstats.ScriptState: Pig features used in the script: UNKNOWN
2024-04-24T11:40:39,505  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:40:39,505  INFO [main] optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2024-04-24T11:40:39,506  INFO [main] mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
2024-04-24T11:40:39,507  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 1
2024-04-24T11:40:39,507  INFO [main] mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 1
2024-04-24T11:40:39,513  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,515  INFO [main] mapreduce.MRScriptState: Pig script settings are added to the job
2024-04-24T11:40:39,516  INFO [main] mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2024-04-24T11:40:39,528  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T11:40:39,529  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T11:40:39,529  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T11:40:39,530  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T11:40:39,531  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T11:40:39,534  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:39,546  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:39,552  INFO [main] mapReduceLayer.JobControlCompiler: Setting up single store job
2024-04-24T11:40:39,559  INFO [main] mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
2024-04-24T11:40:39,561  WARN [JobControl] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,578  WARN [JobControl] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T11:40:39,583  WARN [JobControl] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T11:40:39,586  INFO [JobControl] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Using differences={hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.llap.io.cache.orc.size=8388608, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, hive.mapjoin.max.gc.time.percentage=0.99, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.stats.key.prefix.reserve.length=0, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.test.dummystats.aggregator=value2, hive.users.in.admin.role=hive_admin_user, iceberg.hive.keep.stats=true, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.query.reexecution.stats.persist.scope=query, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, test.log.dir=${test.tmp.dir}/log/, hive.cbo.fallback.strategy=TEST, hive.exec.mode.local.auto=false, hive.support.concurrency=true, javax.jdo.option.ConnectionUserName=APP, hive.ignore.mapjoin.hint=false, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, datanucleus.connectionPool.maxPoolSize=4, hive.strict.timestamp.conversion=false, datanucleus.schema.autoCreateAll=true, test.data.files=${hive.root}/data/files, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.stats.fetch.bitvector=true, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.conf.restricted.list=dummy.config.value, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.fetch.task.conversion=minimal, test.data.scripts=${hive.root}/data/scripts, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.schema.verification=false, hive.query.results.cache.enabled=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.cache.orc.alloc.min=32768, hive.llap.io.allocator.direct=false, hive.stats.column.autogather=true, hive.llap.cache.allow.synthetic.fileid=true, javax.jdo.option.ConnectionPassword=mine, hive.metastore.client.cache.recordStats=true, hive.llap.io.cache.orc.arena.size=8388608, hive.scheduled.queries.executor.enabled=false, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.in.test=true, hive.metastore.client.cache.enabled=true, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml}
2024-04-24T11:40:39,587  INFO [JobControl] orc.OrcInputFormat: getSplits started
2024-04-24T11:40:39,593  INFO [JobControl] orc.OrcInputFormat: Context:: isAcid: false isVectorMode: false sarg: null minSplitSize: 0 maxSplitSize: 268435456 splitStrategy: HYBRID footerInSplits: false numBuckets: 0 numThreads: 10 cacheMemSize: 268435456 cacheStripeDetails: true useSoftReference: false writeIdList: null:9223372036854775807:9223372036854775807:: isTransactionalTable: false txnProperties: null 
2024-04-24T11:40:39,593  INFO [JobControl] orc.OrcInputFormat: ORC pushdown predicate: null
2024-04-24T11:40:39,638  INFO [JobControl] orc.OrcInputFormat: FooterCacheHitRatio: 0/1
2024-04-24T11:40:39,640  INFO [JobControl] orc.OrcInputFormat: getSplits finished (#splits: 1). duration: 53 ms
2024-04-24T11:40:39,640  INFO [JobControl] util.MapRedUtil: Total input paths (combined) to process : 1
2024-04-24T11:40:39,660  INFO [JobControl] mapreduce.JobSubmitter: number of splits:1
2024-04-24T11:40:39,674  INFO [JobControl] mapreduce.JobSubmitter: Submitting tokens for job: job_local243977891_0003
2024-04-24T11:40:39,674  INFO [JobControl] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T11:40:39,733  INFO [JobControl] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T11:40:39,734  INFO [Thread-166] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T11:40:39,738  INFO [Thread-166] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,738  INFO [Thread-166] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,738  INFO [Thread-166] mapred.LocalJobRunner: OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2024-04-24T11:40:39,748  INFO [Thread-166] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T11:40:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local243977891_0003_m_000000_0
2024-04-24T11:40:39,754  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,754  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,755  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T11:40:39,757  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Number of splits :1
Total Length = 361
Input split[0]:
   Length = 361
   ClassName: org.apache.hive.hcatalog.mapreduce.HCatSplit
   Locations:

-----------------------

2024-04-24T11:40:39,761  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigRecordReader: Current split being processed org.apache.hive.hcatalog.mapreduce.HCatSplit@2352c6bc
2024-04-24T11:40:39,762  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T11:40:39,762  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T11:40:39,778  INFO [LocalJobRunner Map Task Executor #0] orc.ReaderImpl: Reading ORC rows from file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/org.apache.hive.hcatalog.pig.TestE2EScenarios-1713984026128/warehouse/orc5318/part-m-00001 with {include: null, offset: 3, length: 361, schema: struct<ti:tinyint,si:smallint,i:int,bi:bigint,f:float,d:double,b:boolean>, includeAcidColumns: true}
2024-04-24T11:40:39,805  INFO [LocalJobRunner Map Task Executor #0] mapreduce.InternalUtil: Initializing org.apache.hadoop.hive.ql.io.orc.OrcSerde with properties {name=default.orc5318, numFiles=1, columns.types=tinyint,smallint,int,bigint,float,double,boolean, numFilesErasureCoded=0, serialization.format=1, columns=ti,si,i,bi,f,d,b, rawDataSize=0, columns.comments=null null null null null null null, numRows=0, bucketing_version=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, totalSize=710, column.name.delimiter=,, serialization.null.format=\N, transient_lastDdlTime=1713984035}
2024-04-24T11:40:39,806  INFO [LocalJobRunner Map Task Executor #0] util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 1431830528 to monitor. collectionUsageThreshold = 1064828928, usageThreshold = 1064828928
2024-04-24T11:40:39,806  WARN [LocalJobRunner Map Task Executor #0] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
log4j: Could not find root logger information. Is this OK?
log4j: Finished configuring.
2024-04-24T11:40:39,807  INFO [LocalJobRunner Map Task Executor #0] mapReduceLayer.PigMapOnly$Map: Aliases being processed per job phase (AliasName[line,offset]): M: X[1,4] C:  R: 
2024-04-24T11:40:39,809  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:39,809  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local243977891_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T11:40:39,811  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T11:40:39,812  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local243977891_0003_m_000000_0 is allowed to commit now
2024-04-24T11:40:39,814  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local243977891_0003_m_000000_0' to file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp487836413
2024-04-24T11:40:39,815  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T11:40:39,815  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local243977891_0003_m_000000_0' done.
2024-04-24T11:40:39,815  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local243977891_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=11345
		FILE: Number of bytes written=1696581
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=2336
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=883425280
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T11:40:39,815  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local243977891_0003_m_000000_0
2024-04-24T11:40:39,815  INFO [Thread-166] mapred.LocalJobRunner: map task executor complete.
2024-04-24T11:40:39,935  INFO [main] mapReduceLayer.MapReduceLauncher: HadoopJobId: job_local243977891_0003
2024-04-24T11:40:39,935  INFO [main] mapReduceLayer.MapReduceLauncher: Processing aliases X
2024-04-24T11:40:39,935  INFO [main] mapReduceLayer.MapReduceLauncher: detailed locations: M: X[1,4] C:  R: 
2024-04-24T11:40:39,942  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,949  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,955  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,963  INFO [main] mapReduceLayer.MapReduceLauncher: 100% complete
2024-04-24T11:40:39,963  INFO [main] mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
3.1.0	0.16.0	alex	2024-04-24 11:40:39	2024-04-24 11:40:39	UNKNOWN

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_local243977891_0003	1	0	n/a	n/a	n/a	n/a	0	0	0	0	X	MAP_ONLY	file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp487836413,

Input(s):
Successfully read 2 records from: "orc5318"

Output(s):
Successfully stored 2 records in: "file:/home/alex/Repositories/hive/hcatalog/hcatalog-pig-adapter/target/tmp/HCatBaseTest_1713984037484/pig/temp/temp1752845161/tmp487836413"

Counters:
Total records written : 2
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_local243977891_0003


2024-04-24T11:40:39,967  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,973  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T11:40:39,976  INFO [main] mapReduceLayer.MapReduceLauncher: Success!
2024-04-24T11:40:39,977  WARN [main] data.SchemaTupleBackend: SchemaTupleBackend has already been initialized
2024-04-24T11:40:39,987  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T11:40:39,987  INFO [main] util.MapRedUtil: Total input paths to process : 1
	(java.lang.Integer:-3)	(java.lang.Integer:9001)	(java.lang.Integer:86400)	(java.lang.Long:4294967297)	(java.lang.Float:34.532)	(java.lang.Double:2.184239842983489E15)	(java.lang.Boolean:true)
	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Integer:0)	(java.lang.Long:0)	(java.lang.Float:0.0)	(java.lang.Double:0.0)	(java.lang.Boolean:false)
===
2024-04-24T11:40:39,989  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table inpy
2024-04-24T11:40:39,991  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:40,004  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,005  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:40,005  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:40,005  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:40,005  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getTable_(GetTableRequest)=13, isCompatibleWith_(Configuration)=0}
2024-04-24T11:40:40,005  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.017 seconds
2024-04-24T11:40:40,005  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:40,006  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:40,006  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table inpy
2024-04-24T11:40:40,006  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:40,006  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:40,020  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,020  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.inpy	
2024-04-24T11:40:40,033  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.inpy	
2024-04-24T11:40:40,287  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:40,287  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=266, getTable_(GetTableRequest)=14}
2024-04-24T11:40:40,287  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.281 seconds
2024-04-24T11:40:40,288  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table rc5318
2024-04-24T11:40:40,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:40,342  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,342  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:40,342  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:40,342  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:40,342  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=53, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T11:40:40,343  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.054 seconds
2024-04-24T11:40:40,343  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:40,343  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:40,343  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table rc5318
2024-04-24T11:40:40,343  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:40,343  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:40,357  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,357  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.rc5318	
2024-04-24T11:40:40,370  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,371  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.rc5318	
2024-04-24T11:40:40,438  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:40,438  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=14, dropTable_(String, String, boolean, boolean, boolean)=80}
2024-04-24T11:40:40,438  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.095 seconds
2024-04-24T11:40:40,439  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table orc5318
2024-04-24T11:40:40,439  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:40,452  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,452  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T11:40:40,452  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T11:40:40,453  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T11:40:40,453  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13}
2024-04-24T11:40:40,453  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.014 seconds
2024-04-24T11:40:40,453  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T11:40:40,453  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T11:40:40,453  INFO [main] ql.Driver: Executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159): drop table orc5318
2024-04-24T11:40:40,454  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T11:40:40,454  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:40,467  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,467  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.orc5318	
2024-04-24T11:40:40,480  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T11:40:40,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.orc5318	
2024-04-24T11:40:40,527  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T11:40:40,528  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13, dropTable_(String, String, boolean, boolean, boolean)=60}
2024-04-24T11:40:40,528  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424114027_4362a843-88b3-4cd9-ac9e-6b4d8195a159); Time taken: 0.074 seconds
2024-04-24T11:40:40,546  INFO [pool-2-thread-1] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T11:40:40,546  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
