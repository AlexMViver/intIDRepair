<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="40.115" tests="8" errors="0" skipped="2" failures="6">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter7129979033752240238.jar /home/alex/Repositories/hive/hcatalog/core/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire3974758172225785206tmp surefire_37534460158786737847581tmp"/>
    <property name="nondexExecid" value="pMz92uAeDNfRoBpeHBYLk9N8fM4SPyxto1cB2sHBk0="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/derby.log"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/hcatalog/core/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/hcatalog/core/../../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/hcatalog/core/target"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/hcatalog/core/.nondex"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/hcatalog/core/.nondex"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="nondexStart" value="0"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/hcatalog/core/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/hcatalog/core/../../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/test-classes:/home/alex/Repositories/hive/hcatalog/core/target/classes:/home/alex/Repositories/hive/cli/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar:/home/alex/.m2/repository/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/3.1.0/hadoop-mapreduce-client-hs-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.0/hadoop-mapreduce-client-app-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.0/hadoop-mapreduce-client-shuffle-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/home/alex/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/3.1.0/hadoop-yarn-server-tests-3.1.0-tests.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.0/hadoop-yarn-server-nodemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-timelineservice/3.1.0/hadoop-yarn-server-timelineservice-3.1.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-csv/1.0/commons-csv-1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-minicluster/3.1.0/hadoop-minicluster-3.1.0.jar:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/alex/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/alex/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/alex/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/alex/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/alex/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/hcatalog/core/target/testconf:/home/alex/Repositories/hive/hcatalog/core/../../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/hcatalog/core/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="1016066"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/hcatalog/core/target/surefire/surefirebooter7129979033752240238.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/hcatalog/core/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/hcatalog/core"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/hcatalog/core/../../"/>
  </properties>
  <testcase name="testHCatPartitionedTable[0]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="7.808">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,095199 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@815b41f]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@815b41f) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@7a8c8dcf
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@75db5df9
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,022804 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/hcatalog/core/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(noConsoleNoAnsi="null", Replace=null, charset="null", disableAnsi="null", PatternSelector=null, alwaysWriteExceptions="null", footer="null", Configuration(HiveLog4j2Test), pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", header="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", direct="null", follow="null", immediateFlush="null", bufferSize="null", bufferedIo="null", ignoreExceptions="null", name="console", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", noConsoleNoAnsi="null", header="null", disableAnsi="null", Configuration(HiveLog4j2Test), footer="null", alwaysWriteExceptions="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", Replace=null, PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(modulate="true", interval="1", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(stopCustomActionsOnError="null", max="30", min="null", compressionLevel="null", ={}, tempCompressedFilePattern="null", fileIndex="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log", fileGroup="null", fileOwner="null", filePermissions="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), filePattern="/home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log.%d{yyyy-MM-dd}", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), append="null", advertise="null", advertiseURI="null", bufferSize="null", immediateFlush="null", bufferedIo="null", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", ignoreExceptions="null", Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log seek to 307260524
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/hcatalog/core/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T09:39:40.811-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-09:39:42.418, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-09:39:42.418, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@75db5df9 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@75db5df9
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@75db5df9 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@3bbc39f8...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@3bbc39f8 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7d9e8ef7
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@815b41f
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@815b41f) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@815b41f] started OK.
2024-04-24T09:39:42,624  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/hcatalog/core/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T09:39:42,715  INFO [main] mapreduce.HCatBaseTest: Using warehouse directory /home/alex/Repositories/hive/hcatalog/core/build/test/data/org.apache.hive.hcatalog.mapreduce.HCatBaseTest-1713976782499/warehouse
2024-04-24T09:39:42,996  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T09:39:43,052  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:43,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:43,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:43,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:43,053  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:43,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:43,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:43,054  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:43,054  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:43,055  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:43,055  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:43,058  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=0 initial-capacity=50 maximum-capacity=50
2024-04-24T09:39:43,109  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:43,287  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:43,323  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:43,336  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T09:39:43,336  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T09:39:43,359  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T09:39:43,364  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T09:39:43,953  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T09:39:43,957  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T09:39:44,586  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T09:39:44,586  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30814f43, with PersistenceManager: null will be shutdown
2024-04-24T09:39:44,612  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30814f43, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23811a09 created in the thread with id: 1
2024-04-24T09:39:46,904  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T09:39:46,905  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T09:39:46,905  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30814f43 from thread id: 1
2024-04-24T09:39:47,411  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T09:39:47,445  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T09:39:47,480  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T09:39:47,483  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T09:39:47,597  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T09:39:47,605  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T09:39:47,607  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T09:39:47,607  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T09:39:47,628  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T09:39:47,631  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T09:39:47,632  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T09:39:47,633  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T09:39:47,635  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T09:39:47,638  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T09:39:47,639  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T09:39:47,640  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T09:39:47,644  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T09:39:47,645  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T09:39:47,646  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T09:39:47,648  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:47,798  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:47,839  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:47,839  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30814f43, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23811a09 will be shutdown
2024-04-24T09:39:47,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:47,840  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T09:39:47,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:47,843  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:47,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: null will be shutdown
2024-04-24T09:39:47,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45117dd created in the thread with id: 1
2024-04-24T09:39:47,860  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075 from thread id: 1
2024-04-24T09:39:47,949  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:47,949  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:47,950  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:47,951  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:47,978  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:47,979  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:47,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45117dd will be shutdown
2024-04-24T09:39:47,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@125d47c4 created in the thread with id: 1
2024-04-24T09:39:47,985  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 395c9ceb-e270-4c66-a7ac-51984bb89d83
2024-04-24T09:39:47,991  INFO [main] SessionState: Hive Session ID = 395c9ceb-e270-4c66-a7ac-51984bb89d83
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:39:48,003  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:39:48,053  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/395c9ceb-e270-4c66-a7ac-51984bb89d83
2024-04-24T09:39:48,056  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/395c9ceb-e270-4c66-a7ac-51984bb89d83
2024-04-24T09:39:48,060  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/395c9ceb-e270-4c66-a7ac-51984bb89d83/_tmp_space.db
2024-04-24T09:39:48,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:48,180  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_TEXTFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_TEXTFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1, EXTERNAL=TRUE}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, transactional=false, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:39:48,192  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile
2024-04-24T09:39:48,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:48,420  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:48,421  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:48,421  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:48,422  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:48,423  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:48,442  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:48,442  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:48,444  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@125d47c4 will be shutdown
2024-04-24T09:39:48,445  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3554bdc0 created in the thread with id: 1
2024-04-24T09:39:48,451  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:48,452  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:48,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:48,452  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cfd1075, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3554bdc0 will be shutdown
2024-04-24T09:39:48,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:48,452  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T09:39:48,453  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:48,456  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:48,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d, with PersistenceManager: null will be shutdown
2024-04-24T09:39:48,458  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47044f7d created in the thread with id: 1
2024-04-24T09:39:48,463  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d from thread id: 1
2024-04-24T09:39:48,470  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:48,526  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:48,673  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T09:39:48,687  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T09:39:48,703  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T09:39:48,703  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:48,761  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:48,763  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:48,764  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:48,764  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47044f7d will be shutdown
2024-04-24T09:39:48,765  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f04993d created in the thread with id: 1
2024-04-24T09:39:48,768  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:48,769  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:48,769  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:48,769  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c075e9d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f04993d will be shutdown
2024-04-24T09:39:48,770  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:48,770  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T09:39:48,770  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:48,772  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:48,773  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98, with PersistenceManager: null will be shutdown
2024-04-24T09:39:48,773  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4db0ba1c created in the thread with id: 1
2024-04-24T09:39:48,777  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98 from thread id: 1
2024-04-24T09:39:48,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value1,501]	
2024-04-24T09:39:48,845  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:48,854  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:48,886  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:48,938  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:48,970  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local953425555_0001
2024-04-24T09:39:48,970  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:49,075  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:49,077  INFO [main] mapreduce.Job: Running job: job_local953425555_0001
2024-04-24T09:39:49,077  INFO [Thread-44] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:49,091  INFO [Thread-44] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,091  INFO [Thread-44] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,098  INFO [Thread-44] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:49,104  INFO [Thread-44] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,104  INFO [Thread-44] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,123  INFO [Thread-44] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:49,123  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local953425555_0001_m_000000_0
2024-04-24T09:39:49,149  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,150  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,153  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,154  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,167  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:49,170  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:39:49,183  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,184  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,244  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:49,250  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local953425555_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:49,250  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,250  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,256  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:49,256  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local953425555_0001_m_000000_0 is allowed to commit now
2024-04-24T09:39:49,256  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:49,256  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:49,268  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local953425555_0001_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9897471306851598/part1=p1value1/part0=501
2024-04-24T09:39:49,270  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:49,270  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local953425555_0001_m_000000_0' done.
2024-04-24T09:39:49,274  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local953425555_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=510105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:49,274  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local953425555_0001_m_000000_0
2024-04-24T09:39:49,275  INFO [Thread-44] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:49,326  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:49,326  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:49,327  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:49,328  INFO [Thread-44] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:49,329  INFO [Thread-44] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:49,330  INFO [Thread-44] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:49,330  INFO [Thread-44] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:49,331  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4216ec7d, with PersistenceManager: null will be shutdown
2024-04-24T09:39:49,331  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4216ec7d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49c4b690 created in the thread with id: 70
2024-04-24T09:39:49,336  INFO [Thread-44] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4216ec7d from thread id: 70
2024-04-24T09:39:49,336  INFO [Thread-44] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:49,337  INFO [Thread-44] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:49,337  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:49,337  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4216ec7d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49c4b690 will be shutdown
2024-04-24T09:39:49,337  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:49,337  INFO [Thread-44] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-04-24T09:39:49,338  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:49,339  INFO [Thread-44] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:49,340  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893, with PersistenceManager: null will be shutdown
2024-04-24T09:39:49,340  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b5e219 created in the thread with id: 70
2024-04-24T09:39:49,343  INFO [Thread-44] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893 from thread id: 70
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:49,397  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:49,398  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:49,398  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:49,398  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:49,398  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:49,399  INFO [Thread-44] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part1=p1value1, part0=501}].
2024-04-24T09:39:49,428  INFO [Thread-44] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9897471306851598/part1=p1value1/part0=501].
2024-04-24T09:39:49,428  INFO [Thread-44] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:49,471  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:49,471  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:49,472  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:49,473  WARN [Thread-44] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:49,473  INFO [Thread-44] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:49,474  INFO [Thread-44] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:49,474  INFO [Thread-44] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:49,475  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b5e219 will be shutdown
2024-04-24T09:39:49,475  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6935ebcd created in the thread with id: 70
2024-04-24T09:39:49,479  INFO [Thread-44] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:49,479  INFO [Thread-44] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:49,480  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:49,480  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@528c7893, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6935ebcd will be shutdown
2024-04-24T09:39:49,480  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:49,480  INFO [Thread-44] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T09:39:49,480  INFO [Thread-44] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:49,481  INFO [Thread-44] metastore.HMSHandler: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:49,482  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6933a935, with PersistenceManager: null will be shutdown
2024-04-24T09:39:49,482  INFO [Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6933a935, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21c2f077 created in the thread with id: 70
2024-04-24T09:39:49,485  INFO [Thread-44] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6933a935 from thread id: 70
2024-04-24T09:39:49,487  INFO [Thread-44] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:49,487  WARN [Thread-44] mapred.LocalJobRunner: job_local953425555_0001
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9897471306851598/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:50,082  INFO [main] mapreduce.Job: Job job_local953425555_0001 running in uber mode : false
2024-04-24T09:39:50,084  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:50,088  INFO [main] mapreduce.Job: Job job_local953425555_0001 failed with state FAILED due to: NA
2024-04-24T09:39:50,092  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=252
		FILE: Number of bytes written=510105
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:50,136  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:50,136  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:50,136  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:50,137  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:50,137  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:50,137  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:50,137  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:50,137  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:50,138  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:50,138  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:50,138  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:50,138  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:50,139  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:50,143  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:50,143  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:50,143  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4db0ba1c will be shutdown
2024-04-24T09:39:50,144  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5873f3f0 created in the thread with id: 1
2024-04-24T09:39:50,148  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:50,148  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:50,148  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:50,148  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1282e98, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5873f3f0 will be shutdown
2024-04-24T09:39:50,149  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:50,149  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-04-24T09:39:50,149  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:50,150  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:50,151  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a, with PersistenceManager: null will be shutdown
2024-04-24T09:39:50,151  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52bba91a created in the thread with id: 1
2024-04-24T09:39:50,154  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a from thread id: 1
2024-04-24T09:39:50,157  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:50,173  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:50,182  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:50,224  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:50,225  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:50,225  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:50,225  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:50,225  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:50,226  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:50,227  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:50,227  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:50,228  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52bba91a will be shutdown
2024-04-24T09:39:50,229  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@dd737ea created in the thread with id: 1
2024-04-24T09:39:50,232  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:50,232  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:50,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:50,233  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3271ec2a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@dd737ea will be shutdown
2024-04-24T09:39:50,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:50,233  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-04-24T09:39:50,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:50,235  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:50,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370, with PersistenceManager: null will be shutdown
2024-04-24T09:39:50,236  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ba024cb created in the thread with id: 1
2024-04-24T09:39:50,240  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370 from thread id: 1
2024-04-24T09:39:50,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-04-24T09:39:50,276  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:50,280  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:50,281  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:50,301  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:50,321  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local681537083_0002
2024-04-24T09:39:50,321  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:50,407  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:50,408  INFO [main] mapreduce.Job: Running job: job_local681537083_0002
2024-04-24T09:39:50,408  INFO [Thread-92] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:50,412  INFO [Thread-92] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,412  INFO [Thread-92] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,414  INFO [Thread-92] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:50,416  INFO [Thread-92] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,416  INFO [Thread-92] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,429  INFO [Thread-92] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:50,429  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local681537083_0002_m_000000_0
2024-04-24T09:39:50,434  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,434  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,437  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,437  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,437  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:50,438  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:39:50,442  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,442  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,458  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:50,459  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local681537083_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:50,459  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,459  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,463  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:50,463  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local681537083_0002_m_000000_0 is allowed to commit now
2024-04-24T09:39:50,463  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:50,463  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:50,474  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local681537083_0002_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,3849486826753148/part1=p1value2/part0=502
2024-04-24T09:39:50,474  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:50,475  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local681537083_0002_m_000000_0' done.
2024-04-24T09:39:50,475  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local681537083_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:50,475  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local681537083_0002_m_000000_0
2024-04-24T09:39:50,475  INFO [Thread-92] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:50,529  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:50,530  INFO [Thread-92] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:50,531  INFO [Thread-92] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:50,532  INFO [Thread-92] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:50,532  INFO [Thread-92] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:50,532  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70ddf90c, with PersistenceManager: null will be shutdown
2024-04-24T09:39:50,532  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70ddf90c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6770c391 created in the thread with id: 120
2024-04-24T09:39:50,537  INFO [Thread-92] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70ddf90c from thread id: 120
2024-04-24T09:39:50,537  INFO [Thread-92] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:50,538  INFO [Thread-92] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:50,538  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:50,538  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70ddf90c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6770c391 will be shutdown
2024-04-24T09:39:50,538  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:50,538  INFO [Thread-92] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-04-24T09:39:50,539  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:50,540  INFO [Thread-92] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:50,541  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd, with PersistenceManager: null will be shutdown
2024-04-24T09:39:50,541  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb1fab3 created in the thread with id: 120
2024-04-24T09:39:50,544  INFO [Thread-92] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd from thread id: 120
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:50,588  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:50,589  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:50,589  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:50,589  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:50,589  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:50,589  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:50,589  INFO [Thread-92] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:39:50,613  INFO [Thread-92] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,3849486826753148/part1=p1value2/part0=502].
2024-04-24T09:39:50,613  INFO [Thread-92] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:50,665  WARN [Thread-92] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:50,666  INFO [Thread-92] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:50,667  INFO [Thread-92] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:50,667  INFO [Thread-92] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:50,667  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bb1fab3 will be shutdown
2024-04-24T09:39:50,668  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b9484f created in the thread with id: 120
2024-04-24T09:39:50,671  INFO [Thread-92] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:50,671  INFO [Thread-92] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:50,671  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:50,671  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7641cebd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16b9484f will be shutdown
2024-04-24T09:39:50,672  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:50,672  INFO [Thread-92] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -9
2024-04-24T09:39:50,672  INFO [Thread-92] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:50,673  INFO [Thread-92] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:50,674  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5fc005d7, with PersistenceManager: null will be shutdown
2024-04-24T09:39:50,674  INFO [Thread-92] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5fc005d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26f53085 created in the thread with id: 120
2024-04-24T09:39:50,678  INFO [Thread-92] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5fc005d7 from thread id: 120
2024-04-24T09:39:50,680  INFO [Thread-92] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:50,680  WARN [Thread-92] mapred.LocalJobRunner: job_local681537083_0002
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,3849486826753148/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:51,409  INFO [main] mapreduce.Job: Job job_local681537083_0002 running in uber mode : false
2024-04-24T09:39:51,409  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:51,410  INFO [main] mapreduce.Job: Job job_local681537083_0002 failed with state FAILED due to: NA
2024-04-24T09:39:51,413  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=564
		FILE: Number of bytes written=1020434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:51,459  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:51,459  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:51,460  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:51,461  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:51,461  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:51,463  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:51,463  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:51,464  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2ba024cb will be shutdown
2024-04-24T09:39:51,464  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fd7b79 created in the thread with id: 1
2024-04-24T09:39:51,467  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:51,468  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:51,468  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:51,468  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ba4f370, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fd7b79 will be shutdown
2024-04-24T09:39:51,468  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:51,468  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -10
2024-04-24T09:39:51,468  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:51,470  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:51,470  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88, with PersistenceManager: null will be shutdown
2024-04-24T09:39:51,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37a67cf created in the thread with id: 1
2024-04-24T09:39:51,474  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88 from thread id: 1
2024-04-24T09:39:51,476  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:51,492  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:51,499  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:51,533  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:51,534  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:51,534  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:51,535  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:51,536  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:51,536  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@37a67cf will be shutdown
2024-04-24T09:39:51,536  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@320ff86f created in the thread with id: 1
2024-04-24T09:39:51,539  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:51,540  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:51,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:51,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@472c9f88, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@320ff86f will be shutdown
2024-04-24T09:39:51,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:51,541  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -11
2024-04-24T09:39:51,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:51,542  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:51,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640, with PersistenceManager: null will be shutdown
2024-04-24T09:39:51,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3973b6d4 created in the thread with id: 1
2024-04-24T09:39:51,546  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640 from thread id: 1
2024-04-24T09:39:51,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_TEXTFILE[p1value2,502]	
2024-04-24T09:39:51,572  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:51,577  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:51,578  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:51,598  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:51,614  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1670046231_0003
2024-04-24T09:39:51,614  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:51,665  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:51,666  INFO [main] mapreduce.Job: Running job: job_local1670046231_0003
2024-04-24T09:39:51,666  INFO [Thread-138] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:51,669  INFO [Thread-138] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,669  INFO [Thread-138] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,671  INFO [Thread-138] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:51,672  INFO [Thread-138] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,672  INFO [Thread-138] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,686  INFO [Thread-138] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:51,686  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1670046231_0003_m_000000_0
2024-04-24T09:39:51,690  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,690  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,692  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,692  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,693  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:51,693  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:39:51,697  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,697  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,713  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:51,714  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1670046231_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:51,714  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,714  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,719  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:51,719  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1670046231_0003_m_000000_0 is allowed to commit now
2024-04-24T09:39:51,719  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:51,719  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:51,729  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1670046231_0003_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9338156330450134/part1=p1value2/part0=502
2024-04-24T09:39:51,730  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:51,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1670046231_0003_m_000000_0' done.
2024-04-24T09:39:51,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1670046231_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1533153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:51,730  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1670046231_0003_m_000000_0
2024-04-24T09:39:51,730  INFO [Thread-138] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:51,781  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:51,782  INFO [Thread-138] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:51,783  INFO [Thread-138] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:51,785  INFO [Thread-138] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:51,785  INFO [Thread-138] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:51,785  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@258ef5d1, with PersistenceManager: null will be shutdown
2024-04-24T09:39:51,786  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@258ef5d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75137c72 created in the thread with id: 168
2024-04-24T09:39:51,790  INFO [Thread-138] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@258ef5d1 from thread id: 168
2024-04-24T09:39:51,790  INFO [Thread-138] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:51,790  INFO [Thread-138] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:51,790  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:51,790  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@258ef5d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75137c72 will be shutdown
2024-04-24T09:39:51,791  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:51,791  INFO [Thread-138] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -12
2024-04-24T09:39:51,791  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:51,793  INFO [Thread-138] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:51,793  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df, with PersistenceManager: null will be shutdown
2024-04-24T09:39:51,793  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ed6574e created in the thread with id: 168
2024-04-24T09:39:51,796  INFO [Thread-138] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df from thread id: 168
2024-04-24T09:39:51,839  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:51,839  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:51,839  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:51,840  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:51,840  INFO [Thread-138] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_textfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:39:51,864  INFO [Thread-138] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9338156330450134/part1=p1value2/part0=502].
2024-04-24T09:39:51,864  INFO [Thread-138] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:51,904  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:51,905  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:51,905  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:51,905  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:51,905  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:51,905  WARN [Thread-138] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:51,905  INFO [Thread-138] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:51,906  INFO [Thread-138] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:51,906  INFO [Thread-138] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:51,907  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ed6574e will be shutdown
2024-04-24T09:39:51,907  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5287368b created in the thread with id: 168
2024-04-24T09:39:51,910  INFO [Thread-138] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:51,910  INFO [Thread-138] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:51,910  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:51,910  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2bd884df, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5287368b will be shutdown
2024-04-24T09:39:51,910  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:51,911  INFO [Thread-138] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -13
2024-04-24T09:39:51,911  INFO [Thread-138] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:51,912  INFO [Thread-138] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:51,912  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f78cb78, with PersistenceManager: null will be shutdown
2024-04-24T09:39:51,913  INFO [Thread-138] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f78cb78, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@356b83e3 created in the thread with id: 168
2024-04-24T09:39:51,915  INFO [Thread-138] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f78cb78 from thread id: 168
2024-04-24T09:39:51,917  INFO [Thread-138] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:51,917  WARN [Thread-138] mapred.LocalJobRunner: job_local1670046231_0003
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_SCRATCH0,9338156330450134/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:52,667  INFO [main] mapreduce.Job: Job job_local1670046231_0003 running in uber mode : false
2024-04-24T09:39:52,667  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:52,668  INFO [main] mapreduce.Job: Job job_local1670046231_0003 failed with state FAILED due to: NA
2024-04-24T09:39:52,671  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=876
		FILE: Number of bytes written=1533153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=691535872
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:52,719  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:52,719  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:52,720  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:52,721  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:52,722  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:52,723  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:52,724  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:52,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3973b6d4 will be shutdown
2024-04-24T09:39:52,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e81617a created in the thread with id: 1
2024-04-24T09:39:52,727  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:52,727  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:52,728  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:52,728  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@74eec640, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e81617a will be shutdown
2024-04-24T09:39:52,728  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:52,728  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -14
2024-04-24T09:39:52,728  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:52,729  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:52,730  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5, with PersistenceManager: null will be shutdown
2024-04-24T09:39:52,730  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@782cc5fa created in the thread with id: 1
2024-04-24T09:39:52,733  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5 from thread id: 1
2024-04-24T09:39:52,735  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:52,749  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:52,757  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:52,797  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:52,797  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:52,797  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:52,797  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:52,797  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:52,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:52,799  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:52,800  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:52,801  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:52,801  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@782cc5fa will be shutdown
2024-04-24T09:39:52,802  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d6b42cf created in the thread with id: 1
2024-04-24T09:39:52,805  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:52,806  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:52,806  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:52,806  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a2df0d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d6b42cf will be shutdown
2024-04-24T09:39:52,807  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:52,807  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -15
2024-04-24T09:39:52,807  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:52,808  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:52,809  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937, with PersistenceManager: null will be shutdown
2024-04-24T09:39:52,809  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@105dc04d created in the thread with id: 1
2024-04-24T09:39:52,812  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937 from thread id: 1
2024-04-24T09:39:52,861  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:52,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:52,863  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:52,863  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:52,865  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:52,865  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:52,866  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@105dc04d will be shutdown
2024-04-24T09:39:52,866  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@343db2f6 created in the thread with id: 1
2024-04-24T09:39:52,868  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:52,869  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:52,869  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:52,870  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5f0d8937, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@343db2f6 will be shutdown
2024-04-24T09:39:52,870  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:52,870  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -16
2024-04-24T09:39:52,871  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:52,872  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:52,872  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f, with PersistenceManager: null will be shutdown
2024-04-24T09:39:52,872  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ec3d8e4 created in the thread with id: 1
2024-04-24T09:39:52,875  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f from thread id: 1
2024-04-24T09:39:52,878  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:52,891  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:52,933  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:52,934  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:52,934  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:52,935  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:52,936  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:52,937  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:52,937  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ec3d8e4 will be shutdown
2024-04-24T09:39:52,937  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ddf42dd created in the thread with id: 1
2024-04-24T09:39:52,940  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:52,941  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:52,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:52,941  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@27db45f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ddf42dd will be shutdown
2024-04-24T09:39:52,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:52,941  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -17
2024-04-24T09:39:52,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:52,943  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:52,943  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2, with PersistenceManager: null will be shutdown
2024-04-24T09:39:52,944  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@277bc3a5 created in the thread with id: 1
2024-04-24T09:39:52,947  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2 from thread id: 1
2024-04-24T09:39:52,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:52,962  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:52,969  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:53,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:53,002  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:53,004  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:53,004  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:53,004  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@277bc3a5 will be shutdown
2024-04-24T09:39:53,005  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63c84d31 created in the thread with id: 1
2024-04-24T09:39:53,007  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:53,007  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:53,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:53,008  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@359e27d2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63c84d31 will be shutdown
2024-04-24T09:39:53,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:53,008  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -18
2024-04-24T09:39:53,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:53,009  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:53,010  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023, with PersistenceManager: null will be shutdown
2024-04-24T09:39:53,010  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26d73519 created in the thread with id: 1
2024-04-24T09:39:53,012  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023 from thread id: 1
2024-04-24T09:39:53,020  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:53,024  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:53,025  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:53,043  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:53,058  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1683679458_0004
2024-04-24T09:39:53,058  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:53,106  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:53,106  INFO [main] mapreduce.Job: Running job: job_local1683679458_0004
2024-04-24T09:39:53,129  INFO [Thread-189] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:53,132  INFO [Thread-189] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:53,134  INFO [Thread-189] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:53,134  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1683679458_0004_m_000000_0
2024-04-24T09:39:53,138  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:53,139  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:39:53,149  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1683679458_0004_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.5230232643849365/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:39:53,149  INFO [Thread-189] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:53,154  INFO [Thread-189] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_textfile/_DYN0.5230232643849365].
2024-04-24T09:39:53,155  INFO [Thread-189] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:53,190  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:53,191  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:53,191  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:53,191  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:53,191  WARN [Thread-189] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:53,191  INFO [Thread-189] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:53,192  INFO [Thread-189] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:53,193  INFO [Thread-189] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:53,194  INFO [Thread-189] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:53,194  INFO [Thread-189] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9750ba, with PersistenceManager: null will be shutdown
2024-04-24T09:39:53,194  INFO [Thread-189] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9750ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65c56128 created in the thread with id: 221
2024-04-24T09:39:53,196  INFO [Thread-189] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9750ba from thread id: 221
2024-04-24T09:39:53,197  INFO [Thread-189] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:53,197  INFO [Thread-189] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:53,197  INFO [Thread-189] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:53,197  INFO [Thread-189] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3d9750ba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65c56128 will be shutdown
2024-04-24T09:39:53,197  INFO [Thread-189] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:53,197  INFO [Thread-189] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -19
2024-04-24T09:39:53,198  INFO [Thread-189] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:53,199  INFO [Thread-189] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:53,199  INFO [Thread-189] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1235fc58, with PersistenceManager: null will be shutdown
2024-04-24T09:39:53,200  INFO [Thread-189] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1235fc58, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@776da649 created in the thread with id: 221
2024-04-24T09:39:53,202  INFO [Thread-189] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1235fc58 from thread id: 221
2024-04-24T09:39:53,203  INFO [Thread-189] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:53,203  WARN [Thread-189] mapred.LocalJobRunner: job_local1683679458_0004
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:39:54,129  INFO [main] mapreduce.Job: Job job_local1683679458_0004 running in uber mode : false
2024-04-24T09:39:54,130  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:39:54,130  INFO [main] mapreduce.Job: Job job_local1683679458_0004 failed with state FAILED due to: NA
2024-04-24T09:39:54,131  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:39:54,167  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:54,168  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:54,169  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:54,169  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:54,171  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:54,171  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:54,172  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26d73519 will be shutdown
2024-04-24T09:39:54,172  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40a28bda created in the thread with id: 1
2024-04-24T09:39:54,175  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:54,175  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:54,175  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:54,175  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a8fb023, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@40a28bda will be shutdown
2024-04-24T09:39:54,176  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:54,176  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -20
2024-04-24T09:39:54,176  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:54,177  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:54,177  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: null will be shutdown
2024-04-24T09:39:54,178  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30c8c6ab created in the thread with id: 1
2024-04-24T09:39:54,180  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f from thread id: 1
2024-04-24T09:39:54,182  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:54,195  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:54,196  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:54,216  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:54,223  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:54,228  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:54,248  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:39:54,266  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2040168736_0005
2024-04-24T09:39:54,266  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:54,312  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:54,312  INFO [main] mapreduce.Job: Running job: job_local2040168736_0005
2024-04-24T09:39:54,313  INFO [Thread-209] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:54,314  INFO [Thread-209] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:54,314  INFO [Thread-209] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:54,315  INFO [Thread-209] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:39:54,323  INFO [Thread-209] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:54,323  INFO [Thread-209] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:55,313  INFO [main] mapreduce.Job: Job job_local2040168736_0005 running in uber mode : false
2024-04-24T09:39:55,314  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:39:55,315  INFO [main] mapreduce.Job: Job job_local2040168736_0005 completed successfully
2024-04-24T09:39:55,315  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:39:55,316  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:55,328  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:55,329  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_TEXTFILE	
2024-04-24T09:39:55,669  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:55,669  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:55,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[1]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.709">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-24T09:39:55,715  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:55,715  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:55,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:55,718  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:55,718  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:55,719  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30c8c6ab will be shutdown
2024-04-24T09:39:55,719  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cc61b3b created in the thread with id: 1
2024-04-24T09:39:55,726  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 8be3574e-ba4d-47f3-91f2-fe86e6d83edb
2024-04-24T09:39:55,726  INFO [main] SessionState: Hive Session ID = 8be3574e-ba4d-47f3-91f2-fe86e6d83edb
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:39:55,726  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:39:55,732  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/8be3574e-ba4d-47f3-91f2-fe86e6d83edb
2024-04-24T09:39:55,735  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/8be3574e-ba4d-47f3-91f2-fe86e6d83edb
2024-04-24T09:39:55,738  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/8be3574e-ba4d-47f3-91f2-fe86e6d83edb/_tmp_space.db
2024-04-24T09:39:55,738  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:55,750  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_SEQUENCEFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.mapred.SequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_SEQUENCEFILE, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1, EXTERNAL=TRUE}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, EXTERNAL=TRUE, transactional=false, immutable=true}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:39:55,756  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:55,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:55,855  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:55,855  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:55,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:55,855  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:55,856  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:39:55,859  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:55,859  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:55,860  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2cc61b3b will be shutdown
2024-04-24T09:39:55,861  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a531637 created in the thread with id: 1
2024-04-24T09:39:55,864  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:55,864  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:55,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:55,865  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f4a605f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a531637 will be shutdown
2024-04-24T09:39:55,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:55,865  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -21
2024-04-24T09:39:55,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:55,867  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:55,868  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349, with PersistenceManager: null will be shutdown
2024-04-24T09:39:55,868  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@86377d5 created in the thread with id: 1
2024-04-24T09:39:55,870  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349 from thread id: 1
2024-04-24T09:39:55,871  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:55,904  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:55,913  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:55,949  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:55,950  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:55,951  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:55,951  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:55,951  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@86377d5 will be shutdown
2024-04-24T09:39:55,952  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e1762e6 created in the thread with id: 1
2024-04-24T09:39:55,955  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:55,955  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:55,956  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:55,956  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37fca349, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e1762e6 will be shutdown
2024-04-24T09:39:55,956  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:55,957  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -22
2024-04-24T09:39:55,957  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:55,959  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:55,960  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d, with PersistenceManager: null will be shutdown
2024-04-24T09:39:55,960  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54b2d002 created in the thread with id: 1
2024-04-24T09:39:55,963  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d from thread id: 1
2024-04-24T09:39:55,967  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value1,501]	
2024-04-24T09:39:55,995  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:55,999  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:55,999  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:56,017  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:56,031  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1026370177_0006
2024-04-24T09:39:56,031  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:56,076  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:56,076  INFO [main] mapreduce.Job: Running job: job_local1026370177_0006
2024-04-24T09:39:56,076  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:56,079  INFO [Thread-243] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,079  INFO [Thread-243] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,080  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:56,081  INFO [Thread-243] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,081  INFO [Thread-243] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,093  INFO [Thread-243] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:56,093  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1026370177_0006_m_000000_0
2024-04-24T09:39:56,099  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,099  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,101  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,101  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,101  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:56,102  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:39:56,108  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,108  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,137  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:56,141  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1026370177_0006_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:56,141  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,141  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,145  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:56,145  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1026370177_0006_m_000000_0 is allowed to commit now
2024-04-24T09:39:56,145  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:56,145  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:56,154  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1026370177_0006_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2621458195052483/part1=p1value1/part0=501
2024-04-24T09:39:56,155  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:56,155  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1026370177_0006_m_000000_0' done.
2024-04-24T09:39:56,155  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1026370177_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3069210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=750780416
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:56,156  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1026370177_0006_m_000000_0
2024-04-24T09:39:56,156  INFO [Thread-243] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:56,195  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:56,195  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:56,195  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:56,195  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:56,196  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:56,196  INFO [Thread-243] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:56,197  INFO [Thread-243] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:56,198  INFO [Thread-243] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:56,198  INFO [Thread-243] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:56,198  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c859b34, with PersistenceManager: null will be shutdown
2024-04-24T09:39:56,198  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c859b34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b498175 created in the thread with id: 277
2024-04-24T09:39:56,201  INFO [Thread-243] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c859b34 from thread id: 277
2024-04-24T09:39:56,201  INFO [Thread-243] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:56,201  INFO [Thread-243] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:56,201  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:56,201  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4c859b34, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b498175 will be shutdown
2024-04-24T09:39:56,202  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:56,202  INFO [Thread-243] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -23
2024-04-24T09:39:56,202  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:56,203  INFO [Thread-243] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:56,204  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff, with PersistenceManager: null will be shutdown
2024-04-24T09:39:56,204  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65c6f389 created in the thread with id: 277
2024-04-24T09:39:56,206  INFO [Thread-243] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff from thread id: 277
2024-04-24T09:39:56,247  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:56,248  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:56,249  INFO [Thread-243] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=501, part1=p1value1}].
2024-04-24T09:39:56,270  INFO [Thread-243] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2621458195052483/part1=p1value1/part0=501].
2024-04-24T09:39:56,270  INFO [Thread-243] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:56,307  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:56,308  WARN [Thread-243] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:56,308  INFO [Thread-243] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:56,309  INFO [Thread-243] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:56,309  INFO [Thread-243] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:56,310  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65c6f389 will be shutdown
2024-04-24T09:39:56,310  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68eab757 created in the thread with id: 277
2024-04-24T09:39:56,312  INFO [Thread-243] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:56,312  INFO [Thread-243] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:56,312  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:56,313  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b6e6aff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@68eab757 will be shutdown
2024-04-24T09:39:56,313  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:56,313  INFO [Thread-243] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -24
2024-04-24T09:39:56,313  INFO [Thread-243] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:56,314  INFO [Thread-243] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:56,314  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7835f998, with PersistenceManager: null will be shutdown
2024-04-24T09:39:56,315  INFO [Thread-243] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7835f998, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@553b826d created in the thread with id: 277
2024-04-24T09:39:56,317  INFO [Thread-243] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7835f998 from thread id: 277
2024-04-24T09:39:56,318  INFO [Thread-243] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:56,318  WARN [Thread-243] mapred.LocalJobRunner: job_local1026370177_0006
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2621458195052483/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:57,077  INFO [main] mapreduce.Job: Job job_local1026370177_0006 running in uber mode : false
2024-04-24T09:39:57,077  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:57,078  INFO [main] mapreduce.Job: Job job_local1026370177_0006 failed with state FAILED due to: NA
2024-04-24T09:39:57,081  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1458
		FILE: Number of bytes written=3069210
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=750780416
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:57,124  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:57,124  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:57,125  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:57,125  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:57,126  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:57,128  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:57,128  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:57,128  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54b2d002 will be shutdown
2024-04-24T09:39:57,129  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c2a3f0c created in the thread with id: 1
2024-04-24T09:39:57,131  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:57,131  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:57,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:57,132  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1191029d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c2a3f0c will be shutdown
2024-04-24T09:39:57,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:57,132  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -25
2024-04-24T09:39:57,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:57,134  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:57,135  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845, with PersistenceManager: null will be shutdown
2024-04-24T09:39:57,135  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cef885d created in the thread with id: 1
2024-04-24T09:39:57,138  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845 from thread id: 1
2024-04-24T09:39:57,141  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:57,154  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:57,161  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:57,193  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:57,194  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:57,195  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:57,195  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:57,195  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@cef885d will be shutdown
2024-04-24T09:39:57,196  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c8e5ac4 created in the thread with id: 1
2024-04-24T09:39:57,198  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:57,198  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:57,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:57,198  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61bd0845, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c8e5ac4 will be shutdown
2024-04-24T09:39:57,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:57,198  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -26
2024-04-24T09:39:57,199  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:57,200  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:57,200  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8, with PersistenceManager: null will be shutdown
2024-04-24T09:39:57,201  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a0c512b created in the thread with id: 1
2024-04-24T09:39:57,203  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8 from thread id: 1
2024-04-24T09:39:57,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-04-24T09:39:57,232  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:57,236  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:57,237  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:57,256  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:57,273  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local858784567_0007
2024-04-24T09:39:57,273  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:57,360  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:57,360  INFO [main] mapreduce.Job: Running job: job_local858784567_0007
2024-04-24T09:39:57,360  INFO [Thread-289] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:57,363  INFO [Thread-289] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,363  INFO [Thread-289] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,364  INFO [Thread-289] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:57,365  INFO [Thread-289] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,365  INFO [Thread-289] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,377  INFO [Thread-289] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:57,377  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local858784567_0007_m_000000_0
2024-04-24T09:39:57,380  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,380  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,382  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,382  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,382  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:57,383  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:39:57,386  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,386  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,401  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:57,401  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local858784567_0007_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:57,402  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,402  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,406  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:57,406  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local858784567_0007_m_000000_0 is allowed to commit now
2024-04-24T09:39:57,406  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:57,406  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:57,417  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local858784567_0007_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9373527159841548/part1=p1value2/part0=502
2024-04-24T09:39:57,417  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:57,417  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local858784567_0007_m_000000_0' done.
2024-04-24T09:39:57,418  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local858784567_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3579928
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:57,418  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local858784567_0007_m_000000_0
2024-04-24T09:39:57,418  INFO [Thread-289] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:57,462  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:57,462  INFO [Thread-289] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:57,464  INFO [Thread-289] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:57,464  INFO [Thread-289] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:57,464  INFO [Thread-289] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:57,465  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b6852e1, with PersistenceManager: null will be shutdown
2024-04-24T09:39:57,465  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b6852e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@358d62d created in the thread with id: 325
2024-04-24T09:39:57,466  INFO [Thread-289] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b6852e1 from thread id: 325
2024-04-24T09:39:57,467  INFO [Thread-289] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:57,467  INFO [Thread-289] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:57,467  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:57,467  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b6852e1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@358d62d will be shutdown
2024-04-24T09:39:57,467  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:57,467  INFO [Thread-289] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -27
2024-04-24T09:39:57,467  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:57,469  INFO [Thread-289] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:57,469  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1, with PersistenceManager: null will be shutdown
2024-04-24T09:39:57,469  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3828273a created in the thread with id: 325
2024-04-24T09:39:57,471  INFO [Thread-289] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1 from thread id: 325
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:57,513  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:57,514  INFO [Thread-289] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:39:57,536  INFO [Thread-289] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9373527159841548/part1=p1value2/part0=502].
2024-04-24T09:39:57,537  INFO [Thread-289] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:57,573  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:57,574  WARN [Thread-289] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:57,575  INFO [Thread-289] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:57,576  INFO [Thread-289] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:57,576  INFO [Thread-289] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:57,576  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3828273a will be shutdown
2024-04-24T09:39:57,576  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74b6ad83 created in the thread with id: 325
2024-04-24T09:39:57,579  INFO [Thread-289] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:57,579  INFO [Thread-289] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:57,580  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:57,580  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e816ca1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74b6ad83 will be shutdown
2024-04-24T09:39:57,580  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:57,580  INFO [Thread-289] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -28
2024-04-24T09:39:57,580  INFO [Thread-289] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:57,581  INFO [Thread-289] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:57,582  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ae34a7d, with PersistenceManager: null will be shutdown
2024-04-24T09:39:57,582  INFO [Thread-289] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ae34a7d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6648482 created in the thread with id: 325
2024-04-24T09:39:57,584  INFO [Thread-289] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ae34a7d from thread id: 325
2024-04-24T09:39:57,585  INFO [Thread-289] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:57,586  WARN [Thread-289] mapred.LocalJobRunner: job_local858784567_0007
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,9373527159841548/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:58,360  INFO [main] mapreduce.Job: Job job_local858784567_0007 running in uber mode : false
2024-04-24T09:39:58,361  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:58,361  INFO [main] mapreduce.Job: Job job_local858784567_0007 failed with state FAILED due to: NA
2024-04-24T09:39:58,364  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=1770
		FILE: Number of bytes written=3579928
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:58,406  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:58,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:58,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:58,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:58,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:58,407  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:58,408  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:39:58,411  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:58,411  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:58,412  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a0c512b will be shutdown
2024-04-24T09:39:58,413  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44392e64 created in the thread with id: 1
2024-04-24T09:39:58,415  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:58,416  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:58,416  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:58,416  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f725b8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44392e64 will be shutdown
2024-04-24T09:39:58,416  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:58,416  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -29
2024-04-24T09:39:58,416  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:58,418  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:58,419  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7, with PersistenceManager: null will be shutdown
2024-04-24T09:39:58,419  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5972e3a created in the thread with id: 1
2024-04-24T09:39:58,422  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7 from thread id: 1
2024-04-24T09:39:58,424  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:58,440  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:58,447  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:58,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:58,485  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:58,486  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:58,486  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:58,486  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5972e3a will be shutdown
2024-04-24T09:39:58,487  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@749ee0e3 created in the thread with id: 1
2024-04-24T09:39:58,490  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:58,490  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:58,491  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:58,491  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f293cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@749ee0e3 will be shutdown
2024-04-24T09:39:58,491  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:58,491  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -30
2024-04-24T09:39:58,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:58,494  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:58,494  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412, with PersistenceManager: null will be shutdown
2024-04-24T09:39:58,495  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69d902f9 created in the thread with id: 1
2024-04-24T09:39:58,497  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412 from thread id: 1
2024-04-24T09:39:58,501  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE[p1value2,502]	
2024-04-24T09:39:58,523  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:58,528  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:58,529  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:58,547  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:58,562  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1783189070_0008
2024-04-24T09:39:58,562  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:39:58,607  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:39:58,607  INFO [main] mapreduce.Job: Running job: job_local1783189070_0008
2024-04-24T09:39:58,607  INFO [Thread-335] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:39:58,610  INFO [Thread-335] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,610  INFO [Thread-335] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,611  INFO [Thread-335] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:39:58,612  INFO [Thread-335] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,612  INFO [Thread-335] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,624  INFO [Thread-335] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:39:58,624  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1783189070_0008_m_000000_0
2024-04-24T09:39:58,626  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,626  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,628  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,628  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,628  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:39:58,629  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:39:58,632  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,632  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,646  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:58,647  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1783189070_0008_m_000000_0 is done. And is in the process of committing
2024-04-24T09:39:58,647  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,647  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,651  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:39:58,651  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1783189070_0008_m_000000_0 is allowed to commit now
2024-04-24T09:39:58,651  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:39:58,651  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:39:58,660  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1783189070_0008_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2711433733594728/part1=p1value2/part0=502
2024-04-24T09:39:58,661  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:39:58,661  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1783189070_0008_m_000000_0' done.
2024-04-24T09:39:58,661  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1783189070_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4093036
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:58,661  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1783189070_0008_m_000000_0
2024-04-24T09:39:58,661  INFO [Thread-335] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:58,704  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:58,704  INFO [Thread-335] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:58,705  INFO [Thread-335] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:58,706  INFO [Thread-335] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:58,706  INFO [Thread-335] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:58,707  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bfd4eaf, with PersistenceManager: null will be shutdown
2024-04-24T09:39:58,707  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bfd4eaf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5832a255 created in the thread with id: 373
2024-04-24T09:39:58,709  INFO [Thread-335] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bfd4eaf from thread id: 373
2024-04-24T09:39:58,709  INFO [Thread-335] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:58,709  INFO [Thread-335] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:58,709  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:58,710  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4bfd4eaf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5832a255 will be shutdown
2024-04-24T09:39:58,710  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:58,710  INFO [Thread-335] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -31
2024-04-24T09:39:58,710  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:58,711  INFO [Thread-335] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:58,711  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727, with PersistenceManager: null will be shutdown
2024-04-24T09:39:58,712  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f442be4 created in the thread with id: 373
2024-04-24T09:39:58,714  INFO [Thread-335] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727 from thread id: 373
2024-04-24T09:39:58,752  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:58,752  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:58,752  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:58,752  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:58,753  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:58,753  INFO [Thread-335] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_sequencefile has new partitions [{part0=502, part1=p1value2}].
2024-04-24T09:39:58,773  INFO [Thread-335] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2711433733594728/part1=p1value2/part0=502].
2024-04-24T09:39:58,774  INFO [Thread-335] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:39:58,806  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:58,806  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:58,806  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:58,807  WARN [Thread-335] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:58,807  INFO [Thread-335] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:58,808  INFO [Thread-335] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:58,808  INFO [Thread-335] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:58,808  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@f442be4 will be shutdown
2024-04-24T09:39:58,808  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@80ea4d4 created in the thread with id: 373
2024-04-24T09:39:58,810  INFO [Thread-335] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:58,810  INFO [Thread-335] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:58,810  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:58,810  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e284727, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@80ea4d4 will be shutdown
2024-04-24T09:39:58,811  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:58,811  INFO [Thread-335] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -32
2024-04-24T09:39:58,811  INFO [Thread-335] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:58,812  INFO [Thread-335] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:58,812  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63a649c6, with PersistenceManager: null will be shutdown
2024-04-24T09:39:58,812  INFO [Thread-335] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63a649c6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5480f27b created in the thread with id: 373
2024-04-24T09:39:58,814  INFO [Thread-335] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63a649c6 from thread id: 373
2024-04-24T09:39:58,816  INFO [Thread-335] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:39:58,816  WARN [Thread-335] mapred.LocalJobRunner: job_local1783189070_0008
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_SCRATCH0,2711433733594728/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:39:59,607  INFO [main] mapreduce.Job: Job job_local1783189070_0008 running in uber mode : false
2024-04-24T09:39:59,608  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:39:59,608  INFO [main] mapreduce.Job: Job job_local1783189070_0008 failed with state FAILED due to: NA
2024-04-24T09:39:59,612  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2082
		FILE: Number of bytes written=4093036
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=752877568
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:59,654  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:59,655  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:59,655  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:59,655  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:59,657  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:59,657  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:59,657  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69d902f9 will be shutdown
2024-04-24T09:39:59,658  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b9c716f created in the thread with id: 1
2024-04-24T09:39:59,659  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:59,660  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:59,660  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:59,660  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b5c9412, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b9c716f will be shutdown
2024-04-24T09:39:59,660  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:59,660  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -33
2024-04-24T09:39:59,660  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:59,662  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:59,663  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37, with PersistenceManager: null will be shutdown
2024-04-24T09:39:59,663  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e355249 created in the thread with id: 1
2024-04-24T09:39:59,665  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37 from thread id: 1
2024-04-24T09:39:59,668  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:59,680  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:59,687  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:59,719  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:59,720  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:59,721  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:59,721  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:59,721  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e355249 will be shutdown
2024-04-24T09:39:59,722  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bf9fd0 created in the thread with id: 1
2024-04-24T09:39:59,724  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:59,724  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:59,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:59,725  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e02cc37, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14bf9fd0 will be shutdown
2024-04-24T09:39:59,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:59,725  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -34
2024-04-24T09:39:59,725  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:59,727  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:59,727  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377, with PersistenceManager: null will be shutdown
2024-04-24T09:39:59,727  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2befb16f created in the thread with id: 1
2024-04-24T09:39:59,729  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377 from thread id: 1
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:59,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:59,773  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:59,773  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:39:59,775  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:59,775  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:59,775  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2befb16f will be shutdown
2024-04-24T09:39:59,776  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27b7204 created in the thread with id: 1
2024-04-24T09:39:59,778  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:59,778  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:59,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:59,778  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36cf6377, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27b7204 will be shutdown
2024-04-24T09:39:59,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:59,778  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -35
2024-04-24T09:39:59,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:59,780  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:59,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e, with PersistenceManager: null will be shutdown
2024-04-24T09:39:59,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@266a47fd created in the thread with id: 1
2024-04-24T09:39:59,782  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e from thread id: 1
2024-04-24T09:39:59,784  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:59,800  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:59,840  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:59,840  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:39:59,841  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:39:59,842  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:59,842  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:59,843  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@266a47fd will be shutdown
2024-04-24T09:39:59,843  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fc256ec created in the thread with id: 1
2024-04-24T09:39:59,845  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:59,845  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:59,845  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:59,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@687fd6e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4fc256ec will be shutdown
2024-04-24T09:39:59,845  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:59,845  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -36
2024-04-24T09:39:59,845  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:59,847  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:59,847  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3, with PersistenceManager: null will be shutdown
2024-04-24T09:39:59,847  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e27d97b created in the thread with id: 1
2024-04-24T09:39:59,849  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3 from thread id: 1
2024-04-24T09:39:59,851  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:39:59,862  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:39:59,869  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:39:59,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:39:59,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:39:59,905  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:39:59,905  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:39:59,906  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:39:59,906  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:39:59,908  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:39:59,908  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:39:59,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e27d97b will be shutdown
2024-04-24T09:39:59,909  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f3f554f created in the thread with id: 1
2024-04-24T09:39:59,911  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:39:59,911  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:39:59,911  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:59,911  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@36b761e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f3f554f will be shutdown
2024-04-24T09:39:59,911  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:39:59,911  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -37
2024-04-24T09:39:59,912  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:39:59,913  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:39:59,913  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070, with PersistenceManager: null will be shutdown
2024-04-24T09:39:59,914  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3346e906 created in the thread with id: 1
2024-04-24T09:39:59,915  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070 from thread id: 1
2024-04-24T09:39:59,923  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:39:59,927  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:39:59,928  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:39:59,947  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:39:59,963  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1883701907_0009
2024-04-24T09:39:59,963  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:00,020  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:00,020  INFO [main] mapreduce.Job: Running job: job_local1883701907_0009
2024-04-24T09:40:00,020  INFO [Thread-386] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:00,024  INFO [Thread-386] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:00,025  INFO [Thread-386] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:00,025  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1883701907_0009_m_000000_0
2024-04-24T09:40:00,029  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:00,030  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:40:00,036  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local1883701907_0009_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.7240767991100936/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:40:00,036  INFO [Thread-386] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:00,039  INFO [Thread-386] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_sequencefile/_DYN0.7240767991100936].
2024-04-24T09:40:00,039  INFO [Thread-386] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:00,077  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:00,078  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:00,078  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:00,078  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:00,078  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:00,078  WARN [Thread-386] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:00,078  INFO [Thread-386] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:00,079  INFO [Thread-386] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:00,080  INFO [Thread-386] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:00,080  INFO [Thread-386] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:00,080  INFO [Thread-386] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58cd1ec6, with PersistenceManager: null will be shutdown
2024-04-24T09:40:00,080  INFO [Thread-386] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58cd1ec6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e5ba186 created in the thread with id: 426
2024-04-24T09:40:00,082  INFO [Thread-386] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58cd1ec6 from thread id: 426
2024-04-24T09:40:00,082  INFO [Thread-386] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:00,082  INFO [Thread-386] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:00,083  INFO [Thread-386] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:00,083  INFO [Thread-386] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58cd1ec6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e5ba186 will be shutdown
2024-04-24T09:40:00,083  INFO [Thread-386] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:00,083  INFO [Thread-386] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -38
2024-04-24T09:40:00,083  INFO [Thread-386] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:00,084  INFO [Thread-386] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:00,084  INFO [Thread-386] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ac65fa9, with PersistenceManager: null will be shutdown
2024-04-24T09:40:00,085  INFO [Thread-386] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ac65fa9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@72a4c319 created in the thread with id: 426
2024-04-24T09:40:00,087  INFO [Thread-386] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@ac65fa9 from thread id: 426
2024-04-24T09:40:00,088  INFO [Thread-386] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:00,088  WARN [Thread-386] mapred.LocalJobRunner: job_local1883701907_0009
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:40:01,020  INFO [main] mapreduce.Job: Job job_local1883701907_0009 running in uber mode : false
2024-04-24T09:40:01,021  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:01,021  INFO [main] mapreduce.Job: Job job_local1883701907_0009 failed with state FAILED due to: NA
2024-04-24T09:40:01,021  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:01,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:01,058  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:01,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:01,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:01,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:01,059  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:01,059  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:01,060  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:01,062  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:01,062  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:01,062  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3346e906 will be shutdown
2024-04-24T09:40:01,063  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@da67c46 created in the thread with id: 1
2024-04-24T09:40:01,064  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:01,064  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:01,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:01,065  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cb76070, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@da67c46 will be shutdown
2024-04-24T09:40:01,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:01,065  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -39
2024-04-24T09:40:01,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:01,066  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:01,067  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: null will be shutdown
2024-04-24T09:40:01,067  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d3990a5 created in the thread with id: 1
2024-04-24T09:40:01,068  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603 from thread id: 1
2024-04-24T09:40:01,071  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:40:01,081  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:01,082  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:40:01,093  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:01,100  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:01,105  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:01,124  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:40:01,167  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local815062968_0010
2024-04-24T09:40:01,167  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:01,216  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:01,216  INFO [main] mapreduce.Job: Running job: job_local815062968_0010
2024-04-24T09:40:01,217  INFO [Thread-406] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:01,217  INFO [Thread-406] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:01,217  INFO [Thread-406] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:01,217  INFO [Thread-406] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:40:01,225  INFO [Thread-406] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:01,225  INFO [Thread-406] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:02,217  INFO [main] mapreduce.Job: Job job_local815062968_0010 running in uber mode : false
2024-04-24T09:40:02,217  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:02,218  INFO [main] mapreduce.Job: Job job_local815062968_0010 completed successfully
2024-04-24T09:40:02,218  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:02,219  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:40:02,237  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:02,237  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_SEQUENCEFILE	
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,388  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[2]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.399">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,426  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,428  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:02,428  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:02,428  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d3990a5 will be shutdown
2024-04-24T09:40:02,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@261609a7 created in the thread with id: 1
2024-04-24T09:40:02,431  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = dc6d8be1-9e0f-4df8-93de-2875dbbbdc19
2024-04-24T09:40:02,431  INFO [main] SessionState: Hive Session ID = dc6d8be1-9e0f-4df8-93de-2875dbbbdc19
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:02,431  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:02,437  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/dc6d8be1-9e0f-4df8-93de-2875dbbbdc19
2024-04-24T09:40:02,440  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/dc6d8be1-9e0f-4df8-93de-2875dbbbdc19
2024-04-24T09:40:02,442  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/dc6d8be1-9e0f-4df8-93de-2875dbbbdc19/_tmp_space.db
2024-04-24T09:40:02,442  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:02,445  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_RCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_RCFILE, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1, EXTERNAL=TRUE}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:40:02,449  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,509  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:02,510  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:02,512  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:02,512  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:02,512  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@261609a7 will be shutdown
2024-04-24T09:40:02,512  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17ea3bc0 created in the thread with id: 1
2024-04-24T09:40:02,514  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:02,514  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:02,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:02,515  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39109603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17ea3bc0 will be shutdown
2024-04-24T09:40:02,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:02,515  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -40
2024-04-24T09:40:02,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:02,516  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:02,517  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1, with PersistenceManager: null will be shutdown
2024-04-24T09:40:02,517  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e5af973 created in the thread with id: 1
2024-04-24T09:40:02,518  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1 from thread id: 1
2024-04-24T09:40:02,520  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:02,532  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:02,540  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,573  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:02,575  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:02,575  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:02,575  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e5af973 will be shutdown
2024-04-24T09:40:02,575  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@511a307e created in the thread with id: 1
2024-04-24T09:40:02,577  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:02,577  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:02,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:02,578  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d57b8f1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@511a307e will be shutdown
2024-04-24T09:40:02,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:02,578  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -41
2024-04-24T09:40:02,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:02,580  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:02,580  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5, with PersistenceManager: null will be shutdown
2024-04-24T09:40:02,580  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@799fc4c9 created in the thread with id: 1
2024-04-24T09:40:02,582  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5 from thread id: 1
2024-04-24T09:40:02,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value1,501]	
2024-04-24T09:40:02,605  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:02,610  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:02,611  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:02,630  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:02,643  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2075500926_0011
2024-04-24T09:40:02,643  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:02,706  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:02,706  INFO [main] mapreduce.Job: Running job: job_local2075500926_0011
2024-04-24T09:40:02,706  INFO [Thread-440] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:02,708  INFO [Thread-440] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,708  INFO [Thread-440] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,709  INFO [Thread-440] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:02,710  INFO [Thread-440] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,710  INFO [Thread-440] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,721  INFO [Thread-440] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:02,721  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2075500926_0011_m_000000_0
2024-04-24T09:40:02,726  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,726  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,728  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,728  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,728  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:02,728  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:40:02,734  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,734  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,761  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:02,761  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-04-24T09:40:02,761  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-04-24T09:40:02,763  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2075500926_0011_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:02,763  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,763  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,768  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:02,768  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2075500926_0011_m_000000_0 is allowed to commit now
2024-04-24T09:40:02,768  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:02,768  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:02,778  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2075500926_0011_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,46897233240714375/part1=p1value1/part0=501
2024-04-24T09:40:02,779  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:02,779  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2075500926_0011_m_000000_0' done.
2024-04-24T09:40:02,779  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2075500926_0011_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5627086
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=812122112
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:02,779  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2075500926_0011_m_000000_0
2024-04-24T09:40:02,779  INFO [Thread-440] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,821  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,821  INFO [Thread-440] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:02,822  INFO [Thread-440] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:02,823  INFO [Thread-440] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:02,823  INFO [Thread-440] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:02,823  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@622743b0, with PersistenceManager: null will be shutdown
2024-04-24T09:40:02,824  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@622743b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ee615d0 created in the thread with id: 482
2024-04-24T09:40:02,825  INFO [Thread-440] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@622743b0 from thread id: 482
2024-04-24T09:40:02,825  INFO [Thread-440] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:02,826  INFO [Thread-440] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:02,826  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:02,826  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@622743b0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ee615d0 will be shutdown
2024-04-24T09:40:02,826  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:02,826  INFO [Thread-440] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -42
2024-04-24T09:40:02,826  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:02,827  INFO [Thread-440] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:02,828  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e, with PersistenceManager: null will be shutdown
2024-04-24T09:40:02,828  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@46b13152 created in the thread with id: 482
2024-04-24T09:40:02,829  INFO [Thread-440] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e from thread id: 482
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,871  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,872  INFO [Thread-440] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part1=p1value1, part0=501}].
2024-04-24T09:40:02,893  INFO [Thread-440] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,46897233240714375/part1=p1value1/part0=501].
2024-04-24T09:40:02,893  INFO [Thread-440] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:02,928  WARN [Thread-440] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:02,929  INFO [Thread-440] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:02,929  INFO [Thread-440] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:02,930  INFO [Thread-440] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:02,930  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@46b13152 will be shutdown
2024-04-24T09:40:02,930  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70107c03 created in the thread with id: 482
2024-04-24T09:40:02,932  INFO [Thread-440] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:02,932  INFO [Thread-440] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:02,932  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:02,932  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6ee155e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70107c03 will be shutdown
2024-04-24T09:40:02,932  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:02,932  INFO [Thread-440] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -43
2024-04-24T09:40:02,933  INFO [Thread-440] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:02,934  INFO [Thread-440] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:02,934  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68d8c10f, with PersistenceManager: null will be shutdown
2024-04-24T09:40:02,934  INFO [Thread-440] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68d8c10f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b2ff6ae created in the thread with id: 482
2024-04-24T09:40:02,936  INFO [Thread-440] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68d8c10f from thread id: 482
2024-04-24T09:40:02,937  INFO [Thread-440] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:02,937  WARN [Thread-440] mapred.LocalJobRunner: job_local2075500926_0011
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,46897233240714375/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:03,706  INFO [main] mapreduce.Job: Job job_local2075500926_0011 running in uber mode : false
2024-04-24T09:40:03,707  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:03,707  INFO [main] mapreduce.Job: Job job_local2075500926_0011 failed with state FAILED due to: NA
2024-04-24T09:40:03,710  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2664
		FILE: Number of bytes written=5627086
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=812122112
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:03,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:03,756  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:03,756  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:03,758  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:03,758  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:03,758  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@799fc4c9 will be shutdown
2024-04-24T09:40:03,759  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d3768ce created in the thread with id: 1
2024-04-24T09:40:03,761  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:03,761  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:03,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:03,761  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@516155b5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d3768ce will be shutdown
2024-04-24T09:40:03,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:03,761  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -44
2024-04-24T09:40:03,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:03,763  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:03,763  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff, with PersistenceManager: null will be shutdown
2024-04-24T09:40:03,763  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25dc2c0 created in the thread with id: 1
2024-04-24T09:40:03,765  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff from thread id: 1
2024-04-24T09:40:03,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:03,779  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:03,785  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:03,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:03,816  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:03,817  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:03,817  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:03,818  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25dc2c0 will be shutdown
2024-04-24T09:40:03,818  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@556944cd created in the thread with id: 1
2024-04-24T09:40:03,820  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:03,820  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:03,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:03,820  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4add4dff, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@556944cd will be shutdown
2024-04-24T09:40:03,821  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:03,821  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -45
2024-04-24T09:40:03,821  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:03,822  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:03,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f, with PersistenceManager: null will be shutdown
2024-04-24T09:40:03,823  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c3ca482 created in the thread with id: 1
2024-04-24T09:40:03,825  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f from thread id: 1
2024-04-24T09:40:03,827  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-04-24T09:40:03,846  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:03,850  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:03,851  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:03,868  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:03,881  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1392064685_0012
2024-04-24T09:40:03,881  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:03,926  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:03,926  INFO [main] mapreduce.Job: Running job: job_local1392064685_0012
2024-04-24T09:40:03,926  INFO [Thread-486] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:03,928  INFO [Thread-486] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,928  INFO [Thread-486] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,929  INFO [Thread-486] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:03,930  INFO [Thread-486] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,930  INFO [Thread-486] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,942  INFO [Thread-486] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:03,942  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1392064685_0012_m_000000_0
2024-04-24T09:40:03,945  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,946  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,948  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,948  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,948  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:03,948  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:03,951  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,951  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1392064685_0012_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,966  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,971  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:03,971  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1392064685_0012_m_000000_0 is allowed to commit now
2024-04-24T09:40:03,971  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:03,971  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:03,981  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1392064685_0012_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,32993417802016145/part1=p1value2/part0=502
2024-04-24T09:40:03,981  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:03,982  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1392064685_0012_m_000000_0' done.
2024-04-24T09:40:03,982  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1392064685_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6140315
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=812122112
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:03,982  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1392064685_0012_m_000000_0
2024-04-24T09:40:03,982  INFO [Thread-486] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:04,025  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:04,025  INFO [Thread-486] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:04,026  INFO [Thread-486] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:04,027  INFO [Thread-486] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:04,027  INFO [Thread-486] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:04,027  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d9befdc, with PersistenceManager: null will be shutdown
2024-04-24T09:40:04,028  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d9befdc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ee3d677 created in the thread with id: 530
2024-04-24T09:40:04,029  INFO [Thread-486] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d9befdc from thread id: 530
2024-04-24T09:40:04,029  INFO [Thread-486] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:04,029  INFO [Thread-486] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:04,030  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:04,030  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2d9befdc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ee3d677 will be shutdown
2024-04-24T09:40:04,030  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:04,030  INFO [Thread-486] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -46
2024-04-24T09:40:04,030  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:04,031  INFO [Thread-486] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:04,031  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd, with PersistenceManager: null will be shutdown
2024-04-24T09:40:04,032  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47fe27f3 created in the thread with id: 530
2024-04-24T09:40:04,033  INFO [Thread-486] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd from thread id: 530
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:04,076  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:04,076  INFO [Thread-486] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:04,097  INFO [Thread-486] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,32993417802016145/part1=p1value2/part0=502].
2024-04-24T09:40:04,097  INFO [Thread-486] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:04,129  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:04,129  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:04,129  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:04,129  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:04,129  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:04,130  WARN [Thread-486] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:04,130  INFO [Thread-486] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:04,131  INFO [Thread-486] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:04,131  INFO [Thread-486] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:04,131  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47fe27f3 will be shutdown
2024-04-24T09:40:04,131  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e7af983 created in the thread with id: 530
2024-04-24T09:40:04,133  INFO [Thread-486] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:04,133  INFO [Thread-486] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:04,133  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:04,133  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5cfcfcdd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e7af983 will be shutdown
2024-04-24T09:40:04,134  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:04,134  INFO [Thread-486] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -47
2024-04-24T09:40:04,134  INFO [Thread-486] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:04,135  INFO [Thread-486] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:04,136  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71ef079f, with PersistenceManager: null will be shutdown
2024-04-24T09:40:04,136  INFO [Thread-486] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71ef079f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1df2b7d3 created in the thread with id: 530
2024-04-24T09:40:04,137  INFO [Thread-486] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@71ef079f from thread id: 530
2024-04-24T09:40:04,138  INFO [Thread-486] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:04,138  WARN [Thread-486] mapred.LocalJobRunner: job_local1392064685_0012
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,32993417802016145/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:04,927  INFO [main] mapreduce.Job: Job job_local1392064685_0012 running in uber mode : false
2024-04-24T09:40:04,927  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:04,928  INFO [main] mapreduce.Job: Job job_local1392064685_0012 failed with state FAILED due to: NA
2024-04-24T09:40:04,931  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=2976
		FILE: Number of bytes written=6140315
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=812122112
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:04,974  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:04,974  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:04,975  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:04,977  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:04,977  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:04,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c3ca482 will be shutdown
2024-04-24T09:40:04,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cb91fa4 created in the thread with id: 1
2024-04-24T09:40:04,979  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:04,979  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:04,980  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:04,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@239bc43f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cb91fa4 will be shutdown
2024-04-24T09:40:04,980  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:04,980  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -48
2024-04-24T09:40:04,980  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:04,981  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:04,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908, with PersistenceManager: null will be shutdown
2024-04-24T09:40:04,982  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43b74979 created in the thread with id: 1
2024-04-24T09:40:04,983  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908 from thread id: 1
2024-04-24T09:40:04,985  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:04,997  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:05,004  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:05,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:05,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:05,036  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:05,038  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:05,038  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:05,038  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43b74979 will be shutdown
2024-04-24T09:40:05,039  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c28009f created in the thread with id: 1
2024-04-24T09:40:05,040  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:05,041  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:05,041  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:05,041  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13cae908, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c28009f will be shutdown
2024-04-24T09:40:05,041  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:05,041  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -49
2024-04-24T09:40:05,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:05,043  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:05,043  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85, with PersistenceManager: null will be shutdown
2024-04-24T09:40:05,044  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@173b24c4 created in the thread with id: 1
2024-04-24T09:40:05,045  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85 from thread id: 1
2024-04-24T09:40:05,048  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_RCFILE[p1value2,502]	
2024-04-24T09:40:05,066  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:05,071  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:05,071  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:05,088  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:05,104  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2002562188_0013
2024-04-24T09:40:05,104  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:05,137  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-24T09:40:05,152  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:05,152  INFO [main] mapreduce.Job: Running job: job_local2002562188_0013
2024-04-24T09:40:05,152  INFO [Thread-532] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:05,154  INFO [Thread-532] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,154  INFO [Thread-532] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,156  INFO [Thread-532] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:05,156  INFO [Thread-532] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,156  INFO [Thread-532] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,168  INFO [Thread-532] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:05,168  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2002562188_0013_m_000000_0
2024-04-24T09:40:05,171  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,171  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,173  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,174  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,174  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:05,174  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:05,177  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,177  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,214  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:05,214  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 20,  Compr Total Column Value Length: 20
2024-04-24T09:40:05,214  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-24T09:40:05,214  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2002562188_0013_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:05,215  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,215  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,218  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:05,218  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local2002562188_0013_m_000000_0 is allowed to commit now
2024-04-24T09:40:05,218  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:05,218  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:05,227  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local2002562188_0013_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,4224355142958671/part1=p1value2/part0=502
2024-04-24T09:40:05,228  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:05,228  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2002562188_0013_m_000000_0' done.
2024-04-24T09:40:05,228  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2002562188_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6653531
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=815792128
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:05,228  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2002562188_0013_m_000000_0
2024-04-24T09:40:05,228  INFO [Thread-532] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:05,267  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:05,268  INFO [Thread-532] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:05,269  INFO [Thread-532] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:05,269  INFO [Thread-532] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:05,269  INFO [Thread-532] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:05,270  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@217b8aba, with PersistenceManager: null will be shutdown
2024-04-24T09:40:05,270  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@217b8aba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ecd699b created in the thread with id: 578
2024-04-24T09:40:05,272  INFO [Thread-532] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@217b8aba from thread id: 578
2024-04-24T09:40:05,272  INFO [Thread-532] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:05,272  INFO [Thread-532] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:05,273  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:05,273  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@217b8aba, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ecd699b will be shutdown
2024-04-24T09:40:05,273  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:05,273  INFO [Thread-532] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -50
2024-04-24T09:40:05,273  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:05,275  INFO [Thread-532] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:05,275  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39, with PersistenceManager: null will be shutdown
2024-04-24T09:40:05,275  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74111fa5 created in the thread with id: 578
2024-04-24T09:40:05,277  INFO [Thread-532] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39 from thread id: 578
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:05,316  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:05,316  INFO [Thread-532] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:05,337  INFO [Thread-532] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,4224355142958671/part1=p1value2/part0=502].
2024-04-24T09:40:05,337  INFO [Thread-532] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:05,369  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:05,369  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:05,369  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:05,370  WARN [Thread-532] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:05,370  INFO [Thread-532] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:05,371  INFO [Thread-532] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:05,371  INFO [Thread-532] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:05,371  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74111fa5 will be shutdown
2024-04-24T09:40:05,371  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70ebb6da created in the thread with id: 578
2024-04-24T09:40:05,373  INFO [Thread-532] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:05,373  INFO [Thread-532] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:05,373  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:05,373  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65fe3e39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70ebb6da will be shutdown
2024-04-24T09:40:05,374  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:05,374  INFO [Thread-532] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -51
2024-04-24T09:40:05,374  INFO [Thread-532] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:05,375  INFO [Thread-532] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:05,375  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d25936c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:05,375  INFO [Thread-532] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d25936c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64b8f756 created in the thread with id: 578
2024-04-24T09:40:05,377  INFO [Thread-532] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6d25936c from thread id: 578
2024-04-24T09:40:05,378  INFO [Thread-532] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:05,378  WARN [Thread-532] mapred.LocalJobRunner: job_local2002562188_0013
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_SCRATCH0,4224355142958671/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:06,153  INFO [main] mapreduce.Job: Job job_local2002562188_0013 running in uber mode : false
2024-04-24T09:40:06,153  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:06,154  INFO [main] mapreduce.Job: Job job_local2002562188_0013 failed with state FAILED due to: NA
2024-04-24T09:40:06,156  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3288
		FILE: Number of bytes written=6653531
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=815792128
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,199  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:06,200  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:06,202  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,202  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@173b24c4 will be shutdown
2024-04-24T09:40:06,202  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7575f7e1 created in the thread with id: 1
2024-04-24T09:40:06,204  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,204  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,204  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,204  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e80de85, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7575f7e1 will be shutdown
2024-04-24T09:40:06,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,205  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -52
2024-04-24T09:40:06,205  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,206  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,206  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b850bb7 created in the thread with id: 1
2024-04-24T09:40:06,208  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077 from thread id: 1
2024-04-24T09:40:06,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:06,220  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:06,226  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,256  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,257  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,257  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,257  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:06,258  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,258  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,258  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b850bb7 will be shutdown
2024-04-24T09:40:06,259  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f03fdc0 created in the thread with id: 1
2024-04-24T09:40:06,260  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,260  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,261  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626ff077, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2f03fdc0 will be shutdown
2024-04-24T09:40:06,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,261  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -53
2024-04-24T09:40:06,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,262  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,263  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,263  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7a6b214c created in the thread with id: 1
2024-04-24T09:40:06,264  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a from thread id: 1
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,307  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,308  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,308  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,308  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,308  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:06,308  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:06,310  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,310  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,310  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7a6b214c will be shutdown
2024-04-24T09:40:06,311  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f00c40e created in the thread with id: 1
2024-04-24T09:40:06,312  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,312  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,313  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,313  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@256c6f7a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f00c40e will be shutdown
2024-04-24T09:40:06,313  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,313  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -54
2024-04-24T09:40:06,313  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,314  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,315  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,315  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b160208 created in the thread with id: 1
2024-04-24T09:40:06,316  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539 from thread id: 1
2024-04-24T09:40:06,318  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:06,328  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,366  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,367  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,367  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:06,367  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:06,369  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,369  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,369  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b160208 will be shutdown
2024-04-24T09:40:06,370  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6046fba0 created in the thread with id: 1
2024-04-24T09:40:06,372  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,372  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,372  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,372  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1443539, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6046fba0 will be shutdown
2024-04-24T09:40:06,372  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,372  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -55
2024-04-24T09:40:06,372  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,373  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@125ba798 created in the thread with id: 1
2024-04-24T09:40:06,375  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c from thread id: 1
2024-04-24T09:40:06,377  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:06,386  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:06,393  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,423  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,423  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:06,424  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,424  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,425  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@125ba798 will be shutdown
2024-04-24T09:40:06,425  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74070994 created in the thread with id: 1
2024-04-24T09:40:06,427  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,427  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,427  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@66df362c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74070994 will be shutdown
2024-04-24T09:40:06,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,427  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -56
2024-04-24T09:40:06,428  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,429  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,429  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34525143 created in the thread with id: 1
2024-04-24T09:40:06,431  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d from thread id: 1
2024-04-24T09:40:06,438  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:06,442  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:06,442  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:06,459  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:06,473  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2024970749_0014
2024-04-24T09:40:06,473  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:06,544  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:06,544  INFO [main] mapreduce.Job: Running job: job_local2024970749_0014
2024-04-24T09:40:06,544  INFO [Thread-583] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:06,546  INFO [Thread-583] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:06,547  INFO [Thread-583] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:06,548  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2024970749_0014_m_000000_0
2024-04-24T09:40:06,551  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:06,551  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:40:06,556  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local2024970749_0014_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.24137754908716724/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:40:06,557  INFO [Thread-583] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:06,558  INFO [Thread-583] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile/_DYN0.24137754908716724].
2024-04-24T09:40:06,558  INFO [Thread-583] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:06,590  WARN [Thread-583] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:06,591  INFO [Thread-583] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:06,591  INFO [Thread-583] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:06,592  INFO [Thread-583] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,592  INFO [Thread-583] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:06,592  INFO [Thread-583] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d69c53a, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,593  INFO [Thread-583] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d69c53a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3666d1ca created in the thread with id: 631
2024-04-24T09:40:06,595  INFO [Thread-583] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d69c53a from thread id: 631
2024-04-24T09:40:06,595  INFO [Thread-583] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:06,595  INFO [Thread-583] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:06,595  INFO [Thread-583] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:06,595  INFO [Thread-583] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d69c53a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3666d1ca will be shutdown
2024-04-24T09:40:06,596  INFO [Thread-583] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:06,596  INFO [Thread-583] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -57
2024-04-24T09:40:06,596  INFO [Thread-583] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:06,597  INFO [Thread-583] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:06,598  INFO [Thread-583] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d84f8f2, with PersistenceManager: null will be shutdown
2024-04-24T09:40:06,598  INFO [Thread-583] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d84f8f2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1eb8091d created in the thread with id: 631
2024-04-24T09:40:06,599  INFO [Thread-583] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d84f8f2 from thread id: 631
2024-04-24T09:40:06,601  INFO [Thread-583] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:06,601  WARN [Thread-583] mapred.LocalJobRunner: job_local2024970749_0014
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:40:07,545  INFO [main] mapreduce.Job: Job job_local2024970749_0014 running in uber mode : false
2024-04-24T09:40:07,545  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:07,545  INFO [main] mapreduce.Job: Job job_local2024970749_0014 failed with state FAILED due to: NA
2024-04-24T09:40:07,546  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:07,582  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:07,582  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:07,583  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:07,585  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:07,585  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:07,585  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34525143 will be shutdown
2024-04-24T09:40:07,585  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@28b16193 created in the thread with id: 1
2024-04-24T09:40:07,587  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:07,587  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:07,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:07,588  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@67cd193d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@28b16193 will be shutdown
2024-04-24T09:40:07,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:07,588  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -58
2024-04-24T09:40:07,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:07,589  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:07,589  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: null will be shutdown
2024-04-24T09:40:07,590  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3eadfbbb created in the thread with id: 1
2024-04-24T09:40:07,591  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55 from thread id: 1
2024-04-24T09:40:07,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:07,606  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:07,607  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:07,615  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:07,623  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:07,628  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:07,646  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:40:07,660  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local555105538_0015
2024-04-24T09:40:07,660  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:07,706  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:07,706  INFO [main] mapreduce.Job: Running job: job_local555105538_0015
2024-04-24T09:40:07,706  INFO [Thread-603] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:07,706  INFO [Thread-603] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:07,707  INFO [Thread-603] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:07,707  INFO [Thread-603] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:40:07,713  INFO [Thread-603] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:07,713  INFO [Thread-603] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:08,707  INFO [main] mapreduce.Job: Job job_local555105538_0015 running in uber mode : false
2024-04-24T09:40:08,707  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:08,708  INFO [main] mapreduce.Job: Job job_local555105538_0015 completed successfully
2024-04-24T09:40:08,708  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:08,709  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:08,723  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:08,724  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_RCFILE	
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:08,786  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:08,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:08,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:08,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[3]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.375">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-24T09:40:08,822  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:08,823  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:08,824  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:08,825  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:08,825  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3eadfbbb will be shutdown
2024-04-24T09:40:08,825  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75c30a4f created in the thread with id: 1
2024-04-24T09:40:08,827  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 1b403334-83ff-425c-ac34-2aa89ca39369
2024-04-24T09:40:08,827  INFO [main] SessionState: Hive Session ID = 1b403334-83ff-425c-ac34-2aa89ca39369
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:08,828  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:08,833  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/1b403334-83ff-425c-ac34-2aa89ca39369
2024-04-24T09:40:08,836  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/1b403334-83ff-425c-ac34-2aa89ca39369
2024-04-24T09:40:08,838  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/1b403334-83ff-425c-ac34-2aa89ca39369/_tmp_space.db
2024-04-24T09:40:08,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:08,841  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_ORCFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_ORCFILE, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1, EXTERNAL=TRUE}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{immutable=true, transactional=false, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:40:08,844  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:08,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:08,908  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:08,908  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:08,910  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:08,910  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:08,910  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75c30a4f will be shutdown
2024-04-24T09:40:08,911  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1964ef9 created in the thread with id: 1
2024-04-24T09:40:08,913  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:08,913  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:08,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:08,913  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@30b29f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1964ef9 will be shutdown
2024-04-24T09:40:08,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:08,913  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -59
2024-04-24T09:40:08,913  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:08,915  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:08,915  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971, with PersistenceManager: null will be shutdown
2024-04-24T09:40:08,915  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c7787a7 created in the thread with id: 1
2024-04-24T09:40:08,917  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971 from thread id: 1
2024-04-24T09:40:08,919  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:08,928  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:08,941  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:08,971  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:08,971  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:08,973  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:08,973  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:08,973  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3c7787a7 will be shutdown
2024-04-24T09:40:08,973  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4df54c1 created in the thread with id: 1
2024-04-24T09:40:08,975  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:08,975  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:08,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:08,976  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e5df971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4df54c1 will be shutdown
2024-04-24T09:40:08,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:08,976  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -60
2024-04-24T09:40:08,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:08,977  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:08,978  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122, with PersistenceManager: null will be shutdown
2024-04-24T09:40:08,978  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a5c115b created in the thread with id: 1
2024-04-24T09:40:08,979  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122 from thread id: 1
2024-04-24T09:40:08,981  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value1,501]	
2024-04-24T09:40:09,006  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:09,010  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:09,011  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:09,028  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:09,041  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1625085329_0016
2024-04-24T09:40:09,041  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:09,085  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:09,085  INFO [main] mapreduce.Job: Running job: job_local1625085329_0016
2024-04-24T09:40:09,085  INFO [Thread-637] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:09,087  INFO [Thread-637] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,087  INFO [Thread-637] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,088  INFO [Thread-637] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:09,089  INFO [Thread-637] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,089  INFO [Thread-637] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,100  INFO [Thread-637] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:09,100  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1625085329_0016_m_000000_0
2024-04-24T09:40:09,104  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,104  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,106  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,106  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,106  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:09,107  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:40:09,112  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,113  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,143  INFO [LocalJobRunner Map Task Executor #0] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-24T09:40:09,147  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,33991651584310845/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1625085329_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-24T09:40:09,197  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,33991651584310845/part1=p1value1/part0=501/_temporary/0/_temporary/attempt_local1625085329_0016_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-24T09:40:09,203  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:09,256  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1625085329_0016_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:09,256  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,256  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,260  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:09,260  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1625085329_0016_m_000000_0 is allowed to commit now
2024-04-24T09:40:09,260  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:09,260  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:09,269  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1625085329_0016_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,33991651584310845/part1=p1value1/part0=501
2024-04-24T09:40:09,270  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:09,270  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1625085329_0016_m_000000_0' done.
2024-04-24T09:40:09,270  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1625085329_0016_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8187597
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=815792128
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:09,270  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1625085329_0016_m_000000_0
2024-04-24T09:40:09,270  INFO [Thread-637] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:09,312  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:09,312  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:09,312  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:09,312  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:09,312  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:09,313  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:09,313  INFO [Thread-637] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:09,314  INFO [Thread-637] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:09,315  INFO [Thread-637] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:09,315  INFO [Thread-637] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:09,316  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7de0f130, with PersistenceManager: null will be shutdown
2024-04-24T09:40:09,316  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7de0f130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66c01a0b created in the thread with id: 687
2024-04-24T09:40:09,318  INFO [Thread-637] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7de0f130 from thread id: 687
2024-04-24T09:40:09,318  INFO [Thread-637] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:09,318  INFO [Thread-637] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:09,319  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:09,319  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7de0f130, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66c01a0b will be shutdown
2024-04-24T09:40:09,319  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:09,319  INFO [Thread-637] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -61
2024-04-24T09:40:09,319  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:09,321  INFO [Thread-637] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:09,321  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374, with PersistenceManager: null will be shutdown
2024-04-24T09:40:09,321  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c9092b3 created in the thread with id: 687
2024-04-24T09:40:09,323  INFO [Thread-637] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374 from thread id: 687
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:09,362  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:09,363  INFO [Thread-637] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part1=p1value1, part0=501}].
2024-04-24T09:40:09,382  INFO [Thread-637] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,33991651584310845/part1=p1value1/part0=501].
2024-04-24T09:40:09,383  INFO [Thread-637] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:09,416  WARN [Thread-637] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:09,416  INFO [Thread-637] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:09,417  INFO [Thread-637] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:09,417  INFO [Thread-637] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:09,417  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c9092b3 will be shutdown
2024-04-24T09:40:09,417  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ee879c8 created in the thread with id: 687
2024-04-24T09:40:09,419  INFO [Thread-637] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:09,419  INFO [Thread-637] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:09,420  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:09,420  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7d314374, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ee879c8 will be shutdown
2024-04-24T09:40:09,420  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:09,420  INFO [Thread-637] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -62
2024-04-24T09:40:09,420  INFO [Thread-637] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:09,421  INFO [Thread-637] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:09,422  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ba4a426, with PersistenceManager: null will be shutdown
2024-04-24T09:40:09,422  INFO [Thread-637] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ba4a426, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe58958 created in the thread with id: 687
2024-04-24T09:40:09,424  INFO [Thread-637] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ba4a426 from thread id: 687
2024-04-24T09:40:09,425  INFO [Thread-637] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:09,425  WARN [Thread-637] mapred.LocalJobRunner: job_local1625085329_0016
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,33991651584310845/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:10,086  INFO [main] mapreduce.Job: Job job_local1625085329_0016 running in uber mode : false
2024-04-24T09:40:10,086  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:10,087  INFO [main] mapreduce.Job: Job job_local1625085329_0016 failed with state FAILED due to: NA
2024-04-24T09:40:10,090  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=3870
		FILE: Number of bytes written=8187597
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=815792128
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:10,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:10,135  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:10,135  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:10,137  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:10,137  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:10,137  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2a5c115b will be shutdown
2024-04-24T09:40:10,138  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbc11ed created in the thread with id: 1
2024-04-24T09:40:10,139  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:10,140  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:10,140  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:10,140  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e243122, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7bbc11ed will be shutdown
2024-04-24T09:40:10,140  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:10,140  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -63
2024-04-24T09:40:10,140  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:10,141  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:10,142  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9, with PersistenceManager: null will be shutdown
2024-04-24T09:40:10,142  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e6f7c25 created in the thread with id: 1
2024-04-24T09:40:10,144  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9 from thread id: 1
2024-04-24T09:40:10,145  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:10,158  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:10,166  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:10,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:10,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:10,201  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:10,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:10,202  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:10,204  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:10,204  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:10,204  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e6f7c25 will be shutdown
2024-04-24T09:40:10,205  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55f54852 created in the thread with id: 1
2024-04-24T09:40:10,206  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:10,207  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:10,207  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:10,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d4337f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55f54852 will be shutdown
2024-04-24T09:40:10,207  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:10,207  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -64
2024-04-24T09:40:10,208  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:10,209  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:10,209  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b, with PersistenceManager: null will be shutdown
2024-04-24T09:40:10,209  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d2ce035 created in the thread with id: 1
2024-04-24T09:40:10,211  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b from thread id: 1
2024-04-24T09:40:10,213  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-04-24T09:40:10,259  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:10,264  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:10,264  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:10,281  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:10,293  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local662645114_0017
2024-04-24T09:40:10,293  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:10,341  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:10,341  INFO [main] mapreduce.Job: Running job: job_local662645114_0017
2024-04-24T09:40:10,341  INFO [Thread-683] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:10,343  INFO [Thread-683] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,343  INFO [Thread-683] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,344  INFO [Thread-683] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:10,344  INFO [Thread-683] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,344  INFO [Thread-683] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,355  INFO [Thread-683] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:10,355  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local662645114_0017_m_000000_0
2024-04-24T09:40:10,358  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,358  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,359  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,360  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,360  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:10,360  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:10,362  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,362  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,365  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6890492527853781/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local662645114_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-24T09:40:10,373  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6890492527853781/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local662645114_0017_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-24T09:40:10,374  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:10,377  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local662645114_0017_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:10,377  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,377  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,380  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:10,380  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local662645114_0017_m_000000_0 is allowed to commit now
2024-04-24T09:40:10,380  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:10,380  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:10,389  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local662645114_0017_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6890492527853781/part1=p1value2/part0=502
2024-04-24T09:40:10,390  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:10,390  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local662645114_0017_m_000000_0' done.
2024-04-24T09:40:10,390  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local662645114_0017_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8697993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=854589440
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:10,390  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local662645114_0017_m_000000_0
2024-04-24T09:40:10,390  INFO [Thread-683] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:10,429  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:10,429  INFO [Thread-683] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:10,430  INFO [Thread-683] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:10,431  INFO [Thread-683] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:10,431  INFO [Thread-683] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:10,431  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a3f8810, with PersistenceManager: null will be shutdown
2024-04-24T09:40:10,431  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a3f8810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d57708d created in the thread with id: 735
2024-04-24T09:40:10,433  INFO [Thread-683] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a3f8810 from thread id: 735
2024-04-24T09:40:10,433  INFO [Thread-683] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:10,433  INFO [Thread-683] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:10,433  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:10,433  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a3f8810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d57708d will be shutdown
2024-04-24T09:40:10,433  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:10,433  INFO [Thread-683] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -65
2024-04-24T09:40:10,434  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:10,435  INFO [Thread-683] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:10,435  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5, with PersistenceManager: null will be shutdown
2024-04-24T09:40:10,435  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70b36493 created in the thread with id: 735
2024-04-24T09:40:10,437  INFO [Thread-683] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5 from thread id: 735
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:10,474  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:10,474  INFO [Thread-683] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part0=502, part1=p1value2}].
2024-04-24T09:40:10,496  INFO [Thread-683] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6890492527853781/part1=p1value2/part0=502].
2024-04-24T09:40:10,496  INFO [Thread-683] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:10,533  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:10,534  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:10,534  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:10,534  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:10,534  WARN [Thread-683] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:10,534  INFO [Thread-683] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:10,535  INFO [Thread-683] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:10,535  INFO [Thread-683] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:10,536  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70b36493 will be shutdown
2024-04-24T09:40:10,536  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34a5897c created in the thread with id: 735
2024-04-24T09:40:10,537  INFO [Thread-683] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:10,538  INFO [Thread-683] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:10,538  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:10,538  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e0112d5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34a5897c will be shutdown
2024-04-24T09:40:10,538  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:10,538  INFO [Thread-683] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -66
2024-04-24T09:40:10,539  INFO [Thread-683] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:10,540  INFO [Thread-683] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:10,540  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b714319, with PersistenceManager: null will be shutdown
2024-04-24T09:40:10,540  INFO [Thread-683] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b714319, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5fefa6ef created in the thread with id: 735
2024-04-24T09:40:10,542  INFO [Thread-683] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b714319 from thread id: 735
2024-04-24T09:40:10,543  INFO [Thread-683] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:10,543  WARN [Thread-683] mapred.LocalJobRunner: job_local662645114_0017
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,6890492527853781/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:11,341  INFO [main] mapreduce.Job: Job job_local662645114_0017 running in uber mode : false
2024-04-24T09:40:11,341  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:11,342  INFO [main] mapreduce.Job: Job job_local662645114_0017 failed with state FAILED due to: NA
2024-04-24T09:40:11,345  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4182
		FILE: Number of bytes written=8697993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=854589440
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:11,386  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:11,386  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:11,387  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:11,389  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:11,389  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:11,389  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d2ce035 will be shutdown
2024-04-24T09:40:11,389  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@367653cc created in the thread with id: 1
2024-04-24T09:40:11,391  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:11,391  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:11,391  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:11,391  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fd3197b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@367653cc will be shutdown
2024-04-24T09:40:11,391  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:11,391  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -67
2024-04-24T09:40:11,392  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:11,393  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:11,393  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19, with PersistenceManager: null will be shutdown
2024-04-24T09:40:11,393  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@765d67dd created in the thread with id: 1
2024-04-24T09:40:11,395  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19 from thread id: 1
2024-04-24T09:40:11,397  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:11,406  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:11,412  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:11,441  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:11,441  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:11,441  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:11,441  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:11,441  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:11,442  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:11,442  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:11,443  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:11,443  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:11,443  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@765d67dd will be shutdown
2024-04-24T09:40:11,444  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b4b2c03 created in the thread with id: 1
2024-04-24T09:40:11,446  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:11,446  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:11,446  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:11,446  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b9cfc19, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b4b2c03 will be shutdown
2024-04-24T09:40:11,446  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:11,446  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -68
2024-04-24T09:40:11,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:11,448  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:11,448  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211, with PersistenceManager: null will be shutdown
2024-04-24T09:40:11,449  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74ec4df3 created in the thread with id: 1
2024-04-24T09:40:11,450  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211 from thread id: 1
2024-04-24T09:40:11,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_ORCFILE[p1value2,502]	
2024-04-24T09:40:11,468  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:11,472  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:11,473  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:11,490  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:11,503  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1514499718_0018
2024-04-24T09:40:11,503  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:11,548  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:11,549  INFO [main] mapreduce.Job: Running job: job_local1514499718_0018
2024-04-24T09:40:11,549  INFO [Thread-729] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:11,551  INFO [Thread-729] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,551  INFO [Thread-729] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,552  INFO [Thread-729] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:11,552  INFO [Thread-729] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,552  INFO [Thread-729] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,564  INFO [Thread-729] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:11,564  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1514499718_0018_m_000000_0
2024-04-24T09:40:11,566  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,566  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,568  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,568  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:11,569  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:11,571  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,571  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,573  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,31518897276670754/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1514499718_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 blockSize: 268435456 compression: Compress: ZLIB buffer: 262144
2024-04-24T09:40:11,582  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,31518897276670754/part1=p1value2/part0=502/_temporary/0/_temporary/attempt_local1514499718_0018_m_000000_0/part-m-00000 with stripeSize: 67108864 options: Compress: ZLIB buffer: 262144
2024-04-24T09:40:11,584  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:11,587  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1514499718_0018_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:11,587  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,587  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,592  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:11,592  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1514499718_0018_m_000000_0 is allowed to commit now
2024-04-24T09:40:11,592  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:11,592  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:11,601  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1514499718_0018_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,31518897276670754/part1=p1value2/part0=502
2024-04-24T09:40:11,602  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:11,602  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1514499718_0018_m_000000_0' done.
2024-04-24T09:40:11,602  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1514499718_0018_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9210784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=854589440
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:11,602  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1514499718_0018_m_000000_0
2024-04-24T09:40:11,602  INFO [Thread-729] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:11,642  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:11,642  INFO [Thread-729] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:11,644  INFO [Thread-729] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:11,644  INFO [Thread-729] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:11,644  INFO [Thread-729] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:11,645  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eaf9ed, with PersistenceManager: null will be shutdown
2024-04-24T09:40:11,645  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eaf9ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@477e44de created in the thread with id: 783
2024-04-24T09:40:11,646  INFO [Thread-729] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eaf9ed from thread id: 783
2024-04-24T09:40:11,646  INFO [Thread-729] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:11,646  INFO [Thread-729] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:11,647  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:11,647  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eaf9ed, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@477e44de will be shutdown
2024-04-24T09:40:11,647  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:11,647  INFO [Thread-729] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -69
2024-04-24T09:40:11,647  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:11,648  INFO [Thread-729] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:11,648  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738, with PersistenceManager: null will be shutdown
2024-04-24T09:40:11,649  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d8fdfd9 created in the thread with id: 783
2024-04-24T09:40:11,650  INFO [Thread-729] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738 from thread id: 783
2024-04-24T09:40:11,686  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:11,686  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:11,686  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:11,686  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:11,687  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:11,687  INFO [Thread-729] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_orcfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:11,707  INFO [Thread-729] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,31518897276670754/part1=p1value2/part0=502].
2024-04-24T09:40:11,707  INFO [Thread-729] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:11,740  WARN [Thread-729] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:11,740  INFO [Thread-729] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:11,741  INFO [Thread-729] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:11,742  INFO [Thread-729] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:11,742  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d8fdfd9 will be shutdown
2024-04-24T09:40:11,742  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3545926e created in the thread with id: 783
2024-04-24T09:40:11,744  INFO [Thread-729] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:11,744  INFO [Thread-729] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:11,744  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:11,744  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@408b1738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3545926e will be shutdown
2024-04-24T09:40:11,744  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:11,744  INFO [Thread-729] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -70
2024-04-24T09:40:11,745  INFO [Thread-729] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:11,746  INFO [Thread-729] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:11,746  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a764713, with PersistenceManager: null will be shutdown
2024-04-24T09:40:11,746  INFO [Thread-729] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a764713, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2708f599 created in the thread with id: 783
2024-04-24T09:40:11,748  INFO [Thread-729] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a764713 from thread id: 783
2024-04-24T09:40:11,749  INFO [Thread-729] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:11,749  WARN [Thread-729] mapred.LocalJobRunner: job_local1514499718_0018
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_SCRATCH0,31518897276670754/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:12,029  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-24T09:40:12,549  INFO [main] mapreduce.Job: Job job_local1514499718_0018 running in uber mode : false
2024-04-24T09:40:12,550  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:12,550  INFO [main] mapreduce.Job: Job job_local1514499718_0018 failed with state FAILED due to: NA
2024-04-24T09:40:12,552  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=4494
		FILE: Number of bytes written=9210784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=854589440
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,608  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,609  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,609  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,609  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,609  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,609  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:12,610  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:12,611  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,612  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,612  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@74ec4df3 will be shutdown
2024-04-24T09:40:12,613  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d816d32 created in the thread with id: 1
2024-04-24T09:40:12,614  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,614  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,614  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,614  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2b9a7211, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d816d32 will be shutdown
2024-04-24T09:40:12,614  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,614  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -71
2024-04-24T09:40:12,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,616  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,616  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,616  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2aac60b created in the thread with id: 1
2024-04-24T09:40:12,618  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c from thread id: 1
2024-04-24T09:40:12,620  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:12,630  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:12,637  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,667  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,668  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,668  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,668  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:12,669  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,669  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,669  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2aac60b will be shutdown
2024-04-24T09:40:12,670  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bbff652 created in the thread with id: 1
2024-04-24T09:40:12,672  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,672  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,672  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,672  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@cc3fc5c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bbff652 will be shutdown
2024-04-24T09:40:12,673  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,673  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -72
2024-04-24T09:40:12,673  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,674  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,675  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75937998 created in the thread with id: 1
2024-04-24T09:40:12,676  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7 from thread id: 1
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,717  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,717  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:12,718  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:12,719  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,719  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,720  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@75937998 will be shutdown
2024-04-24T09:40:12,720  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@763a72da created in the thread with id: 1
2024-04-24T09:40:12,721  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,721  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,722  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,722  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@57f83dc7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@763a72da will be shutdown
2024-04-24T09:40:12,722  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,722  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -73
2024-04-24T09:40:12,722  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,723  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,723  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,724  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf2c83 created in the thread with id: 1
2024-04-24T09:40:12,725  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae from thread id: 1
2024-04-24T09:40:12,727  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:12,735  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,773  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,774  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:12,774  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:12,776  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,776  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,776  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cdf2c83 will be shutdown
2024-04-24T09:40:12,776  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308f18c0 created in the thread with id: 1
2024-04-24T09:40:12,778  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,778  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,778  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1899c7ae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@308f18c0 will be shutdown
2024-04-24T09:40:12,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,778  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -74
2024-04-24T09:40:12,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,780  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45398bb0 created in the thread with id: 1
2024-04-24T09:40:12,781  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c from thread id: 1
2024-04-24T09:40:12,783  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:12,794  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:12,800  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,835  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,836  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:12,837  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,837  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,837  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45398bb0 will be shutdown
2024-04-24T09:40:12,837  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c3eeda4 created in the thread with id: 1
2024-04-24T09:40:12,839  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,839  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,840  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7893b8c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1c3eeda4 will be shutdown
2024-04-24T09:40:12,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,840  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -75
2024-04-24T09:40:12,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,841  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,842  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,842  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59cbeaee created in the thread with id: 1
2024-04-24T09:40:12,843  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1 from thread id: 1
2024-04-24T09:40:12,850  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:12,855  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:12,855  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:12,874  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:12,889  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local643192861_0019
2024-04-24T09:40:12,889  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:12,934  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:12,934  INFO [main] mapreduce.Job: Running job: job_local643192861_0019
2024-04-24T09:40:12,934  INFO [Thread-780] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:12,936  INFO [Thread-780] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:12,938  INFO [Thread-780] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:12,938  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local643192861_0019_m_000000_0
2024-04-24T09:40:12,941  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:12,942  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:40:12,947  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local643192861_0019_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.9083143277718756/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:40:12,947  INFO [Thread-780] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:12,949  INFO [Thread-780] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_orcfile/_DYN0.9083143277718756].
2024-04-24T09:40:12,949  INFO [Thread-780] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:12,984  WARN [Thread-780] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:12,984  INFO [Thread-780] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:12,985  INFO [Thread-780] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:12,986  INFO [Thread-780] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,986  INFO [Thread-780] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:12,986  INFO [Thread-780] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eeb4108, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,986  INFO [Thread-780] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eeb4108, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27267031 created in the thread with id: 836
2024-04-24T09:40:12,987  INFO [Thread-780] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eeb4108 from thread id: 836
2024-04-24T09:40:12,988  INFO [Thread-780] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:12,988  INFO [Thread-780] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:12,988  INFO [Thread-780] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:12,988  INFO [Thread-780] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4eeb4108, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27267031 will be shutdown
2024-04-24T09:40:12,988  INFO [Thread-780] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:12,988  INFO [Thread-780] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -76
2024-04-24T09:40:12,988  INFO [Thread-780] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:12,990  INFO [Thread-780] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:12,990  INFO [Thread-780] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d511e83, with PersistenceManager: null will be shutdown
2024-04-24T09:40:12,990  INFO [Thread-780] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d511e83, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d23f026 created in the thread with id: 836
2024-04-24T09:40:12,991  INFO [Thread-780] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d511e83 from thread id: 836
2024-04-24T09:40:12,993  INFO [Thread-780] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:12,993  WARN [Thread-780] mapred.LocalJobRunner: job_local643192861_0019
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:40:13,935  INFO [main] mapreduce.Job: Job job_local643192861_0019 running in uber mode : false
2024-04-24T09:40:13,935  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:13,936  INFO [main] mapreduce.Job: Job job_local643192861_0019 failed with state FAILED due to: NA
2024-04-24T09:40:13,936  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:13,969  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:13,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:13,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:13,969  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:13,969  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:13,970  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:13,970  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:13,971  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:13,972  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:13,972  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:13,972  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59cbeaee will be shutdown
2024-04-24T09:40:13,973  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ad2cb6d created in the thread with id: 1
2024-04-24T09:40:13,974  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:13,974  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:13,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:13,975  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@458500d1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6ad2cb6d will be shutdown
2024-04-24T09:40:13,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:13,975  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -77
2024-04-24T09:40:13,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:13,976  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:13,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: null will be shutdown
2024-04-24T09:40:13,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26f0ab88 created in the thread with id: 1
2024-04-24T09:40:13,978  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf from thread id: 1
2024-04-24T09:40:13,981  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:13,990  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:13,990  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:13,996  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:14,002  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:14,006  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:14,024  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:40:14,038  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local431267612_0020
2024-04-24T09:40:14,038  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:14,084  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:14,084  INFO [main] mapreduce.Job: Running job: job_local431267612_0020
2024-04-24T09:40:14,084  INFO [Thread-800] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:14,084  INFO [Thread-800] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:14,084  INFO [Thread-800] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:14,084  INFO [Thread-800] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:40:14,091  INFO [Thread-800] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:14,091  INFO [Thread-800] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:15,085  INFO [main] mapreduce.Job: Job job_local431267612_0020 running in uber mode : false
2024-04-24T09:40:15,085  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:15,086  INFO [main] mapreduce.Job: Job job_local431267612_0020 completed successfully
2024-04-24T09:40:15,086  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:15,086  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:15,098  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:15,098  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_ORCFILE	
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,162  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,162  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[4]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-04-24T09:40:15,198  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,199  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,201  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,201  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,201  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26f0ab88 will be shutdown
2024-04-24T09:40:15,201  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27381497 created in the thread with id: 1
2024-04-24T09:40:15,203  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = b6404f57-6307-4748-a8d2-03c78deb1086
2024-04-24T09:40:15,203  INFO [main] SessionState: Hive Session ID = b6404f57-6307-4748-a8d2-03c78deb1086
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,204  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,234  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/b6404f57-6307-4748-a8d2-03c78deb1086
2024-04-24T09:40:15,236  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/b6404f57-6307-4748-a8d2-03c78deb1086
2024-04-24T09:40:15,238  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/b6404f57-6307-4748-a8d2-03c78deb1086/_tmp_space.db
2024-04-24T09:40:15,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_PARQUETFILE	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[5]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="0">
    <skipped message="got: &lt;false&gt;, expected: is &lt;true&gt;"/>
    <system-err><![CDATA[2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,275  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,277  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,277  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27381497 will be shutdown
2024-04-24T09:40:15,277  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25d5327 created in the thread with id: 1
2024-04-24T09:40:15,279  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = 90e22db0-5f92-4f97-b868-6cc212c81b91
2024-04-24T09:40:15,279  INFO [main] SessionState: Hive Session ID = 90e22db0-5f92-4f97-b868-6cc212c81b91
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,279  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,284  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/90e22db0-5f92-4f97-b868-6cc212c81b91
2024-04-24T09:40:15,286  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/90e22db0-5f92-4f97-b868-6cc212c81b91
2024-04-24T09:40:15,289  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/90e22db0-5f92-4f97-b868-6cc212c81b91/_tmp_space.db
2024-04-24T09:40:15,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_AVRO	
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[6]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.369">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,327  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,328  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,328  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,329  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,329  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@25d5327 will be shutdown
2024-04-24T09:40:15,330  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@174da9a0 created in the thread with id: 1
2024-04-24T09:40:15,332  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = d1645ae5-481b-46a7-a718-6ded7c697061
2024-04-24T09:40:15,332  INFO [main] SessionState: Hive Session ID = d1645ae5-481b-46a7-a718-6ded7c697061
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,332  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:15,337  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/d1645ae5-481b-46a7-a718-6ded7c697061
2024-04-24T09:40:15,340  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/d1645ae5-481b-46a7-a718-6ded7c697061
2024-04-24T09:40:15,342  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/d1645ae5-481b-46a7-a718-6ded7c697061/_tmp_space.db
2024-04-24T09:40:15,342  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:15,344  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_JSONFILE, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_JSONFILE, serializationLib:org.apache.hadoop.hive.serde2.JsonSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, EXTERNAL=TRUE, immutable=true}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:40:15,347  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,401  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,402  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:15,402  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:15,404  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,404  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,404  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@174da9a0 will be shutdown
2024-04-24T09:40:15,405  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@672ba9cc created in the thread with id: 1
2024-04-24T09:40:15,406  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:15,406  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:15,406  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:15,406  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ab17cf, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@672ba9cc will be shutdown
2024-04-24T09:40:15,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:15,407  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -78
2024-04-24T09:40:15,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:15,408  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:15,408  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79, with PersistenceManager: null will be shutdown
2024-04-24T09:40:15,408  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e7c66b3 created in the thread with id: 1
2024-04-24T09:40:15,410  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79 from thread id: 1
2024-04-24T09:40:15,412  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:15,421  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:15,435  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,465  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:15,466  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,467  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,467  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e7c66b3 will be shutdown
2024-04-24T09:40:15,467  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1464a177 created in the thread with id: 1
2024-04-24T09:40:15,469  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:15,469  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:15,469  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:15,469  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@75c5ab79, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1464a177 will be shutdown
2024-04-24T09:40:15,469  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:15,469  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -79
2024-04-24T09:40:15,470  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:15,471  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:15,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38, with PersistenceManager: null will be shutdown
2024-04-24T09:40:15,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4843b35f created in the thread with id: 1
2024-04-24T09:40:15,473  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38 from thread id: 1
2024-04-24T09:40:15,475  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value1,501]	
2024-04-24T09:40:15,492  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:15,496  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:15,497  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:15,515  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:15,528  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1687107063_0021
2024-04-24T09:40:15,528  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:15,574  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:15,574  INFO [main] mapreduce.Job: Running job: job_local1687107063_0021
2024-04-24T09:40:15,574  INFO [Thread-842] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:15,576  INFO [Thread-842] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,576  INFO [Thread-842] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,577  INFO [Thread-842] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:15,578  INFO [Thread-842] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,578  INFO [Thread-842] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,590  INFO [Thread-842] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:15,590  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1687107063_0021_m_000000_0
2024-04-24T09:40:15,595  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,595  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,598  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,598  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,598  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:15,598  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:40:15,605  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,605  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,624  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:15,626  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1687107063_0021_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:15,626  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,626  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,629  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:15,629  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1687107063_0021_m_000000_0 is allowed to commit now
2024-04-24T09:40:15,629  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:15,629  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:15,638  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1687107063_0021_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6107170467145948/part1=p1value1/part0=501
2024-04-24T09:40:15,639  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:15,639  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1687107063_0021_m_000000_0' done.
2024-04-24T09:40:15,639  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1687107063_0021_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10741749
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:15,639  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1687107063_0021_m_000000_0
2024-04-24T09:40:15,639  INFO [Thread-842] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,678  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,678  INFO [Thread-842] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:15,679  INFO [Thread-842] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,680  INFO [Thread-842] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:15,680  INFO [Thread-842] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,680  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3aaca630, with PersistenceManager: null will be shutdown
2024-04-24T09:40:15,680  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3aaca630, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43f9229a created in the thread with id: 900
2024-04-24T09:40:15,682  INFO [Thread-842] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3aaca630 from thread id: 900
2024-04-24T09:40:15,682  INFO [Thread-842] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:15,682  INFO [Thread-842] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:15,682  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:15,682  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3aaca630, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@43f9229a will be shutdown
2024-04-24T09:40:15,682  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:15,683  INFO [Thread-842] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -80
2024-04-24T09:40:15,683  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:15,684  INFO [Thread-842] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:15,684  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94, with PersistenceManager: null will be shutdown
2024-04-24T09:40:15,684  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b3aa83f created in the thread with id: 900
2024-04-24T09:40:15,686  INFO [Thread-842] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94 from thread id: 900
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,722  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,723  INFO [Thread-842] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=501, part1=p1value1}].
2024-04-24T09:40:15,744  INFO [Thread-842] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6107170467145948/part1=p1value1/part0=501].
2024-04-24T09:40:15,744  INFO [Thread-842] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:15,778  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:15,778  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:15,778  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:15,779  WARN [Thread-842] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:15,779  INFO [Thread-842] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:15,780  INFO [Thread-842] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:15,780  INFO [Thread-842] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:15,781  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b3aa83f will be shutdown
2024-04-24T09:40:15,781  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2927ebf2 created in the thread with id: 900
2024-04-24T09:40:15,783  INFO [Thread-842] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:15,783  INFO [Thread-842] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:15,784  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:15,784  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e81fe94, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2927ebf2 will be shutdown
2024-04-24T09:40:15,784  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:15,784  INFO [Thread-842] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -81
2024-04-24T09:40:15,784  INFO [Thread-842] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:15,786  INFO [Thread-842] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:15,786  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38599e6a, with PersistenceManager: null will be shutdown
2024-04-24T09:40:15,786  INFO [Thread-842] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38599e6a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@738f53fa created in the thread with id: 900
2024-04-24T09:40:15,788  INFO [Thread-842] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@38599e6a from thread id: 900
2024-04-24T09:40:15,790  INFO [Thread-842] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:15,790  WARN [Thread-842] mapred.LocalJobRunner: job_local1687107063_0021
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,6107170467145948/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:16,574  INFO [main] mapreduce.Job: Job job_local1687107063_0021 running in uber mode : false
2024-04-24T09:40:16,575  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:16,575  INFO [main] mapreduce.Job: Job job_local1687107063_0021 failed with state FAILED due to: NA
2024-04-24T09:40:16,578  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5076
		FILE: Number of bytes written=10741749
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:16,621  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:16,621  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:16,623  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:16,623  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:16,623  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4843b35f will be shutdown
2024-04-24T09:40:16,624  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d8cbb32 created in the thread with id: 1
2024-04-24T09:40:16,625  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:16,626  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:16,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:16,626  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6e212f38, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d8cbb32 will be shutdown
2024-04-24T09:40:16,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:16,626  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -82
2024-04-24T09:40:16,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:16,627  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:16,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b, with PersistenceManager: null will be shutdown
2024-04-24T09:40:16,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6960e7a6 created in the thread with id: 1
2024-04-24T09:40:16,629  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b from thread id: 1
2024-04-24T09:40:16,631  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:16,640  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:16,648  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:16,680  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:16,681  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:16,682  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:16,682  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:16,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6960e7a6 will be shutdown
2024-04-24T09:40:16,683  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1484cb57 created in the thread with id: 1
2024-04-24T09:40:16,684  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:16,684  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:16,684  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:16,684  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@18b8518b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1484cb57 will be shutdown
2024-04-24T09:40:16,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:16,685  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -83
2024-04-24T09:40:16,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:16,686  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:16,686  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828, with PersistenceManager: null will be shutdown
2024-04-24T09:40:16,687  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e966e67 created in the thread with id: 1
2024-04-24T09:40:16,688  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828 from thread id: 1
2024-04-24T09:40:16,690  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-04-24T09:40:16,706  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:16,711  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:16,711  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:16,730  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:16,743  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1820252534_0022
2024-04-24T09:40:16,743  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:16,786  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:16,786  INFO [main] mapreduce.Job: Running job: job_local1820252534_0022
2024-04-24T09:40:16,786  INFO [Thread-888] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:16,788  INFO [Thread-888] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,789  INFO [Thread-888] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,790  INFO [Thread-888] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:16,790  INFO [Thread-888] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,790  INFO [Thread-888] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,801  INFO [Thread-888] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:16,802  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1820252534_0022_m_000000_0
2024-04-24T09:40:16,804  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,804  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,806  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,806  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,806  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:16,806  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:16,808  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,808  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,822  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:16,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1820252534_0022_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:16,823  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,823  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,826  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:16,826  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1820252534_0022_m_000000_0 is allowed to commit now
2024-04-24T09:40:16,826  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:16,826  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:16,835  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1820252534_0022_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,872877160614847/part1=p1value2/part0=502
2024-04-24T09:40:16,835  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:16,835  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1820252534_0022_m_000000_0' done.
2024-04-24T09:40:16,836  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1820252534_0022_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11254691
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:16,836  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1820252534_0022_m_000000_0
2024-04-24T09:40:16,836  INFO [Thread-888] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:16,875  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:16,876  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:16,876  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:16,876  INFO [Thread-888] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:16,877  INFO [Thread-888] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:16,877  INFO [Thread-888] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:16,877  INFO [Thread-888] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:16,878  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b42d0fa, with PersistenceManager: null will be shutdown
2024-04-24T09:40:16,878  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b42d0fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63f2ce2f created in the thread with id: 948
2024-04-24T09:40:16,879  INFO [Thread-888] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b42d0fa from thread id: 948
2024-04-24T09:40:16,879  INFO [Thread-888] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:16,880  INFO [Thread-888] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:16,880  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:16,880  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@b42d0fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63f2ce2f will be shutdown
2024-04-24T09:40:16,880  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:16,880  INFO [Thread-888] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -84
2024-04-24T09:40:16,880  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:16,881  INFO [Thread-888] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:16,882  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946, with PersistenceManager: null will be shutdown
2024-04-24T09:40:16,882  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cdf1d57 created in the thread with id: 948
2024-04-24T09:40:16,883  INFO [Thread-888] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946 from thread id: 948
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:16,918  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:16,919  INFO [Thread-888] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part0=502, part1=p1value2}].
2024-04-24T09:40:16,938  INFO [Thread-888] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,872877160614847/part1=p1value2/part0=502].
2024-04-24T09:40:16,938  INFO [Thread-888] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:16,970  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:16,970  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:16,970  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:16,971  WARN [Thread-888] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:16,971  INFO [Thread-888] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:16,972  INFO [Thread-888] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:16,972  INFO [Thread-888] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:16,972  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4cdf1d57 will be shutdown
2024-04-24T09:40:16,972  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d08f9b3 created in the thread with id: 948
2024-04-24T09:40:16,974  INFO [Thread-888] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:16,974  INFO [Thread-888] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:16,974  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:16,974  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@24476946, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d08f9b3 will be shutdown
2024-04-24T09:40:16,974  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:16,974  INFO [Thread-888] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -85
2024-04-24T09:40:16,974  INFO [Thread-888] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:16,975  INFO [Thread-888] metastore.HMSHandler: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:16,976  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2820f7b1, with PersistenceManager: null will be shutdown
2024-04-24T09:40:16,976  INFO [Thread-888] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2820f7b1, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1459e0da created in the thread with id: 948
2024-04-24T09:40:16,977  INFO [Thread-888] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2820f7b1 from thread id: 948
2024-04-24T09:40:16,978  INFO [Thread-888] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:16,978  WARN [Thread-888] mapred.LocalJobRunner: job_local1820252534_0022
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,872877160614847/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:17,787  INFO [main] mapreduce.Job: Job job_local1820252534_0022 running in uber mode : false
2024-04-24T09:40:17,787  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:17,787  INFO [main] mapreduce.Job: Job job_local1820252534_0022 failed with state FAILED due to: NA
2024-04-24T09:40:17,789  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5388
		FILE: Number of bytes written=11254691
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:17,846  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:17,847  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:17,847  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:17,849  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:17,849  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:17,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e966e67 will be shutdown
2024-04-24T09:40:17,849  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66859669 created in the thread with id: 1
2024-04-24T09:40:17,851  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:17,851  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:17,851  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:17,851  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e147828, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66859669 will be shutdown
2024-04-24T09:40:17,851  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:17,851  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -86
2024-04-24T09:40:17,851  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:17,852  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:17,853  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810, with PersistenceManager: null will be shutdown
2024-04-24T09:40:17,853  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e3062f0 created in the thread with id: 1
2024-04-24T09:40:17,854  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810 from thread id: 1
2024-04-24T09:40:17,856  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:17,864  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:17,871  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:17,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:17,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:17,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:17,902  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:17,902  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:17,903  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:17,903  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:17,904  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e3062f0 will be shutdown
2024-04-24T09:40:17,904  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a5e591b created in the thread with id: 1
2024-04-24T09:40:17,905  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:17,905  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:17,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:17,906  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c8e4810, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a5e591b will be shutdown
2024-04-24T09:40:17,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:17,906  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -87
2024-04-24T09:40:17,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:17,908  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:17,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971, with PersistenceManager: null will be shutdown
2024-04-24T09:40:17,908  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@808f65 created in the thread with id: 1
2024-04-24T09:40:17,909  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971 from thread id: 1
2024-04-24T09:40:17,911  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_JSONFILE[p1value2,502]	
2024-04-24T09:40:17,928  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:17,932  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:17,933  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:17,950  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:17,963  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1473653074_0023
2024-04-24T09:40:17,963  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:18,007  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:18,007  INFO [main] mapreduce.Job: Running job: job_local1473653074_0023
2024-04-24T09:40:18,008  INFO [Thread-934] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:18,009  INFO [Thread-934] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,009  INFO [Thread-934] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,010  INFO [Thread-934] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:18,011  INFO [Thread-934] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,011  INFO [Thread-934] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,022  INFO [Thread-934] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:18,022  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1473653074_0023_m_000000_0
2024-04-24T09:40:18,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,025  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,026  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,027  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,027  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:18,027  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:18,029  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,029  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,043  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:18,043  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1473653074_0023_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:18,043  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,043  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,047  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:18,047  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1473653074_0023_m_000000_0 is allowed to commit now
2024-04-24T09:40:18,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:18,047  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:18,056  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1473653074_0023_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,41146439262776613/part1=p1value2/part0=502
2024-04-24T09:40:18,057  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:18,057  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1473653074_0023_m_000000_0' done.
2024-04-24T09:40:18,057  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1473653074_0023_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11767651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:18,057  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1473653074_0023_m_000000_0
2024-04-24T09:40:18,057  INFO [Thread-934] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:18,097  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:18,097  INFO [Thread-934] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:18,098  INFO [Thread-934] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:18,099  INFO [Thread-934] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:18,099  INFO [Thread-934] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:18,099  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a43bed5, with PersistenceManager: null will be shutdown
2024-04-24T09:40:18,099  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a43bed5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a715fb1 created in the thread with id: 996
2024-04-24T09:40:18,101  INFO [Thread-934] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a43bed5 from thread id: 996
2024-04-24T09:40:18,101  INFO [Thread-934] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:18,101  INFO [Thread-934] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:18,101  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:18,101  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a43bed5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a715fb1 will be shutdown
2024-04-24T09:40:18,101  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:18,101  INFO [Thread-934] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -88
2024-04-24T09:40:18,101  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:18,103  INFO [Thread-934] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:18,103  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284, with PersistenceManager: null will be shutdown
2024-04-24T09:40:18,103  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@752f487c created in the thread with id: 996
2024-04-24T09:40:18,104  INFO [Thread-934] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284 from thread id: 996
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:18,140  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:18,141  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:18,141  INFO [Thread-934] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_jsonfile has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:18,161  INFO [Thread-934] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,41146439262776613/part1=p1value2/part0=502].
2024-04-24T09:40:18,161  INFO [Thread-934] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:18,194  WARN [Thread-934] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:18,194  INFO [Thread-934] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:18,195  INFO [Thread-934] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:18,195  INFO [Thread-934] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:18,196  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@752f487c will be shutdown
2024-04-24T09:40:18,196  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d20ab8 created in the thread with id: 996
2024-04-24T09:40:18,197  INFO [Thread-934] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:18,197  INFO [Thread-934] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:18,198  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:18,198  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@11de6284, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5d20ab8 will be shutdown
2024-04-24T09:40:18,198  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:18,198  INFO [Thread-934] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -89
2024-04-24T09:40:18,198  INFO [Thread-934] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:18,199  INFO [Thread-934] metastore.HMSHandler: 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:18,199  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9d6f53, with PersistenceManager: null will be shutdown
2024-04-24T09:40:18,200  INFO [Thread-934] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9d6f53, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a7c708a created in the thread with id: 996
2024-04-24T09:40:18,201  INFO [Thread-934] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a9d6f53 from thread id: 996
2024-04-24T09:40:18,202  INFO [Thread-934] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:18,202  WARN [Thread-934] mapred.LocalJobRunner: job_local1473653074_0023
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_SCRATCH0,41146439262776613/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:18,553  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-24T09:40:19,008  INFO [main] mapreduce.Job: Job job_local1473653074_0023 running in uber mode : false
2024-04-24T09:40:19,008  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:19,009  INFO [main] mapreduce.Job: Job job_local1473653074_0023 failed with state FAILED due to: NA
2024-04-24T09:40:19,011  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=5700
		FILE: Number of bytes written=11767651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=858783744
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,053  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,053  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:19,054  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:19,055  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,056  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,056  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@808f65 will be shutdown
2024-04-24T09:40:19,056  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@393b99d created in the thread with id: 1
2024-04-24T09:40:19,058  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,058  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,058  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e316971, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@393b99d will be shutdown
2024-04-24T09:40:19,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,058  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -90
2024-04-24T09:40:19,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,059  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,060  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7227e3f1 created in the thread with id: 1
2024-04-24T09:40:19,061  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa from thread id: 1
2024-04-24T09:40:19,063  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:19,071  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:19,079  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:19,108  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,109  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,109  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:19,110  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,110  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,110  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7227e3f1 will be shutdown
2024-04-24T09:40:19,111  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5843ab8 created in the thread with id: 1
2024-04-24T09:40:19,112  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,112  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,113  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@16ef07fa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5843ab8 will be shutdown
2024-04-24T09:40:19,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,113  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -91
2024-04-24T09:40:19,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,114  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,115  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d911f95 created in the thread with id: 1
2024-04-24T09:40:19,116  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b from thread id: 1
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,156  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:19,157  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:19,158  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,158  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,159  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d911f95 will be shutdown
2024-04-24T09:40:19,159  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14b3976 created in the thread with id: 1
2024-04-24T09:40:19,160  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,161  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,161  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4cb084b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@14b3976 will be shutdown
2024-04-24T09:40:19,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,161  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -92
2024-04-24T09:40:19,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,162  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,163  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,163  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b87c881 created in the thread with id: 1
2024-04-24T09:40:19,164  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7 from thread id: 1
2024-04-24T09:40:19,166  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:19,176  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,220  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,221  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:19,222  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:19,224  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,224  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,224  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b87c881 will be shutdown
2024-04-24T09:40:19,224  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3aede2ff created in the thread with id: 1
2024-04-24T09:40:19,226  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,226  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,226  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@618a9cb7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3aede2ff will be shutdown
2024-04-24T09:40:19,226  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,227  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -93
2024-04-24T09:40:19,227  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,228  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,228  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,228  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@734d870f created in the thread with id: 1
2024-04-24T09:40:19,230  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9 from thread id: 1
2024-04-24T09:40:19,232  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:19,242  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:19,250  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,284  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,285  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,285  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:19,286  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,286  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,286  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@734d870f will be shutdown
2024-04-24T09:40:19,287  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bfab643 created in the thread with id: 1
2024-04-24T09:40:19,288  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,289  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,289  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44835de9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3bfab643 will be shutdown
2024-04-24T09:40:19,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,289  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -94
2024-04-24T09:40:19,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,291  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,291  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,291  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19c28c97 created in the thread with id: 1
2024-04-24T09:40:19,293  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0 from thread id: 1
2024-04-24T09:40:19,300  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:19,304  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:19,305  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:19,355  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:19,369  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local409294418_0024
2024-04-24T09:40:19,369  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:19,413  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:19,413  INFO [main] mapreduce.Job: Running job: job_local409294418_0024
2024-04-24T09:40:19,414  INFO [Thread-985] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:19,416  INFO [Thread-985] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:19,417  INFO [Thread-985] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:19,417  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local409294418_0024_m_000000_0
2024-04-24T09:40:19,420  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:19,421  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:40:19,426  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local409294418_0024_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.9389919274540797/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:40:19,426  INFO [Thread-985] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:19,428  INFO [Thread-985] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_jsonfile/_DYN0.9389919274540797].
2024-04-24T09:40:19,428  INFO [Thread-985] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:19,463  WARN [Thread-985] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:19,464  INFO [Thread-985] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:19,465  INFO [Thread-985] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:19,465  INFO [Thread-985] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,465  INFO [Thread-985] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:19,466  INFO [Thread-985] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58b875d7, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,466  INFO [Thread-985] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58b875d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69c0dfa2 created in the thread with id: 1049
2024-04-24T09:40:19,467  INFO [Thread-985] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58b875d7 from thread id: 1049
2024-04-24T09:40:19,467  INFO [Thread-985] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:19,467  INFO [Thread-985] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:19,468  INFO [Thread-985] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:19,468  INFO [Thread-985] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@58b875d7, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@69c0dfa2 will be shutdown
2024-04-24T09:40:19,468  INFO [Thread-985] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:19,468  INFO [Thread-985] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -95
2024-04-24T09:40:19,468  INFO [Thread-985] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:19,469  INFO [Thread-985] metastore.HMSHandler: 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:19,470  INFO [Thread-985] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6578d06e, with PersistenceManager: null will be shutdown
2024-04-24T09:40:19,470  INFO [Thread-985] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6578d06e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4b267a38 created in the thread with id: 1049
2024-04-24T09:40:19,471  INFO [Thread-985] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6578d06e from thread id: 1049
2024-04-24T09:40:19,473  INFO [Thread-985] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:19,473  WARN [Thread-985] mapred.LocalJobRunner: job_local409294418_0024
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:40:20,415  INFO [main] mapreduce.Job: Job job_local409294418_0024 running in uber mode : false
2024-04-24T09:40:20,415  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:20,415  INFO [main] mapreduce.Job: Job job_local409294418_0024 failed with state FAILED due to: NA
2024-04-24T09:40:20,416  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:20,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:20,451  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:20,451  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:20,453  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:20,453  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:20,453  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@19c28c97 will be shutdown
2024-04-24T09:40:20,454  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ec25389 created in the thread with id: 1
2024-04-24T09:40:20,455  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:20,455  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:20,455  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:20,455  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@79296ce0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ec25389 will be shutdown
2024-04-24T09:40:20,455  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:20,455  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -96
2024-04-24T09:40:20,456  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:20,457  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:20,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: null will be shutdown
2024-04-24T09:40:20,457  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26aecf31 created in the thread with id: 1
2024-04-24T09:40:20,458  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87 from thread id: 1
2024-04-24T09:40:20,460  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:20,471  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:20,472  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:20,479  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:20,485  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:20,490  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:20,509  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:40:20,522  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local442636605_0025
2024-04-24T09:40:20,522  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:20,570  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:20,570  INFO [main] mapreduce.Job: Running job: job_local442636605_0025
2024-04-24T09:40:20,570  INFO [Thread-1005] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:20,570  INFO [Thread-1005] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:20,570  INFO [Thread-1005] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:20,571  INFO [Thread-1005] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:40:20,578  INFO [Thread-1005] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:20,578  INFO [Thread-1005] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:21,571  INFO [main] mapreduce.Job: Job job_local442636605_0025 running in uber mode : false
2024-04-24T09:40:21,571  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:21,571  INFO [main] mapreduce.Job: Job job_local442636605_0025 completed successfully
2024-04-24T09:40:21,572  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:21,572  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:21,585  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:21,585  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_JSONFILE	
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:21,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
]]></system-err>
  </testcase>
  <testcase name="testHCatPartitionedTable[7]" classname="org.apache.hive.hcatalog.mapreduce.TestHCatExternalPartitioned" time="6.321">
    <failure message="expected:&lt;30&gt; but was:&lt;0&gt;" type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError: expected:<30> but was:<0>
	at org.junit.Assert.fail(Assert.java:89)
	at org.junit.Assert.failNotEquals(Assert.java:835)
	at org.junit.Assert.assertEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:633)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:411)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest.runMRRead(HCatMapReduceTest.java:372)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitioned.testHCatPartitionedTable(TestHCatPartitioned.java:165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83)
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75)
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></failure>
    <system-err><![CDATA[2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:21,699  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:21,702  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:21,702  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:21,702  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@26aecf31 will be shutdown
2024-04-24T09:40:21,703  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23ac164d created in the thread with id: 1
2024-04-24T09:40:21,704  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
Hive Session ID = ea48c980-cd73-4ef2-97dc-dcf7dfa3d892
2024-04-24T09:40:21,705  INFO [main] SessionState: Hive Session ID = ea48c980-cd73-4ef2-97dc-dcf7dfa3d892
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:21,705  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,file:/home/alex/.m2/repository/org/apache/pig/pig/0.16.0/pig-0.16.0-h2.jar!/ivysettings.xml will be used
2024-04-24T09:40:21,710  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ea48c980-cd73-4ef2-97dc-dcf7dfa3d892
2024-04-24T09:40:21,713  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/localscratchdir/ea48c980-cd73-4ef2-97dc-dcf7dfa3d892
2024-04-24T09:40:21,715  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/hcatalog/core/target/tmp/scratchdir/alex/ea48c980-cd73-4ef2-97dc-dcf7dfa3d892/_tmp_space.db
2024-04-24T09:40:21,716  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:21,718  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:testHCatPartitionedTable_rcfile_columnar, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable_rcfile_columnar, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{EXTERNAL=TRUE, serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:int, comment:)], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, EXTERNAL=TRUE, transactional=false, immutable=true}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:40:21,722  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:21,782  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:21,783  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:21,783  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, hive.stats.column.autogather=true, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:21,785  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:21,785  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:21,785  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23ac164d will be shutdown
2024-04-24T09:40:21,786  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52a9c251 created in the thread with id: 1
2024-04-24T09:40:21,787  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:21,787  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:21,788  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:21,788  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@a19fe87, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@52a9c251 will be shutdown
2024-04-24T09:40:21,788  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:21,788  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -97
2024-04-24T09:40:21,788  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:21,789  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:21,789  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d, with PersistenceManager: null will be shutdown
2024-04-24T09:40:21,790  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@319e02e7 created in the thread with id: 1
2024-04-24T09:40:21,791  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d from thread id: 1
2024-04-24T09:40:21,793  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:21,802  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:21,809  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:21,838  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:21,839  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:21,840  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:21,840  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:21,840  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@319e02e7 will be shutdown
2024-04-24T09:40:21,840  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11c95035 created in the thread with id: 1
2024-04-24T09:40:21,842  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:21,842  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:21,842  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:21,842  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@35f79e6d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@11c95035 will be shutdown
2024-04-24T09:40:21,842  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:21,842  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -98
2024-04-24T09:40:21,843  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:21,844  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:21,844  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36, with PersistenceManager: null will be shutdown
2024-04-24T09:40:21,845  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e24f013 created in the thread with id: 1
2024-04-24T09:40:21,846  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36 from thread id: 1
2024-04-24T09:40:21,848  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value1,501]	
2024-04-24T09:40:21,865  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:21,869  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:21,870  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:21,887  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:21,900  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1341091083_0026
2024-04-24T09:40:21,900  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:21,945  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:21,945  INFO [main] mapreduce.Job: Running job: job_local1341091083_0026
2024-04-24T09:40:21,946  INFO [Thread-1039] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:21,948  INFO [Thread-1039] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,948  INFO [Thread-1039] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,949  INFO [Thread-1039] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:21,950  INFO [Thread-1039] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,950  INFO [Thread-1039] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,961  INFO [Thread-1039] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:21,961  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1341091083_0026_m_000000_0
2024-04-24T09:40:21,965  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,965  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,967  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,967  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,967  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:21,967  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+40
2024-04-24T09:40:21,972  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,973  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,985  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:21,985  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 10,  Compr Total Column Value Length: 10
2024-04-24T09:40:21,985  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 90,  Compr Total Column Value Length: 90
2024-04-24T09:40:21,987  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1341091083_0026_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:21,987  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,987  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:21,991  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:21,991  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local1341091083_0026_m_000000_0 is allowed to commit now
2024-04-24T09:40:21,991  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:21,991  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:22,000  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local1341091083_0026_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,31821636171560264/part1=p1value1/part0=501
2024-04-24T09:40:22,000  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:22,000  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1341091083_0026_m_000000_0' done.
2024-04-24T09:40:22,000  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1341091083_0026_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13299247
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:22,000  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1341091083_0026_m_000000_0
2024-04-24T09:40:22,001  INFO [Thread-1039] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:22,039  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:22,040  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:22,040  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:22,040  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:22,040  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:22,040  INFO [Thread-1039] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:22,041  INFO [Thread-1039] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:22,041  INFO [Thread-1039] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:22,041  INFO [Thread-1039] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:22,042  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c25331a, with PersistenceManager: null will be shutdown
2024-04-24T09:40:22,042  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c25331a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50cca442 created in the thread with id: 1105
2024-04-24T09:40:22,043  INFO [Thread-1039] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c25331a from thread id: 1105
2024-04-24T09:40:22,043  INFO [Thread-1039] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:22,043  INFO [Thread-1039] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:22,044  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:22,044  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c25331a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50cca442 will be shutdown
2024-04-24T09:40:22,044  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:22,044  INFO [Thread-1039] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -99
2024-04-24T09:40:22,044  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:22,045  INFO [Thread-1039] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:22,046  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57, with PersistenceManager: null will be shutdown
2024-04-24T09:40:22,046  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6693aa9d created in the thread with id: 1105
2024-04-24T09:40:22,047  INFO [Thread-1039] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57 from thread id: 1105
2024-04-24T09:40:22,082  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:22,083  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:22,083  INFO [Thread-1039] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part1=p1value1, part0=501}].
2024-04-24T09:40:22,103  INFO [Thread-1039] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,31821636171560264/part1=p1value1/part0=501].
2024-04-24T09:40:22,104  INFO [Thread-1039] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:22,136  WARN [Thread-1039] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:22,136  INFO [Thread-1039] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:22,137  INFO [Thread-1039] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:22,137  INFO [Thread-1039] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:22,137  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6693aa9d will be shutdown
2024-04-24T09:40:22,137  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b9631d created in the thread with id: 1105
2024-04-24T09:40:22,139  INFO [Thread-1039] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:22,139  INFO [Thread-1039] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:22,139  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:22,139  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3acdbf57, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2b9631d will be shutdown
2024-04-24T09:40:22,140  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:22,140  INFO [Thread-1039] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -100
2024-04-24T09:40:22,140  INFO [Thread-1039] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:22,141  INFO [Thread-1039] metastore.HMSHandler: 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:22,141  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6eae1e90, with PersistenceManager: null will be shutdown
2024-04-24T09:40:22,141  INFO [Thread-1039] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6eae1e90, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@72d7a460 created in the thread with id: 1105
2024-04-24T09:40:22,143  INFO [Thread-1039] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6eae1e90 from thread id: 1105
2024-04-24T09:40:22,144  INFO [Thread-1039] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:22,144  WARN [Thread-1039] mapred.LocalJobRunner: job_local1341091083_0026
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,31821636171560264/part1=p1value1/part0=501, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:22,946  INFO [main] mapreduce.Job: Job job_local1341091083_0026 running in uber mode : false
2024-04-24T09:40:22,946  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:22,947  INFO [main] mapreduce.Job: Job job_local1341091083_0026 failed with state FAILED due to: NA
2024-04-24T09:40:22,949  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6282
		FILE: Number of bytes written=13299247
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=10
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=56
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:22,989  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:22,989  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:22,990  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:22,990  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:22,991  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:40:22,992  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:22,992  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:22,993  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5e24f013 will be shutdown
2024-04-24T09:40:22,993  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5259469d created in the thread with id: 1
2024-04-24T09:40:22,995  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:22,995  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:22,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:22,995  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@59ea2a36, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5259469d will be shutdown
2024-04-24T09:40:22,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:22,995  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -101
2024-04-24T09:40:22,996  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:22,997  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:22,997  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382, with PersistenceManager: null will be shutdown
2024-04-24T09:40:22,997  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ae45ff created in the thread with id: 1
2024-04-24T09:40:22,999  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382 from thread id: 1
2024-04-24T09:40:23,001  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:23,010  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:23,017  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:23,048  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:23,049  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:23,050  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:23,050  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:23,050  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4ae45ff will be shutdown
2024-04-24T09:40:23,050  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e6a643 created in the thread with id: 1
2024-04-24T09:40:23,052  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:23,052  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:23,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:23,052  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@50c8a382, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e6a643 will be shutdown
2024-04-24T09:40:23,053  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:23,053  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -102
2024-04-24T09:40:23,053  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:23,054  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:23,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938, with PersistenceManager: null will be shutdown
2024-04-24T09:40:23,055  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54ba7b3f created in the thread with id: 1
2024-04-24T09:40:23,057  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938 from thread id: 1
2024-04-24T09:40:23,060  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-04-24T09:40:23,079  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:23,083  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:23,084  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:23,100  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:23,113  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local952376193_0027
2024-04-24T09:40:23,113  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:23,158  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:23,158  INFO [main] mapreduce.Job: Running job: job_local952376193_0027
2024-04-24T09:40:23,158  INFO [Thread-1085] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:23,160  INFO [Thread-1085] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,160  INFO [Thread-1085] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,161  INFO [Thread-1085] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:23,162  INFO [Thread-1085] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,162  INFO [Thread-1085] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,173  INFO [Thread-1085] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:23,173  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local952376193_0027_m_000000_0
2024-04-24T09:40:23,175  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,175  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,176  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,176  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,176  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:23,177  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:23,179  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,179  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,191  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:23,191  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-04-24T09:40:23,191  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-24T09:40:23,192  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local952376193_0027_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:23,192  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,192  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,195  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:23,195  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local952376193_0027_m_000000_0 is allowed to commit now
2024-04-24T09:40:23,195  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:23,195  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:23,204  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local952376193_0027_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7435726240547214/part1=p1value2/part0=502
2024-04-24T09:40:23,204  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:23,204  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local952376193_0027_m_000000_0' done.
2024-04-24T09:40:23,204  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local952376193_0027_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13810202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:23,204  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local952376193_0027_m_000000_0
2024-04-24T09:40:23,204  INFO [Thread-1085] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:23,244  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:23,244  INFO [Thread-1085] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:23,245  INFO [Thread-1085] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:23,246  INFO [Thread-1085] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:23,246  INFO [Thread-1085] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:23,246  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@879068, with PersistenceManager: null will be shutdown
2024-04-24T09:40:23,246  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@879068, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d590b81 created in the thread with id: 1153
2024-04-24T09:40:23,248  INFO [Thread-1085] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@879068 from thread id: 1153
2024-04-24T09:40:23,248  INFO [Thread-1085] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:23,248  INFO [Thread-1085] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:23,248  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:23,248  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@879068, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4d590b81 will be shutdown
2024-04-24T09:40:23,248  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:23,248  INFO [Thread-1085] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -103
2024-04-24T09:40:23,249  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:23,250  INFO [Thread-1085] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:23,250  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd, with PersistenceManager: null will be shutdown
2024-04-24T09:40:23,250  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@234d900d created in the thread with id: 1153
2024-04-24T09:40:23,251  INFO [Thread-1085] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd from thread id: 1153
2024-04-24T09:40:23,287  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:23,287  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:23,287  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:23,287  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:23,288  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:23,288  INFO [Thread-1085] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:23,308  INFO [Thread-1085] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7435726240547214/part1=p1value2/part0=502].
2024-04-24T09:40:23,308  INFO [Thread-1085] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:23,342  WARN [Thread-1085] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:23,342  INFO [Thread-1085] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:23,343  INFO [Thread-1085] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:23,343  INFO [Thread-1085] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:23,344  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@234d900d will be shutdown
2024-04-24T09:40:23,344  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@513ec21a created in the thread with id: 1153
2024-04-24T09:40:23,345  INFO [Thread-1085] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:23,345  INFO [Thread-1085] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:23,346  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:23,346  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@23d670dd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@513ec21a will be shutdown
2024-04-24T09:40:23,346  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:23,346  INFO [Thread-1085] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -104
2024-04-24T09:40:23,346  INFO [Thread-1085] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:23,347  INFO [Thread-1085] metastore.HMSHandler: 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:23,348  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6831de61, with PersistenceManager: null will be shutdown
2024-04-24T09:40:23,348  INFO [Thread-1085] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6831de61, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@422e12a2 created in the thread with id: 1153
2024-04-24T09:40:23,349  INFO [Thread-1085] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6831de61 from thread id: 1153
2024-04-24T09:40:23,350  INFO [Thread-1085] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:23,350  WARN [Thread-1085] mapred.LocalJobRunner: job_local952376193_0027
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7435726240547214/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:24,159  INFO [main] mapreduce.Job: Job job_local952376193_0027 running in uber mode : false
2024-04-24T09:40:24,159  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:24,159  INFO [main] mapreduce.Job: Job job_local952376193_0027 failed with state FAILED due to: NA
2024-04-24T09:40:24,161  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6594
		FILE: Number of bytes written=13810202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:24,203  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:24,203  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:24,204  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:24,205  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:24,206  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:24,206  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:24,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@54ba7b3f will be shutdown
2024-04-24T09:40:24,207  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@380f9c1d created in the thread with id: 1
2024-04-24T09:40:24,208  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:24,208  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:24,209  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:24,209  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@37b17938, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@380f9c1d will be shutdown
2024-04-24T09:40:24,209  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:24,209  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -105
2024-04-24T09:40:24,209  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:24,210  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:24,210  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90, with PersistenceManager: null will be shutdown
2024-04-24T09:40:24,211  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@358b70c4 created in the thread with id: 1
2024-04-24T09:40:24,212  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90 from thread id: 1
2024-04-24T09:40:24,214  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:24,222  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:24,228  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:24,260  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:24,260  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:24,260  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:24,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:24,261  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:24,262  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:24,262  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:24,262  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@358b70c4 will be shutdown
2024-04-24T09:40:24,263  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c7ec499 created in the thread with id: 1
2024-04-24T09:40:24,264  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:24,264  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:24,265  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:24,265  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4afb2c90, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c7ec499 will be shutdown
2024-04-24T09:40:24,265  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:24,265  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -106
2024-04-24T09:40:24,265  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:24,266  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:24,267  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f, with PersistenceManager: null will be shutdown
2024-04-24T09:40:24,267  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5410bbdf created in the thread with id: 1
2024-04-24T09:40:24,268  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f from thread id: 1
2024-04-24T09:40:24,270  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar[p1value2,502]	
2024-04-24T09:40:24,286  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:24,290  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:24,291  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:24,307  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:24,321  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local732688763_0028
2024-04-24T09:40:24,321  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:24,389  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:24,389  INFO [main] mapreduce.Job: Running job: job_local732688763_0028
2024-04-24T09:40:24,390  INFO [Thread-1131] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:24,392  INFO [Thread-1131] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,392  INFO [Thread-1131] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,393  INFO [Thread-1131] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:24,394  INFO [Thread-1131] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,394  INFO [Thread-1131] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,409  INFO [Thread-1131] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:24,409  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local732688763_0028_m_000000_0
2024-04-24T09:40:24,412  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,412  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,414  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,414  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,414  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:24,415  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
2024-04-24T09:40:24,417  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,417  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,434  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:24,434  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#0 : Plain Total Column Value Length: 30,  Compr Total Column Value Length: 30
2024-04-24T09:40:24,434  INFO [LocalJobRunner Map Task Executor #0] io.RCFile: Column#1 : Plain Total Column Value Length: 190,  Compr Total Column Value Length: 190
2024-04-24T09:40:24,434  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local732688763_0028_m_000000_0 is done. And is in the process of committing
2024-04-24T09:40:24,435  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,435  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,439  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T09:40:24,439  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task attempt_local732688763_0028_m_000000_0 is allowed to commit now
2024-04-24T09:40:24,439  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:24,440  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:24,451  INFO [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter: Saved output of task 'attempt_local732688763_0028_m_000000_0' to pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7290689145791865/part1=p1value2/part0=502
2024-04-24T09:40:24,452  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T09:40:24,452  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local732688763_0028_m_000000_0' done.
2024-04-24T09:40:24,452  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local732688763_0028_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14321157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:24,452  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local732688763_0028_m_000000_0
2024-04-24T09:40:24,452  INFO [Thread-1131] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:24,503  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:24,503  INFO [Thread-1131] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:24,504  INFO [Thread-1131] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:24,505  INFO [Thread-1131] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:24,505  INFO [Thread-1131] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:24,505  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3879de2d, with PersistenceManager: null will be shutdown
2024-04-24T09:40:24,506  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3879de2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2285307e created in the thread with id: 1201
2024-04-24T09:40:24,507  INFO [Thread-1131] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3879de2d from thread id: 1201
2024-04-24T09:40:24,507  INFO [Thread-1131] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:24,508  INFO [Thread-1131] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:24,508  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:24,508  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3879de2d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2285307e will be shutdown
2024-04-24T09:40:24,508  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:24,508  INFO [Thread-1131] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -107
2024-04-24T09:40:24,508  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:24,510  INFO [Thread-1131] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:24,510  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:24,510  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1960b611 created in the thread with id: 1201
2024-04-24T09:40:24,511  INFO [Thread-1131] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c from thread id: 1201
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:24,571  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:24,571  INFO [Thread-1131] mapreduce.FileOutputCommitterContainer: HAR not is not being used. The table testhcatpartitionedtable_rcfile_columnar has new partitions [{part1=p1value2, part0=502}].
2024-04-24T09:40:24,591  INFO [Thread-1131] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7290689145791865/part1=p1value2/part0=502].
2024-04-24T09:40:24,592  INFO [Thread-1131] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:24,624  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:24,624  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:24,625  WARN [Thread-1131] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:24,625  INFO [Thread-1131] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:24,626  INFO [Thread-1131] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:24,626  INFO [Thread-1131] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:24,626  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1960b611 will be shutdown
2024-04-24T09:40:24,626  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55593091 created in the thread with id: 1201
2024-04-24T09:40:24,628  INFO [Thread-1131] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:24,628  INFO [Thread-1131] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:24,628  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:24,628  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5c8d3c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55593091 will be shutdown
2024-04-24T09:40:24,628  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:24,628  INFO [Thread-1131] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -108
2024-04-24T09:40:24,628  INFO [Thread-1131] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:24,630  INFO [Thread-1131] metastore.HMSHandler: 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:24,630  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f0933e, with PersistenceManager: null will be shutdown
2024-04-24T09:40:24,630  INFO [Thread-1131] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f0933e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@13ab583 created in the thread with id: 1201
2024-04-24T09:40:24,631  INFO [Thread-1131] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4f0933e from thread id: 1201
2024-04-24T09:40:24,632  INFO [Thread-1131] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:24,632  WARN [Thread-1131] mapred.LocalJobRunner: job_local732688763_0028
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2002 : Partition already present with given partition key values : Data already exists in pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_SCRATCH0,7290689145791865/part1=p1value2/part0=502, duplicate publish not possible.
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.moveTaskOutputs(FileOutputCommitterContainer.java:586) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.registerPartitions(FileOutputCommitterContainer.java:857) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:252) ~[classes/:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:567) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T09:40:24,943  INFO [communication thread] mapred.LocalJobRunner: map > map
2024-04-24T09:40:25,390  INFO [main] mapreduce.Job: Job job_local732688763_0028 running in uber mode : false
2024-04-24T09:40:25,390  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:40:25,390  INFO [main] mapreduce.Job: Job job_local732688763_0028 failed with state FAILED due to: NA
2024-04-24T09:40:25,391  INFO [main] mapreduce.Job: Counters: 15
	File System Counters
		FILE: Number of bytes read=6906
		FILE: Number of bytes written=14321157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=20
		Map output records=20
		Input split bytes=142
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=896532480
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=0
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,433  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,433  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:25,434  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:25,435  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,435  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,436  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5410bbdf will be shutdown
2024-04-24T09:40:25,436  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ac60eeb created in the thread with id: 1
2024-04-24T09:40:25,437  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,437  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,438  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,438  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@775c865f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3ac60eeb will be shutdown
2024-04-24T09:40:25,438  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,438  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -109
2024-04-24T09:40:25,438  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,439  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,439  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,439  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f19f197 created in the thread with id: 1
2024-04-24T09:40:25,441  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4 from thread id: 1
2024-04-24T09:40:25,442  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:25,453  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:25,460  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,490  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,490  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:25,491  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,491  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,491  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f19f197 will be shutdown
2024-04-24T09:40:25,492  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c7485d2 created in the thread with id: 1
2024-04-24T09:40:25,493  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,493  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,493  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3bc57af4, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c7485d2 will be shutdown
2024-04-24T09:40:25,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,494  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -110
2024-04-24T09:40:25,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,495  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,496  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,496  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c006046 created in the thread with id: 1
2024-04-24T09:40:25,497  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe from thread id: 1
2024-04-24T09:40:25,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,536  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,536  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,537  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,537  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:25,538  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.fetch.task.conversion=minimal, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:25,539  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,539  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4c006046 will be shutdown
2024-04-24T09:40:25,540  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c40ae2d created in the thread with id: 1
2024-04-24T09:40:25,541  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,541  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,541  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@224855fe, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c40ae2d will be shutdown
2024-04-24T09:40:25,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,542  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -111
2024-04-24T09:40:25,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,543  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,543  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47fb038d created in the thread with id: 1
2024-04-24T09:40:25,545  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c from thread id: 1
2024-04-24T09:40:25,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:25,555  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,593  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:25,594  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.exec.mode.local.auto=false, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:25,595  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,596  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,596  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@47fb038d will be shutdown
2024-04-24T09:40:25,596  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@484313a6 created in the thread with id: 1
2024-04-24T09:40:25,598  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,598  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,598  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,598  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@587107c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@484313a6 will be shutdown
2024-04-24T09:40:25,598  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,598  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -112
2024-04-24T09:40:25,598  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,600  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,600  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,600  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e01d838 created in the thread with id: 1
2024-04-24T09:40:25,601  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39 from thread id: 1
2024-04-24T09:40:25,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:25,611  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:25,617  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,647  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,648  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:25,649  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,649  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e01d838 will be shutdown
2024-04-24T09:40:25,649  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2174fda1 created in the thread with id: 1
2024-04-24T09:40:25,651  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,651  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,651  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,651  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@558bff39, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2174fda1 will be shutdown
2024-04-24T09:40:25,651  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,652  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -113
2024-04-24T09:40:25,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,653  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dad7323 created in the thread with id: 1
2024-04-24T09:40:25,655  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab from thread id: 1
2024-04-24T09:40:25,661  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:25,665  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:25,666  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:40:25,683  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:40:25,695  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local556394183_0029
2024-04-24T09:40:25,696  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:25,739  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:25,739  INFO [main] mapreduce.Job: Running job: job_local556394183_0029
2024-04-24T09:40:25,740  INFO [Thread-1182] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:25,742  INFO [Thread-1182] mapred.LocalJobRunner: OutputCommitter is org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer
2024-04-24T09:40:25,743  INFO [Thread-1182] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:25,743  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local556394183_0029_m_000000_0
2024-04-24T09:40:25,747  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T09:40:25,747  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/home/alex/Repositories/hive/hcatalog/core/mapred/testHCatMapReduceInput:0+100
org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236)
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111)
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252)
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-24T09:40:25,752  INFO [LocalJobRunner Map Task Executor #0] mapreduce.TaskCommitContextRegistry: Registering committer for TaskAttemptID:attempt_local556394183_0029_m_000000_0@pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.5816541536666361/part1=__HIVE_DEFAULT_PARTITION__/part0=__HIVE_DEFAULT_PARTITION__
2024-04-24T09:40:25,752  INFO [Thread-1182] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:25,754  INFO [Thread-1182] mapreduce.FileOutputCommitterContainer: Job failed. Try cleaning up temporary directory [pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/testhcatpartitionedtable_rcfile_columnar/_DYN0.5816541536666361].
2024-04-24T09:40:25,754  INFO [Thread-1182] mapreduce.FileOutputCommitterContainer: Cancelling delegation token for the job.
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:25,787  WARN [Thread-1182] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:25,788  INFO [Thread-1182] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:40:25,788  INFO [Thread-1182] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:25,789  INFO [Thread-1182] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,789  INFO [Thread-1182] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:25,789  INFO [Thread-1182] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@786494a9, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,790  INFO [Thread-1182] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@786494a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e809245 created in the thread with id: 1254
2024-04-24T09:40:25,791  INFO [Thread-1182] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@786494a9 from thread id: 1254
2024-04-24T09:40:25,791  INFO [Thread-1182] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:25,791  INFO [Thread-1182] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:25,792  INFO [Thread-1182] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:25,792  INFO [Thread-1182] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@786494a9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e809245 will be shutdown
2024-04-24T09:40:25,792  INFO [Thread-1182] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:25,792  INFO [Thread-1182] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -114
2024-04-24T09:40:25,792  INFO [Thread-1182] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:25,793  INFO [Thread-1182] metastore.HMSHandler: 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:25,793  INFO [Thread-1182] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc74b, with PersistenceManager: null will be shutdown
2024-04-24T09:40:25,794  INFO [Thread-1182] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc74b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@539dfa1d created in the thread with id: 1254
2024-04-24T09:40:25,795  INFO [Thread-1182] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@25bfc74b from thread id: 1254
2024-04-24T09:40:25,796  INFO [Thread-1182] mapreduce.FileOutputCommitterContainer: FileOutputCommitterContainer::cancelDelegationTokens(): Could not find tokenStrForm, or HCAT_KEY_TOKEN_SIGNATURE. Skipping token cancellation.
2024-04-24T09:40:25,796  WARN [Thread-1182] mapred.LocalJobRunner: job_local556394183_0029
java.lang.Exception: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
Caused by: java.io.IOException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:257) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 2010 : Invalid partition values specified : Unable to configure dynamic partitioning for storage handler, mismatch between number of partition values obtained[0] and number of partition values required[2]
	at org.apache.hive.hcatalog.mapreduce.HCatBaseOutputFormat.configureOutputStorageHandler(HCatBaseOutputFormat.java:154) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.configureDynamicStorageHandler(DynamicPartitionFileRecordWriterContainer.java:236) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:158) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:111) ~[classes/:?]
	at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:55) ~[classes/:?]
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.write(MapTask.java:670) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:252) ~[test-classes/:?]
	at org.apache.hive.hcatalog.mapreduce.HCatMapReduceTest$MapCreate.map(HCatMapReduceTest.java:243) ~[test-classes/:?]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
2024-04-24T09:40:26,740  INFO [main] mapreduce.Job: Job job_local556394183_0029 running in uber mode : false
2024-04-24T09:40:26,741  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:26,741  INFO [main] mapreduce.Job: Job job_local556394183_0029 failed with state FAILED due to: NA
2024-04-24T09:40:26,741  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:26,775  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:26,776  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:40:26,776  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.stats.column.autogather=true, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.conf.restricted.list=dummy.config.value, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.scheduled.queries.executor.enabled=false, hive.llap.cache.allow.synthetic.fileid=true, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:40:26,778  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:40:26,778  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:40:26,778  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2dad7323 will be shutdown
2024-04-24T09:40:26,778  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21e441d1 created in the thread with id: 1
2024-04-24T09:40:26,780  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T09:40:26,780  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:40:26,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:40:26,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19324eab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@21e441d1 will be shutdown
2024-04-24T09:40:26,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:40:26,780  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -115
2024-04-24T09:40:26,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:40:26,782  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:40:26,782  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c42dc9f, with PersistenceManager: null will be shutdown
2024-04-24T09:40:26,782  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c42dc9f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@70bca957 created in the thread with id: 1
2024-04-24T09:40:26,783  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3c42dc9f from thread id: 1
2024-04-24T09:40:26,785  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:26,792  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:26,793  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_by_filter : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:26,799  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T09:40:26,805  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:40:26,809  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:40:26,827  INFO [main] mapreduce.JobSubmitter: number of splits:0
2024-04-24T09:40:26,840  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1978431424_0030
2024-04-24T09:40:26,840  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:40:26,883  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T09:40:26,883  INFO [main] mapreduce.Job: Running job: job_local1978431424_0030
2024-04-24T09:40:26,884  INFO [Thread-1202] mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-24T09:40:26,884  INFO [Thread-1202] output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-04-24T09:40:26,884  INFO [Thread-1202] output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-04-24T09:40:26,884  INFO [Thread-1202] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-24T09:40:26,891  INFO [Thread-1202] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T09:40:26,891  INFO [Thread-1202] mapred.LocalJobRunner: map task executor complete.
2024-04-24T09:40:27,884  INFO [main] mapreduce.Job: Job job_local1978431424_0030 running in uber mode : false
2024-04-24T09:40:27,885  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:40:27,885  INFO [main] mapreduce.Job: Job job_local1978431424_0030 completed successfully
2024-04-24T09:40:27,885  INFO [main] mapreduce.Job: Counters: 0
2024-04-24T09:40:27,886  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:27,916  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:40:27,917  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.testHCatPartitionedTable_rcfile_columnar	
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:40:27,977  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:40:27,978  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:40:27,978  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
]]></system-err>
  </testcase>
</testsuite>