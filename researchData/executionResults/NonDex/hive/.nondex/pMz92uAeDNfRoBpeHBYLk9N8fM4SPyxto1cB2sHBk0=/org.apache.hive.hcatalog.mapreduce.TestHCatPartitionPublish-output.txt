2024-04-24T09:38:09,136  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:38:09,137  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:38:09,138  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:38:09,139  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@713d8f55, with PersistenceManager: null will be shutdown
2024-04-24T09:38:09,140  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@713d8f55, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5cac1cf5 created in the thread with id: 412
2024-04-24T09:38:09,155  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@713d8f55 from thread id: 412
2024-04-24T09:38:09,277  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testHCatPartitionedTable, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:string, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:38:09,302  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/44391/testhcatpartitionedtable
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:38:09,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:38:09,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:38:09,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:38:09,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:38:09,740  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:38:09,740  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:38:09,740  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:38:09,742  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, datanucleus.schema.autoCreateAll=true, test.data.scripts=${hive.root}/data/scripts, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.stats.key.prefix.reserve.length=0, hive.metastore.client.cache.enabled=true, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T09:38:09,776  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T09:38:09,816  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:38:09,816  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:44391]
2024-04-24T09:38:09,817  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:44391)
2024-04-24T09:38:09,817  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:44391) current connections: 2
2024-04-24T09:38:09,818  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:38:09,881  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:38:09,883  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:38:09,883  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:38:09,883  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@103ff7cd, with PersistenceManager: null will be shutdown
2024-04-24T09:38:09,884  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@103ff7cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67ce1b5c created in the thread with id: 419
2024-04-24T09:38:09,889  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@103ff7cd from thread id: 419
2024-04-24T09:38:09,936  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:38:10,021  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:38:10,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:38:10,145  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:38:10,145  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:38:10,145  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:38:10,145  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:38:10,145  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:38:10,331  INFO [main] client.RMProxy: Connecting to ResourceManager at Lenovo-Bot/127.0.1.1:46561
2024-04-24T09:38:11,128  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:38:11,128  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:38:11,128  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:38:11,128  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:38:11,129  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:38:11,130  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:38:11,133  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:38:11,655  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:38:11,665  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:38:11,780  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:38:11,924  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:38:11,972  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1713976680032_0001
2024-04-24T09:38:11,972  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:38:12,285  INFO [main] mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
2024-04-24T09:38:12,993  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T09:38:12,993  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T09:38:13,009  INFO [main] impl.YarnClientImpl: Submitted application application_1713976680032_0001
2024-04-24T09:38:13,142  INFO [main] mapreduce.Job: The url to track the job: http://Lenovo-Bot:0/proxy/application_1713976680032_0001/
2024-04-24T09:38:13,145  INFO [main] mapreduce.Job: Running job: job_1713976680032_0001
2024-04-24T09:38:14,531  INFO [Socket Reader #1 for port 42321] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:19,652  INFO [Socket Reader #1 for port 40475] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:21,394  INFO [main] mapreduce.Job: Job job_1713976680032_0001 running in uber mode : false
2024-04-24T09:38:21,396  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:38:22,020  INFO [Socket Reader #1 for port 42321] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:22,032  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713976680032_0001
2024-04-24T09:38:25,501  INFO [main] mapreduce.Job: Task Id : attempt_1713976680032_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:38:25,912  INFO [Socket Reader #1 for port 42321] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:26,930  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713976680032_0001
2024-04-24T09:38:27,034  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner started
2024-04-24T09:38:27,034  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner complete
2024-04-24T09:38:29,554  INFO [main] mapreduce.Job: Task Id : attempt_1713976680032_0001_m_000000_1, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:38:31,965  INFO [Socket Reader #1 for port 42321] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:31,973  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713976680032_0001
2024-04-24T09:38:34,582  INFO [main] mapreduce.Job: Task Id : attempt_1713976680032_0001_m_000000_2, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:38:35,988  INFO [Socket Reader #1 for port 42321] ipc.Server: Auth successful for appattempt_1713976680032_0001_000001 (auth:SIMPLE)
2024-04-24T09:38:36,779  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713976680032_0001
2024-04-24T09:38:40,613  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:38:44,638  INFO [main] mapreduce.Job: Job job_1713976680032_0001 failed with state FAILED due to: Task failed task_1713976680032_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2024-04-24T09:38:44,810  INFO [main] mapreduce.Job: Counters: 9
	Job Counters 
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=3
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=11669
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=11669
		Total vcore-milliseconds taken by all map tasks=11669
		Total megabyte-milliseconds taken by all map tasks=11949056
2024-04-24T09:38:44,825  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:38:44,853  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:38:44,874  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:38:44,938  WARN [ContainersLauncher #0] nodemanager.DefaultContainerExecutor: Exit code from container container_1713976680032_0001_01_000001 is : 143
2024-04-24T09:39:01,979 ERROR [Thread[Thread-276,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:39:01,984  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T09:39:01,988  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T09:39:01,988 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T09:39:01,993  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T09:39:01,993  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T09:39:01,993  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T09:39:01,993  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T09:39:01,993  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T09:39:01,994 ERROR [Thread[Thread-99,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:39:01,994  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T09:39:01,994  INFO [main] impl.MetricsSystemImpl: Stopping JobHistoryServer metrics system...
2024-04-24T09:39:02,005  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system stopped.
2024-04-24T09:39:02,005  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system shutdown complete.
2024-04-24T09:39:02,009  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T09:39:02,009  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T09:39:02,012 ERROR [Thread[Thread-73,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:39:02,030  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T09:39:02,030  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:39:02,030  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@103ff7cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@67ce1b5c will be shutdown
