2024-04-24T12:40:41,990  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New topics: [Set(TEST-CREATE_TOPIC)], deleted topics: [Set()], new partition replica assignment [Map(TEST-CREATE_TOPIC-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))]
2024-04-24T12:40:41,991  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for TEST-CREATE_TOPIC-0
2024-04-24T12:40:42,021  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:42,040  INFO [data-plane-kafka-request-handler-1] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(TEST-CREATE_TOPIC-0)
2024-04-24T12:40:42,099  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:42,114  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123] Loading producer state till offset 0 with message format version 2
2024-04-24T12:40:42,119  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms
2024-04-24T12:40:42,122  INFO [data-plane-kafka-request-handler-1] log.LogManager: Created log for partition TEST-CREATE_TOPIC-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123/TEST-CREATE_TOPIC-0 with properties {max.compaction.lag.ms -> 9223372036854775807, flush.ms -> 9223372036854775807, message.timestamp.difference.max.ms -> 9223372036854775807, preallocate -> false, message.format.version -> 2.5-IV0, delete.retention.ms -> 86400000, flush.messages -> 9223372036854775807, retention.ms -> 604800000, unclean.leader.election.enable -> false, file.delete.delay.ms -> 60000, message.timestamp.type -> CreateTime, segment.bytes -> 1073741824, cleanup.policy -> [delete], index.interval.bytes -> 4096, compression.type -> producer, min.insync.replicas -> 1, retention.bytes -> -1, min.cleanable.dirty.ratio -> 0.5, segment.index.bytes -> 10485760, segment.jitter.ms -> 0, segment.ms -> 604800000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.downconversion.enable -> true}.
2024-04-24T12:40:42,122  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] No checkpointed highwatermark is found for partition TEST-CREATE_TOPIC-0
2024-04-24T12:40:42,123  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] Log loaded for partition TEST-CREATE_TOPIC-0 with initial high watermark 0
2024-04-24T12:40:42,124  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] TEST-CREATE_TOPIC-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:40:42,138  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:42,138  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:42,138  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987642138
2024-04-24T12:40:42,154  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:42,157  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:42,167  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:42,175  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:42,175  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:42,175  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987642175
2024-04-24T12:40:42,184  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9290]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:42,208  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:42,208  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:42,209  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987642208
2024-04-24T12:40:42,210  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:40:42,215  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:42,216  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:42,220  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:42,220  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,223  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:42,231  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:42,231  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:42,231  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987642231
2024-04-24T12:40:42,233  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:6090]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 1000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 100
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 100
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:42,244  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:42,244  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:42,244  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987642244
2024-04-24T12:40:42,245  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:40:42,246  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:42,246  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,308  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:42,308  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,320  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:42,320  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,409  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:42,409  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,471  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:42,471  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,663  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:42,663  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:42,674  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:42,674  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:43,069  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:40:43,070  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:40:43,081  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:43,081  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:43,258 ERROR [main] kafka.SimpleKafkaWriter: WriterId [460b361a-32ec-41ec-86a0-4e222c841c42] lost record from Topic [t], delivery Semantic [AT_LEAST_ONCE] -> ACTION=ABORT, ERROR caused by [Topic t not present in metadata after 1000 ms.]
2024-04-24T12:40:43,260  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [460b361a-32ec-41ec-86a0-4e222c841c42]
2024-04-24T12:40:43,261  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [460b361a-32ec-41ec-86a0-4e222c841c42]
2024-04-24T12:40:43,261  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:40:43,264  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [460b361a-32ec-41ec-86a0-4e222c841c42] Delivery semantic [AT_LEAST_ONCE], Topic[t], Total sent Records [1], Total Lost Records [1]
2024-04-24T12:40:43,264 ERROR [main] kafka.SimpleKafkaWriter: Send Exception Aborting write from writerId [460b361a-32ec-41ec-86a0-4e222c841c42]
2024-04-24T12:40:43,264  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 0 ms.
2024-04-24T12:40:43,267  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:43,267  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:40:43,271  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:40:43,278  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:43,278  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:43,278  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987643278
2024-04-24T12:40:43,279  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:40:43,287  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:40:43,288  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:40:43,288  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987643287
2024-04-24T12:40:43,289  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [edbdbb67-206f-45e5-885e-a3bff9ba16ee]
2024-04-24T12:40:43,314  INFO [data-plane-kafka-request-handler-2] zk.AdminZkClient: Creating topic edbdbb67-206f-45e5-885e-a3bff9ba16ee with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0))
2024-04-24T12:40:43,319  INFO [data-plane-kafka-request-handler-2] server.KafkaApis: [KafkaApi-0] Auto creation of topic edbdbb67-206f-45e5-885e-a3bff9ba16ee with 1 partitions and replication factor 1 is successful
2024-04-24T12:40:43,320  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New topics: [Set(edbdbb67-206f-45e5-885e-a3bff9ba16ee)], deleted topics: [Set()], new partition replica assignment [Map(edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))]
2024-04-24T12:40:43,320  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for edbdbb67-206f-45e5-885e-a3bff9ba16ee-0
2024-04-24T12:40:43,329  INFO [data-plane-kafka-request-handler-4] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(edbdbb67-206f-45e5-885e-a3bff9ba16ee-0)
2024-04-24T12:40:43,330  WARN [kafka-producer-network-thread | producer-3] clients.NetworkClient: [Producer clientId=producer-3] Error while fetching metadata with correlation id 1 : {edbdbb67-206f-45e5-885e-a3bff9ba16ee=LEADER_NOT_AVAILABLE}
2024-04-24T12:40:43,331  INFO [kafka-producer-network-thread | producer-3] clients.Metadata: [Producer clientId=producer-3] Cluster ID: U7zY_fiWRySrsvznMUD1-g
2024-04-24T12:40:43,333  INFO [data-plane-kafka-request-handler-4] log.Log: [Log partition=edbdbb67-206f-45e5-885e-a3bff9ba16ee-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123] Loading producer state till offset 0 with message format version 2
2024-04-24T12:40:43,333  INFO [data-plane-kafka-request-handler-4] log.Log: [Log partition=edbdbb67-206f-45e5-885e-a3bff9ba16ee-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2024-04-24T12:40:43,334  INFO [data-plane-kafka-request-handler-4] log.LogManager: Created log for partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-9210681386132647123/edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 with properties {preallocate -> false, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, segment.ms -> 604800000, segment.index.bytes -> 10485760, flush.ms -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, compression.type -> producer, retention.ms -> 604800000, segment.jitter.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, retention.bytes -> -1, min.insync.replicas -> 1, file.delete.delay.ms -> 60000, message.timestamp.type -> CreateTime, min.compaction.lag.ms -> 0, message.downconversion.enable -> true, unclean.leader.election.enable -> false, delete.retention.ms -> 86400000, segment.bytes -> 1073741824, cleanup.policy -> [delete], index.interval.bytes -> 4096, message.format.version -> 2.5-IV0, flush.messages -> 9223372036854775807}.
2024-04-24T12:40:43,335  INFO [data-plane-kafka-request-handler-4] cluster.Partition: [Partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 broker=0] No checkpointed highwatermark is found for partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0
2024-04-24T12:40:43,335  INFO [data-plane-kafka-request-handler-4] cluster.Partition: [Partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 broker=0] Log loaded for partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 with initial high watermark 0
2024-04-24T12:40:43,335  INFO [data-plane-kafka-request-handler-4] cluster.Partition: [Partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 broker=0] edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:40:43,603  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [9c840943-f4cf-4cdf-8d33-83d480d4d0ef]
2024-04-24T12:40:43,668  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [9c840943-f4cf-4cdf-8d33-83d480d4d0ef]
2024-04-24T12:40:43,668  INFO [main] producer.KafkaProducer: [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:40:43,673  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [9c840943-f4cf-4cdf-8d33-83d480d4d0ef] Delivery semantic [AT_LEAST_ONCE], Topic[edbdbb67-206f-45e5-885e-a3bff9ba16ee], Total sent Records [17384], Total Lost Records [0]
2024-04-24T12:40:43,673  INFO [main] consumer.KafkaConsumer: [Consumer clientId=consumer-4, groupId=null] Subscribed to partition(s): edbdbb67-206f-45e5-885e-a3bff9ba16ee-0
2024-04-24T12:40:43,679  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Seeking to EARLIEST offset of partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0
2024-04-24T12:40:43,697  INFO [main] clients.Metadata: [Consumer clientId=consumer-4, groupId=null] Cluster ID: U7zY_fiWRySrsvznMUD1-g
2024-04-24T12:40:43,721  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Resetting offset for partition edbdbb67-206f-45e5-885e-a3bff9ba16ee-0 to offset 0.
2024-04-24T12:40:43,886  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:43,886  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:44,116  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:40:44,116  INFO [main] server.KafkaServer: [KafkaServer id=0] shutting down
2024-04-24T12:40:44,117  INFO [main] server.KafkaServer: [KafkaServer id=0] Starting controlled shutdown
2024-04-24T12:40:44,125  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] Shutting down broker 0
2024-04-24T12:40:44,130  INFO [main] server.KafkaServer: [KafkaServer id=0] Controlled shutdown succeeded
2024-04-24T12:40:44,136  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutting down
2024-04-24T12:40:44,137  INFO [/config/changes-event-process-thread] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Stopped
2024-04-24T12:40:44,137  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutdown completed
2024-04-24T12:40:44,137  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopping socket server request processors
2024-04-24T12:40:44,146  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopped socket server request processors
2024-04-24T12:40:44,147  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shutting down
2024-04-24T12:40:44,149  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-04-24T12:40:44,151  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutting down
2024-04-24T12:40:44,319  INFO [ExpirationReaper-0-AlterAcls] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Stopped
2024-04-24T12:40:44,319  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-04-24T12:40:44,321  INFO [main] server.KafkaApis: [KafkaApi-0] Shutdown complete.
2024-04-24T12:40:44,322  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutting down
2024-04-24T12:40:44,410  INFO [ExpirationReaper-0-topic] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Stopped
2024-04-24T12:40:44,410  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutdown completed
2024-04-24T12:40:44,414  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutting down.
2024-04-24T12:40:44,415  INFO [main] transaction.ProducerIdManager: [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2024-04-24T12:40:44,416  INFO [main] transaction.TransactionStateManager: [Transaction State Manager 0]: Shutdown complete
2024-04-24T12:40:44,417  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutting down
2024-04-24T12:40:44,418  INFO [TxnMarkerSenderThread-0] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Stopped
2024-04-24T12:40:44,418  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutdown completed
2024-04-24T12:40:44,419  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutdown complete.
2024-04-24T12:40:44,419  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutting down.
2024-04-24T12:40:44,419  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutting down
2024-04-24T12:40:44,615  INFO [ExpirationReaper-0-Heartbeat] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Stopped
2024-04-24T12:40:44,616  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-04-24T12:40:44,617  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutting down
2024-04-24T12:40:44,746  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:44,746  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:44,816  INFO [ExpirationReaper-0-Rebalance] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Stopped
2024-04-24T12:40:44,816  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-04-24T12:40:44,817  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutdown complete.
2024-04-24T12:40:44,819  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shutting down
2024-04-24T12:40:44,820  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutting down
2024-04-24T12:40:44,820  INFO [LogDirFailureHandler] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Stopped
2024-04-24T12:40:44,820  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutdown completed
2024-04-24T12:40:44,821  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutting down
2024-04-24T12:40:44,823  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutdown completed
2024-04-24T12:40:44,823  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-04-24T12:40:44,823  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-04-24T12:40:44,824  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutting down
2024-04-24T12:40:44,909  INFO [ExpirationReaper-0-Fetch] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Stopped
2024-04-24T12:40:44,909  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutdown completed
2024-04-24T12:40:44,910  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutting down
2024-04-24T12:40:45,109  INFO [ExpirationReaper-0-Produce] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Stopped
2024-04-24T12:40:45,109  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutdown completed
2024-04-24T12:40:45,110  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-04-24T12:40:45,310  INFO [ExpirationReaper-0-DeleteRecords] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Stopped
2024-04-24T12:40:45,310  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-04-24T12:40:45,311  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutting down
2024-04-24T12:40:45,510  INFO [ExpirationReaper-0-ElectLeader] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Stopped
2024-04-24T12:40:45,510  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-04-24T12:40:45,516  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shut down completely
2024-04-24T12:40:45,517  INFO [main] log.LogManager: Shutting down.
2024-04-24T12:40:45,520  INFO [main] log.LogCleaner: Shutting down the log cleaner.
2024-04-24T12:40:45,520  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutting down
2024-04-24T12:40:45,521  INFO [kafka-log-cleaner-thread-0] log.LogCleaner: [kafka-log-cleaner-thread-0]: Stopped
2024-04-24T12:40:45,521  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutdown completed
2024-04-24T12:40:45,536  INFO [pool-9-thread-1] log.ProducerStateManager: [ProducerStateManager partition=edbdbb67-206f-45e5-885e-a3bff9ba16ee-0] Writing producer snapshot at offset 17384
2024-04-24T12:40:45,552  INFO [main] log.LogManager: Shutdown complete.
2024-04-24T12:40:45,552  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutting down
2024-04-24T12:40:45,553  INFO [controller-event-thread] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Stopped
2024-04-24T12:40:45,553  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutdown completed
2024-04-24T12:40:45,555  INFO [main] controller.ZkPartitionStateMachine: [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-04-24T12:40:45,555  INFO [main] controller.ZkReplicaStateMachine: [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-04-24T12:40:45,555  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutting down
2024-04-24T12:40:45,555  INFO [Controller-0-to-broker-0-send-thread] controller.RequestSendThread: [RequestSendThread controllerId=0] Stopped
2024-04-24T12:40:45,556  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutdown completed
2024-04-24T12:40:45,558  INFO [main] controller.KafkaController: [Controller id=0] Resigned
2024-04-24T12:40:45,559  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closing.
2024-04-24T12:40:45,658  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:45,659  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:45,663  INFO [main] zookeeper.ZooKeeper: Session: 0x1000968d4830000 closed
2024-04-24T12:40:45,665  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closed.
2024-04-24T12:40:45,666  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutting down
2024-04-24T12:40:46,087  INFO [ThrottledChannelReaper-Fetch] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Stopped
2024-04-24T12:40:46,087  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-04-24T12:40:46,087  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutting down
2024-04-24T12:40:46,567  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:46,567  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:47,087  INFO [ThrottledChannelReaper-Produce] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Stopped
2024-04-24T12:40:47,087  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutdown completed
2024-04-24T12:40:47,087  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutting down
2024-04-24T12:40:47,528  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:40:47,528  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:40:48,088  INFO [ThrottledChannelReaper-Request] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Stopped
2024-04-24T12:40:48,088  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutdown completed
2024-04-24T12:40:48,090  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutting down socket server
2024-04-24T12:40:48,113  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutdown completed
2024-04-24T12:40:48,117  INFO [main] server.KafkaServer: [KafkaServer id=0] shut down completed
2024-04-24T12:40:48,117  INFO [ConnnectionExpirer] server.NIOServerCnxnFactory: ConnnectionExpirerThread interrupted
2024-04-24T12:40:48,118  INFO [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0] server.NIOServerCnxnFactory: accept thread exitted run method
2024-04-24T12:40:48,118  INFO [NIOServerCxnFactory.SelectorThread-1] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:40:48,118  INFO [NIOServerCxnFactory.SelectorThread-0] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:40:48,118  INFO [main] server.ZooKeeperServer: shutting down
2024-04-24T12:40:48,118  INFO [main] server.SessionTrackerImpl: Shutting down
2024-04-24T12:40:48,118  INFO [main] server.PrepRequestProcessor: Shutting down
2024-04-24T12:40:48,119  INFO [main] server.SyncRequestProcessor: Shutting down
2024-04-24T12:40:48,119  INFO [ProcessThread(sid:0 cport:40883):] server.PrepRequestProcessor: PrepRequestProcessor exited loop!
2024-04-24T12:40:48,119  INFO [SyncThread:0] server.SyncRequestProcessor: SyncRequestProcessor exited!
2024-04-24T12:40:48,119  INFO [main] server.FinalRequestProcessor: shutdown of request processor complete
