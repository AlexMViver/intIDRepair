2024-04-24T12:04:34,838  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:04:34,877  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:exim, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:04:34,888  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:04:34,901  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:04:34,904  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:04:35,060  INFO [TThreadPoolServer WorkerProcess-%d] conf.MetastoreConf: Found configuration file: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/testconf/hivemetastore-site.xml
2024-04-24T12:04:35,062  INFO [TThreadPoolServer WorkerProcess-%d] conf.MetastoreConf: Unable to find config file: metastore-site.xml
2024-04-24T12:04:35,274  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:04:35,336  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:04:35,337  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:04:35,337  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:04:35,337  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:04:35,337  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:04:35,337  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:04:35,381  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:basicSrc, dbName:exim, owner:alex, createTime:1713985475, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:b, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:04:35,434  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc
2024-04-24T12:04:35,654  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:04:35,750  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:35,904  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplEximTmp' OVERWRITE INTO TABLE exim.basicSrc
2024-04-24T12:04:40,602  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,622  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,668  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,671  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,674  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,681  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,681  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:04:40,924  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:04:40,924  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34489]
2024-04-24T12:04:40,924  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34489)
2024-04-24T12:04:40,924  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34489) current connections: 2
2024-04-24T12:04:40,925  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:04:40,997  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_functions	
2024-04-24T12:04:40,999  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:04:41,000  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65a3a912, with PersistenceManager: null will be shutdown
2024-04-24T12:04:41,000  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65a3a912, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9eaa3d5 created in the thread with id: 42
2024-04-24T12:04:41,004  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65a3a912 from thread id: 42
2024-04-24T12:04:41,717  INFO [main] reflections.Reflections: Reflections took 563 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T12:04:42,312  INFO [main] reflections.Reflections: Reflections took 348 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T12:04:42,688  INFO [main] reflections.Reflections: Reflections took 360 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T12:04:42,922  INFO [main] parse.LoadSemanticAnalyzer: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:42,951  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:04:42,968  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,282  INFO [main] parse.LoadSemanticAnalyzer: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:43,282  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:04:43,293  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:04:43,304  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:04:43,304  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=33, getAllFunctions_()=70, flushCache_()=29, isCompatibleWith_(Configuration)=1}
2024-04-24T12:04:43,305  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 7.405 seconds
2024-04-24T12:04:43,307  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:04:43,308  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:04:43,315  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplEximTmp' OVERWRITE INTO TABLE exim.basicSrc
2024-04-24T12:04:43,328  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table exim.basicsrc
2024-04-24T12:04:43,332  INFO [main] exec.Task: Loading data to table exim.basicsrc from file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplEximTmp
2024-04-24T12:04:43,333  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:04:43,345  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,350  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:04:43,362  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,363  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:04:43,367  INFO [main] common.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc
2024-04-24T12:04:43,394  WARN [main] metadata.Hive: Cannot get a table snapshot for basicsrc
2024-04-24T12:04:43,430  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.exim.basicsrc newtbl=basicsrc	
2024-04-24T12:04:43,532  INFO [main] ql.Driver: Starting task [Stage-1:STATS] in serial mode
2024-04-24T12:04:43,533  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:04:43,545  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,545  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T12:04:43,546  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:04:43,556  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,671  WARN [main] metadata.Hive: Cannot get a table snapshot for basicsrc
2024-04-24T12:04:43,672  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.exim.basicsrc newtbl=basicsrc	
2024-04-24T12:04:43,706  INFO [main] stats.BasicStatsTask: Table exim.basicsrc stats: [numFiles=1, totalSize=14, numFilesErasureCoded=0]
2024-04-24T12:04:43,707  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:04:43,707  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=49, isCompatibleWith_(Configuration)=0, getDatabase_(String)=2, alter_table_(String, String, String, Table, EnvironmentContext, String)=161}
2024-04-24T12:04:43,707  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.392 seconds
2024-04-24T12:04:43,708  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicSrc
2024-04-24T12:04:43,844  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:43,849  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T12:04:43,877  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ee9676e0-3853-4d25-b6f8-3167fe8a2056, clientType=HIVECLI]
2024-04-24T12:04:43,884  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T12:04:43,896  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T12:04:43,896  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:04:43,896  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@65a3a912, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9eaa3d5 will be shutdown
2024-04-24T12:04:43,897  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:04:43,897  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:04:43,898  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:04:43,898  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34489]
2024-04-24T12:04:43,898  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34489)
2024-04-24T12:04:43,899  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34489) current connections: 2
2024-04-24T12:04:43,899  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:04:43,914  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T12:04:43,914  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:04:43,916  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:04:43,916  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34489]
2024-04-24T12:04:43,916  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34489)
2024-04-24T12:04:43,916  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34489) current connections: 3
2024-04-24T12:04:43,917  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:04:43,918  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:04:43,919  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:04:43,920  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f86ebeb, with PersistenceManager: null will be shutdown
2024-04-24T12:04:43,921  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f86ebeb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fe7e4cd created in the thread with id: 51
2024-04-24T12:04:43,926  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3f86ebeb from thread id: 51
2024-04-24T12:04:43,943  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:43,944  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:04:43,962  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:04:43,981  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T12:04:47,739  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_table_constraints : tbl=hive.exim.basicsrc	
2024-04-24T12:04:47,740  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:04:47,741  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41fe724a, with PersistenceManager: null will be shutdown
2024-04-24T12:04:47,741  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41fe724a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bee5f2b created in the thread with id: 50
2024-04-24T12:04:47,744  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41fe724a from thread id: 50
2024-04-24T12:04:49,244  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for exim.basicsrc, projIndxSet: [0], allowMissingStats: true
2024-04-24T12:04:49,297  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: table=hive.exim.basicsrc	
2024-04-24T12:04:49,349  WARN [main] calcite.RelOptHiveTable: No Stats for exim@basicsrc, Columns: b
No Stats for exim@basicsrc, Columns: b
2024-04-24T12:04:49,349  INFO [main] SessionState: No Stats for exim@basicsrc, Columns: b
2024-04-24T12:04:49,630  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:04:49,630  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:04:49,630  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:04:49,792  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-43_708_7456692983235424615-1/-mr-10001/.hive-staging_hive_2024-04-24_12-04-43_708_7456692983235424615-1
2024-04-24T12:04:49,820  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T12:04:50,022  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has 0<2 buckets 
2024-04-24T12:04:50,066  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T12:04:50,066  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:50,067  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:04:50,067  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:basicsrc.b, type:string, comment:null)], properties:null)
2024-04-24T12:04:50,117  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T12:04:50,117  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T12:04:50,134  INFO [main] exec.SelectOperator: SELECT struct<b:string>
2024-04-24T12:04:50,134  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T12:04:50,149  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:04:50,149  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=128, getTableColumnStatistics_(String, String, List, String)=69}
2024-04-24T12:04:50,149  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 6.441 seconds
2024-04-24T12:04:50,150  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:04:50,150  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:04:50,150  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicSrc
2024-04-24T12:04:50,150  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:04:50,150  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T12:04:50,151  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.0 seconds
2024-04-24T12:04:50,226  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T12:04:50,272  INFO [main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T12:04:50,273  INFO [main] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:04:50,273  INFO [main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T12:04:50,274  INFO [main] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:04:50,274  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T12:04:50,274  INFO [main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:04:50,279  INFO [main] repl.CommandTestUtils: About to run :EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim' FOR METADATA REPLICATION('222')
2024-04-24T12:04:50,280  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-43_708_7456692983235424615-1
2024-04-24T12:04:50,281  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-43_708_7456692983235424615-1 on fs with scheme file
2024-04-24T12:04:50,282  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim' FOR METADATA REPLICATION('222')
2024-04-24T12:04:50,285  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:04:50,296  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:50,297  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T12:04:50,297  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 2
2024-04-24T12:04:50,298  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:04:50,298  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@41fe724a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6bee5f2b will be shutdown
2024-04-24T12:04:50,298  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:04:50,299  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:04:50,302  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:04:50,303  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34489]
2024-04-24T12:04:50,303  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34489)
2024-04-24T12:04:50,303  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34489) current connections: 3
2024-04-24T12:04:50,304  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:04:50,305  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:04:50,306  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:04:50,306  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@682ad717, with PersistenceManager: null will be shutdown
2024-04-24T12:04:50,307  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@682ad717, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e6130a3 created in the thread with id: 57
2024-04-24T12:04:50,326  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@682ad717 from thread id: 57
2024-04-24T12:04:50,336  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:50,357  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,358  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,358  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,358  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,366  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:04:50,366  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:04:50,366  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:04:50,366  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=33}
2024-04-24T12:04:50,367  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.085 seconds
2024-04-24T12:04:50,367  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:04:50,367  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:04:50,367  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim' FOR METADATA REPLICATION('222')
2024-04-24T12:04:50,367  INFO [main] ql.Driver: Starting task [Stage-0:REPL_DUMP] in serial mode
2024-04-24T12:04:50,367  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,368  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,368  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,368  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,390  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:04:50,390  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T12:04:50,391  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.023 seconds
2024-04-24T12:04:50,394  INFO [main] repl.CommandTestUtils: Export returned the following _metadata contents:
2024-04-24T12:04:50,395  INFO [main] repl.CommandTestUtils: {"version":"0.2","repl.scope":"metadata","repl.event.id":"222","repl.last.id":"222","repl.noop":"false","repl.is.replace":"true","table":"{\"1\":{\"str\":\"basicsrc\"},\"2\":{\"str\":\"exim\"},\"3\":{\"str\":\"alex\"},\"4\":{\"i32\":1713985475},\"5\":{\"i32\":0},\"6\":{\"i32\":0},\"7\":{\"rec\":{\"1\":{\"lst\":[\"rec\",1,{\"1\":{\"str\":\"b\"},\"2\":{\"str\":\"string\"}}]},\"2\":{\"str\":\"pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc\"},\"3\":{\"str\":\"org.apache.hadoop.mapred.TextInputFormat\"},\"4\":{\"str\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\"},\"5\":{\"tf\":0},\"6\":{\"i32\":0},\"7\":{\"rec\":{\"2\":{\"str\":\"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\"},\"3\":{\"map\":[\"str\",\"str\",1,{\"serialization.format\":\"1\"}]}}},\"8\":{\"lst\":[\"str\",0]},\"9\":{\"lst\":[\"rec\",0]},\"10\":{\"map\":[\"str\",\"str\",0,{}]},\"11\":{\"rec\":{\"1\":{\"lst\":[\"str\",0]},\"2\":{\"lst\":[\"lst\",0]},\"3\":{\"map\":[\"lst\",\"str\",0,{}]}}},\"12\":{\"tf\":0}}},\"8\":{\"lst\":[\"rec\",0]},\"9\":{\"map\":[\"str\",\"str\",6,{\"bucketing_version\":\"2\",\"transient_lastDdlTime\":\"1713985483\",\"repl.last.id\":\"222\",\"numFilesErasureCoded\":\"0\",\"numFiles\":\"1\",\"totalSize\":\"14\"}]},\"12\":{\"str\":\"MANAGED_TABLE\"},\"15\":{\"tf\":0},\"17\":{\"str\":\"hive\"},\"18\":{\"i32\":1},\"19\":{\"i64\":0},\"25\":{\"i64\":1}}","partitions":[]}
2024-04-24T12:04:50,395  INFO [main] repl.CommandTestUtils: About to run :IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim'
2024-04-24T12:04:50,396  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim'
2024-04-24T12:04:50,449  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,449  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,476  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,476  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim
2024-04-24T12:04:50,479  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:04:50,482  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:04:50,826  INFO [main] reflections.Reflections: Reflections took 335 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T12:04:51,266  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:04:51,266  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:04:51,266  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:04:51,266  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=2, flushCache_()=0}
2024-04-24T12:04:51,266  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.87 seconds
2024-04-24T12:04:51,266  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:04:51,266  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:04:51,266  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testMetadataReplExim'
2024-04-24T12:04:51,267  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T12:04:51,270  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:04:51,290  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:basicDst, dbName:exim, owner:alex, createTime:1713985491, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:b, type:string, comment:null)], location:pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=14, repl.last.id=222, bucketing_version=2, numFilesErasureCoded=0, numFiles=1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T12:04:51,295  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Location: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst specified for non-external table:basicDst
2024-04-24T12:04:51,356  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:04:51,356  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=72}
2024-04-24T12:04:51,356  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.09 seconds
2024-04-24T12:04:51,356  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicDst
2024-04-24T12:04:51,358  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:51,358  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T12:04:51,358  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T12:04:51,358  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:04:51,358  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicdst	
2024-04-24T12:04:51,375  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:04:51,375  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:04:51,375  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:04:51,376  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T12:04:51,387  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_table_constraints : tbl=hive.exim.basicdst	
2024-04-24T12:04:51,396  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for exim.basicdst, projIndxSet: [0], allowMissingStats: true
2024-04-24T12:04:51,397  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: table=hive.exim.basicdst	
2024-04-24T12:04:51,410  WARN [main] calcite.RelOptHiveTable: No Stats for exim@basicdst, Columns: b
No Stats for exim@basicdst, Columns: b
2024-04-24T12:04:51,410  INFO [main] SessionState: No Stats for exim@basicdst, Columns: b
2024-04-24T12:04:51,524  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:04:51,524  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:04:51,524  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:04:51,525  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-51_356_4329601759595441893-1/-mr-10001/.hive-staging_hive_2024-04-24_12-04-51_356_4329601759595441893-1
2024-04-24T12:04:51,535  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T12:04:51,538  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has 0<2 buckets 
2024-04-24T12:04:51,539  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T12:04:51,539  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:04:51,539  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:04:51,539  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:basicdst.b, type:string, comment:null)], properties:null)
2024-04-24T12:04:51,541  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T12:04:51,542  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T12:04:51,542  INFO [main] exec.SelectOperator: SELECT struct<b:string>
2024-04-24T12:04:51,542  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T12:04:51,543  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:04:51,543  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=17, isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0, getTableColumnStatistics_(String, String, List, String)=13}
2024-04-24T12:04:51,543  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.187 seconds
2024-04-24T12:04:51,544  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:04:51,544  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:04:51,544  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicDst
2024-04-24T12:04:51,544  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:04:51,544  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T12:04:51,545  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.0 seconds
2024-04-24T12:04:51,553  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T12:04:51,554  INFO [main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T12:04:51,554  INFO [main] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:04:51,554  INFO [main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T12:04:51,554  INFO [main] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:2, 
2024-04-24T12:04:51,554  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T12:04:51,554  INFO [main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:04:51,590  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:04:51,621  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:51,621  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:51,662  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:04:51,716  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=exim tbls=basicdst,basicsrc	
2024-04-24T12:04:51,765  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:04:51,766  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:04:51,767  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:04:51,773  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:04:51,785  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:04:51,841  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:51,845  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:04:51,959  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:04:51,960  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T12:04:51,962  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:04:51,962  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T12:04:51,966  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:04:51,967  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T12:04:51,968  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:04:51,969  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T12:04:52,021 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:04:54,023  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:04:54,028  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:04:54,030  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:04:54,031  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:04:54,032  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:04:54,034  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:54,037  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:04:54,042 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:04:56,043  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:04:56,048  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:04:56,049  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:04:56,050  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:04:56,051  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:04:56,052  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:56,056  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:04:56,060 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:04:58,062  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:04:58,066  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:04:58,067  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:04:58,069  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:04:58,070  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:04:58,071  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:04:58,075  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:04:58,080 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:00,082  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:05:00,085  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:05:00,086  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:05:00,087  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:00,088  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:00,089  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:00,093  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:05:00,097 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:02,099  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:05:02,103  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:05:02,105  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:05:02,110  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:02,114  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:02,117  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:02,177  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.exim.basicdst	
2024-04-24T12:05:02,343  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:05:02,372 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:04,373  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:05:04,389  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:05:04,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:05:04,400  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:04,406  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:04,410  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:04,417  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:05:04,423 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:06,424  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:05:06,429  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:05:06,430  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:05:06,432  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:06,434  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:06,436  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:06,441  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:05:06,447 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:08,448  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#exim	
2024-04-24T12:05:08,453  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#exim	
2024-04-24T12:05:08,454  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#exim pat=*	
2024-04-24T12:05:08,456  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:08,457  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:08,458  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=exim pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:08,474  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,501  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.exim.basicdst	
2024-04-24T12:05:08,537  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.exim along with all tables
2024-04-24T12:05:08,567  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db does not exist; Force to delete it.
2024-04-24T12:05:08,567 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:05:08,570  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:exim, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:05:08,577  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:05:08,577  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:05:08,580  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db
2024-04-24T12:05:08,587  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:05:08,651  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:08,651  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:08,651  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:08,652  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:08,653  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:basicSrc, dbName:exim, owner:alex, createTime:1713985508, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:b, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:05:08,658  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc
2024-04-24T12:05:08,681  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:05:08,695  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,696  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-51_356_4329601759595441893-1
2024-04-24T12:05:08,697  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-04-51_356_4329601759595441893-1 on fs with scheme file
2024-04-24T12:05:08,697  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplEximTmp' OVERWRITE INTO TABLE exim.basicSrc
2024-04-24T12:05:08,698  INFO [main] parse.LoadSemanticAnalyzer: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:08,698  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:05:08,707  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,710  INFO [main] parse.LoadSemanticAnalyzer: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:08,710  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:08,710  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:08,710  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:08,710  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=10}
2024-04-24T12:05:08,711  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.013 seconds
2024-04-24T12:05:08,711  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:08,711  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:08,711  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): LOAD DATA LOCAL INPATH '/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplEximTmp' OVERWRITE INTO TABLE exim.basicSrc
2024-04-24T12:05:08,711  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table exim.basicsrc
2024-04-24T12:05:08,712  INFO [main] exec.Task: Loading data to table exim.basicsrc from file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplEximTmp
2024-04-24T12:05:08,712  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,721  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,723  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,732  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,733  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:05:08,735  INFO [main] common.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc
2024-04-24T12:05:08,743  WARN [main] metadata.Hive: Cannot get a table snapshot for basicsrc
2024-04-24T12:05:08,743  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.exim.basicsrc newtbl=basicsrc	
2024-04-24T12:05:08,769  INFO [main] ql.Driver: Starting task [Stage-1:STATS] in serial mode
2024-04-24T12:05:08,770  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,779  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,779  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T12:05:08,780  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,789  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,796  WARN [main] metadata.Hive: Cannot get a table snapshot for basicsrc
2024-04-24T12:05:08,797  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.exim.basicsrc newtbl=basicsrc	
2024-04-24T12:05:08,823  INFO [main] stats.BasicStatsTask: Table exim.basicsrc stats: [numFiles=1, totalSize=14, numFilesErasureCoded=0]
2024-04-24T12:05:08,823  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:08,823  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=2, alter_table_(String, String, String, Table, EnvironmentContext, String)=52, getTable_(GetTableRequest)=37}
2024-04-24T12:05:08,823  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.112 seconds
2024-04-24T12:05:08,824  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicSrc
2024-04-24T12:05:08,825  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:08,825  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T12:05:08,825  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T12:05:08,825  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:05:08,825  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,833  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:08,834  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:05:08,834  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:05:08,835  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T12:05:08,845  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_table_constraints : tbl=hive.exim.basicsrc	
2024-04-24T12:05:08,855  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for exim.basicsrc, projIndxSet: [0], allowMissingStats: true
2024-04-24T12:05:08,855  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: table=hive.exim.basicsrc	
2024-04-24T12:05:08,864  WARN [main] calcite.RelOptHiveTable: No Stats for exim@basicsrc, Columns: b
No Stats for exim@basicsrc, Columns: b
2024-04-24T12:05:08,864  INFO [main] SessionState: No Stats for exim@basicsrc, Columns: b
2024-04-24T12:05:08,974  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:05:08,974  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:05:08,974  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:05:08,975  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-08_823_9054925162308993940-1/-mr-10001/.hive-staging_hive_2024-04-24_12-05-08_823_9054925162308993940-1
2024-04-24T12:05:08,984  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T12:05:08,986  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has 0<2 buckets 
2024-04-24T12:05:08,987  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T12:05:08,987  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:08,987  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:08,987  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:basicsrc.b, type:string, comment:null)], properties:null)
2024-04-24T12:05:08,988  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T12:05:08,990  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T12:05:08,990  INFO [main] exec.SelectOperator: SELECT struct<b:string>
2024-04-24T12:05:08,990  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T12:05:08,990  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:08,991  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=9, getAllTableConstraints_(AllTableConstraintsRequest)=6, getTableColumnStatistics_(String, String, List, String)=9, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T12:05:08,991  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.166 seconds
2024-04-24T12:05:08,991  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:08,991  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:08,991  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicSrc
2024-04-24T12:05:08,992  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:08,992  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T12:05:08,992  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.001 seconds
2024-04-24T12:05:08,999  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T12:05:09,000  INFO [main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T12:05:09,000  INFO [main] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:2, 
2024-04-24T12:05:09,000  INFO [main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T12:05:09,000  INFO [main] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:05:09,000  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T12:05:09,000  INFO [main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:2, 
2024-04-24T12:05:09,000  INFO [main] repl.CommandTestUtils: About to run :EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim' FOR REPLICATION('111')
2024-04-24T12:05:09,001  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-08_823_9054925162308993940-1
2024-04-24T12:05:09,001  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-08_823_9054925162308993940-1 on fs with scheme file
2024-04-24T12:05:09,002  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim' FOR REPLICATION('111')
2024-04-24T12:05:09,004  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:05:09,012  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,057  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicSrc	
2024-04-24T12:05:09,065  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,066  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,066  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,066  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,066  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,067  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,067  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:09,067  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,067  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=18, isCompatibleWith_(Configuration)=1, getCurrentNotificationEventId_()=43, flushCache_()=0}
2024-04-24T12:05:09,067  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.065 seconds
2024-04-24T12:05:09,068  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,068  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,068  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE exim.basicSrc TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim' FOR REPLICATION('111')
2024-04-24T12:05:09,068  INFO [main] ql.Driver: Starting task [Stage-0:REPL_DUMP] in serial mode
2024-04-24T12:05:09,068  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,069  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,069  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,069  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,110  WARN [main] shims.Utils: XAttr won't be preserved since it is not supported for file system: pfile:///
2024-04-24T12:05:09,121  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,121  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T12:05:09,121  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.053 seconds
2024-04-24T12:05:09,124  INFO [main] repl.CommandTestUtils: Export returned the following _metadata contents:
2024-04-24T12:05:09,124  INFO [main] repl.CommandTestUtils: {"version":"0.2","repl.scope":"all","repl.event.id":"111","repl.last.id":"12","repl.noop":"false","repl.is.replace":"true","table":"{\"1\":{\"str\":\"basicsrc\"},\"2\":{\"str\":\"exim\"},\"3\":{\"str\":\"alex\"},\"4\":{\"i32\":1713985508},\"5\":{\"i32\":0},\"6\":{\"i32\":0},\"7\":{\"rec\":{\"1\":{\"lst\":[\"rec\",1,{\"1\":{\"str\":\"b\"},\"2\":{\"str\":\"string\"}}]},\"2\":{\"str\":\"pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/exim.db/basicsrc\"},\"3\":{\"str\":\"org.apache.hadoop.mapred.TextInputFormat\"},\"4\":{\"str\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\"},\"5\":{\"tf\":0},\"6\":{\"i32\":0},\"7\":{\"rec\":{\"2\":{\"str\":\"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\"},\"3\":{\"map\":[\"str\",\"str\",1,{\"serialization.format\":\"1\"}]}}},\"8\":{\"lst\":[\"str\",0]},\"9\":{\"lst\":[\"rec\",0]},\"10\":{\"map\":[\"str\",\"str\",0,{}]},\"11\":{\"rec\":{\"1\":{\"lst\":[\"str\",0]},\"2\":{\"lst\":[\"lst\",0]},\"3\":{\"map\":[\"lst\",\"str\",0,{}]}}},\"12\":{\"tf\":0}}},\"8\":{\"lst\":[\"rec\",0]},\"9\":{\"map\":[\"str\",\"str\",6,{\"bucketing_version\":\"2\",\"numFilesErasureCoded\":\"0\",\"numFiles\":\"1\",\"totalSize\":\"14\",\"repl.last.id\":\"12\",\"transient_lastDdlTime\":\"1713985508\"}]},\"12\":{\"str\":\"MANAGED_TABLE\"},\"15\":{\"tf\":0},\"17\":{\"str\":\"hive\"},\"18\":{\"i32\":1},\"19\":{\"i64\":0},\"25\":{\"i64\":3}}","partitions":[]}
2024-04-24T12:05:09,125  INFO [main] repl.CommandTestUtils: About to run :IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim'
2024-04-24T12:05:09,125  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim'
2024-04-24T12:05:09,126  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,126  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,128  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,128  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim
2024-04-24T12:05:09,128  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:05:09,131  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:05:09,134  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:05:09,136  INFO [main] common.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1
2024-04-24T12:05:09,152  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,152  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:09,153  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,153  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=5, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T12:05:09,153  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.028 seconds
2024-04-24T12:05:09,153  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,153  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,153  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE exim.basicDst FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim'
2024-04-24T12:05:09,154  INFO [main] ql.Driver: Starting task [Stage-0:COPY] in serial mode
Copying data from pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim/data
2024-04-24T12:05:09,154  INFO [main] exec.Task: Copying data from pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim/data to pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1/-ext-10000
Copying file: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim/data/testBasicReplEximTmp
2024-04-24T12:05:09,160  INFO [main] exec.Task: Copying file: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim/data/testBasicReplEximTmp
2024-04-24T12:05:09,161  INFO [main] common.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1/-ext-10000
2024-04-24T12:05:09,172  INFO [main] repl.CopyUtils: Attempt: 1. Copying files: [pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testBasicReplExim/data/testBasicReplEximTmp]
2024-04-24T12:05:09,173  WARN [main] shims.Utils: XAttr won't be preserved since it is not supported for file system: pfile:///
2024-04-24T12:05:09,187  INFO [main] ql.Driver: Starting task [Stage-2:DDL] in serial mode
2024-04-24T12:05:09,188  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:05:09,192  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:basicDst, dbName:exim, owner:alex, createTime:1713985509, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:b, type:string, comment:null)], location:pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=1, repl.last.id=12, totalSize=14, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T12:05:09,197  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Location: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst specified for non-external table:basicDst
2024-04-24T12:05:09,230  INFO [main] ql.Driver: Starting task [Stage-1:MOVE] in serial mode
Loading data to table exim.basicDst
2024-04-24T12:05:09,231  INFO [main] exec.Task: Loading data to table exim.basicDst from pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1/-ext-10000
2024-04-24T12:05:09,231  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:05:09,242  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,243  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:05:09,253  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,254  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: exim	
2024-04-24T12:05:09,270  INFO [main] common.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst
2024-04-24T12:05:09,275  INFO [Move-Thread-0] metadata.Hive: Deleted destination filepfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/testBasicReplEximTmp
2024-04-24T12:05:09,276  WARN [main] metadata.Hive: Cannot get a table snapshot for basicdst
2024-04-24T12:05:09,277  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.exim.basicdst newtbl=basicdst	
2024-04-24T12:05:09,304  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updating table stats for basicdst
2024-04-24T12:05:09,304  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updated size of table basicdst to 14
2024-04-24T12:05:09,312  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,312  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=2, createTable_(Table)=39, getDatabase_(String)=2, getTable_(GetTableRequest)=23, alter_table_(String, String, String, Table, EnvironmentContext, String)=36}
2024-04-24T12:05:09,312  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.159 seconds
2024-04-24T12:05:09,313  INFO [main] ql.Context: Deleting scratch dir: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1
2024-04-24T12:05:09,313  INFO [main] cleanup.SyncCleanupService: Deleted directory: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/exim.db/basicdst/.hive-staging_hive_2024-04-24_12-05-09_125_8677692395059868859-1 on fs with scheme pfile
2024-04-24T12:05:09,313  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicDst
2024-04-24T12:05:09,314  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:09,314  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T12:05:09,314  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T12:05:09,314  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:05:09,315  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicdst	
2024-04-24T12:05:09,323  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,323  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:05:09,323  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:05:09,324  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T12:05:09,334  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_table_constraints : tbl=hive.exim.basicdst	
2024-04-24T12:05:09,341  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for exim.basicdst, projIndxSet: [0], allowMissingStats: true
2024-04-24T12:05:09,342  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: table=hive.exim.basicdst	
2024-04-24T12:05:09,352  WARN [main] calcite.RelOptHiveTable: No Stats for exim@basicdst, Columns: b
No Stats for exim@basicdst, Columns: b
2024-04-24T12:05:09,352  INFO [main] SessionState: No Stats for exim@basicdst, Columns: b
2024-04-24T12:05:09,459  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T12:05:09,459  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T12:05:09,459  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T12:05:09,460  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-09_313_6006998484632290379-1/-mr-10001/.hive-staging_hive_2024-04-24_12-05-09_313_6006998484632290379-1
2024-04-24T12:05:09,468  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T12:05:09,470  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has 0<2 buckets 
2024-04-24T12:05:09,471  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T12:05:09,471  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932
2024-04-24T12:05:09,471  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,471  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:basicdst.b, type:string, comment:null)], properties:null)
2024-04-24T12:05:09,472  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T12:05:09,473  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T12:05:09,473  INFO [main] exec.SelectOperator: SELECT struct<b:string>
2024-04-24T12:05:09,473  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T12:05:09,473  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,473  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getTable_(GetTableRequest)=8, getTableColumnStatistics_(String, String, List, String)=10, getAllTableConstraints_(AllTableConstraintsRequest)=5, isCompatibleWith_(Configuration)=0}
2024-04-24T12:05:09,473  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.16 seconds
2024-04-24T12:05:09,474  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,474  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,474  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): SELECT * from exim.basicDst
2024-04-24T12:05:09,474  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,474  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T12:05:09,474  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.0 seconds
2024-04-24T12:05:09,481  INFO [main] mapred.FileInputFormat: Total input files to process : 1
2024-04-24T12:05:09,482  INFO [main] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T12:05:09,482  INFO [main] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:2, 
2024-04-24T12:05:09,482  INFO [main] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T12:05:09,482  INFO [main] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:2, 
2024-04-24T12:05:09,483  INFO [main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T12:05:09,483  INFO [main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T12:05:09,483  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.exim.basicDst	
2024-04-24T12:05:09,493  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:09,494  INFO [main] repl.CommandTestUtils: About to run :EXPORT TABLE doesNotExist1713985509494.nope1713985509494 TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim' FOR REPLICATION('333')
2024-04-24T12:05:09,494  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-09_313_6006998484632290379-1
2024-04-24T12:05:09,495  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/localscratchdir/ee9676e0-3853-4d25-b6f8-3167fe8a2056/hive_2024-04-24_12-05-09_313_6006998484632290379-1 on fs with scheme file
2024-04-24T12:05:09,495  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE doesNotExist1713985509494.nope1713985509494 TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim' FOR REPLICATION('333')
2024-04-24T12:05:09,496  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.doesNotExist1713985509494.nope1713985509494	
2024-04-24T12:05:09,500  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.doesNotExist1713985509494.nope1713985509494	
2024-04-24T12:05:09,502  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,502  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,502  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,502  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,503  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,503  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:09,503  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,503  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getCurrentNotificationEventId_()=1, isCompatibleWith_(Configuration)=1}
2024-04-24T12:05:09,503  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.008 seconds
2024-04-24T12:05:09,503  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,503  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,503  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): EXPORT TABLE doesNotExist1713985509494.nope1713985509494 TO 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim' FOR REPLICATION('333')
2024-04-24T12:05:09,504  INFO [main] ql.Driver: Starting task [Stage-0:REPL_DUMP] in serial mode
2024-04-24T12:05:09,504  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,504  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,504  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,504  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,511  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,512  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T12:05:09,512  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.008 seconds
2024-04-24T12:05:09,515  INFO [main] repl.CommandTestUtils: Export returned the following _metadata contents:
2024-04-24T12:05:09,515  INFO [main] repl.CommandTestUtils: {"version":"0.2","repl.scope":"all","repl.event.id":"333","repl.last.id":"14","repl.noop":"true","repl.is.replace":"true"}
2024-04-24T12:05:09,515  INFO [main] repl.CommandTestUtils: About to run :IMPORT TABLE doesNotExist1713985509494.nope1713985509494 FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim'
2024-04-24T12:05:09,516  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE doesNotExist1713985509494.nope1713985509494 FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim'
2024-04-24T12:05:09,517  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,517  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,517  INFO [main] parse.EximUtil: Path before norm :/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,517  INFO [main] parse.EximUtil: Scheme:pfile, authority:null, path:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim
2024-04-24T12:05:09,517  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,517  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:09,518  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,518  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T12:05:09,518  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.002 seconds
2024-04-24T12:05:09,518  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,518  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,518  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): IMPORT TABLE doesNotExist1713985509494.nope1713985509494 FROM 'pfile:///home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/org.apache.hive.hcatalog.api.repl.commands.TestCommands-1713985473961/testNoopReplExim'
2024-04-24T12:05:09,518  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,518  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T12:05:09,518  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.0 seconds
2024-04-24T12:05:09,519  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: doesNotExist1713985509494	
2024-04-24T12:05:09,532  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: cmd_testdb	
2024-04-24T12:05:09,533  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:cmd_testdb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:05:09,536  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/cmd_testdb.db
2024-04-24T12:05:09,536  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/cmd_testdb.db
2024-04-24T12:05:09,538  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/cmd_testdb.db
2024-04-24T12:05:09,543  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: cmd_testdb	
2024-04-24T12:05:09,545  INFO [main] repl.CommandTestUtils: About to run :DROP DATABASE IF EXISTS cmd_testdb CASCADE
2024-04-24T12:05:09,545  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): DROP DATABASE IF EXISTS cmd_testdb CASCADE
2024-04-24T12:05:09,547  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: cmd_testdb	
2024-04-24T12:05:09,553  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=cmd_testdb tbls=null	
2024-04-24T12:05:09,567  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=cmd_testdb tbls=	
2024-04-24T12:05:09,569  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T12:05:09,569  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T12:05:09,569  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T12:05:09,569  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTables_(String, String)=17, getTableObjectsByName_(String, List)=1, getDatabase_(String)=1, flushCache_()=0}
2024-04-24T12:05:09,569  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.024 seconds
2024-04-24T12:05:09,569  INFO [main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T12:05:09,569  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T12:05:09,569  INFO [main] ql.Driver: Executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932): DROP DATABASE IF EXISTS cmd_testdb CASCADE
2024-04-24T12:05:09,570  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T12:05:09,570  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: cmd_testdb	
2024-04-24T12:05:09,572  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#cmd_testdb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:09,572  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=cmd_testdb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:09,574  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#cmd_testdb	
2024-04-24T12:05:09,577  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=cmd_testdb tbls=	
2024-04-24T12:05:09,577  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#cmd_testdb	
2024-04-24T12:05:09,578  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#cmd_testdb	
2024-04-24T12:05:09,579  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#cmd_testdb pat=*	
2024-04-24T12:05:09,580  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:09,581  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:09,582  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=cmd_testdb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:09,584  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.cmd_testdb along with all tables
2024-04-24T12:05:09,607  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/cmd_testdb.db does not exist; Force to delete it.
2024-04-24T12:05:09,607 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34489/cmd_testdb.db
2024-04-24T12:05:09,609  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T12:05:09,609  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropDatabase_(String, boolean, boolean, boolean)=37, isCompatibleWith_(Configuration)=0}
2024-04-24T12:05:09,609  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424120433_13352372-5990-4eba-b2da-8c6e55935932); Time taken: 0.04 seconds
2024-04-24T12:05:09,610  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: cmd_testdb	
2024-04-24T12:05:09,611  INFO [main] api.TestHCatClient: Shutting down metastore.
2024-04-24T12:05:09,630  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 2
2024-04-24T12:05:09,630  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:05:09,630  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a89a98d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@558ed5b5 will be shutdown
2024-04-24T12:05:09,631  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:05:09,631  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
