2024-04-24T12:05:33,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:33,540  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:33,540  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:33,540  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:33,541  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:33,541  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:33,541  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:33,541  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:33,541  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:33,542  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:33,542  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:33,542  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:05:33,545  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:05:33,579  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T12:05:33,654  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:05:33,654  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34727]
2024-04-24T12:05:33,655  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:05:33,672  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 1
2024-04-24T12:05:33,730  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:05:33,808  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:05:33,809  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:05:33,810  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dfcb64e, with PersistenceManager: null will be shutdown
2024-04-24T12:05:33,811  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dfcb64e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7dd8f1da created in the thread with id: 33
2024-04-24T12:05:33,821  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dfcb64e from thread id: 33
2024-04-24T12:05:33,913  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:05:33,955  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:05:33,966  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:33,979  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:33,982  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:34,140  INFO [TThreadPoolServer WorkerProcess-%d] conf.MetastoreConf: Found configuration file: file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/testconf/hivemetastore-site.xml
2024-04-24T12:05:34,142  INFO [TThreadPoolServer WorkerProcess-%d] conf.MetastoreConf: Unable to find config file: metastore-site.xml
2024-04-24T12:05:34,342  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:34,407  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:34,408  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:34,408  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:34,408  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:34,409  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:34,454  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:alex, createTime:1713985534, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:05:34,508  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable
2024-04-24T12:05:34,712  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:05:34,781  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:34,880  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:34,894  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:34,926  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:34,946  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2011_12_31/grid=AB
2024-04-24T12:05:35,007  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,024  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:35,025  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,035  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2012_01_01/grid=AB
2024-04-24T12:05:35,062  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,080  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:35,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,095  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/grid=OB/dt=2012_01_01
2024-04-24T12:05:35,117  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,130  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:35,131  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,140  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2012_01_01/grid=XB
2024-04-24T12:05:35,160  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:05:35,178  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:35,210  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.mydb.mytable	
2024-04-24T12:05:35,433  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:05:35,462  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:35,462  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:35,505  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:35,552  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:05:35,594  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:35,596  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:35,597  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:35,620  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:35,645  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:35,708  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:35,713  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:35,838  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:05:35,841  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T12:05:35,843  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:05:35,844  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T12:05:35,849  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:05:35,851  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T12:05:35,853  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:05:35,853  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T12:05:35,915 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 49 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (2).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 51 more

2024-04-24T12:05:37,917  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:37,923  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:37,924  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:37,927  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:37,929  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:37,930  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:38,075  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,283  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:38,331  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db does not exist; Force to delete it.
2024-04-24T12:05:38,331 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:38,394  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:38,395  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:38,395  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:05:38,396  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:05:38,401  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:05:38,402  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:05:38,408  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: locationDB	
2024-04-24T12:05:38,410  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:locationDB, description:null, locationUri:/tmp/locationDB, parameters:null, catalogName:hive)	
2024-04-24T12:05:38,417  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Failed to create external path file:/tmp/locationDB for database locationDB. This may result in access not being allowed if the StorageBasedAuthorizationProvider is enabled
2024-04-24T12:05:38,425  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: locationDB	
2024-04-24T12:05:38,431  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2024-04-24T12:05:38,488  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:38,489  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:38,490  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:38,496  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:05:38,498  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:05:38,499  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:05:38,499  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:05:38,502  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:05:38,503  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:05:38,506  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:38,506  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:38,510  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:05:38,514  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:05:38,576  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:05:38,576  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:05:38,576  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:05:38,576  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:05:38,577  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:05:38,578  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:alex, createTime:1713985538, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:05:38,583  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable
2024-04-24T12:05:38,644  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:05:38,670  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,672  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,681  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,682  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,699  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2011_12_31/grid=AB
2024-04-24T12:05:38,730  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,741  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,742  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,750  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2012_01_01/grid=AB
2024-04-24T12:05:38,769  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,781  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,782  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,803  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2012_01_01/grid=OB
2024-04-24T12:05:38,819  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,830  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,831  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:05:38,842  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2012_01_01/grid=XB
2024-04-24T12:05:38,862  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=myDb,table=myTable, partitionSpec: [{dt=2012_01_01}]).
2024-04-24T12:05:38,863  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:05:38,875  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:38,876  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:05:42,080  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,088  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,090  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,090  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,099  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,123  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,158  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T12:05:42,977  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:05:42,999  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:05:43,008  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:05:43,036  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.myDb.myTable	
2024-04-24T12:05:43,071  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:05:43,074  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:43,074  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:43,080  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:43,085  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:05:43,091  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:43,093  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:43,094  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:43,099  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:43,103  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:43,108  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:43,112  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:43,140 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:45,142  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:45,146  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:45,146  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:45,149  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:45,150  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:45,151  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:45,155  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:45,160 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:47,161  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:47,167  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:47,170  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:47,173  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:47,174  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:47,176  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:47,180  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:47,184 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:49,185  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:49,190  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:49,191  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:49,193  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:49,194  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:49,195  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:49,198  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:49,202 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:51,203  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:51,208  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:51,209  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:51,211  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:51,212  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:51,213  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:51,216  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:51,221 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:53,222  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:53,225  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:53,226  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:53,228  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:53,229  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:53,230  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:53,233  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:53,238 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:55,239  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:55,243  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:55,244  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:55,245  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:55,246  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:55,247  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:55,251  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:55,256 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:57,257  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:57,261  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:57,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:57,269  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:57,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:57,277  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:57,289  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:57,300 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:05:59,301  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:05:59,305  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:05:59,305  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:05:59,307  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:05:59,308  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:05:59,309  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:05:59,313  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:05:59,317 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:01,318  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:01,323  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:01,324  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:01,325  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:01,326  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:01,328  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:01,331  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:01,336 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:03,337  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:03,341  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:03,342  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:03,344  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:03,345  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:03,346  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:03,350  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:03,354 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:03,358  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testDropPartitionsWithPartialSpec(TestHCatClient.java:805) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:06:04,359  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:06:04,362  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2024-04-24T12:06:04,362  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:06:04,363  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 2
2024-04-24T12:06:04,364  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:06:04,365  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:06:04,366  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d3cbb1c, with PersistenceManager: null will be shutdown
2024-04-24T12:06:04,366  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d3cbb1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7db26b8b created in the thread with id: 69
2024-04-24T12:06:04,406  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d3cbb1c from thread id: 69
2024-04-24T12:06:04,408  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:04,408  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:04,411  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:04,414  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:06:04,416  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:04,417  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:04,418  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:04,420  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:04,421  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:04,423  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:04,425  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:04,433 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:05,962  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:06:05,962  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6dfcb64e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7dd8f1da will be shutdown
2024-04-24T12:06:05,963  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:06:06,435  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:06,438  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:06,439  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:06,440  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:06,441  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:06,442  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:06,444  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:06,450 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:08,452  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:08,455  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:08,456  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:08,457  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:08,459  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:08,460  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:08,463  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:08,468 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 48 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 50 more

2024-04-24T12:06:10,469  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:10,472  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:10,473  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:10,475  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:10,476  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:10,476  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:10,480  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:10,485 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:12,486  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:12,489  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:12,491  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:12,493  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:12,494  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:12,495  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:12,498  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:12,503 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:14,504  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:14,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:14,509  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:14,510  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:14,511  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:14,512  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:14,514  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:14,518 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:16,519  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:16,522  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:16,523  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:16,524  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:16,525  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:16,526  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:16,528  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:16,532 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:18,533  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:18,541  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:18,541  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:18,543  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:18,544  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:18,546  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:18,548  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:18,553 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:20,554  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:20,557  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:20,558  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:20,559  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:20,560  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:20,560  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:20,563  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:20,566 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:22,567  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:22,570  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:22,571  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:22,572  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:22,573  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:22,574  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:22,576  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:22,580 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:24,581  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:24,584  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:24,584  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:24,586  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:24,587  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:24,588  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:24,590  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:24,594 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:24,595 ERROR [main] api.TestHCatClient: Unexpected exception!
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : MetaException while dropping db.. Cause : MetaException(message:javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:164) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testDropPartitionsWithPartialSpec(TestHCatClient.java:805) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) ~[classes/:?]
	... 42 more
2024-04-24T12:06:24,675  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:24,675  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:24,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:24,676  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:24,676  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:24,678  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:06:24,679  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:06:24,679  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:24,683  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testdb	
2024-04-24T12:06:24,684  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testdb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:06:24,688  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db
2024-04-24T12:06:24,689  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db
2024-04-24T12:06:24,691  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db
2024-04-24T12:06:24,704  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#*	
2024-04-24T12:06:24,708  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testdb	
2024-04-24T12:06:24,715  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:24,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:24,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:24,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:24,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:24,777  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:24,778  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable1, dbName:testdb, owner:alex, createTime:1713985584, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:24,783  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db/testtable1
2024-04-24T12:06:24,838  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable1	
2024-04-24T12:06:24,864  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:24,865  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable1, dbName:testdb, owner:alex, createTime:1713985584, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:24,883  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: create_table_req got 
org.apache.hadoop.hive.metastore.api.AlreadyExistsException: Table hive.testdb.testTable1 already exists
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2339) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2598) [classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [classes/:?]
	at com.sun.proxy.$Proxy34.create_table_req(Unknown Source) [?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18993) [classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18972) [classes/:?]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) [classes/:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) [classes/:?]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248) [libthrift-0.14.1.jar:0.14.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T12:06:24,884 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: AlreadyExistsException(message:Table hive.testdb.testTable1 already exists)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2339)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2598)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.create_table_req(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18993)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18972)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:24,888  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable1	
2024-04-24T12:06:24,897  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:24,925  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testdb.testTable1	
2024-04-24T12:06:25,031  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:25,094  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,094  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,095  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,096  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable2, dbName:testdb, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{mapkey.delim=, serialization.format=1, serialization.null.format=, escape.delim=, line.delim=, field.delim=, collection.delim=}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:25,102  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db/testtable2
2024-04-24T12:06:25,120  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable2	
2024-04-24T12:06:25,128  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:25,136  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:25,201  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,203  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable3, dbName:testdb, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:25,207  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testdb.db/testtable3
2024-04-24T12:06:25,228  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable3	
2024-04-24T12:06:25,237  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:25,238  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2024-04-24T12:06:25,291  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,291  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,291  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,291  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,291  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,292  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,292  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:25,294  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:06:25,294  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:06:25,295  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:25,296  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,355  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,356  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:Temptable11101001011111100110101000010111000101101011011111010111010001110101011011110111111010000000010001010010001011101000110000010110101000111000011101101101000010010011011111001011110110011000001110110100001110110100110000001111111001000001100101001110011101111110, dbName:default, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:25,362  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable11101001011111100110101000010111000101101011011111010111010001110101011011110111111010000000010001010010001011101000110000010110101000111000011101101101000010010011011111001011110110011000001110110100001110110100110000001111111001000001100101001110011101111110
2024-04-24T12:06:25,362  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: create_table_req got 
org.apache.hadoop.hive.metastore.api.MetaException: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable11101001011111100110101000010111000101101011011111010111010001110101011011110111111010000000010001010010001011101000110000010110101000111000011101101101000010010011011111001011110110011000001110110100001110110100110000001111111001000001100101001110011101111110 is not a directory or unable to create one
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2422) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2598) [classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [classes/:?]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [classes/:?]
	at com.sun.proxy.$Proxy34.create_table_req(Unknown Source) [?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18993) [classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18972) [classes/:?]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) [classes/:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) [classes/:?]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248) [libthrift-0.14.1.jar:0.14.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T12:06:25,363 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: MetaException(message:pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable11101001011111100110101000010111000101101011011111010111010001110101011011110111111010000000010001010010001011101000110000010110101000111000011101101101000010010011011111001011110110011000001110110100001110110100110000001111111001000001100101001110011101111110 is not a directory or unable to create one)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2422)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2598)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.create_table_req(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18993)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:18972)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:25,417  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,418  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,418  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:25,420  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:06:25,421  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:06:25,421  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:25,423  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2024-04-24T12:06:25,426  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:25,483  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,484  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,485  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:goodTable, dbName:default, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:25,490  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/goodtable
2024-04-24T12:06:25,504  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2024-04-24T12:06:25,512  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:25,513  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=false
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,573  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,574  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,574  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:25,575  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:06:25,576  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:06:25,576  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:25,578  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2024-04-24T12:06:25,581  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.mytable	
2024-04-24T12:06:25,583  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:25,642  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,642  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,642  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,642  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,643  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,644  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:temptable, dbName:default, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:25,648  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable
2024-04-24T12:06:25,661  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2024-04-24T12:06:25,669  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:25,700  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.default.temptable newtbl=mytable	
2024-04-24T12:06:25,726  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Renaming pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable to pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mytable
2024-04-24T12:06:25,768  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2024-04-24T12:06:25,770  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.mytable	
2024-04-24T12:06:25,781  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:25,781  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=false
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,833  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,834  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,834  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,834  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,834  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:25,835  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:06:25,836  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:06:25,836  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:25,838  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableToBeDropped	
2024-04-24T12:06:25,841  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableToBeDropped	
2024-04-24T12:06:25,843  INFO [main] api.TestHCatClient: Drop Table Exception: NoSuchObjectException(message:hive.default.tableToBeDropped table not found)
2024-04-24T12:06:25,843  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=false
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:25,892  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:25,893  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:25,893  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:25,894  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:06:25,895  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:06:25,895  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:25,939  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testReplicationTaskIter	
2024-04-24T12:06:25,941  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testReplicationTaskIter, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:06:25,943  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db
2024-04-24T12:06:25,943  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db
2024-04-24T12:06:25,945  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db
2024-04-24T12:06:25,951  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:26,010  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:26,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:26,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:26,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:26,011  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:T1, dbName:testReplicationTaskIter, owner:alex, createTime:1713985585, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:26,015  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t1
2024-04-24T12:06:26,030  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:26,089  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:26,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:26,090  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:26,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:26,090  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:26,090  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:T2, dbName:testReplicationTaskIter, owner:alex, createTime:1713985586, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:b, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:26,094  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2
2024-04-24T12:06:26,110  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,118  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,119  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,127  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,128  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,139  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=test1
2024-04-24T12:06:26,158  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,166  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,167  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,174  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul0
2024-04-24T12:06:26,189  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul0}]).
2024-04-24T12:06:26,190  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,201  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,202  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,295  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,299  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,307  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,308  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,314  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul1
2024-04-24T12:06:26,330  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul1}]).
2024-04-24T12:06:26,330  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,338  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,338  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,515  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,519  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,531  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,532  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,539  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul2
2024-04-24T12:06:26,553  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul2}]).
2024-04-24T12:06:26,553  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,562  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,562  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,627  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,631  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,639  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,640  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,647  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul3
2024-04-24T12:06:26,664  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul3}]).
2024-04-24T12:06:26,664  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,671  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,672  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,743  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,747  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,754  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,755  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,761  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul4
2024-04-24T12:06:26,772  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul4}]).
2024-04-24T12:06:26,772  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,779  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,780  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,850  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,854  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,863  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,864  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:26,873  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul5
2024-04-24T12:06:26,888  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul5}]).
2024-04-24T12:06:26,889  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:26,899  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:26,899  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:26,986  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:26,990  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,001  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,003  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,012  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul6
2024-04-24T12:06:27,033  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul6}]).
2024-04-24T12:06:27,033  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,043  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,044  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,105  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,110  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,118  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,119  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,125  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul7
2024-04-24T12:06:27,140  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul7}]).
2024-04-24T12:06:27,141  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,150  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,150  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,217  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,222  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,232  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,233  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,240  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul8
2024-04-24T12:06:27,252  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul8}]).
2024-04-24T12:06:27,253  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,261  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,261  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,328  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,332  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,340  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,341  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,347  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul9
2024-04-24T12:06:27,359  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul9}]).
2024-04-24T12:06:27,360  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,367  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,368  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,435  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,439  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,447  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,448  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,455  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul10
2024-04-24T12:06:27,467  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul10}]).
2024-04-24T12:06:27,467  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,475  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,475  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,539  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,543  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,552  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,553  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,558  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul11
2024-04-24T12:06:27,576  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul11}]).
2024-04-24T12:06:27,577  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,584  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,585  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,660  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,664  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,671  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,672  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,678  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul12
2024-04-24T12:06:27,691  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul12}]).
2024-04-24T12:06:27,691  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,698  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,699  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,763  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,767  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,776  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,777  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,785  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul13
2024-04-24T12:06:27,797  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul13}]).
2024-04-24T12:06:27,797  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,805  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,805  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,870  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,875  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,883  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,884  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,892  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul14
2024-04-24T12:06:27,907  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul14}]).
2024-04-24T12:06:27,908  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:27,914  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,914  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:27,974  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:27,978  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,985  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:27,986  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:27,991  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul15
2024-04-24T12:06:28,001  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul15}]).
2024-04-24T12:06:28,001  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,008  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,008  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:28,070  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:28,074  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,084  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,086  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,092  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul16
2024-04-24T12:06:28,109  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul16}]).
2024-04-24T12:06:28,109  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,118  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,119  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:28,179  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:28,183  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,190  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,191  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,196  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul17
2024-04-24T12:06:28,208  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul17}]).
2024-04-24T12:06:28,208  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,216  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,217  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:28,281  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:28,284  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,296  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,297  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,306  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul18
2024-04-24T12:06:28,320  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul18}]).
2024-04-24T12:06:28,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,327  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,327  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:28,389  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:28,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,398  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,399  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2024-04-24T12:06:28,404  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testreplicationtaskiter.db/t2/b=testmul19
2024-04-24T12:06:28,415  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul19}]).
2024-04-24T12:06:28,415  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,422  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,422  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:06:28,484  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:06:28,488  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T1	
2024-04-24T12:06:28,495  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,496  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testReplicationTaskIter.T1	
2024-04-24T12:06:28,609  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,620  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:28,621  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testReplicationTaskIter.T2	
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:1:1713985534,t:CREATE_DATABASE,o:myDb.null
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:2:1713985534,t:CREATE_TABLE,o:myDb.myTable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:3:1713985534,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:4:1713985535,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:5:1713985535,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:6:1713985535,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:7:1713985538,t:DROP_TABLE,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:8:1713985538,t:DROP_DATABASE,o:mydb.null
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:9:1713985538,t:CREATE_DATABASE,o:locationDB.null
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:10:1713985538,t:CREATE_DATABASE,o:myDb.null
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:11:1713985538,t:CREATE_TABLE,o:myDb.myTable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:12:1713985538,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:13:1713985538,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:14:1713985538,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:15:1713985538,t:ADD_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:16:1713985542,t:DROP_PARTITION,o:mydb.mytable
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:17:1713985584,t:CREATE_DATABASE,o:testdb.null
2024-04-24T12:06:28,740  INFO [main] api.TestHCatClient: notif from dblistener:18:1713985584,t:CREATE_TABLE,o:testdb.testTable1
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:19:1713985585,t:DROP_TABLE,o:testdb.testtable1
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:20:1713985585,t:CREATE_TABLE,o:testdb.testTable2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:21:1713985585,t:CREATE_TABLE,o:testdb.testTable3
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:22:1713985585,t:CREATE_TABLE,o:default.goodTable
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:23:1713985585,t:CREATE_TABLE,o:default.temptable
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:24:1713985585,t:ALTER_TABLE,o:default.mytable
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:25:1713985585,t:CREATE_DATABASE,o:testReplicationTaskIter.null
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:26:1713985586,t:CREATE_TABLE,o:testReplicationTaskIter.T1
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:27:1713985586,t:CREATE_TABLE,o:testReplicationTaskIter.T2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:28:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:29:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:30:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:31:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:32:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:33:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:34:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:35:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:36:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:37:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:38:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:39:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:40:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:41:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:42:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:43:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:44:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:45:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:46:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:47:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:48:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:49:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:50:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:51:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:52:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:53:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:54:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:55:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:56:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:57:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:58:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:59:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:60:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:61:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:62:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:63:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:64:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:65:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:66:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:67:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:68:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:69:1713985588,t:DROP_TABLE,o:testreplicationtaskiter.t1
2024-04-24T12:06:28,741  INFO [main] api.TestHCatClient: notif from dblistener:70:1713985588,t:DROP_TABLE,o:testreplicationtaskiter.t2
2024-04-24T12:06:28,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:28,816  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:28,816  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:28,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:28,861  INFO [main] api.TestHCatClient: notif from tasks:25:1713985585,t:CREATE_DATABASE,o:testReplicationTaskIter.null,s:DB
2024-04-24T12:06:28,861  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateDatabaseReplicationTask
2024-04-24T12:06:28,861  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,862  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,872  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPGQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[25]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,872  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,872  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPGQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[25]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,938  INFO [main] api.TestHCatClient: notif from tasks:26:1713985586,t:CREATE_TABLE,o:testReplicationTaskIter.T1,s:TABLE
2024-04-24T12:06:28,938  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateTableReplicationTask
2024-04-24T12:06:28,938  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,938  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,940  INFO [main] api.TestHCatClient: getStagingDirectory(26.testreplicationtaskiter.t1.null.1755218969) called!
2024-04-24T12:06:28,940  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQxATcAAAAyL3RtcC8yNi50ZXN0cmVwbGljYXRpb250YXNraXRlci50MS5udWxsLjE3NTUyMTg5NjkFAA8a
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[26]
CMD:EXPORT TABLE testReplicationTaskIter.T1 TO '/tmp/26.testreplicationtaskiter.t1.null.1755218969' FOR REPLICATION('26')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/26.testreplicationtaskiter.t1.null.1755218969
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/26.testreplicationtaskiter.t1.null.1755218969

2024-04-24T12:06:28,940  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: getStagingDirectory(26.testreplicationtaskiter.t1.null.1755218969) called!
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQxATcAAAAyL3RtcC8yNi50ZXN0cmVwbGljYXRpb250YXNraXRlci50MS5udWxsLjE3NTUyMTg5NjkFAA8a
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[26]
CMD:IMPORT TABLE testReplicationTaskIter.T1 FROM '/tmp/26.testreplicationtaskiter.t1.null.1755218969'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/26.testreplicationtaskiter.t1.null.1755218969

2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: notif from tasks:27:1713985586,t:CREATE_TABLE,o:testReplicationTaskIter.T2,s:TABLE
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateTableReplicationTask
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: getStagingDirectory(27.testreplicationtaskiter.t2.null.1755219000) called!
2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQyATcAAAAyL3RtcC8yNy50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5udWxsLjE3NTUyMTkwMDAFAA8b
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[27]
CMD:EXPORT TABLE testReplicationTaskIter.T2 TO '/tmp/27.testreplicationtaskiter.t2.null.1755219000' FOR REPLICATION('27')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/27.testreplicationtaskiter.t2.null.1755219000
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/27.testreplicationtaskiter.t2.null.1755219000

2024-04-24T12:06:28,941  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,942  INFO [main] api.TestHCatClient: getStagingDirectory(27.testreplicationtaskiter.t2.null.1755219000) called!
2024-04-24T12:06:28,942  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQyATcAAAAyL3RtcC8yNy50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5udWxsLjE3NTUyMTkwMDAFAA8b
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[27]
CMD:IMPORT TABLE testReplicationTaskIter.T2 FROM '/tmp/27.testreplicationtaskiter.t2.null.1755219000'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/27.testreplicationtaskiter.t2.null.1755219000

2024-04-24T12:06:28,947  INFO [main] api.TestHCatClient: notif from tasks:28:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,947  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,947  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,947  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,947  INFO [main] api.TestHCatClient: getStagingDirectory(28.testreplicationtaskiter.t2.b=test1.-1038536203) called!
2024-04-24T12:06:28,948  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAABXRlc3QxNwAAADYvdG1wLzI4LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdDEuLTEwMzg1MzYyMDMFAA8c
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[28]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="test1") TO '/tmp/28.testreplicationtaskiter.t2.b=test1.-1038536203' FOR REPLICATION('28')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/28.testreplicationtaskiter.t2.b=test1.-1038536203
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/28.testreplicationtaskiter.t2.b=test1.-1038536203

2024-04-24T12:06:28,948  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,948  INFO [main] api.TestHCatClient: getStagingDirectory(28.testreplicationtaskiter.t2.b=test1.-1038536203) called!
2024-04-24T12:06:28,948  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAABXRlc3QxNwAAADYvdG1wLzI4LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdDEuLTEwMzg1MzYyMDMFAA8c
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[28]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="test1") FROM '/tmp/28.testreplicationtaskiter.t2.b=test1.-1038536203'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/28.testreplicationtaskiter.t2.b=test1.-1038536203

2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: notif from tasks:29:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: getStagingDirectory(29.testreplicationtaskiter.t2.b=testmul0.2000150612) called!
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwwNwAAADgvdG1wLzI5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDAuMjAwMDE1MDYxMgUADx0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[29]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul0") TO '/tmp/29.testreplicationtaskiter.t2.b=testmul0.2000150612' FOR REPLICATION('29')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/29.testreplicationtaskiter.t2.b=testmul0.2000150612
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/29.testreplicationtaskiter.t2.b=testmul0.2000150612

2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: getStagingDirectory(29.testreplicationtaskiter.t2.b=testmul0.2000150612) called!
2024-04-24T12:06:28,949  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwwNwAAADgvdG1wLzI5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDAuMjAwMDE1MDYxMgUADx0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[29]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul0") FROM '/tmp/29.testreplicationtaskiter.t2.b=testmul0.2000150612'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/29.testreplicationtaskiter.t2.b=testmul0.2000150612

2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: notif from tasks:30:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPHg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[30]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,953  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,954  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMAUBDx4=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[30]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul0") FOR REPLICATION('30')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: notif from tasks:31:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: getStagingDirectory(31.testreplicationtaskiter.t2.b=testmul1.2000150613) called!
2024-04-24T12:06:28,957  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwxNwAAADgvdG1wLzMxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDEuMjAwMDE1MDYxMwUADx8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[31]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul1") TO '/tmp/31.testreplicationtaskiter.t2.b=testmul1.2000150613' FOR REPLICATION('31')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul1.2000150613
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul1.2000150613

2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: getStagingDirectory(31.testreplicationtaskiter.t2.b=testmul1.2000150613) called!
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwxNwAAADgvdG1wLzMxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDEuMjAwMDE1MDYxMwUADx8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[31]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul1") FROM '/tmp/31.testreplicationtaskiter.t2.b=testmul1.2000150613'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul1.2000150613

2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: notif from tasks:32:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPIA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[32]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMQUBDyA=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[32]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul1") FOR REPLICATION('32')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: notif from tasks:33:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,958  INFO [main] api.TestHCatClient: getStagingDirectory(33.testreplicationtaskiter.t2.b=testmul2.2000150810) called!
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwyNwAAADgvdG1wLzMzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDIuMjAwMDE1MDgxMAUADyE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[33]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul2") TO '/tmp/33.testreplicationtaskiter.t2.b=testmul2.2000150810' FOR REPLICATION('33')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul2.2000150810
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul2.2000150810

2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: getStagingDirectory(33.testreplicationtaskiter.t2.b=testmul2.2000150810) called!
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwyNwAAADgvdG1wLzMzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDIuMjAwMDE1MDgxMAUADyE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[33]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul2") FROM '/tmp/33.testreplicationtaskiter.t2.b=testmul2.2000150810'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul2.2000150810

2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: notif from tasks:34:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPIg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[34]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMgUBDyI=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[34]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul2") FOR REPLICATION('34')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: notif from tasks:35:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,959  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: getStagingDirectory(35.testreplicationtaskiter.t2.b=testmul3.2000150811) called!
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwzNwAAADgvdG1wLzM1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDMuMjAwMDE1MDgxMQUADyM=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[35]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul3") TO '/tmp/35.testreplicationtaskiter.t2.b=testmul3.2000150811' FOR REPLICATION('35')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul3.2000150811
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul3.2000150811

2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: getStagingDirectory(35.testreplicationtaskiter.t2.b=testmul3.2000150811) called!
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwzNwAAADgvdG1wLzM1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDMuMjAwMDE1MDgxMQUADyM=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[35]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul3") FROM '/tmp/35.testreplicationtaskiter.t2.b=testmul3.2000150811'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul3.2000150811

2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: notif from tasks:36:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,960  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,961  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPJA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[36]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,961  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,961  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMwUBDyQ=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[36]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul3") FOR REPLICATION('36')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: notif from tasks:37:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: getStagingDirectory(37.testreplicationtaskiter.t2.b=testmul4.2000150808) called!
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw0NwAAADgvdG1wLzM3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDQuMjAwMDE1MDgwOAUADyU=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[37]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul4") TO '/tmp/37.testreplicationtaskiter.t2.b=testmul4.2000150808' FOR REPLICATION('37')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul4.2000150808
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul4.2000150808

2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: getStagingDirectory(37.testreplicationtaskiter.t2.b=testmul4.2000150808) called!
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw0NwAAADgvdG1wLzM3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDQuMjAwMDE1MDgwOAUADyU=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[37]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul4") FROM '/tmp/37.testreplicationtaskiter.t2.b=testmul4.2000150808'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul4.2000150808

2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: notif from tasks:38:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,962  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPJg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[38]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNAUBDyY=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[38]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul4") FOR REPLICATION('38')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: notif from tasks:39:1713985586,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,963  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: getStagingDirectory(39.testreplicationtaskiter.t2.b=testmul5.2000150809) called!
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw1NwAAADgvdG1wLzM5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDUuMjAwMDE1MDgwOQUADyc=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[39]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul5") TO '/tmp/39.testreplicationtaskiter.t2.b=testmul5.2000150809' FOR REPLICATION('39')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul5.2000150809
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul5.2000150809

2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: getStagingDirectory(39.testreplicationtaskiter.t2.b=testmul5.2000150809) called!
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw1NwAAADgvdG1wLzM5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDUuMjAwMDE1MDgwOQUADyc=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[39]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul5") FROM '/tmp/39.testreplicationtaskiter.t2.b=testmul5.2000150809'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul5.2000150809

2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: notif from tasks:40:1713985586,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPKA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[40]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,964  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,965  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNQUBDyg=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[40]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul5") FOR REPLICATION('40')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: notif from tasks:41:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: getStagingDirectory(41.testreplicationtaskiter.t2.b=testmul6.2000150814) called!
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw2NwAAADgvdG1wLzQxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDYuMjAwMDE1MDgxNAUADyk=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[41]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul6") TO '/tmp/41.testreplicationtaskiter.t2.b=testmul6.2000150814' FOR REPLICATION('41')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul6.2000150814
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul6.2000150814

2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: getStagingDirectory(41.testreplicationtaskiter.t2.b=testmul6.2000150814) called!
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw2NwAAADgvdG1wLzQxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDYuMjAwMDE1MDgxNAUADyk=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[41]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul6") FROM '/tmp/41.testreplicationtaskiter.t2.b=testmul6.2000150814'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul6.2000150814

2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: notif from tasks:42:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPKg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[42]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,968  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNgUBDyo=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[42]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul6") FOR REPLICATION('42')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: notif from tasks:43:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: getStagingDirectory(43.testreplicationtaskiter.t2.b=testmul7.2000150815) called!
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw3NwAAADgvdG1wLzQzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDcuMjAwMDE1MDgxNQUADys=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[43]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul7") TO '/tmp/43.testreplicationtaskiter.t2.b=testmul7.2000150815' FOR REPLICATION('43')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul7.2000150815
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul7.2000150815

2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: getStagingDirectory(43.testreplicationtaskiter.t2.b=testmul7.2000150815) called!
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw3NwAAADgvdG1wLzQzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDcuMjAwMDE1MDgxNQUADys=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[43]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul7") FROM '/tmp/43.testreplicationtaskiter.t2.b=testmul7.2000150815'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul7.2000150815

2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: notif from tasks:44:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPLA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[44]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,969  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNwUBDyw=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[44]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul7") FOR REPLICATION('44')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: notif from tasks:45:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: getStagingDirectory(45.testreplicationtaskiter.t2.b=testmul8.2000150812) called!
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw4NwAAADgvdG1wLzQ1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDguMjAwMDE1MDgxMgUADy0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[45]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul8") TO '/tmp/45.testreplicationtaskiter.t2.b=testmul8.2000150812' FOR REPLICATION('45')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul8.2000150812
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul8.2000150812

2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: getStagingDirectory(45.testreplicationtaskiter.t2.b=testmul8.2000150812) called!
2024-04-24T12:06:28,970  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw4NwAAADgvdG1wLzQ1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDguMjAwMDE1MDgxMgUADy0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[45]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul8") FROM '/tmp/45.testreplicationtaskiter.t2.b=testmul8.2000150812'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul8.2000150812

2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: notif from tasks:46:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPLg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[46]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsOAUBDy4=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[46]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul8") FOR REPLICATION('46')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: notif from tasks:47:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: getStagingDirectory(47.testreplicationtaskiter.t2.b=testmul9.2000150813) called!
2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw5NwAAADgvdG1wLzQ3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDkuMjAwMDE1MDgxMwUADy8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[47]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul9") TO '/tmp/47.testreplicationtaskiter.t2.b=testmul9.2000150813' FOR REPLICATION('47')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul9.2000150813
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul9.2000150813

2024-04-24T12:06:28,971  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: getStagingDirectory(47.testreplicationtaskiter.t2.b=testmul9.2000150813) called!
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw5NwAAADgvdG1wLzQ3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDkuMjAwMDE1MDgxMwUADy8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[47]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul9") FROM '/tmp/47.testreplicationtaskiter.t2.b=testmul9.2000150813'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul9.2000150813

2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: notif from tasks:48:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPMA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[48]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,972  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsOQUBDzA=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[48]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul9") FOR REPLICATION('48')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: notif from tasks:49:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: getStagingDirectory(49.testreplicationtaskiter.t2.b=testmul10.1979021355) called!
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMDcAAAA5L3RtcC80OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMC4xOTc5MDIxMzU1BQAPMQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[49]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul10") TO '/tmp/49.testreplicationtaskiter.t2.b=testmul10.1979021355' FOR REPLICATION('49')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul10.1979021355
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul10.1979021355

2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: getStagingDirectory(49.testreplicationtaskiter.t2.b=testmul10.1979021355) called!
2024-04-24T12:06:28,973  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMDcAAAA5L3RtcC80OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMC4xOTc5MDIxMzU1BQAPMQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[49]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul10") FROM '/tmp/49.testreplicationtaskiter.t2.b=testmul10.1979021355'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul10.1979021355

2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: notif from tasks:50:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPMg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[50]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,974  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTAFAQ8y
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[50]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul10") FOR REPLICATION('50')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,977  INFO [main] api.TestHCatClient: notif from tasks:51:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,977  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,977  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,977  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,977  INFO [main] api.TestHCatClient: getStagingDirectory(51.testreplicationtaskiter.t2.b=testmul11.1979021352) called!
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMTcAAAA5L3RtcC81MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMS4xOTc5MDIxMzUyBQAPMw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[51]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul11") TO '/tmp/51.testreplicationtaskiter.t2.b=testmul11.1979021352' FOR REPLICATION('51')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul11.1979021352
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul11.1979021352

2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: getStagingDirectory(51.testreplicationtaskiter.t2.b=testmul11.1979021352) called!
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMTcAAAA5L3RtcC81MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMS4xOTc5MDIxMzUyBQAPMw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[51]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul11") FROM '/tmp/51.testreplicationtaskiter.t2.b=testmul11.1979021352'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul11.1979021352

2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: notif from tasks:52:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPNA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[52]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTEFAQ80
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[52]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul11") FOR REPLICATION('52')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: notif from tasks:53:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,978  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,979  INFO [main] api.TestHCatClient: getStagingDirectory(53.testreplicationtaskiter.t2.b=testmul12.1979021353) called!
2024-04-24T12:06:28,979  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMjcAAAA5L3RtcC81My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMi4xOTc5MDIxMzUzBQAPNQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[53]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul12") TO '/tmp/53.testreplicationtaskiter.t2.b=testmul12.1979021353' FOR REPLICATION('53')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul12.1979021353
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul12.1979021353

2024-04-24T12:06:28,979  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,979  INFO [main] api.TestHCatClient: getStagingDirectory(53.testreplicationtaskiter.t2.b=testmul12.1979021353) called!
2024-04-24T12:06:28,979  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMjcAAAA5L3RtcC81My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMi4xOTc5MDIxMzUzBQAPNQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[53]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul12") FROM '/tmp/53.testreplicationtaskiter.t2.b=testmul12.1979021353'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul12.1979021353

2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: notif from tasks:54:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPNg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[54]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTIFAQ82
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[54]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul12") FOR REPLICATION('54')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,980  INFO [main] api.TestHCatClient: notif from tasks:55:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: getStagingDirectory(55.testreplicationtaskiter.t2.b=testmul13.1979021358) called!
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMzcAAAA5L3RtcC81NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMy4xOTc5MDIxMzU4BQAPNw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[55]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul13") TO '/tmp/55.testreplicationtaskiter.t2.b=testmul13.1979021358' FOR REPLICATION('55')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul13.1979021358
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul13.1979021358

2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: getStagingDirectory(55.testreplicationtaskiter.t2.b=testmul13.1979021358) called!
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMzcAAAA5L3RtcC81NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMy4xOTc5MDIxMzU4BQAPNw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[55]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul13") FROM '/tmp/55.testreplicationtaskiter.t2.b=testmul13.1979021358'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul13.1979021358

2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: notif from tasks:56:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,981  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPOA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[56]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTMFAQ84
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[56]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul13") FOR REPLICATION('56')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: notif from tasks:57:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,982  INFO [main] api.TestHCatClient: getStagingDirectory(57.testreplicationtaskiter.t2.b=testmul14.1979021359) called!
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNDcAAAA5L3RtcC81Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNC4xOTc5MDIxMzU5BQAPOQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[57]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul14") TO '/tmp/57.testreplicationtaskiter.t2.b=testmul14.1979021359' FOR REPLICATION('57')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul14.1979021359
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul14.1979021359

2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: getStagingDirectory(57.testreplicationtaskiter.t2.b=testmul14.1979021359) called!
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNDcAAAA5L3RtcC81Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNC4xOTc5MDIxMzU5BQAPOQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[57]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul14") FROM '/tmp/57.testreplicationtaskiter.t2.b=testmul14.1979021359'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul14.1979021359

2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: notif from tasks:58:1713985587,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPOg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[58]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTQFAQ86
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[58]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul14") FOR REPLICATION('58')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: notif from tasks:59:1713985587,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,983  INFO [main] api.TestHCatClient: getStagingDirectory(59.testreplicationtaskiter.t2.b=testmul15.1979021356) called!
2024-04-24T12:06:28,984  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNTcAAAA5L3RtcC81OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNS4xOTc5MDIxMzU2BQAPOw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[59]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul15") TO '/tmp/59.testreplicationtaskiter.t2.b=testmul15.1979021356' FOR REPLICATION('59')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul15.1979021356
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul15.1979021356

2024-04-24T12:06:28,984  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,984  INFO [main] api.TestHCatClient: getStagingDirectory(59.testreplicationtaskiter.t2.b=testmul15.1979021356) called!
2024-04-24T12:06:28,984  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNTcAAAA5L3RtcC81OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNS4xOTc5MDIxMzU2BQAPOw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[59]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul15") FROM '/tmp/59.testreplicationtaskiter.t2.b=testmul15.1979021356'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul15.1979021356

2024-04-24T12:06:28,984  INFO [main] api.TestHCatClient: notif from tasks:60:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPPA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[60]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,985  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTUFAQ88
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[60]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul15") FOR REPLICATION('60')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: notif from tasks:61:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: getStagingDirectory(61.testreplicationtaskiter.t2.b=testmul16.1979021357) called!
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNjcAAAA5L3RtcC82MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNi4xOTc5MDIxMzU3BQAPPQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[61]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul16") TO '/tmp/61.testreplicationtaskiter.t2.b=testmul16.1979021357' FOR REPLICATION('61')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul16.1979021357
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul16.1979021357

2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: getStagingDirectory(61.testreplicationtaskiter.t2.b=testmul16.1979021357) called!
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNjcAAAA5L3RtcC82MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNi4xOTc5MDIxMzU3BQAPPQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[61]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul16") FROM '/tmp/61.testreplicationtaskiter.t2.b=testmul16.1979021357'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul16.1979021357

2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: notif from tasks:62:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,988  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPPg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[62]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTYFAQ8-
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[62]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul16") FOR REPLICATION('62')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: notif from tasks:63:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: getStagingDirectory(63.testreplicationtaskiter.t2.b=testmul17.1979021362) called!
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNzcAAAA5L3RtcC82My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNy4xOTc5MDIxMzYyBQAPPw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[63]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul17") TO '/tmp/63.testreplicationtaskiter.t2.b=testmul17.1979021362' FOR REPLICATION('63')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul17.1979021362
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul17.1979021362

2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,989  INFO [main] api.TestHCatClient: getStagingDirectory(63.testreplicationtaskiter.t2.b=testmul17.1979021362) called!
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNzcAAAA5L3RtcC82My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNy4xOTc5MDIxMzYyBQAPPw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[63]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul17") FROM '/tmp/63.testreplicationtaskiter.t2.b=testmul17.1979021362'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul17.1979021362

2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: notif from tasks:64:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPQA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[64]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTcFAQ9A
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[64]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul17") FOR REPLICATION('64')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: notif from tasks:65:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,990  INFO [main] api.TestHCatClient: getStagingDirectory(65.testreplicationtaskiter.t2.b=testmul18.1979021363) called!
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxODcAAAA5L3RtcC82NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOC4xOTc5MDIxMzYzBQAPQQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[65]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul18") TO '/tmp/65.testreplicationtaskiter.t2.b=testmul18.1979021363' FOR REPLICATION('65')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul18.1979021363
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul18.1979021363

2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: getStagingDirectory(65.testreplicationtaskiter.t2.b=testmul18.1979021363) called!
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxODcAAAA5L3RtcC82NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOC4xOTc5MDIxMzYzBQAPQQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[65]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul18") FROM '/tmp/65.testreplicationtaskiter.t2.b=testmul18.1979021363'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul18.1979021363

2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: notif from tasks:66:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPQg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[66]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTgFAQ9C
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[66]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul18") FOR REPLICATION('66')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: notif from tasks:67:1713985588,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2024-04-24T12:06:28,991  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: getStagingDirectory(67.testreplicationtaskiter.t2.b=testmul19.1979021360) called!
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxOTcAAAA5L3RtcC82Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOS4xOTc5MDIxMzYwBQAPQw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[67]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul19") TO '/tmp/67.testreplicationtaskiter.t2.b=testmul19.1979021360' FOR REPLICATION('67')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul19.1979021360
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul19.1979021360

2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: getStagingDirectory(67.testreplicationtaskiter.t2.b=testmul19.1979021360) called!
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxOTcAAAA5L3RtcC82Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOS4xOTc5MDIxMzYwBQAPQw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[67]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul19") FROM '/tmp/67.testreplicationtaskiter.t2.b=testmul19.1979021360'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul19.1979021360

2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: notif from tasks:68:1713985588,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[68]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,992  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTkFAQ9E
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[68]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul19") FOR REPLICATION('68')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,995  INFO [main] api.TestHCatClient: notif from tasks:69:1713985588,t:DROP_TABLE,o:testreplicationtaskiter.t1,s:TABLE
2024-04-24T12:06:28,995  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropTableReplicationTask
2024-04-24T12:06:28,995  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,995  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,996  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[69]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,996  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,996  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADtvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFRhYmxlQ29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQxBQEPRQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropTableCommand]
EVENTID:[69]
CMD:DROP TABLE IF EXISTS testreplicationtaskiter.t1 FOR REPLICATION('69')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: notif from tasks:70:1713985588,t:DROP_TABLE,o:testreplicationtaskiter.t2,s:TABLE
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropTableReplicationTask
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: task was actionable!
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: On src:
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[70]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: On dest:
2024-04-24T12:06:28,997  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADtvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFRhYmxlQ29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyBQEPRg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropTableCommand]
EVENTID:[70]
CMD:DROP TABLE IF EXISTS testreplicationtaskiter.t2 FOR REPLICATION('70')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:29,048  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:29,049  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:29,049  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:29,049  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:29,049  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:29,049  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:29,049  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:29,051  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:06:29,051  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2024-04-24T12:06:29,052  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:29,056  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testObjectNotFoundException_DBName	
2024-04-24T12:06:29,057  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testObjectNotFoundException_DBName	
2024-04-24T12:06:29,058  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ObjectNotFoundException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : NoSuchObjectException while fetching database. Cause : NoSuchObjectException(message:database hive.testObjectNotFoundException_DBName)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getDatabase(HCatClientHMSImpl.java:116) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:573) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: database hive.testObjectNotFoundException_DBName
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result$get_database_req_resultStandardScheme.read(ThriftHiveMetastore.java:53354) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result$get_database_req_resultStandardScheme.read(ThriftHiveMetastore.java:53331) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result.read(ThriftHiveMetastore.java:53262) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_database_req(ThriftHiveMetastore.java:1373) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_database_req(ThriftHiveMetastore.java:1360) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabaseInternal(HiveMetaStoreClient.java:2279) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:2266) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:2247) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.getDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getDatabase(HCatClientHMSImpl.java:111) ~[classes/:?]
	... 42 more
2024-04-24T12:06:29,059  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testObjectNotFoundException_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:06:29,063  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testobjectnotfoundexception_dbname.db
2024-04-24T12:06:29,063  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testobjectnotfoundexception_dbname.db
2024-04-24T12:06:29,065  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testobjectnotfoundexception_dbname.db
2024-04-24T12:06:29,076  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2024-04-24T12:06:29,078  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ObjectNotFoundException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : NoSuchObjectException while fetching table.. Cause : NoSuchObjectException(message:hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName table not found)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getTable(HCatClientHMSImpl.java:200) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:584) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName table not found
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result$get_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result$get_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table_req(ThriftHiveMetastore.java:2666) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table_req(ThriftHiveMetastore.java:2653) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTableInternal(HiveMetaStoreClient.java:2550) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:2608) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:2486) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor84.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.getTable(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getTable(HCatClientHMSImpl.java:193) ~[classes/:?]
	... 42 more
2024-04-24T12:06:29,082  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:06:29,140  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:29,140  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:29,141  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:29,142  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testObjectNotFoundException_TableName, dbName:testObjectNotFoundException_DBName, owner:alex, createTime:1713985589, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:part, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:06:29,146  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testobjectnotfoundexception_dbname.db/testobjectnotfoundexception_tablename
2024-04-24T12:06:29,175  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2024-04-24T12:06:29,181  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:29,182  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2024-04-24T12:06:29,189  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:29,221  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName[foobar]	
2024-04-24T12:06:29,234  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ObjectNotFoundException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : NoSuchObjectException while retrieving partition.. Cause : NoSuchObjectException(message:partition values=[foobar])
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:464) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:605) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: partition values=[foobar]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_result$get_partition_resultStandardScheme.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_result$get_partition_resultStandardScheme.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_result.read(ThriftHiveMetastore.java) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3400) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3385) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2303) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2285) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	... 42 more
2024-04-24T12:06:29,235  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testobjectnotfoundexception_dbname.testobjectnotfoundexception_tablename	
2024-04-24T12:06:29,241  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:29,242  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testobjectnotfoundexception_dbname.testobjectnotfoundexception_tablename	
2024-04-24T12:06:29,247  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testobjectnotfoundexception_dbname.db/testobjectnotfoundexception_tablename/part=foobar
2024-04-24T12:06:29,263  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2024-04-24T12:06:29,270  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:29,271  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.testobjectnotfoundexception_dbname.testobjectnotfoundexception_tablename	
2024-04-24T12:06:29,281  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2024-04-24T12:06:29,288  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:06:29,288  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : Partition-spec doesn't have the right number of partition keys.
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:442) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:622) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:06:29,347  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:29,347  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:29,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:29,349  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-24T12:06:29,414  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_34877;create=true
2024-04-24T12:06:29,960  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T12:06:29,960  INFO [MetaStoreThread-34877] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
2024-04-24T12:06:29,962  INFO [MetaStoreThread-34877] metastore.HMSHandler: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:06:29,962  INFO [MetaStoreThread-34877] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T12:06:29,962  INFO [MetaStoreThread-34877] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:06:29,996  WARN [MetaStoreThread-34877] hikari.HikariConfig: HikariPool-4 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:06:29,998  INFO [MetaStoreThread-34877] hikari.HikariDataSource: HikariPool-4 - Starting...
2024-04-24T12:06:30,000  INFO [MetaStoreThread-34877] pool.PoolBase: HikariPool-4 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:06:30,001  INFO [MetaStoreThread-34877] hikari.HikariDataSource: HikariPool-4 - Start completed.
2024-04-24T12:06:30,961  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T12:06:31,495  INFO [MetaStoreThread-34877] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:06:31,495  INFO [MetaStoreThread-34877] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a12da67, with PersistenceManager: null will be shutdown
2024-04-24T12:06:31,495  INFO [MetaStoreThread-34877] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a12da67, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e7d2bce created in the thread with id: 129
2024-04-24T12:06:31,961  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2024-04-24T12:06:32,349  INFO [MetaStoreThread-34877] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6a12da67 from thread id: 129
2024-04-24T12:06:32,357  INFO [MetaStoreThread-34877] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-24T12:06:32,366  INFO [MetaStoreThread-34877] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T12:06:32,382  INFO [MetaStoreThread-34877] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T12:06:32,396  INFO [MetaStoreThread-34877] metastore.HMSHandler: Added admin role in metastore
2024-04-24T12:06:32,397  INFO [MetaStoreThread-34877] metastore.HMSHandler: Added public role in metastore
2024-04-24T12:06:32,423  INFO [MetaStoreThread-34877] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T12:06:32,423  INFO [MetaStoreThread-34877] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Started the new metaserver on port [34877]...
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: TCP keepalive = true
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Enable SSL = false
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Compaction HMS parameters:
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.initiator.on = false
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.worker.threads = 0
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: hive.metastore.runworker.in = metastore
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.history.retention.attempted = 2
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.history.retention.failed = 3
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.history.retention.succeeded = 3
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.initiator.failed.compacts.threshold = 2
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: metastore.compactor.enable.stats.compression
2024-04-24T12:06:32,424  WARN [MetaStoreThread-34877] metastore.HiveMetaStore: Compactor Initiator is turned Off. Automatic compaction will not be triggered.
2024-04-24T12:06:32,424  WARN [MetaStoreThread-34877] metastore.HiveMetaStore: Invalid number of Compactor Worker threads(0) on HMS
2024-04-24T12:06:32,424  INFO [MetaStoreThread-34877] metastore.HiveMetaStore: Direct SQL optimization = true
2024-04-24T12:06:32,971  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34877) is created
2024-04-24T12:06:32,971  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 34877 with warehouse dir: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34877 with jdbcUrl: jdbc:derby:memory:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_34877;create=true
2024-04-24T12:06:32,973  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:06:33,025  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:06:33,025  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:06:33,027  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:06:33,027  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2024-04-24T12:06:33,028  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:33,028 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:35,029  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:35,030 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:37,031  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:37,032 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:39,033  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:39,034 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:41,036  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:41,037 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:43,038  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:43,039 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:45,040  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:45,040 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:47,041  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:47,042 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:49,043  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:49,044 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:51,045  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:51,045 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:53,046  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:06:53,047 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:06:53,058  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 5
2024-04-24T12:06:53,059  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2024-04-24T12:06:53,059  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=4 expired=true
2024-04-24T12:06:53,060  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:06:53,060  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34727]
2024-04-24T12:06:53,060  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:06:53,060  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 3
2024-04-24T12:06:53,061  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:06:53,061  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:06:53,062  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:06:53,062  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:06:53,064  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-5 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:06:53,066  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-5 - Starting...
2024-04-24T12:06:53,067  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-5 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:06:53,068  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-5 - Start completed.
2024-04-24T12:06:54,464  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:06:54,464  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f129e09, with PersistenceManager: null will be shutdown
2024-04-24T12:06:54,464  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f129e09, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@343bf584 created in the thread with id: 139
2024-04-24T12:06:55,118  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f129e09 from thread id: 139
2024-04-24T12:06:55,122  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:55,122  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:55,127  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:55,131  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:06:55,136  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:55,137  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:55,137  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:55,148  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:55,156  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:55,199  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:55,201  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:55,256 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:57,257  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:57,260  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:57,260  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:57,261  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:57,262  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:57,263  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:57,266  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:57,269 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:06:59,270  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:06:59,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:06:59,274  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:06:59,275  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:06:59,275  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:06:59,276  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:06:59,278  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:06:59,282 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (4).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:07:01,282  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:07:01,285  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:07:01,286  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:07:01,289  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:07:01,290  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:07:01,291  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:07:01,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2024-04-24T12:07:01,510  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:07:01,526  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db does not exist; Force to delete it.
2024-04-24T12:07:01,526 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:07:01,580  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,581  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,581  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:01,583  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:01,584  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:07:01,584  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:01,589  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:07:01,608  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:07:01,608  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:07:01,611  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,674  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,675  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,675  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:01,677  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:01,679  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:07:01,679  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:01,681  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:07:01,746  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,746  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,746  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,747  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,748  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:alex, createTime:1713985621, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:07:01,754  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,862  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,863  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:01,864  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:01,865  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2024-04-24T12:07:01,865  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:01,867  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:07:01,885  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:07:01,937  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,937  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,937  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,938  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:01,940  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:01,941  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2024-04-24T12:07:01,941  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:01,997  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:01,998  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:01,998  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:01,999  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:02,002  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:07:02,002  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34877]
2024-04-24T12:07:02,003  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34877)
2024-04-24T12:07:02,003  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34877) current connections: 4
2024-04-24T12:07:02,004  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:07:02,004  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:02,005  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:07:02,006  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T12:07:02,006  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:07:02,008  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-6 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:07:02,009  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-6 - Starting...
2024-04-24T12:07:02,011  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-6 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:07:02,011  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-6 - Start completed.
2024-04-24T12:07:03,404  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:07:03,404  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4080f3f2, with PersistenceManager: null will be shutdown
2024-04-24T12:07:03,404  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4080f3f2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59e74ed3 created in the thread with id: 149
2024-04-24T12:07:03,961  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4080f3f2 from thread id: 149
2024-04-24T12:07:03,965  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:04,014  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:04,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:04,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:04,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:04,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:04,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:04,015  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:04,017  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:07:04,017  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:07:04,017  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:04,019  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:07:04,024  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34877/mydb.db
2024-04-24T12:07:04,024  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34877/mydb.db
2024-04-24T12:07:04,026  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34877/mydb.db
2024-04-24T12:07:04,099  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:04,100  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:04,100  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:04,102  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:04,103  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:07:04,103  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:04,154  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:04,155  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:04,157  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:04,158  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2024-04-24T12:07:04,158  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:04,161  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:mytable, dbName:mydb, owner:alex, createTime:1713985624, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{transient_lastDdlTime=1713985621, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:07:04,169  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Location: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable specified for non-external table:mytable
2024-04-24T12:07:04,260  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:04,261  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:04,261  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:04,263  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:07:04,264  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2024-04-24T12:07:04,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:04,266  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:07:04,302  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:04,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:04,350  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:04,350  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:04,350  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:04,351  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:04,352  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2024-04-24T12:07:04,352  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:04,353 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:06,353  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:06,354 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:08,355  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:08,356 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:10,356  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:10,357 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:12,358  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:12,359 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:14,359  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:14,360 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:16,361  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:16,362 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:18,363  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:18,364 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:20,365  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:20,366 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:22,367  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:22,368 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:24,368  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:24,369 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:24,370  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 6
2024-04-24T12:07:24,370  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=true
2024-04-24T12:07:24,370  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2024-04-24T12:07:24,373  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:07:24,373  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34727]
2024-04-24T12:07:24,374  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:07:24,374  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 5
2024-04-24T12:07:24,375  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:07:24,376  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.myDb.myTable newtbl=mytable	
2024-04-24T12:07:24,377  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:07:24,377  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:07:24,380  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-7 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:07:24,380  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-7 - Starting...
2024-04-24T12:07:24,382  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-7 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:07:24,383  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-7 - Start completed.
2024-04-24T12:07:25,745  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:07:25,745  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d86a4c3, with PersistenceManager: null will be shutdown
2024-04-24T12:07:25,745  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d86a4c3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63907919 created in the thread with id: 158
2024-04-24T12:07:26,005  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=5 expired=true
2024-04-24T12:07:26,005  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:07:26,005  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6f129e09, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@343bf584 will be shutdown
2024-04-24T12:07:26,005  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:07:26,021  WARN [Finalizer] transport.TIOStreamTransport: Error closing output stream.
java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[?:1.8.0_402]
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) ~[?:1.8.0_402]
	at java.io.FilterOutputStream.close(FilterOutputStream.java:158) ~[?:1.8.0_402]
	at org.apache.thrift.transport.TIOStreamTransport.close(TIOStreamTransport.java:156) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.transport.TSocket.close(TSocket.java:252) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.close(HiveMetaStoreClient.java:844) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.tearDown(HiveClientCache.java:510) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.finalize(HiveClientCache.java:536) [classes/:?]
	at java.lang.System$2.invokeFinalize(System.java:1285) [?:1.8.0_402]
	at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:102) [?:1.8.0_402]
	at java.lang.ref.Finalizer.access$100(Finalizer.java:34) [?:1.8.0_402]
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189) [?:1.8.0_402]
2024-04-24T12:07:26,021  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2024-04-24T12:07:26,385  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d86a4c3 from thread id: 158
2024-04-24T12:07:26,418  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:26,510  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:26,511  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:26,511  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:26,512  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:26,513  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:07:26,513  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:26,517  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:07:26,525  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:26,580  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:26,581  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:26,582  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:07:26,583  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2024-04-24T12:07:26,583  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:26,584 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:28,585  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:28,586 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:30,587  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:30,588 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:32,589  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:32,589 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:34,590  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:34,591 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:36,592  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:36,592 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:38,593  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:38,594 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:40,594  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:40,595 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:42,596  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:42,597 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:44,598  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:44,598 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:46,600  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:46,600 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:46,601  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 6
2024-04-24T12:07:46,601  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=true
2024-04-24T12:07:46,601  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2024-04-24T12:07:46,604  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:07:46,604  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34877]
2024-04-24T12:07:46,604  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34877)
2024-04-24T12:07:46,605  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34877) current connections: 5
2024-04-24T12:07:46,607  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:07:46,610  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.myDb.myTable newtbl=mytable	
2024-04-24T12:07:46,613  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:07:46,613  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T12:07:46,614  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:07:46,617  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-8 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:07:46,618  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-8 - Starting...
2024-04-24T12:07:46,619  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-8 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:07:46,620  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-8 - Start completed.
2024-04-24T12:07:47,983  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=5 expired=true
2024-04-24T12:07:47,984  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:07:47,984  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4080f3f2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@59e74ed3 will be shutdown
2024-04-24T12:07:47,984  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:07:47,985  WARN [Finalizer] transport.TIOStreamTransport: Error closing output stream.
java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[?:1.8.0_402]
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) ~[?:1.8.0_402]
	at java.io.FilterOutputStream.close(FilterOutputStream.java:158) ~[?:1.8.0_402]
	at org.apache.thrift.transport.TIOStreamTransport.close(TIOStreamTransport.java:156) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.transport.TSocket.close(TSocket.java:252) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.close(HiveMetaStoreClient.java:844) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.tearDown(HiveClientCache.java:510) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.finalize(HiveClientCache.java:536) [classes/:?]
	at java.lang.System$2.invokeFinalize(System.java:1285) [?:1.8.0_402]
	at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:102) [?:1.8.0_402]
	at java.lang.ref.Finalizer.access$100(Finalizer.java:34) [?:1.8.0_402]
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189) [?:1.8.0_402]
2024-04-24T12:07:47,985  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2024-04-24T12:07:48,003  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:07:48,003  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c5180a, with PersistenceManager: null will be shutdown
2024-04-24T12:07:48,003  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c5180a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77c3fd54 created in the thread with id: 165
2024-04-24T12:07:48,518  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c5180a from thread id: 165
2024-04-24T12:07:48,544  WARN [TThreadPoolServer WorkerProcess-%d] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2024-04-24T12:07:48,633  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:48,633  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:48,634  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:48,634  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:48,636  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:48,636  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:07:48,637  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:48,640  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:07:48,646  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:07:48,694  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:07:48,695  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:07:48,696  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:07:48,698  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:07:48,698  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:48,698 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:50,699  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:50,700 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:52,701  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:52,701 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:54,703  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:54,703 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:56,704  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:56,705 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:07:58,706  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:07:58,706 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:00,707  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:00,708 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:02,709  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:02,709 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:04,710  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:04,711 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:06,712  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:06,713 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:08,714  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:08,714 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:08,715  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 3
2024-04-24T12:08:08,715  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=true
2024-04-24T12:08:08,715  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=true
2024-04-24T12:08:08,718  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:08:08,718  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34727]
2024-04-24T12:08:08,718  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:08:08,719  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 5
2024-04-24T12:08:08,720  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:08:08,720  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testEmptyCreate	
2024-04-24T12:08:08,721  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:08:08,721  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:08:08,724  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-9 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:08:08,725  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-9 - Starting...
2024-04-24T12:08:08,727  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-9 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:08:08,728  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-9 - Start completed.
2024-04-24T12:08:09,904  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=2 expired=true
2024-04-24T12:08:09,904  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:08:09,904  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5d86a4c3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63907919 will be shutdown
2024-04-24T12:08:09,904  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:08:09,905  WARN [Finalizer] transport.TIOStreamTransport: Error closing output stream.
java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118) ~[?:1.8.0_402]
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) ~[?:1.8.0_402]
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) ~[?:1.8.0_402]
	at java.io.FilterOutputStream.close(FilterOutputStream.java:158) ~[?:1.8.0_402]
	at org.apache.thrift.transport.TIOStreamTransport.close(TIOStreamTransport.java:156) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.thrift.transport.TSocket.close(TSocket.java:252) [libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.close(HiveMetaStoreClient.java:844) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.tearDown(HiveClientCache.java:510) [classes/:?]
	at org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient.finalize(HiveClientCache.java:536) [classes/:?]
	at java.lang.System$2.invokeFinalize(System.java:1285) [?:1.8.0_402]
	at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:102) [?:1.8.0_402]
	at java.lang.ref.Finalizer.access$100(Finalizer.java:34) [?:1.8.0_402]
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189) [?:1.8.0_402]
2024-04-24T12:08:09,905  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2024-04-24T12:08:10,129  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:08:10,129  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e373da6, with PersistenceManager: null will be shutdown
2024-04-24T12:08:10,130  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e373da6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44ea9730 created in the thread with id: 172
2024-04-24T12:08:10,663  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e373da6 from thread id: 172
2024-04-24T12:08:10,670  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:10,728  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:10,728  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:10,728  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:10,729  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:10,729  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testEmptyCreate, dbName:default, owner:alex, createTime:1713985690, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:10,732  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testemptycreate
2024-04-24T12:08:10,753  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testEmptyCreate	
2024-04-24T12:08:10,763  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:10,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:10,817  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:10,819  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:10,819  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:08:10,820  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:10,823  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: ptnDB	
2024-04-24T12:08:10,824  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ptnDB, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:08:10,830  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db
2024-04-24T12:08:10,830  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db
2024-04-24T12:08:10,832  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db
2024-04-24T12:08:10,838  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:10,901  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:10,902  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:pageView, dbName:ptnDB, owner:alex, createTime:1713985690, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:userid, type:int, comment:id columns), FieldSchema(name:viewtime, type:bigint, comment:view time columns), FieldSchema(name:pageurl, type:string, comment:), FieldSchema(name:ip, type:string, comment:IP Address of the User)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:date column), FieldSchema(name:country, type:string, comment:country column)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:10,906  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db/pageview
2024-04-24T12:08:10,920  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:10,927  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:10,928  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptndb.pageview	
2024-04-24T12:08:10,934  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:10,935  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2024-04-24T12:08:10,936  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2024-04-24T12:08:10,945  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db/pageview/dt=04%2F30%2F2012/country=usa
2024-04-24T12:08:10,965 ERROR [main] api.HCatAddPartitionDesc: Unsupported! HCatAddPartitionDesc requires HCatTable to be specified explicitly.
2024-04-24T12:08:10,966  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:10,972  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:10,973  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2024-04-24T12:08:10,973  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2024-04-24T12:08:10,978  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db/pageview/dt=04%2F12%2F2012/country=brazil
2024-04-24T12:08:10,991 ERROR [main] api.HCatAddPartitionDesc: Unsupported! HCatAddPartitionDesc requires HCatTable to be specified explicitly.
2024-04-24T12:08:10,991  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:10,997  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:10,998  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2024-04-24T12:08:10,998  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2024-04-24T12:08:11,004  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/ptndb.db/pageview/dt=04%2F13%2F2012/country=argentina
2024-04-24T12:08:11,017  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:11,024  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,025  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.ptndb.pageview	
2024-04-24T12:08:11,053  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:11,060  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,061  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.ptnDB.pageView[04/30/2012,usa]	
2024-04-24T12:08:11,076  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=ptnDB,table=pageView, partitionSpec: [{dt=04/30/2012, country=usa}]).
2024-04-24T12:08:11,076  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:11,084  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,084  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2024-04-24T12:08:11,159  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2024-04-24T12:08:11,166  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:11,172  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,173  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.ptndb.pageview	
2024-04-24T12:08:11,198  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2024-04-24T12:08:11,204  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,205  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.ptndb.pageview	
2024-04-24T12:08:11,258  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 markPartitionForEvent : tbl=hive.ptnDB.pageViewpartition={country=argentina, dt=04/13/2012}	
2024-04-24T12:08:11,352  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 isPartitionMarkedForEvent : tbl=hive.ptnDB.pageViewpartition={country=argentina, dt=04/13/2012}	
2024-04-24T12:08:11,365  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2024-04-24T12:08:11,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,413  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,413  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:11,415  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:11,415  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2024-04-24T12:08:11,415  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:11,419  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableone	
2024-04-24T12:08:11,421  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tabletwo	
2024-04-24T12:08:11,423  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,480  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,481  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:tableone, dbName:default, owner:alex, createTime:1713985691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:11,485  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/tableone
2024-04-24T12:08:11,510  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableone	
2024-04-24T12:08:11,516  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,517  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:tabletwo, dbName:default, owner:null, createTime:1713985691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/tableone, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:null, parameters:{transient_lastDdlTime=1713985691, bucketing_version=2, EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:11,530  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updating table stats for tabletwo
2024-04-24T12:08:11,530  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updated size of table tabletwo to 0
2024-04-24T12:08:11,543  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=default tbls=null	
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,600  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,600  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:11,602  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:11,602  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:08:11,603  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:11,605  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.Temptable	
2024-04-24T12:08:11,606  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,664  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:Temptable, dbName:default, owner:alex, createTime:1713985691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:11,668  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/temptable
2024-04-24T12:08:11,679  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.foo.Temptable	
2024-04-24T12:08:11,681  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2024-04-24T12:08:11,687  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,687  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.goodTable	
2024-04-24T12:08:11,827  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:11,886  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,886  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,886  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,886  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,887  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,887  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:goodTable, dbName:default, owner:alex, createTime:1713985691, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:11,892  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/goodtable
2024-04-24T12:08:11,903  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2024-04-24T12:08:11,909  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:11,909  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=false
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:11,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:11,957  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:11,957  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:11,957  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:11,957  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:11,957  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:11,957  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:11,959  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:11,959  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:08:11,960  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:11,962  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:08:11,963  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:11,963  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:11,967  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:11,971  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:08:11,976  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:11,977  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:11,977  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:11,988  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:11,995  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:12,032  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:12,035  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:12,077 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:14,078  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:14,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:14,082  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:14,084  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:14,084  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:14,085  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:14,088  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:14,091 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:16,092  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:16,096  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:16,097  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:16,098  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:16,099  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:16,100  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:16,110  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2024-04-24T12:08:16,128  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:16,136  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db does not exist; Force to delete it.
2024-04-24T12:08:16,136 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:08:16,187  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,188  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,188  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,190  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:16,190  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2024-04-24T12:08:16,190  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,192  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:08:16,196  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:08:16,196  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:08:16,198  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,249  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,250  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,251  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:08:16,253  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2024-04-24T12:08:16,253  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,255  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,311  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,312  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:alex, createTime:1713985696, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2, comment=Source table.}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:08:16,315  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,376  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,376  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,378  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:16,378  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2024-04-24T12:08:16,379  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:08:16,387  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,438  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,438  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,440  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:08:16,440  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 7 HCatClient: thread: 1 users=7 expired=false closed=false
2024-04-24T12:08:16,440  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,442  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2024-04-24T12:08:16,448  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:16,449  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2024-04-24T12:08:16,457  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/mydb.db/mytable/dt=2011_12_31/grid=AB
2024-04-24T12:08:16,538  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,538  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,538  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,538  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,539  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,539  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,541  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:16,542  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 8 HCatClient: thread: 1 users=8 expired=false closed=false
2024-04-24T12:08:16,542  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,544  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:08:16,549  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:16,550  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.myDb.myTable	
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,621  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,622  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:08:16,624  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 9 HCatClient: thread: 1 users=9 expired=false closed=false
2024-04-24T12:08:16,624  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,625  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2024-04-24T12:08:16,633  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:08:16,634  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition : tbl=hive.myDb.myTable[2011_12_31,AB]	
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:08:16,707  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:08:16,708  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:08:16,708  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:08:16,708  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:08:16,710  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:08:16,711  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2024-04-24T12:08:16,711  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:16,711 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:18,712  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:18,713 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:20,714  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:20,714 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:22,715  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:22,716 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:24,717  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:24,718 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:26,719  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:26,720 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:28,721  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:28,722 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:30,723  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:30,724 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:32,725  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:32,726 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:34,726  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:34,727 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:36,728  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:08:36,728 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:08:36,728  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 3
2024-04-24T12:08:36,728  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=true
2024-04-24T12:08:36,729  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=true
2024-04-24T12:08:36,729  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:08:36,729  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34877]
2024-04-24T12:08:36,730  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34877)
2024-04-24T12:08:36,730  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34877) current connections: 5
2024-04-24T12:08:36,731  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:08:36,731  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:08:36,732  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:08:36,732  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T12:08:36,733  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:08:36,735  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-10 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:08:36,736  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-10 - Starting...
2024-04-24T12:08:36,737  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-10 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:08:36,738  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-10 - Start completed.
2024-04-24T12:08:38,094  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:08:38,094  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ad1217b, with PersistenceManager: null will be shutdown
2024-04-24T12:08:38,095  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ad1217b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@655c6667 created in the thread with id: 202
2024-04-24T12:08:38,549  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=2 expired=true
2024-04-24T12:08:38,549  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:08:38,549  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63c5180a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77c3fd54 will be shutdown
2024-04-24T12:08:38,549  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:08:38,550  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2024-04-24T12:08:38,550  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:08:39,051  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ad1217b from thread id: 202
2024-04-24T12:08:39,054  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:39,054  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:39,058  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:39,062  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:08:39,067  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:39,068  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:39,068  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:39,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:39,089  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:39,125  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:39,127  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:39,165 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:41,165  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:41,168  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:41,170  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:41,172  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:41,172  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:41,173  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:41,175  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:41,179 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:43,179  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:43,182  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:43,183  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:43,184  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:43,185  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:43,185  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:43,187  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:43,190 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:45,191  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:45,193  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:45,194  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:45,195  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:45,195  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:45,196  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:45,198  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:45,201 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:47,202  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:47,205  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:47,206  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:47,210  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:47,212  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:47,215  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:47,221  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:47,231 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:49,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:49,234  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:49,235  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:49,239  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:49,240  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:49,240  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:49,242  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:49,245 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:51,246  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:51,249  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:51,249  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:51,250  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:51,251  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:51,252  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:51,254  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:51,257 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:53,258  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:53,260  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:53,261  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:53,262  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:53,263  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:53,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:53,266  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:53,269 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:55,269  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:55,272  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:55,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:55,275  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:55,275  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:55,276  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:55,278  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:55,281 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:57,282  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:57,285  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:57,286  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:57,289  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:57,289  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:57,290  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:57,292  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:57,294 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:59,295  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:08:59,296  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:08:59,297  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:08:59,298  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:08:59,299  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:08:59,300  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:08:59,301  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:08:59,304 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:08:59,305  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema(TestHCatClient.java:1278) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:09:00,306  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:09:00,306  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34877)
2024-04-24T12:09:00,307  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34877) current connections: 5
2024-04-24T12:09:00,309  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:09:00,313  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:09:00,313  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T12:09:00,314  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33e5c388, with PersistenceManager: null will be shutdown
2024-04-24T12:09:00,315  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33e5c388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36bd308c created in the thread with id: 209
2024-04-24T12:09:00,317  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33e5c388 from thread id: 209
2024-04-24T12:09:00,318  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:00,318  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:00,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:00,322  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:09:00,323  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:00,324  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:00,325  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:00,326  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:00,327  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:00,328  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:00,331  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:00,335 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:02,336  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:02,339  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:02,340  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:02,343  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:02,343  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:02,344  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:02,346  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:02,349 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:04,350  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:04,353  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:04,354  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:04,355  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:04,356  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:04,357  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:04,359  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:04,362 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:06,363  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:06,365  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:06,366  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:06,367  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:06,368  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:06,369  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:06,370  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:06,374 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:08,375  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:08,377  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:08,377  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:08,379  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:08,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:08,381  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:08,382  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:08,386 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:10,386  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:10,389  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:10,390  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:10,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:10,393  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:10,393  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:10,395  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:10,398 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:12,398  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:12,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:12,402  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:12,403  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:12,403  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:12,404  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:12,406  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:12,409 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:14,410  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:14,412  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:14,413  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:14,416  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:14,417  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:14,418  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:14,420  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:14,423 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:16,424  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:16,426  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:16,427  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:16,428  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:16,429  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:16,430  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:16,432  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:16,435 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:18,436  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:18,436  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:18,437  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:18,438  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:18,439  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:18,439  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:18,441  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:18,444 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:20,445  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:09:20,447  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:09:20,448  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:09:20,450  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:20,451  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:20,451  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:20,454  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:09:20,456 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:20,457 ERROR [main] api.TestHCatClient: Unexpected exception! 
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : MetaException while dropping db.. Cause : MetaException(message:javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:164) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema(TestHCatClient.java:1278) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) ~[classes/:?]
	... 42 more
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:09:20,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:09:20,504  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:09:20,506  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:09:20,506  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 10 HCatClient: thread: 1 users=10 expired=false closed=false
2024-04-24T12:09:20,507  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:20,507 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:22,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:22,508 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:24,509  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:24,510 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:26,511  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:26,512 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:28,513  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:28,513 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:30,514  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:30,515 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:32,516  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:32,517 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:34,518  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:34,519 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:36,519  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:36,520 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:38,521  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:38,521 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:40,522  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:09:40,523 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2235)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:481)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:652)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:12974)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1007)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1895)
	at sun.reflect.GeneratedMethodAccessor156.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18318)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18297)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2024-04-24T12:09:40,524  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 10
2024-04-24T12:09:40,524  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=10 expired=true
2024-04-24T12:09:40,524  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=9 expired=true
2024-04-24T12:09:40,526  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T12:09:40,527  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:34727]
2024-04-24T12:09:40,527  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:09:40,528  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 6
2024-04-24T12:09:40,530  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T12:09:40,533  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testUpdateTableSchema_DBName	
2024-04-24T12:09:40,535  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:09:40,536  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T12:09:40,541  WARN [TThreadPoolServer WorkerProcess-%d] hikari.HikariConfig: HikariPool-11 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T12:09:40,543  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-11 - Starting...
2024-04-24T12:09:40,547  INFO [TThreadPoolServer WorkerProcess-%d] pool.PoolBase: HikariPool-11 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T12:09:40,549  INFO [TThreadPoolServer WorkerProcess-%d] hikari.HikariDataSource: HikariPool-11 - Start completed.
2024-04-24T12:09:41,627  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=9 expired=true
2024-04-24T12:09:41,628  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 5
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1ad1217b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@655c6667 will be shutdown
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e373da6, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@44ea9730 will be shutdown
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:09:41,628  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:09:41,629  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:09:41,924  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T12:09:41,924  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b1b744d, with PersistenceManager: null will be shutdown
2024-04-24T12:09:41,924  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b1b744d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9139719 created in the thread with id: 210
2024-04-24T12:09:42,433  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b1b744d from thread id: 210
2024-04-24T12:09:42,435  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testUpdateTableSchema_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:09:42,440  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testupdatetableschema_dbname.db
2024-04-24T12:09:42,440  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testupdatetableschema_dbname.db
2024-04-24T12:09:42,442  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testupdatetableschema_dbname.db
2024-04-24T12:09:42,453  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:09:42,509  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:09:42,510  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testUpdateTableSchema_TableName, dbName:testUpdateTableSchema_DBName, owner:alex, createTime:1713985782, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:09:42,517  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testupdatetableschema_dbname.db/testupdatetableschema_tablename
2024-04-24T12:09:42,550  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName	
2024-04-24T12:09:42,561  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:09:42,562  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName newtbl=testupdatetableschema_tablename	
2024-04-24T12:09:42,577  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updating table stats for testupdatetableschema_tablename
2024-04-24T12:09:42,577  INFO [TThreadPoolServer WorkerProcess-%d] utils.MetaStoreServerUtils: Updated size of table testupdatetableschema_tablename to 0
2024-04-24T12:09:42,606  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName	
2024-04-24T12:09:42,611  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:09:42,612  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testUpdateTableSchema_DBName	
2024-04-24T12:09:42,614  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:42,614  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:42,618  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:42,621  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testUpdateTableSchema_DBName tbls=testupdatetableschema_tablename	
2024-04-24T12:09:42,626  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:42,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:42,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:42,637  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:42,643  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:42,693  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:42,695  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:42,736 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:44,737  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:44,740  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:44,741  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:44,743  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:44,743  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:44,744  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:44,746  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:44,749 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:46,750  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:46,753  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:46,754  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:46,756  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:46,757  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:46,758  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:46,763  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:46,768 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:48,769  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:48,773  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:48,774  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:48,775  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:48,776  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:48,777  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:48,779  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:48,782 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:50,783  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:50,786  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:50,788  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:50,792  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:50,795  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:50,798  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:50,807  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:50,816 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:52,817  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:52,821  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:52,821  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:52,822  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:52,823  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:52,824  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:52,826  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:52,829 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:54,830  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:54,833  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:54,835  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:54,839  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:54,842  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:54,844  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:54,853  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:54,860 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:56,860  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:56,863  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:56,864  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:56,865  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:56,866  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:56,867  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:56,869  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:56,873 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:09:58,874  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:58,877  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:09:58,877  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:09:58,878  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:09:58,879  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:09:58,880  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:09:58,883  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:09:58,886 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:00,887  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:00,890  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:00,892  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:00,893  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:00,894  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:00,895  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:00,897  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:00,900 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:02,901  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:02,904  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:02,905  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:02,906  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:02,907  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:02,908  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:02,910  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:02,915 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:02,916  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testUpdateTableSchema(TestHCatClient.java:555) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:10:03,919  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:10:03,920  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:10:03,920  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 6
2024-04-24T12:10:03,923  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testUpdateTableSchema_DBName	
2024-04-24T12:10:03,925  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:10:03,927  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e195a22, with PersistenceManager: null will be shutdown
2024-04-24T12:10:03,928  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e195a22, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@529404a8 created in the thread with id: 221
2024-04-24T12:10:03,941  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e195a22 from thread id: 221
2024-04-24T12:10:03,944  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:03,944  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:03,949  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:03,955  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testUpdateTableSchema_DBName tbls=testupdatetableschema_tablename	
2024-04-24T12:10:03,958  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:03,958  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:03,959  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:03,960  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:03,961  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:03,962  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:03,964  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:03,968 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:05,969  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:05,971  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:05,973  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:05,974  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:05,975  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:05,975  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:05,977  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:05,980 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:07,981  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:07,983  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:07,985  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:07,986  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:07,986  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:07,987  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:07,989  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:07,992 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:09,993  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:09,995  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:09,996  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:09,998  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:09,999  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:10,000  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:10,002  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:10,004 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:12,005  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:12,008  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:12,008  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:12,010  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:12,011  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:12,012  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:12,013  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:12,017 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:14,018  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:14,020  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:14,021  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:14,022  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:14,023  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:14,024  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:14,025  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:14,028 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:16,029  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:16,031  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:16,032  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:16,034  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:16,035  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:16,036  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:16,038  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:16,040 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:18,041  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:18,044  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:18,045  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:18,046  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:18,046  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:18,047  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:18,049  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:18,051 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:20,052  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:20,054  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:20,055  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:20,056  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:20,057  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:20,057  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:20,059  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:20,063 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:22,063  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:22,065  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:22,067  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:22,069  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:22,070  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:22,070  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:22,072  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:22,074 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:24,075  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:24,077  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2024-04-24T12:10:24,078  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2024-04-24T12:10:24,080  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:24,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:24,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:24,083  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2024-04-24T12:10:24,085 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:24,086 ERROR [main] api.TestHCatClient: Unexpected exception.
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : MetaException while dropping db.. Cause : MetaException(message:javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:164) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testUpdateTableSchema(TestHCatClient.java:555) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (31).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) ~[classes/:?]
	... 42 more
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:10:24,134  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:10:24,134  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:10:24,136  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.metastore.client.cache.enabled=true, hive.query.results.cache.enabled=false, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2024-04-24T12:10:24,137  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:10:24,140  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testGetMessageBusTopicName_DBName	
2024-04-24T12:10:24,141  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testGetMessageBusTopicName_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2024-04-24T12:10:24,142  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Creating database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db
2024-04-24T12:10:24,142  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db
2024-04-24T12:10:24,145  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created database path in external directory pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db
2024-04-24T12:10:24,148  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2024-04-24T12:10:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:10:24,204  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:10:24,205  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:10:24,206  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testGetMessageBusTopicName_TableName, dbName:testGetMessageBusTopicName_DBName, owner:alex, createTime:1713985824, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{hcat.msgbus.topic.name=MY.topic.name, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T12:10:24,209  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db/testgetmessagebustopicname_tablename
2024-04-24T12:10:24,222  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testGetMessageBusTopicName_DBName.testGetMessageBusTopicName_TableName	
2024-04-24T12:10:24,230  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T12:10:24,230  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testGetMessageBusTopicName_DBName	
2024-04-24T12:10:24,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:24,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:24,233  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:24,235  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testGetMessageBusTopicName_DBName tbls=testgetmessagebustopicname_tablename	
2024-04-24T12:10:24,237  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:24,238  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:24,239  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:24,240  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:24,241  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:24,242  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:24,244  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:24,257 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:26,258  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:26,261  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:26,262  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:26,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:26,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:26,265  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:26,267  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:26,270 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:28,271  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:28,272  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:28,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:28,275  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:28,276  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:28,277  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:28,281  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:28,286 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:30,287  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:30,291  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:30,292  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:30,293  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:30,293  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:30,294  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:30,297  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:30,300 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:32,300  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:32,304  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:32,306  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:32,307  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:32,307  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:32,308  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:32,311  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:32,314 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:34,314  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:34,317  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:34,319  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:34,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:34,321  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:34,322  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:34,324  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:34,327 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:36,328  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:36,329  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:36,329  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:36,331  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:36,332  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:36,333  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:36,335  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:36,339 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:38,339  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:38,342  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:38,344  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:38,348  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:38,351  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:38,353  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:38,362  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:38,372 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:40,374  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:40,378  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:40,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:40,381  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:40,382  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:40,382  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:40,385  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:40,388 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:42,388  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:42,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:42,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:42,393  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:42,394  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:42,395  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:42,397  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:42,400 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:44,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:44,405  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:44,405  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:44,406  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:44,407  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:44,408  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:44,410  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:44,413 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:44,413  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testGetMessageBusTopicName(TestHCatClient.java:652) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:10:45,418  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:10:45,418  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:10:45,419  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 7
2024-04-24T12:10:45,453  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testGetMessageBusTopicName_DBName	
2024-04-24T12:10:45,454  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:10:45,454  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4478b3, with PersistenceManager: null will be shutdown
2024-04-24T12:10:45,454  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4478b3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b698d58 created in the thread with id: 224
2024-04-24T12:10:45,456  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4478b3 from thread id: 224
2024-04-24T12:10:45,457  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:45,457  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:45,458  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:45,459  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testGetMessageBusTopicName_DBName tbls=testgetmessagebustopicname_tablename	
2024-04-24T12:10:45,461  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:45,461  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:45,461  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:45,462  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:45,463  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:45,464  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:45,465  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:45,468 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:47,469  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:47,470  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:47,471  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:47,472  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:47,473  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:47,474  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:47,476  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:47,478 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:49,479  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:49,481  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:49,483  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:49,484  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:49,484  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:49,485  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:49,486  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:49,489 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (32).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:51,490  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:51,492  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2024-04-24T12:10:51,493  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2024-04-24T12:10:51,494  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:51,495  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:51,496  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:51,523  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testgetmessagebustopicname_dbname.testgetmessagebustopicname_tablename	
2024-04-24T12:10:51,612  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2024-04-24T12:10:51,621  WARN [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: File file:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db does not exist; Force to delete it.
2024-04-24T12:10:51,621 ERROR [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Failed to delete pfile:/home/alex/Repositories/hive/hcatalog/webhcat/java-client/target/warehouse/34727/testgetmessagebustopicname_dbname.db
2024-04-24T12:10:51,621  WARN [main] metastore.HiveMetaStoreClient: Unexpected attempt to decrement user count of zero: 0 HCatClient: thread: 1 users=0 expired=false closed=false
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:10:51,668  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:10:51,668  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:10:51,670  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.users.in.admin.role=hive_admin_user, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.mapjoin.max.gc.time.percentage=0.99, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:10:51,671  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:10:51,674  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:10:51,676  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:51,676  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:51,677  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:51,679  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:10:51,680  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:10:51,681  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:51,682  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:10:51,683  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:51,684  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:51,685  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:51,687  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:10:51,699 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:53,700  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:10:53,703  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:53,705  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:10:53,709  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:53,711  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:53,714  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:53,723  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:10:53,734 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:55,735  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:10:55,740  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:55,741  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:10:55,742  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:55,743  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:55,744  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:55,746  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:10:55,750 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:57,750  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:10:57,753  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:57,755  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:10:57,757  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:57,758  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:57,758  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:57,761  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:10:57,764 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:10:59,765  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:10:59,768  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:10:59,769  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:10:59,770  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:10:59,770  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:10:59,771  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:10:59,774  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:10:59,777 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:01,778  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:01,781  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:01,783  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:01,784  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:01,785  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:01,785  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:01,788  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:01,790 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:03,791  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:03,794  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:03,796  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:03,797  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:03,798  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:03,799  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:03,801  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:03,804 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:05,805  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:05,808  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:05,810  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:05,811  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:05,812  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:05,813  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:05,815  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:05,818 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:07,819  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:07,822  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:07,824  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:07,825  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:07,826  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:07,826  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:07,829  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:07,832 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:09,832  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:09,836  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:09,837  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:09,841  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:09,844  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:09,847  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:09,856  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:09,865 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:11,867  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:11,870  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:11,872  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:11,873  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:11,874  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:11,875  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:11,877  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:11,880 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:11,880  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema(TestHCatClient.java:1112) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:11:12,884  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:11:12,884  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:11:12,885  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 8
2024-04-24T12:11:12,887  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:11:12,889  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:11:12,891  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626d9416, with PersistenceManager: null will be shutdown
2024-04-24T12:11:12,891  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626d9416, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10b4c28f created in the thread with id: 227
2024-04-24T12:11:12,897  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626d9416 from thread id: 227
2024-04-24T12:11:12,898  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:12,898  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:12,899  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:12,900  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:11:12,902  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:12,902  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:12,903  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:12,904  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:12,904  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:12,905  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:12,907  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:12,909 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:14,910  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:14,913  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:14,914  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:14,916  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:14,916  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:14,917  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:14,918  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:14,921 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:16,921  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:16,924  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:16,924  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:16,926  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:16,926  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:16,927  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:16,929  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:16,932 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:18,932  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:18,934  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:18,936  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:18,937  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:18,938  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:18,938  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:18,940  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:18,943 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:20,944  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:20,946  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:20,947  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:20,948  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:20,949  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:20,949  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:20,951  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:20,955 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:22,955  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:22,958  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:22,959  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:22,961  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:22,962  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:22,962  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:22,964  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:22,967 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:24,968  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:24,970  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:24,971  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:24,973  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:24,974  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:24,974  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:24,976  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:24,978 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:26,979  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:26,981  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:26,983  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:26,984  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:26,985  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:26,985  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:26,987  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:26,990 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:28,991  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:28,993  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:28,993  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:28,994  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:28,995  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:28,996  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:28,997  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:29,000 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:31,001  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:31,003  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:31,004  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:31,005  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:31,006  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:31,007  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:31,008  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:31,011 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:33,012  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:33,014  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:33,016  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:33,017  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:33,018  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:33,018  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:33,020  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:33,022 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:33,022 ERROR [main] api.TestHCatClient: Unexpected exception! 
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : MetaException while dropping db.. Cause : MetaException(message:javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:164) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema(TestHCatClient.java:1112) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) ~[classes/:?]
	... 42 more
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T12:11:33,071  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T12:11:33,072  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T12:11:33,072  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T12:11:33,072  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T12:11:33,072  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T12:11:33,072  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T12:11:33,073  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.fetch.task.conversion=minimal, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.mapjoin.max.gc.time.percentage=0.99, hive.in.test=true, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.exec.submit.local.task.via.child=false, hive.metastore.schema.verification=false, hive.conf.restricted.list=from.hivemetastore-site.xml}
2024-04-24T12:11:33,074  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T12:11:33,075  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:11:33,076  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:33,076  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:33,077  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:33,078  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:11:33,080  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:33,080  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:33,080  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:33,081  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:33,082  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:33,083  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:33,084  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:33,087 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:35,088  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:35,090  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:35,091  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:35,093  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:35,094  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:35,095  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:35,096  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:35,099 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:37,100  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:37,102  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:37,104  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:37,105  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:37,106  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:37,106  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:37,108  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:37,110 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:38,594  INFO [HiveClientCache-cleaner-0] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 7
2024-04-24T12:11:38,594  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:11:38,594  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@33e5c388, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36bd308c will be shutdown
2024-04-24T12:11:38,595  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:11:38,595  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:11:39,111  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:39,113  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:39,115  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:39,118  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:39,120  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:39,123  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:39,129  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:39,138 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:41,139  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:41,141  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:41,143  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:41,144  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:41,144  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:41,145  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:41,146  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:41,149 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:43,149  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:43,152  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:43,153  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:43,157  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:43,158  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:43,158  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:43,160  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:43,163 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:45,163  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:45,166  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:45,167  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:45,171  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:45,173  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:45,175  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:45,181  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:45,184 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:47,185  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:47,187  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:47,189  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:47,192  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:47,194  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:47,197  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:47,203  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:47,212 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:49,213  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:49,215  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:49,217  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:49,219  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:49,220  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:49,220  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:49,222  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:49,225 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:51,226  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:51,228  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:51,229  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:51,231  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:51,231  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:51,232  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:51,233  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:51,236 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:53,237  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:53,239  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:53,241  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:53,242  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:53,243  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:53,243  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:53,245  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:53,248 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:53,248  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. dropDatabase
org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) [classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) [?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) [classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema(TestHCatClient.java:668) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T12:11:54,252  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as alex (auth:SIMPLE)
2024-04-24T12:11:54,252  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:34727)
2024-04-24T12:11:54,253  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:34727) current connections: 8
2024-04-24T12:11:54,256  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2024-04-24T12:11:54,258  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T12:11:54,259  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176cf525, with PersistenceManager: null will be shutdown
2024-04-24T12:11:54,259  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176cf525, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f41484e created in the thread with id: 228
2024-04-24T12:11:54,262  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176cf525 from thread id: 228
2024-04-24T12:11:54,263  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:54,264  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:54,265  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:54,267  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2024-04-24T12:11:54,269  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:54,270  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:54,271  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:54,272  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:54,272  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:54,273  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:54,275  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:54,278 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:56,279  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:56,281  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:56,282  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:56,285  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:56,285  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:56,286  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:56,288  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:56,291 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:11:58,292  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:11:58,294  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:11:58,295  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:11:58,299  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:11:58,301  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:11:58,303  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:11:58,309  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:11:58,319 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:00,320  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:00,322  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:00,324  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:00,327  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:00,330  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:00,332  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:00,338  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:00,348 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:02,350  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:02,352  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:02,353  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:02,354  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:02,354  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:02,355  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:02,358  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:02,361 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:04,362  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:04,364  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:04,365  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:04,368  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:04,368  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:04,369  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:04,370  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:04,374 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:06,374  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:06,376  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:06,378  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:06,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:06,380  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:06,381  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:06,383  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:06,385 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:07,626  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:12:07,626  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:12:07,626  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1e195a22, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@529404a8 will be shutdown
2024-04-24T12:12:07,626  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3b1b744d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9139719 will be shutdown
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e4478b3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3b698d58 will be shutdown
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@626d9416, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10b4c28f will be shutdown
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:12:07,627  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:12:08,386  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:08,388  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:08,390  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:08,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:08,392  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:08,393  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:08,394  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:08,397 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:10,398  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:10,400  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:10,401  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:10,403  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:10,403  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:10,404  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:10,406  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:10,409 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:12,410  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:12,412  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:12,414  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:12,416  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:12,417  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:12,417  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:12,419  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:12,422 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:14,423  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: @hive#myDb	
2024-04-24T12:12:14,425  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2024-04-24T12:12:14,426  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2024-04-24T12:12:14,427  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2024-04-24T12:12:14,428  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2024-04-24T12:12:14,428  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2024-04-24T12:12:14,430  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2024-04-24T12:12:14,432 ERROR [TThreadPoolServer WorkerProcess-%d] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:542)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2081)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:675)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:643)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:729)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:95)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:528)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:222)
	at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4068)
	at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:448)
	at org.datanucleus.ExecutionContextImpl.flush(ExecutionContextImpl.java:4009)
	at org.datanucleus.ExecutionContextThreadedImpl.flush(ExecutionContextThreadedImpl.java:434)
	at org.datanucleus.api.jdo.JDOPersistenceManager.flush(JDOPersistenceManager.java:2064)
	at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:11639)
	at sun.reflect.GeneratedMethodAccessor68.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy32.addNotificationEvent(Unknown Source)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.process(DbNotificationListener.java:1403)
	at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropDatabase(DbNotificationListener.java:513)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier$26.notify(MetaStoreListenerNotifier.java:99)
	at org.apache.hadoop.hive.metastore.MetaStoreListenerNotifier.notifyEvent(MetaStoreListenerNotifier.java:339)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database_core(HMSHandler.java:1785)
	at org.apache.hadoop.hive.metastore.HMSHandler.drop_database(HMSHandler.java:1869)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy34.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18285)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_database.getResult(ThriftHiveMetastore.java:18264)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:248)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 47 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 49 more

2024-04-24T12:12:14,433 ERROR [main] api.TestHCatClient: Unexpected exception!
org.apache.hive.hcatalog.common.HCatException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : MetaException while dropping db.. Cause : MetaException(message:javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:164) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSchema(TestHCatClient.java:668) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) [junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) [junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:128) [junit-4.13.jar:4.13]
	at org.junit.runners.Suite.runChild(Suite.java:27) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) [junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) [junit-4.13.jar:4.13]
	at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeEager(JUnitCoreWrapper.java:107) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:83) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) [surefire-junit47-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.MetaException: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
NestedThrowables:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (22).  The statement has been rolled back.
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54495) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result$drop_database_resultStandardScheme.read(ThriftHiveMetastore.java:54463) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$drop_database_result.read(ThriftHiveMetastore.java:54397) ~[classes/:?]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[libthrift-0.14.1.jar:0.14.1]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_drop_database(ThriftHiveMetastore.java:1404) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.drop_database(ThriftHiveMetastore.java:1389) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabaseCascadePerDb(HiveMetaStoreClient.java:1601) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1532) ~[classes/:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:1485) ~[classes/:?]
	at sun.reflect.GeneratedMethodAccessor358.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[classes/:?]
	at com.sun.proxy.$Proxy35.dropDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.dropDatabase(HCatClientHMSImpl.java:154) ~[classes/:?]
	... 42 more
2024-04-24T12:12:14,435  INFO [main] api.TestHCatClient: Shutting down metastore.
2024-04-24T12:12:14,508  INFO [pool-3-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 7
2024-04-24T12:12:14,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T12:12:14,508  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176cf525, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7f41484e will be shutdown
2024-04-24T12:12:14,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T12:12:14,508  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
