<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="20.378" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter591848353506045806.jar /home/alex/Repositories/hive/service/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire3741479552068138343tmp surefire_32308715887151430347615tmp"/>
    <property name="nondexExecid" value="clean_zsvPawAEPs4VM393aDedovVOETFCNp1HyCdR5bCgo="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="line.separator" value="&#10;"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/service/.nondex"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="nondexJarDir" value=".nondex"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="nondexStart" value="0"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="clustermode" value=""/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="933178"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter591848353506045806.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="16.304">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,117798 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@7f31245a
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619]...
DEBUG StatusLogger Reconfiguration started for context[name=7f31245a] at URI null (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@4b520ea8
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,026089 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 894922
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T06:45:20.223-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-06:45:22.239, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-06:45:22.240, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@5d908d47 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@157853da...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@157853da OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3a1dd365
TRACE StatusLogger Reregistering context (1/1): '7f31245a' org.apache.logging.log4j.core.LoggerContext@3de8f619
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=7f31245a,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=7f31245a] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3de8f619) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=7f31245a, org.apache.logging.log4j.core.LoggerContext@3de8f619] started OK.
2024-04-24T06:45:22,355  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T06:45:22,899  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T06:45:22,994  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T06:45:22,994  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T06:45:22,995  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T06:45:22,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T06:45:22,995  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T06:45:22,995  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T06:45:22,996  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T06:45:22,997  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T06:45:22,997  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T06:45:22,997  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T06:45:22,997  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T06:45:22,998  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 70ca60d3-089c-42fd-9e56-968be565452b
2024-04-24T06:45:23,044  INFO [main] SessionState: Hive Session ID = 70ca60d3-089c-42fd-9e56-968be565452b
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:23,059  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:23,450  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/70ca60d3-089c-42fd-9e56-968be565452b
2024-04-24T06:45:23,454  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/70ca60d3-089c-42fd-9e56-968be565452b
2024-04-24T06:45:23,458  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/70ca60d3-089c-42fd-9e56-968be565452b/_tmp_space.db
2024-04-24T06:45:23,485  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=70ca60d3-089c-42fd-9e56-968be565452b, clientType=HIVESERVER2]
2024-04-24T06:45:23,558  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:23,869  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:23,920  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:23,933  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T06:45:23,933  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T06:45:23,971  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T06:45:23,977  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T06:45:24,884  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T06:45:24,887  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T06:45:25,628  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T06:45:25,628  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: null will be shutdown
2024-04-24T06:45:25,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f created in the thread with id: 1
2024-04-24T06:45:28,796  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T06:45:28,797  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T06:45:28,797  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64 from thread id: 1
2024-04-24T06:45:28,958  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T06:45:28,996  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T06:45:29,035  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T06:45:29,037  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T06:45:29,158  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T06:45:29,166  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T06:45:29,167  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T06:45:29,171  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T06:45:29,202  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T06:45:29,207  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T06:45:29,209  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T06:45:29,210  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T06:45:29,212  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T06:45:29,214  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T06:45:29,217  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T06:45:29,217  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T06:45:29,227  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T06:45:29,229  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T06:45:29,231  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T06:45:29,238  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:29,419  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:30,048  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,054  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,058  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,059  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,059  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,061  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,061  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T06:45:30,115  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T06:45:30,117  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T06:45:30,117  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T06:45:30,117  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T06:45:30,119  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T06:45:30,122  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-04-24T06:45:30,129  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-04-24T06:45:30,143  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T06:45:30,144  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T06:45:30,144  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T06:45:30,144  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T06:45:30,145  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T06:45:30,146  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T06:45:30,169  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T06:45:30,174  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:30,181  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:30,194  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:30,198  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:30,202  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37fab798-d478-4cac-9295-262702b26ae6/_tmp_space.db
2024-04-24T06:45:30,206  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T06:45:30,207  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T06:45:30,208  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:30,209  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:30,211  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4f89331f will be shutdown
2024-04-24T06:45:30,212  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f68a7f8 created in the thread with id: 1
2024-04-24T06:45:30,235  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:30,235  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:30,237  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T06:45:30,298  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:30,298  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd9aa64, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3f68a7f8 will be shutdown
2024-04-24T06:45:30,298  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:30,298  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T06:45:30,300  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:30,302  INFO [main] service.CompositeService: Session opened, SessionHandle [37fab798-d478-4cac-9295-262702b26ae6], current sessions:1
2024-04-24T06:45:30,308  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T06:45:30,314  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:30,335  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6257cf43-d53d-4d2a-9ba8-0acb34480a9d] SessionHandle [37fab798-d478-4cac-9295-262702b26ae6]
2024-04-24T06:45:30,340  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f.test
2024-04-24T06:45:30,355  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f, startTime=1713966330331, sessionId=37fab798-d478-4cac-9295-262702b26ae6, createTime=1713966330178, userName=anonymous, ipAddress=null]
2024-04-24T06:45:30,424  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Compiling command(queryId=alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:31,261  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:31,264  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: null will be shutdown
2024-04-24T06:45:31,264  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4466cf5d created in the thread with id: 1
2024-04-24T06:45:31,274  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb from thread id: 1
2024-04-24T06:45:31,493  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] reflections.Reflections: Reflections took 181 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T06:45:31,644  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] reflections.Reflections: Reflections took 108 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T06:45:31,784  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] reflections.Reflections: Reflections took 130 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T06:45:31,887  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
2024-04-24T06:45:31,891  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:31,891  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=37fab798-d478-4cac-9295-262702b26ae6, clientType=HIVESERVER2]
2024-04-24T06:45:31,895  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:31,896  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:31,896  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:31,902  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:31,918  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:33,368  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:34,051  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:34,057  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:34,073  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:34,073  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:34,129  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-30_388_7398215928544237111-1
2024-04-24T06:45:34,189  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:34,294  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:34,325  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:34,418  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:34,427  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:34,431  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:34,431  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
2024-04-24T06:45:34,431  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:34,434  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:34,448  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:34,457  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:34,457  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=100, flushCache_()=15, getAllFunctions_()=60}
2024-04-24T06:45:34,458  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed compiling command(queryId=alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f); Time taken: 4.036 seconds
2024-04-24T06:45:34,459  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:34,462  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T06:45:34,471  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:34,476  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Executing command(queryId=alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:34,479  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T06:45:34,479  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:34,480  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001
2024-04-24T06:45:34,480  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001
2024-04-24T06:45:34,484  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
2024-04-24T06:45:34,485  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Query ID = alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
Total jobs = 1
2024-04-24T06:45:34,485  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:34,485  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:34,494  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:34,495  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:34,506  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:34,512  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:34,512  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/dummy_path
2024-04-24T06:45:34,616  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:34,648  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T06:45:34,817  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T06:45:34,834  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T06:45:34,853  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T06:45:34,853  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T06:45:34,877  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:34,933  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:34,943  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:34,947  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:34,949  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-24T06:45:34,961  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/dummy_path
2024-04-24T06:45:35,022  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:35,053  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:35,055  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:35,093  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:35,160  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local573247914_0001
2024-04-24T06:45:35,160  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:35,401  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T06:45:35,403  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:35,404  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:35,405  INFO [Thread-61] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:35,424  INFO [Thread-61] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:35,429  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local573247914_0001_m_000000_0
2024-04-24T06:45:35,490  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:35,503  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:35,517  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:35,551  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T06:45:35,560  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:35,569  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:35,571  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:35,574  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:35,575  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:35,579  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:35,580  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:35,581  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@5685ffe4, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@14fd2eb0, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@43ca59a5
2024-04-24T06:45:35,590  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-30_388_7398215928544237111-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:35,590  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-30_388_7398215928544237111-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:35,590  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-30_388_7398215928544237111-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:35,628  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:35,628  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T06:45:35,628  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:35,628  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T06:45:35,628  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:35,629  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:35,631  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-24T06:45:35,635  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T06:45:35,647  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local573247914_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T06:45:35,648  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T06:45:35,648  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local573247914_0001_m_000000_0' done.
2024-04-24T06:45:35,665  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local573247914_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5586
		FILE: Number of bytes written=1152370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=910163968
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T06:45:35,665  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local573247914_0001_m_000000_0
2024-04-24T06:45:35,666  INFO [Thread-61] mapred.LocalJobRunner: map task executor complete.
2024-04-24 06:45:36,422 Stage-1 map = 100%,  reduce = 0%
2024-04-24T06:45:36,423  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Task: 2024-04-24 06:45:36,422 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local573247914_0001
2024-04-24T06:45:36,429  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.Task: Ended Job = job_local573247914_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:36,445  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T06:45:36,445  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:36,445  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001
2024-04-24T06:45:36,445  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1/-mr-10001
2024-04-24T06:45:36,446  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:36,446  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:36,446  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T06:45:36,456  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:36,457  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:36,457  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed executing command(queryId=alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f); Time taken: 1.97 seconds
2024-04-24T06:45:36,457  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:36,463  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,464  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b64d71ca-6c7f-4440-8b10-aa0292f74025] SessionHandle [37fab798-d478-4cac-9295-262702b26ae6]
2024-04-24T06:45:36,465  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917.test
2024-04-24T06:45:36,471  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917, startTime=1713966336463, sessionId=37fab798-d478-4cac-9295-262702b26ae6, createTime=1713966330178, userName=anonymous, ipAddress=null]
2024-04-24T06:45:36,473  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Compiling command(queryId=alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,476  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
2024-04-24T06:45:36,476  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:36,477  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:36,477  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,477  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,477  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,477  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:36,493  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,609  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,610  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,613  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,613  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,614  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1
2024-04-24T06:45:36,621  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:36,624  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:36,626  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:36,642  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
2024-04-24T06:45:36,643  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:36,644  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:36,645  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:36,645  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:36,645  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=4, flushCache_()=0}
2024-04-24T06:45:36,645  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed compiling command(queryId=alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917); Time taken: 0.172 seconds
2024-04-24T06:45:36,646  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:36,647  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,648  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Thread context registration is done.
2024-04-24T06:45:36,649  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=242c487b-3519-4e18-9e4a-b89c89bb597d] SessionHandle [37fab798-d478-4cac-9295-262702b26ae6]
2024-04-24T06:45:36,649  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:36,649  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c.test
2024-04-24T06:45:36,653  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c, startTime=1713966336647, sessionId=37fab798-d478-4cac-9295-262702b26ae6, createTime=1713966330178, userName=anonymous, ipAddress=null]
2024-04-24T06:45:36,654  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:36,654  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,654  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T06:45:36,655  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: type: QUERY
2024-04-24T06:45:36,655  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Compiling command(queryId=alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:36,655  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001
2024-04-24T06:45:36,655  INFO [HiveServer2-Background-Pool: Thread-121] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001
2024-04-24T06:45:36,656  WARN [HiveServer2-Background-Pool: Thread-121] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
2024-04-24T06:45:36,656  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Query ID = alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
Total jobs = 1
2024-04-24T06:45:36,656  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:36,656  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:36,657  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
2024-04-24T06:45:36,657  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:36,658  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:36,658  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,658  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,658  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,658  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:36,660  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:36,660  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:36,670  INFO [HiveServer2-Background-Pool: Thread-121] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:36,671  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:36,671  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/dummy_path
2024-04-24T06:45:36,681  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,687  INFO [HiveServer2-Background-Pool: Thread-121] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:36,691  INFO [HiveServer2-Background-Pool: Thread-121] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:36,692  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:36,699  WARN [HiveServer2-Background-Pool: Thread-121] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:36,711  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:36,717  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:36,718  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:36,719  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/dummy_path
2024-04-24T06:45:36,728  INFO [HiveServer2-Background-Pool: Thread-121] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:36,729  INFO [HiveServer2-Background-Pool: Thread-121] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:36,729  INFO [HiveServer2-Background-Pool: Thread-121] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:36,773  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:36,784  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,784  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,787  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,788  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,790  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1
2024-04-24T06:45:36,801  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:36,805  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:36,806  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:36,817  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Submitting tokens for job: job_local152228108_0002
2024-04-24T06:45:36,817  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:36,824  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:36,824  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:36,824  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:36,825  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:36,826  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:36,827  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:36,827  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, flushCache_()=0}
2024-04-24T06:45:36,827  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed compiling command(queryId=alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c); Time taken: 0.172 seconds
2024-04-24T06:45:36,835  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:36,835  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,836  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=54f887e0-3b1d-4901-bccc-5851ea0eece4] SessionHandle [37fab798-d478-4cac-9295-262702b26ae6]
2024-04-24T06:45:36,837  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
2024-04-24T06:45:36,844  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0.test
2024-04-24T06:45:36,846  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0, startTime=1713966336835, sessionId=37fab798-d478-4cac-9295-262702b26ae6, createTime=1713966330178, userName=anonymous, ipAddress=null]
2024-04-24T06:45:36,847  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:36,850  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Compiling command(queryId=alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,852  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,855  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:36,855  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:36,856  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:36,857  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T06:45:36,857  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:36,857  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001
2024-04-24T06:45:36,857  INFO [HiveServer2-Background-Pool: Thread-156] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001
2024-04-24T06:45:36,857  WARN [HiveServer2-Background-Pool: Thread-156] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
2024-04-24T06:45:36,858  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Query ID = alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
Total jobs = 1
2024-04-24T06:45:36,858  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:36,858  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:36,865  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:36,865  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:36,878  INFO [HiveServer2-Background-Pool: Thread-156] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:36,879  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:36,879  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/dummy_path
2024-04-24T06:45:36,879  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,893  INFO [HiveServer2-Background-Pool: Thread-156] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:36,897  INFO [HiveServer2-Background-Pool: Thread-156] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T06:45:36,898  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:36,906  WARN [HiveServer2-Background-Pool: Thread-156] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:36,916  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:36,924  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:36,925  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:36,926  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/dummy_path
2024-04-24T06:45:36,935  INFO [HiveServer2-Background-Pool: Thread-156] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:36,935  INFO [HiveServer2-Background-Pool: Thread-156] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:36,936  INFO [HiveServer2-Background-Pool: Thread-156] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:36,961  INFO [HiveServer2-Background-Pool: Thread-121] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T06:45:36,962  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:36,963  INFO [Thread-113] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T06:45:36,975  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:36,976  INFO [Thread-113] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:36,976  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local152228108_0002_m_000000_0
2024-04-24T06:45:36,978  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:36,978  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:36,978  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:36,979  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:36,980  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:36,981  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:36,981  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:36,982  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:36,982  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1
2024-04-24T06:45:36,983  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:36,983  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:36,984  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:36,984  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:36,985  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:36,985  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:36,985  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:36,986  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:36,986  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@1be5d5e0, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@17dc9c60, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@63e36a0e
2024-04-24T06:45:36,991  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:36,995  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:36,996  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:37,008  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Submitting tokens for job: job_local1224613765_0003
2024-04-24T06:45:37,008  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:37,011  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:37,012  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:37,013  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:37,013  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:37,013  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=6}
2024-04-24T06:45:37,013  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed compiling command(queryId=alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0); Time taken: 0.163 seconds
2024-04-24T06:45:37,014  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:37,014  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Thread context registration is done.
2024-04-24T06:45:37,014  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:37,014  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:37,015  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:37,015  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:37,015  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84c97db5-d99f-4e16-80d1-96f28e396d36] SessionHandle [37fab798-d478-4cac-9295-262702b26ae6]
2024-04-24T06:45:37,016  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Thread context registration is done.
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:37,016  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82.test
2024-04-24T06:45:37,022  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82, startTime=1713966337014, sessionId=37fab798-d478-4cac-9295-262702b26ae6, createTime=1713966330178, userName=anonymous, ipAddress=null]
PREHOOK: type: QUERY
2024-04-24T06:45:37,022  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:37,022  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001
2024-04-24T06:45:37,022  INFO [HiveServer2-Background-Pool: Thread-196] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001
2024-04-24T06:45:37,024  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Compiling command(queryId=alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:37,024  WARN [HiveServer2-Background-Pool: Thread-196] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
2024-04-24T06:45:37,024  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Query ID = alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
Total jobs = 1
2024-04-24T06:45:37,024  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:37,024  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:37,025  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:37,026  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:37,027  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:37,028  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:37,035  INFO [HiveServer2-Background-Pool: Thread-196] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:37,036  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:37,036  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/dummy_path
2024-04-24T06:45:37,042  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:37,049  INFO [HiveServer2-Background-Pool: Thread-196] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:37,051  INFO [HiveServer2-Background-Pool: Thread-196] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:37,053  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:37,059  WARN [HiveServer2-Background-Pool: Thread-196] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:37,068  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:37,074  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:37,074  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:37,075  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/dummy_path
2024-04-24T06:45:37,082  INFO [HiveServer2-Background-Pool: Thread-196] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:37,082  INFO [HiveServer2-Background-Pool: Thread-196] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:37,082  INFO [HiveServer2-Background-Pool: Thread-196] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:37,110  INFO [HiveServer2-Background-Pool: Thread-156] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T06:45:37,112  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:37,112  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:37,112  INFO [Thread-150] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:37,116  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:37,116  INFO [Thread-150] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:37,116  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1224613765_0003_m_000000_0
2024-04-24T06:45:37,117  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:37,118  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:37,119  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:37,125  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T06:45:37,126  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:37,127  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:37,128  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:37,128  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:37,129  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:37,129  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:37,129  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:37,130  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@202012a7, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@114d725f, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@58202ca1
2024-04-24T06:45:37,139  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:37,139  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:37,142  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:37,142  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:37,144  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1
2024-04-24T06:45:37,150  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Submitting tokens for job: job_local90371843_0004
2024-04-24T06:45:37,150  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:37,153  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:37,156  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:37,157  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:37,173  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:37,174  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:37,175  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:37,175  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
2024-04-24T06:45:37,175  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:37,175  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:37,176  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:37,176  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:37,176  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-04-24T06:45:37,177  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Completed compiling command(queryId=alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82); Time taken: 0.153 seconds
2024-04-24T06:45:37,177  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:37,177  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Thread context registration is done.
2024-04-24T06:45:37,177  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:37,178  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:37,179  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T06:45:37,179  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T06:45:37,179  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:37,179  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001
2024-04-24T06:45:37,179  INFO [HiveServer2-Background-Pool: Thread-236] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001
2024-04-24T06:45:37,180  WARN [HiveServer2-Background-Pool: Thread-236] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
2024-04-24T06:45:37,180  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Query ID = alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
Total jobs = 1
2024-04-24T06:45:37,180  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:37,180  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:37,183  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:37,183  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:37,191  INFO [HiveServer2-Background-Pool: Thread-236] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:37,191  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:37,191  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/dummy_path
2024-04-24T06:45:37,204  INFO [HiveServer2-Background-Pool: Thread-236] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:37,206  INFO [HiveServer2-Background-Pool: Thread-236] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:37,206  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:37,211  WARN [HiveServer2-Background-Pool: Thread-236] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:37,219  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:37,225  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:37,226  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:37,227  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/dummy_path
2024-04-24T06:45:37,245  INFO [HiveServer2-Background-Pool: Thread-236] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:37,248  INFO [HiveServer2-Background-Pool: Thread-236] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:37,248  INFO [HiveServer2-Background-Pool: Thread-236] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:37,272  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:37,286  INFO [HiveServer2-Background-Pool: Thread-196] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T06:45:37,286  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T06:45:37,286  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:37,287  INFO [Thread-187] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:37,289  INFO [Thread-187] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:37,289  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local90371843_0004_m_000000_0
2024-04-24T06:45:37,290  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:37,291  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:37,292  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:37,294  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:37,294  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:37,294  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:37,295  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:37,296  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:37,296  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:37,296  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:37,296  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:37,297  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@7c9b247d, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@451ec17, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@2d3375a4
2024-04-24T06:45:37,303  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Submitting tokens for job: job_local2139312147_0005
2024-04-24T06:45:37,303  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:37,388  INFO [HiveServer2-Background-Pool: Thread-236] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T06:45:37,388  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T06:45:37,388  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:37,388  INFO [Thread-218] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:37,390  INFO [Thread-218] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:37,390  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2139312147_0005_m_000000_0
2024-04-24T06:45:37,391  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:37,392  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:37,392  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:37,394  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:37,394  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:37,395  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:37,395  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:37,396  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:37,396  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:37,396  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:37,396  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:37,397  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@29343ea5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@5944581b, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@51fc0941
2024-04-24T06:45:37,705  INFO [main] service.CompositeService: Session closed, SessionHandle [37fab798-d478-4cac-9295-262702b26ae6], current sessions:0
2024-04-24T06:45:37,705  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=54f887e0-3b1d-4901-bccc-5851ea0eece4]
2024-04-24T06:45:37,705  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Removed queryId: alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=54f887e0-3b1d-4901-bccc-5851ea0eece4] with tag: null
2024-04-24T06:45:37,706  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0
2024-04-24T06:45:37,707  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T06:45:37,708  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-4
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T06:45:37,708  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T06:45:37,709  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_tmp.-ext-10002/000000_0
2024-04-24 06:45:37,708 Stage-1 map = 0%,  reduce = 0%2024-04-24T06:45:37,708  WARN [Thread-187] mapred.LocalJobRunner: job_local90371843_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]

2024-04-24T06:45:37,709  INFO [HiveServer2-Background-Pool: Thread-196] exec.Task: 2024-04-24 06:45:37,708 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:37,709  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,709  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,709  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-4 operation was queued
2024-04-24T06:45:37,709  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T06:45:37,710  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1
2024-04-24T06:45:37,710  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1 operation was queued
Ended Job = job_local90371843_0004 with errors
2024-04-24T06:45:37,710 ERROR [HiveServer2-Background-Pool: Thread-196] exec.Task: Ended Job = job_local90371843_0004 with errors
2024-04-24T06:45:37,710  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:37,711  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:37,711  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-4
2024-04-24T06:45:37,711  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0 without delay
2024-04-24T06:45:37,711  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1
2024-04-24T06:45:37,712  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b64d71ca-6c7f-4440-8b10-aa0292f74025]
2024-04-24T06:45:37,712  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Removed queryId: alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=b64d71ca-6c7f-4440-8b10-aa0292f74025] with tag: null
2024-04-24T06:45:37,712  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917
2024-04-24T06:45:37,713  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Shutting down task : Stage-1:MAPRED
Error during job, obtaining debugging information...
2024-04-24T06:45:37,713 ERROR [Thread-223] exec.Task: Error during job, obtaining debugging information...
2024-04-24T06:45:37,714  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 06:45:37,714 Stage-1 map = 0%,  reduce = 0%2024-04-24T06:45:37,714  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-2

2024-04-24T06:45:37,714  INFO [HiveServer2-Background-Pool: Thread-121] exec.Task: 2024-04-24 06:45:37,714 Stage-1 map = 0%,  reduce = 0%
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T06:45:37,715  WARN [Thread-113] mapred.LocalJobRunner: job_local152228108_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T06:45:37,715  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,715  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,715  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,716  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-2 operation was queued
2024-04-24T06:45:37,717  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1
2024-04-24T06:45:37,717  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1 operation was queued
2024-04-24T06:45:37,717  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:37,717  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:37,718  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917 without delay
2024-04-24T06:45:37,718  INFO [HiveServer2-Background-Pool: Thread-196] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-04-24T06:45:37,718  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6257cf43-d53d-4d2a-9ba8-0acb34480a9d]
2024-04-24T06:45:37,718  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1
2024-04-24T06:45:37,718  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Removed queryId: alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6257cf43-d53d-4d2a-9ba8-0acb34480a9d] with tag: null
FAILED: Operation cancelled
2024-04-24T06:45:37,719 ERROR [HiveServer2-Background-Pool: Thread-196] ql.Driver: FAILED: Operation cancelled
2024-04-24T06:45:37,719  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1
2024-04-24T06:45:37,719  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1 operation was queued
2024-04-24T06:45:37,719  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:37,719  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:37,719  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:37,719  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f without delay
2024-04-24T06:45:37,719  INFO [HiveServer2-Background-Pool: Thread-196] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:37,720  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=242c487b-3519-4e18-9e4a-b89c89bb597d]
2024-04-24T06:45:37,720  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T06:45:37,720  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Removed queryId: alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=242c487b-3519-4e18-9e4a-b89c89bb597d] with tag: null
2024-04-24T06:45:37,720  WARN [HiveServer2-Background-Pool: Thread-196] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T06:45:37,720  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c
2024-04-24T06:45:37,720  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:37,724  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T06:45:37,725  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-30_388_7398215928544237111-1
2024-04-24T06:45:37,724  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 06:45:37,724 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:37,726  INFO [HiveServer2-Background-Pool: Thread-156] exec.Task: 2024-04-24 06:45:37,724 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:37,724  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-2
2024-04-24T06:45:37,724  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:37,726  INFO [HiveServer2-Background-Pool: Thread-196] ql.Driver: Executing command(queryId=alex_20240424064536_e91ca1d5-a7aa-460a-9834-6cb51c10a4d0) has been interrupted after 0.704 seconds
2024-04-24T06:45:37,727  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-3
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T06:45:37,728  WARN [Thread-150] mapred.LocalJobRunner: job_local1224613765_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T06:45:37,729  WARN [HiveServer2-Background-Pool: Thread-196] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T06:45:37,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,730  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,730  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-3
2024-04-24T06:45:37,731  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-3 operation was queued
2024-04-24T06:45:37,731  INFO [HiveServer2-Background-Pool: Thread-196] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:37,731  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1
2024-04-24T06:45:37,731  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1 operation was queued
2024-04-24T06:45:37,731  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:37,731  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:37,732  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c without delay
2024-04-24T06:45:37,732  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84c97db5-d99f-4e16-80d1-96f28e396d36]
2024-04-24T06:45:37,732  INFO [EventualCleanupService thread 6] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1
2024-04-24T06:45:37,732  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.OperationManager: Removed queryId: alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=84c97db5-d99f-4e16-80d1-96f28e396d36] with tag: null
2024-04-24T06:45:37,733  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 06:45:37,733 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:37,733  INFO [HiveServer2-Background-Pool: Thread-236] exec.Task: 2024-04-24 06:45:37,733 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:37,733  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82
2024-04-24T06:45:37,736  WARN [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T06:45:37,741  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-5
2024-04-24T06:45:37,741  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,741  WARN [Thread-218] mapred.LocalJobRunner: job_local2139312147_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T06:45:37,741  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,741  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-5 operation was queued
2024-04-24T06:45:37,741  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,741  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1
2024-04-24T06:45:37,741  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1 operation was queued
2024-04-24T06:45:37,741  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:37,742  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:37,742  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82 without delay
2024-04-24T06:45:37,742  INFO [37fab798-d478-4cac-9295-262702b26ae6 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:37,743  INFO [EventualCleanupService thread 8] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1
2024-04-24T06:45:37,743  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-5
2024-04-24T06:45:37,744  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37fab798-d478-4cac-9295-262702b26ae6 operation was queued
2024-04-24T06:45:37,744  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6 operation was queued
2024-04-24T06:45:37,745  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:37,745  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6
2024-04-24T06:45:37,747 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:37,747  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:37,750 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T06:45:37,750 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T06:45:37,752 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:37,751  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T06:45:37,751  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:37,752  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-37_023_2449312266394574174-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_023_2449312266394574174-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,753  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,754  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_655_656200046401108368-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_655_656200046401108368-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,755  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:37,755  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T06:45:37,756  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,756  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,756  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_472_2827400760241015406-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_472_2827400760241015406-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,758  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:37,758  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:37,758  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:37,758  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:37,759  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:37,759  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T06:45:37,759  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,760  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:37,760  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/37fab798-d478-4cac-9295-262702b26ae6/hive_2024-04-24_06-45-36_849_6364085706963098541-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-36_849_6364085706963098541-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:37,760  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:37,760  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@677349fb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4466cf5d will be shutdown
2024-04-24T06:45:37,760  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:37,760  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="1.901">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T06:45:37,782  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-24T06:45:37,782  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-24T06:45:37,782  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-24T06:45:37,782  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:0, 
2024-04-24T06:45:37,840  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T06:45:37,840  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T06:45:37,840  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T06:45:37,841  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T06:45:37,842  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 0875acb0-4baa-47e6-95a7-80eba94333a0
2024-04-24T06:45:37,842  INFO [main] SessionState: Hive Session ID = 0875acb0-4baa-47e6-95a7-80eba94333a0
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:37,843  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:37,850  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0875acb0-4baa-47e6-95a7-80eba94333a0
2024-04-24T06:45:37,853  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0875acb0-4baa-47e6-95a7-80eba94333a0
2024-04-24T06:45:37,856  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0875acb0-4baa-47e6-95a7-80eba94333a0/_tmp_space.db
2024-04-24T06:45:37,858  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=0875acb0-4baa-47e6-95a7-80eba94333a0, clientType=HIVESERVER2]
2024-04-24T06:45:37,859  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:37,859  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:37,859  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:37,860  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: null will be shutdown
2024-04-24T06:45:37,860  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@517d9cd5 created in the thread with id: 1
2024-04-24T06:45:37,864  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c from thread id: 1
2024-04-24T06:45:37,864  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:37,864  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:37,865  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T06:45:37,865  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T06:45:37,865  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T06:45:37,865  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T06:45:37,865  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T06:45:37,866  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T06:45:37,869  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T06:45:37,879  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T06:45:37,879  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:37,880  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:37,887  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:37,891  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:37,894  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ad7512ab-923f-43e1-97d6-f03077b9fd80/_tmp_space.db
2024-04-24T06:45:37,894  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T06:45:37,894  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T06:45:37,894  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:37,894  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7fb9a83c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@517d9cd5 will be shutdown
2024-04-24T06:45:37,894  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:37,894  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T06:45:37,895  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:37,895  INFO [main] service.CompositeService: Session opened, SessionHandle [ad7512ab-923f-43e1-97d6-f03077b9fd80], current sessions:1
2024-04-24T06:45:37,895  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T06:45:37,895  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:37,896  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=95bb8d44-380a-41ff-a020-35431abb344b] SessionHandle [ad7512ab-923f-43e1-97d6-f03077b9fd80]
2024-04-24T06:45:37,896  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72.test
2024-04-24T06:45:37,901  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72, startTime=1713966337895, sessionId=ad7512ab-923f-43e1-97d6-f03077b9fd80, createTime=1713966337879, userName=anonymous, ipAddress=null]
2024-04-24T06:45:37,903  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Compiling command(queryId=alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:37,905  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:37,905  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:37,905  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:37,906  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: null will be shutdown
2024-04-24T06:45:37,906  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 created in the thread with id: 1
2024-04-24T06:45:37,910  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148 from thread id: 1
2024-04-24T06:45:37,911  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:37,911  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ad7512ab-923f-43e1-97d6-f03077b9fd80, clientType=HIVESERVER2]
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:37,912  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:37,926  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:37,986  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:37,987  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:37,989  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:37,989  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:37,990  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_903_7784216767072254771-1
2024-04-24T06:45:37,998  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:38,002  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:38,003  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:38,018  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:38,019  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:38,021  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:38,021  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:38,021  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=5, flushCache_()=0}
2024-04-24T06:45:38,021  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Completed compiling command(queryId=alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72); Time taken: 0.118 seconds
2024-04-24T06:45:38,021  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:38,022  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T06:45:38,022  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:38,022  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Executing command(queryId=alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:38,022  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T06:45:38,023  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:38,023  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001
2024-04-24T06:45:38,023  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001
2024-04-24T06:45:38,023  WARN [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72
2024-04-24T06:45:38,023  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Query ID = alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72
Total jobs = 1
2024-04-24T06:45:38,023  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:38,024  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:38,028  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:38,028  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:38,031  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:38,032  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:38,032  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/dummy_path
2024-04-24T06:45:38,045  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:38,046  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T06:45:38,047  WARN [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:38,052  WARN [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:38,060  WARN [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:38,066  WARN [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:38,067  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:38,068  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/dummy_path
2024-04-24T06:45:38,073  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:38,073  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:38,074  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:38,097  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:38,120  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local541851607_0006
2024-04-24T06:45:38,121  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:38,196  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T06:45:38,196  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:38,196  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:38,197  INFO [Thread-296] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:38,198  INFO [Thread-296] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:38,199  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local541851607_0006_m_000000_0
2024-04-24T06:45:38,202  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:38,203  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:38,206  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:38,207  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T06:45:38,208  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:38,210  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:38,211  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:38,211  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:38,211  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:38,211  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:38,211  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:38,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@48f8bf34, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@351dceae, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@7463d2c5
2024-04-24T06:45:38,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_903_7784216767072254771-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:38,212  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_903_7784216767072254771-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:38,213  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-37_903_7784216767072254771-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:38,224  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-24T06:45:38,225  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T06:45:38,229  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local541851607_0006_m_000000_0 is done. And is in the process of committing
2024-04-24T06:45:38,230  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T06:45:38,230  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local541851607_0006_m_000000_0' done.
2024-04-24T06:45:38,230  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local541851607_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33474
		FILE: Number of bytes written=6918946
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1007157248
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T06:45:38,230  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local541851607_0006_m_000000_0
2024-04-24T06:45:38,230  INFO [Thread-296] mapred.LocalJobRunner: map task executor complete.
2024-04-24T06:45:38,716  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local152228108_0002 with errors
2024-04-24T06:45:38,718 ERROR [HiveServer2-Background-Pool: Thread-121] exec.Task: Ended Job = job_local152228108_0002 with errors
Error during job, obtaining debugging information...
2024-04-24T06:45:38,719 ERROR [Thread-303] exec.Task: Error during job, obtaining debugging information...
2024-04-24T06:45:38,722  INFO [HiveServer2-Background-Pool: Thread-121] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T06:45:38,723 ERROR [HiveServer2-Background-Pool: Thread-121] ql.Driver: FAILED: Operation cancelled
2024-04-24T06:45:38,723  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:38,723  INFO [HiveServer2-Background-Pool: Thread-121] metadata.Hive: Total time spent in each metastore function (ms): {close_()=1}
MapReduce Jobs Launched: 
2024-04-24T06:45:38,723  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T06:45:38,724  WARN [HiveServer2-Background-Pool: Thread-121] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T06:45:38,724  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,724  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,724  INFO [HiveServer2-Background-Pool: Thread-121] ql.Driver: Executing command(queryId=alex_20240424064536_7c11c552-1eca-48da-b328-52a1ba322917) has been interrupted after 2.069 seconds
2024-04-24T06:45:38,724  WARN [HiveServer2-Background-Pool: Thread-121] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T06:45:38,725  INFO [HiveServer2-Background-Pool: Thread-121] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:38,727  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local1224613765_0003 with errors
2024-04-24T06:45:38,727 ERROR [HiveServer2-Background-Pool: Thread-156] exec.Task: Ended Job = job_local1224613765_0003 with errors
Error during job, obtaining debugging information...
2024-04-24T06:45:38,728 ERROR [Thread-305] exec.Task: Error during job, obtaining debugging information...
2024-04-24T06:45:38,729  INFO [HiveServer2-Background-Pool: Thread-156] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T06:45:38,730 ERROR [HiveServer2-Background-Pool: Thread-156] ql.Driver: FAILED: Operation cancelled
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T06:45:38,730  WARN [HiveServer2-Background-Pool: Thread-156] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,730  INFO [HiveServer2-Background-Pool: Thread-156] ql.Driver: Executing command(queryId=alex_20240424064536_d9a267d8-f3c9-4ee3-a52d-8d60d111c36c) has been interrupted after 1.874 seconds
2024-04-24T06:45:38,731  WARN [HiveServer2-Background-Pool: Thread-156] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T06:45:38,731  INFO [HiveServer2-Background-Pool: Thread-156] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:38,734  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local2139312147_0005 with errors
2024-04-24T06:45:38,734 ERROR [HiveServer2-Background-Pool: Thread-236] exec.Task: Ended Job = job_local2139312147_0005 with errors
Error during job, obtaining debugging information...
2024-04-24T06:45:38,735 ERROR [Thread-307] exec.Task: Error during job, obtaining debugging information...
2024-04-24T06:45:38,736  INFO [HiveServer2-Background-Pool: Thread-236] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T06:45:38,736 ERROR [HiveServer2-Background-Pool: Thread-236] ql.Driver: FAILED: Operation cancelled
2024-04-24T06:45:38,736  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:38,736  INFO [HiveServer2-Background-Pool: Thread-236] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:38,737  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T06:45:38,737  WARN [HiveServer2-Background-Pool: Thread-236] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T06:45:38,737  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,737  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:38,737  INFO [HiveServer2-Background-Pool: Thread-236] ql.Driver: Executing command(queryId=alex_20240424064537_554d01c7-f220-4faf-816f-cdcca5180c82) has been interrupted after 1.558 seconds
2024-04-24T06:45:38,737  WARN [HiveServer2-Background-Pool: Thread-236] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T06:45:38,738  INFO [HiveServer2-Background-Pool: Thread-236] common.LogUtils: Unregistered logging context.
2024-04-24 06:45:39,201 Stage-1 map = 100%,  reduce = 0%
2024-04-24T06:45:39,201  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Task: 2024-04-24 06:45:39,201 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local541851607_0006
2024-04-24T06:45:39,204  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.Task: Ended Job = job_local541851607_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1/-mr-10001
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:39,208  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T06:45:39,209  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:39,209  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:39,209  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Completed executing command(queryId=alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72); Time taken: 1.186 seconds
2024-04-24T06:45:39,209  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:39,210  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T06:45:39,211  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ead74b84-2034-4d63-9b88-af1253377ecc] SessionHandle [ad7512ab-923f-43e1-97d6-f03077b9fd80]
2024-04-24T06:45:39,212  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb.test
2024-04-24T06:45:39,218  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb, startTime=1713966339210, sessionId=ad7512ab-923f-43e1-97d6-f03077b9fd80, createTime=1713966337879, userName=anonymous, ipAddress=null]
2024-04-24T06:45:39,220  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Compiling command(queryId=alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T06:45:39,223  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb
2024-04-24T06:45:39,223  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:39,224  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-04-24T06:45:39,225  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T06:45:39,331  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] reflections.Reflections: Reflections took 93 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=11, flushCache_()=0}
2024-04-24T06:45:39,405  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Completed compiling command(queryId=alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb); Time taken: 0.186 seconds
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Executing command(queryId=alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T06:45:39,406  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T06:45:39,407  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T06:45:39,514  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1713966339, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFiles=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T06:45:39,522  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/service/target/warehouse/sample_shutdown_hook
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T06:45:39,676  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-04-24T06:45:39,676  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T06:45:39,676  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T06:45:39,676  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=162}
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Driver: Completed executing command(queryId=alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb); Time taken: 0.27 seconds
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:39,677  INFO [main] service.CompositeService: Session closed, SessionHandle [ad7512ab-923f-43e1-97d6-f03077b9fd80], current sessions:0
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=95bb8d44-380a-41ff-a020-35431abb344b]
2024-04-24T06:45:39,677  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Removed queryId: alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=95bb8d44-380a-41ff-a020-35431abb344b] with tag: null
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1 operation was queued
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064537_ad8edcce-8cc1-40f5-9166-ffa29dd1fc72 without delay
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ead74b84-2034-4d63-9b88-af1253377ecc]
2024-04-24T06:45:39,678  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.OperationManager: Removed queryId: alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=ead74b84-2034-4d63-9b88-af1253377ecc] with tag: null
2024-04-24T06:45:39,679  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80/alex_20240424064539_894b1a69-0edf-4fd3-b6f9-f517169a9ebb without delay
2024-04-24T06:45:39,679  INFO [ad7512ab-923f-43e1-97d6-f03077b9fd80 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:39,679  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80/hive_2024-04-24_06-45-37_903_7784216767072254771-1
2024-04-24T06:45:39,680  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ad7512ab-923f-43e1-97d6-f03077b9fd80 operation was queued
2024-04-24T06:45:39,680  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:39,680  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80
2024-04-24T06:45:39,680  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ad7512ab-923f-43e1-97d6-f03077b9fd80 operation was queued
2024-04-24T06:45:39,681  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:39,681  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4601a148, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4e210016 will be shutdown
2024-04-24T06:45:39,682  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:39,682  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.152">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T06:45:39,762  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
Hive Session ID = 441f5afd-4782-4290-b825-53a95c7314ec
2024-04-24T06:45:39,763  INFO [main] SessionState: Hive Session ID = 441f5afd-4782-4290-b825-53a95c7314ec
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:39,763  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:39,770  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/441f5afd-4782-4290-b825-53a95c7314ec
2024-04-24T06:45:39,774  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/441f5afd-4782-4290-b825-53a95c7314ec
2024-04-24T06:45:39,778  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/441f5afd-4782-4290-b825-53a95c7314ec/_tmp_space.db
2024-04-24T06:45:39,778  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=441f5afd-4782-4290-b825-53a95c7314ec, clientType=HIVESERVER2]
2024-04-24T06:45:39,779  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:39,779  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:39,780  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:39,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@156f0281, with PersistenceManager: null will be shutdown
2024-04-24T06:45:39,780  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@156f0281, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e041848 created in the thread with id: 1
2024-04-24T06:45:39,791  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@156f0281 from thread id: 1
2024-04-24T06:45:39,791  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:39,791  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:39,791  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T06:45:39,791  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T06:45:39,791  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T06:45:39,791  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T06:45:39,791  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T06:45:39,792  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T06:45:39,794  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T06:45:39,804  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T06:45:39,804  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:39,805  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T06:45:39,812  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/6a323639-5d87-4148-a654-4ac6fc9a0be2
2024-04-24T06:45:39,815  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2
2024-04-24T06:45:39,818  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/6a323639-5d87-4148-a654-4ac6fc9a0be2/_tmp_space.db
2024-04-24T06:45:39,818  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T06:45:39,818  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T06:45:39,818  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:39,818  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@156f0281, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1e041848 will be shutdown
2024-04-24T06:45:39,818  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:39,818  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T06:45:39,818  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2
2024-04-24T06:45:39,818  INFO [main] service.CompositeService: Session opened, SessionHandle [6a323639-5d87-4148-a654-4ac6fc9a0be2], current sessions:1
2024-04-24T06:45:39,818  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T06:45:39,819  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:39,819  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cbed811e-b0e3-44a8-8585-d8968dfa6d86] SessionHandle [6a323639-5d87-4148-a654-4ac6fc9a0be2]
2024-04-24T06:45:39,819  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f.test
2024-04-24T06:45:39,823  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f, startTime=1713966339819, sessionId=6a323639-5d87-4148-a654-4ac6fc9a0be2, createTime=1713966339804, userName=anonymous, ipAddress=null]
2024-04-24T06:45:39,824  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Compiling command(queryId=alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:39,825  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T06:45:39,825  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T06:45:39,825  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T06:45:39,826  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5edaa572, with PersistenceManager: null will be shutdown
2024-04-24T06:45:39,826  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5edaa572, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1892865f created in the thread with id: 1
2024-04-24T06:45:39,830  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5edaa572 from thread id: 1
2024-04-24T06:45:39,830  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T06:45:39,830  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T06:45:39,831  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f
2024-04-24T06:45:39,831  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:39,831  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=6a323639-5d87-4148-a654-4ac6fc9a0be2, clientType=HIVESERVER2]
2024-04-24T06:45:39,831  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:39,832  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:39,832  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:39,832  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:39,832  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:39,844  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:39,956  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:39,956  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:39,963  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:39,963  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:39,964  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-39_823_968847672234495589-1
2024-04-24T06:45:39,971  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:39,973  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:39,973  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:39,984  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:39,985  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:39,985  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:39,985  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f
2024-04-24T06:45:39,985  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:39,985  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getAllTableConstraints_(AllTableConstraintsRequest)=63, flushCache_()=0}
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Completed compiling command(queryId=alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f); Time taken: 0.162 seconds
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:39,986  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Executing command(queryId=alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001
2024-04-24T06:45:39,987  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Query ID = alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f
Total jobs = 1
2024-04-24T06:45:39,987  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:39,988  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:39,990  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:39,990  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:39,993  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:39,993  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:39,993  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/dummy_path
2024-04-24T06:45:40,005  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:40,006  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:40,007  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:40,011  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:40,018  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:40,023  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:40,024  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:40,025  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/dummy_path
2024-04-24T06:45:40,030  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:40,031  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:40,031  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:40,052  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:40,080  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1545272999_0007
2024-04-24T06:45:40,081  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T06:45:40,161  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T06:45:40,177  INFO [Thread-350] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T06:45:40,177  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:40,178  INFO [Thread-350] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:40,180  INFO [Thread-350] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:40,180  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1545272999_0007_m_000000_0
2024-04-24T06:45:40,183  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:40,184  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:40,187  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:40,188  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T06:45:40,188  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:40,192  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:40,193  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:40,193  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:40,193  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:40,193  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:40,194  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:40,194  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@7c43b0d5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@636ed676, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@28cab020
2024-04-24T06:45:40,195  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-39_823_968847672234495589-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:40,195  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-39_823_968847672234495589-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:40,195  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-39_823_968847672234495589-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:40,207  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:40,207  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T06:45:40,208  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-24T06:45:40,209  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T06:45:40,213  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1545272999_0007_m_000000_0 is done. And is in the process of committing
2024-04-24T06:45:40,214  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T06:45:40,214  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1545272999_0007_m_000000_0' done.
2024-04-24T06:45:40,214  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1545272999_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39050
		FILE: Number of bytes written=8076114
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=340
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1010827264
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T06:45:40,214  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1545272999_0007_m_000000_0
2024-04-24T06:45:40,214  INFO [Thread-350] mapred.LocalJobRunner: map task executor complete.
2024-04-24 06:45:41,185 Stage-1 map = 100%,  reduce = 0%
2024-04-24T06:45:41,185  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Task: 2024-04-24 06:45:41,185 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1545272999_0007
2024-04-24T06:45:41,187  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.Task: Ended Job = job_local1545272999_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T06:45:41,190  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T06:45:41,190  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1/-mr-10001
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:41,191  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Completed executing command(queryId=alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f); Time taken: 1.204 seconds
2024-04-24T06:45:41,192  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:41,192  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T06:45:41,193  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=3f9e777d-95eb-4e74-9d4e-c8d2da1fb2be] SessionHandle [6a323639-5d87-4148-a654-4ac6fc9a0be2]
2024-04-24T06:45:41,193  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43.test
2024-04-24T06:45:41,198  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43, startTime=1713966341192, sessionId=6a323639-5d87-4148-a654-4ac6fc9a0be2, createTime=1713966339804, userName=anonymous, ipAddress=null]
2024-04-24T06:45:41,199  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Compiling command(queryId=alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T06:45:41,201  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
2024-04-24T06:45:41,201  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T06:45:41,202  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T06:45:41,202  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:41,202  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:41,202  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:41,202  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T06:45:41,215  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:41,280  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T06:45:41,280  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T06:45:41,282  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T06:45:41,282  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T06:45:41,283  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1
2024-04-24T06:45:41,289  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T06:45:41,293  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T06:45:41,294  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorized: false
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T06:45:41,311  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T06:45:41,312  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
2024-04-24T06:45:41,312  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T06:45:41,312  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T06:45:41,313  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T06:45:41,313  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T06:45:41,313  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=0}
2024-04-24T06:45:41,313  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Completed compiling command(queryId=alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43); Time taken: 0.114 seconds
2024-04-24T06:45:41,313  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:41,313  INFO [HiveServer2-Background-Pool: Thread-444] common.LogUtils: Thread context registration is done.
2024-04-24T06:45:41,313  INFO [HiveServer2-Background-Pool: Thread-444] reexec.ReExecDriver: Execution #1 of query
2024-04-24T06:45:41,314  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T06:45:41,314  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Executing command(queryId=alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001
2024-04-24T06:45:41,315  WARN [HiveServer2-Background-Pool: Thread-444] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Query ID = alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
Total jobs = 1
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T06:45:41,315  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Launching Job 1 out of 1
2024-04-24T06:45:41,319  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:41,319  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T06:45:41,325  INFO [HiveServer2-Background-Pool: Thread-444] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T06:45:41,325  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Processing alias _dummy_table
2024-04-24T06:45:41,325  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/dummy_path
2024-04-24T06:45:41,338  INFO [HiveServer2-Background-Pool: Thread-444] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T06:45:41,339  INFO [HiveServer2-Background-Pool: Thread-444] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T06:45:41,340  WARN [HiveServer2-Background-Pool: Thread-444] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:41,345  WARN [HiveServer2-Background-Pool: Thread-444] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T06:45:41,352  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T06:45:41,358  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T06:45:41,358  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T06:45:41,360  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/dummy_path
2024-04-24T06:45:41,365  INFO [HiveServer2-Background-Pool: Thread-444] input.FileInputFormat: Total input files to process : 1
2024-04-24T06:45:41,366  INFO [HiveServer2-Background-Pool: Thread-444] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T06:45:41,366  INFO [HiveServer2-Background-Pool: Thread-444] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T06:45:41,387  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: number of splits:1
2024-04-24T06:45:41,412  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: Submitting tokens for job: job_local204764733_0008
2024-04-24T06:45:41,412  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.JobSubmitter: Executing with tokens: []
DEBUG StatusLogger Removing appender alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
DEBUG StatusLogger Removing appender alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
DEBUG StatusLogger Deleting route with alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f key 
DEBUG StatusLogger Deleting route with alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f key 
DEBUG StatusLogger Stopping route with alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f key
DEBUG StatusLogger Stopping route with alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f key
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/37fab798-d478-4cac-9295-262702b26ae6/alex_20240424064530_3f74230b-6665-474a-a59e-d6edf6d7b17f.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-04-24T06:45:41,496  INFO [HiveServer2-Background-Pool: Thread-444] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)2024-04-24T06:45:41,497  INFO [Thread-389] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-04-24T06:45:41,497  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: Job running in-process (local Hadoop)
2024-04-24T06:45:41,497  INFO [Thread-389] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T06:45:41,498  INFO [Thread-389] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T06:45:41,499  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local204764733_0008_m_000000_0
2024-04-24T06:45:41,500  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T06:45:41,500  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T06:45:41,501  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T06:45:41,502  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T06:45:41,503  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T06:45:41,503  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T06:45:41,504  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T06:45:41,504  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T06:45:41,504  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T06:45:41,504  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T06:45:41,504  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T06:45:41,505  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@31b29330, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@63d66761>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@24a5ce40, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@5e680108
2024-04-24T06:45:41,814  INFO [main] service.CompositeService: Session closed, SessionHandle [6a323639-5d87-4148-a654-4ac6fc9a0be2], current sessions:0
2024-04-24T06:45:41,815  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cbed811e-b0e3-44a8-8585-d8968dfa6d86]
2024-04-24T06:45:41,815  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Removed queryId: alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=cbed811e-b0e3-44a8-8585-d8968dfa6d86] with tag: null
2024-04-24T06:45:41,816  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1
2024-04-24T06:45:41,816  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1 operation was queued
2024-04-24T06:45:41,816  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:41,816  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T06:45:41,817  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064539_b204d535-051b-4b37-b89a-c7c33d4a545f without delay
2024-04-24T06:45:41,817  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=3f9e777d-95eb-4e74-9d4e-c8d2da1fb2be]
2024-04-24T06:45:41,817  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.OperationManager: Removed queryId: alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=3f9e777d-95eb-4e74-9d4e-c8d2da1fb2be] with tag: null
2024-04-24T06:45:41,817  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43
2024-04-24T06:45:41,818  WARN [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-04-24T06:45:41,820  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T06:45:41,819  WARN [Thread-389] mapred.LocalJobRunner: job_local204764733_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T06:45:41,820  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-6
2024-04-24 06:45:41,819 Stage-1 map = 0%,  reduce = 0%2024-04-24T06:45:41,820  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-6 operation was queued
2024-04-24T06:45:41,820  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_tmp.-ext-10002/000000_0

2024-04-24T06:45:41,820  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-39_823_968847672234495589-1
2024-04-24T06:45:41,821  INFO [HiveServer2-Background-Pool: Thread-444] exec.Task: 2024-04-24 06:45:41,819 Stage-1 map = 0%,  reduce = 0%
2024-04-24T06:45:41,821  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1
2024-04-24T06:45:41,821  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T06:45:41,822  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:41,822  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1 operation was queued
2024-04-24T06:45:41,822  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T06:45:41,822  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T06:45:41,822  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-6
2024-04-24T06:45:41,822  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
Ended Job = job_local204764733_0008 with errors
2024-04-24T06:45:41,823  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2/alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43 without delay
2024-04-24T06:45:41,824 ERROR [HiveServer2-Background-Pool: Thread-444] exec.Task: Ended Job = job_local204764733_0008 with errors
2024-04-24T06:45:41,824  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1
2024-04-24T06:45:41,825  INFO [6a323639-5d87-4148-a654-4ac6fc9a0be2 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/6a323639-5d87-4148-a654-4ac6fc9a0be2
Error during job, obtaining debugging information...
2024-04-24T06:45:41,826 ERROR [Thread-394] exec.Task: Error during job, obtaining debugging information...
2024-04-24T06:45:41,830 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T06:45:41,830  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/6a323639-5d87-4148-a654-4ac6fc9a0be2 operation was queued
2024-04-24T06:45:41,831  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T06:45:41,831  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T06:45:41,831  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2
2024-04-24T06:45:41,831  INFO [HiveServer2-Background-Pool: Thread-444] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
2024-04-24T06:45:41,831  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/6a323639-5d87-4148-a654-4ac6fc9a0be2
2024-04-24T06:45:41,831  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T06:45:41,831  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2 operation was queued
2024-04-24T06:45:41,832  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
FAILED: Operation cancelled
2024-04-24T06:45:41,832 ERROR [HiveServer2-Background-Pool: Thread-444] ql.Driver: FAILED: Operation cancelled
2024-04-24T06:45:41,832  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T06:45:41,832  INFO [HiveServer2-Background-Pool: Thread-444] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T06:45:41,832  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T06:45:41,832  INFO [HiveServer2-Background-Pool: Thread-444] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T06:45:41,832  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
MapReduce Jobs Launched: 
2024-04-24T06:45:41,832  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T06:45:41,833  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T06:45:41,833  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T06:45:41,833  WARN [HiveServer2-Background-Pool: Thread-444] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-04-24T06:45:41,833  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:41,833  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_task_tmp.-ext-10002/_tmp.000000_0
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T06:45:41,833  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/6a323639-5d87-4148-a654-4ac6fc9a0be2/hive_2024-04-24_06-45-41_199_540084848343424162-1/-mr-10001/.hive-staging_hive_2024-04-24_06-45-41_199_540084848343424162-1/_tmp.-ext-10002/000000_0
2024-04-24T06:45:41,833  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:41,833  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T06:45:41,833  INFO [HiveServer2-Background-Pool: Thread-444] ql.Driver: Executing command(queryId=alex_20240424064541_92f7b8eb-cf03-4188-8675-e1f17a45ab43) has been interrupted after 0.518 seconds
2024-04-24T06:45:41,833  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T06:45:41,834  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5edaa572, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1892865f will be shutdown
2024-04-24T06:45:41,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T06:45:41,834  WARN [HiveServer2-Background-Pool: Thread-444] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T06:45:41,834  INFO [HiveServer2-Background-Pool: Thread-444] common.LogUtils: Unregistered logging context.
2024-04-24T06:45:41,834  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
]]></system-err>
  </testcase>
</testsuite>