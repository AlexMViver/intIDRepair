SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,073382 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@3e08ff24]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@3e08ff24) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@1a245833
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@624ea235
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,017982 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", footer="null", PatternSelector=null, alwaysWriteExceptions="null", header="null", charset="null", disableAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", Replace=null)
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", direct="null", target="SYSTEM_ERR", bufferSize="null", bufferedIo="null", immediateFlush="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), name="console", ignoreExceptions="null", ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", alwaysWriteExceptions="null", Replace=null, Configuration(HiveLog4j2Test), charset="null", header="null", PatternSelector=null, noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", maxRandomDelay="null", modulate="true")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(fileIndex="null", ={}, tempCompressedFilePattern="null", Configuration(HiveLog4j2Test), stopCustomActionsOnError="null", max="30", min="null", compressionLevel="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(advertiseURI="null", filePermissions="null", fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", append="null", fileGroup="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), fileOwner="null", filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", advertise="null", immediateFlush="null", bufferSize="null", bufferedIo="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), name="DRFA", ignoreExceptions="null", Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 1061090916
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T01:50:38.045-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-01:50:39.720, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-01:50:39.721, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@624ea235 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@624ea235
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@624ea235 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@762ef0ea...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@762ef0ea OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@4cf8b2dc
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@3e08ff24
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@3e08ff24) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@3e08ff24] started OK.
2024-04-24T01:50:39,813  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T01:50:40,208  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T01:50:40,262  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:40,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:40,264  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T01:50:40,264  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:40,264  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:40,265  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
Hive Session ID = cf65966a-8f9b-454c-876f-c36a263e4d9e
2024-04-24T01:50:40,281  INFO [main] SessionState: Hive Session ID = cf65966a-8f9b-454c-876f-c36a263e4d9e
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:40,292  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@55e7a35c.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@55e7a35c.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T01:50:40,620  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/cf65966a-8f9b-454c-876f-c36a263e4d9e
2024-04-24T01:50:40,623  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/cf65966a-8f9b-454c-876f-c36a263e4d9e
2024-04-24T01:50:40,626  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/cf65966a-8f9b-454c-876f-c36a263e4d9e/_tmp_space.db
2024-04-24T01:50:40,668  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t1(id1 int, name1 string)
2024-04-24T01:50:41,800  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,801  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,815  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,815  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,817  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,818  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,821  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:50:41,907  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:42,057  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:42,084  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:42,091  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T01:50:42,091  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T01:50:42,110  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:50:42,114  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T01:50:42,741  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:50:42,746  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T01:50:43,326  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T01:50:43,326  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5377414a, with PersistenceManager: null will be shutdown
2024-04-24T01:50:43,349  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5377414a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49fa1d74 created in the thread with id: 1
2024-04-24T01:50:45,702  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T01:50:45,702  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T01:50:45,702  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5377414a from thread id: 1
2024-04-24T01:50:45,826  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T01:50:45,859  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T01:50:45,892  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T01:50:45,895  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T01:50:46,000  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T01:50:46,007  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T01:50:46,009  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T01:50:46,009  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T01:50:46,010  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T01:50:46,032  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:50:46,035  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T01:50:46,037  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:50:46,037  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T01:50:46,039  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:50:46,041  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T01:50:46,043  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:50:46,044  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T01:50:46,048  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T01:50:46,049  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T01:50:46,051  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:46,179  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:46,213  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T01:50:46,487  INFO [main] reflections.Reflections: Reflections took 188 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:50:46,653  INFO [main] reflections.Reflections: Reflections took 138 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:50:46,787  INFO [main] reflections.Reflections: Reflections took 114 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:50:46,854  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:46,857  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:46,876  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=cf65966a-8f9b-454c-876f-c36a263e4d9e, clientType=HIVECLI]
2024-04-24T01:50:46,878  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T01:50:46,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:46,880  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5377414a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49fa1d74 will be shutdown
2024-04-24T01:50:46,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:46,881  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T01:50:46,883  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:46,884  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:46,885  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:46,886  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b, with PersistenceManager: null will be shutdown
2024-04-24T01:50:46,887  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@621624b1 created in the thread with id: 1
2024-04-24T01:50:46,908  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b from thread id: 1
2024-04-24T01:50:46,908  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:46,908  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:46,913  INFO [main] parse.CalcitePlanner: Creating table default.t1 position=13
2024-04-24T01:50:46,924  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:46,924  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:46,926  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@621624b1 will be shutdown
2024-04-24T01:50:46,927  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cba0321 created in the thread with id: 1
2024-04-24T01:50:46,932  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:46,933  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:46,935  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:50:47,081  INFO [main] reflections.Reflections: Reflections took 119 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:50:47,119  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:47,119  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:47,121  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:47,124  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:47,124  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T01:50:47,125  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 6.457 seconds
2024-04-24T01:50:47,126  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:47,128  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t1(id1 int, name1 string)
PREHOOK: query: create table t1(id1 int, name1 string)
2024-04-24T01:50:47,129  INFO [main] SessionState: PREHOOK: query: create table t1(id1 int, name1 string)
PREHOOK: type: CREATETABLE
2024-04-24T01:50:47,129  INFO [main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T01:50:47,130  INFO [main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@t1
2024-04-24T01:50:47,130  INFO [main] SessionState: PREHOOK: Output: default@t1
2024-04-24T01:50:47,133  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:47,134  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T01:50:47,135  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:47,135  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@beabd6b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1cba0321 will be shutdown
2024-04-24T01:50:47,135  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:47,135  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T01:50:47,253  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:47,255  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:47,255  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:47,256  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5103eea2, with PersistenceManager: null will be shutdown
2024-04-24T01:50:47,257  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5103eea2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e77678c created in the thread with id: 1
2024-04-24T01:50:47,263  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5103eea2 from thread id: 1
2024-04-24T01:50:47,263  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:47,264  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:47,265  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:t1, dbName:default, owner:alex, createTime:1713948647, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id1, type:int, comment:null), FieldSchema(name:name1, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, totalSize=0, numFilesErasureCoded=0, numRows=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"id1":"true","name1":"true"}}, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:50:47,287  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/t1
POSTHOOK: query: create table t1(id1 int, name1 string)
2024-04-24T01:50:47,443  INFO [main] SessionState: POSTHOOK: query: create table t1(id1 int, name1 string)
POSTHOOK: type: CREATETABLE
2024-04-24T01:50:47,443  INFO [main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T01:50:47,443  INFO [main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@t1
2024-04-24T01:50:47,443  INFO [main] SessionState: POSTHOOK: Output: default@t1
2024-04-24T01:50:47,444  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:47,444  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=177}
2024-04-24T01:50:47,444  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.316 seconds
2024-04-24T01:50:47,446  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t2(id2 int, id1 int, name2 string)
2024-04-24T01:50:47,448  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:47,448  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:47,448  INFO [main] parse.CalcitePlanner: Creating table default.t2 position=13
2024-04-24T01:50:47,449  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:50:47,452  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:47,452  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:47,452  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:47,452  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:47,452  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, flushCache_()=0, getDatabase_(String)=3}
2024-04-24T01:50:47,452  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.006 seconds
2024-04-24T01:50:47,453  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:47,453  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t2(id2 int, id1 int, name2 string)
PREHOOK: query: create table t2(id2 int, id1 int, name2 string)
2024-04-24T01:50:47,453  INFO [main] SessionState: PREHOOK: query: create table t2(id2 int, id1 int, name2 string)
PREHOOK: type: CREATETABLE
2024-04-24T01:50:47,453  INFO [main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T01:50:47,453  INFO [main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@t2
2024-04-24T01:50:47,453  INFO [main] SessionState: PREHOOK: Output: default@t2
2024-04-24T01:50:47,453  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:47,455  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:t2, dbName:default, owner:alex, createTime:1713948647, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id2, type:int, comment:null), FieldSchema(name:id1, type:int, comment:null), FieldSchema(name:name2, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, numFiles=0, numFilesErasureCoded=0, numRows=0, bucketing_version=2, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"id1":"true","id2":"true","name2":"true"}}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:50:47,471  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/ql/target/warehouse/t2
POSTHOOK: query: create table t2(id2 int, id1 int, name2 string)
2024-04-24T01:50:47,509  INFO [main] SessionState: POSTHOOK: query: create table t2(id2 int, id1 int, name2 string)
POSTHOOK: type: CREATETABLE
2024-04-24T01:50:47,509  INFO [main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T01:50:47,509  INFO [main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@t2
2024-04-24T01:50:47,509  INFO [main] SessionState: POSTHOOK: Output: default@t2
2024-04-24T01:50:47,509  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:47,509  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=54, isCompatibleWith_(Configuration)=0}
2024-04-24T01:50:47,510  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.056 seconds
2024-04-24T01:50:47,511  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t3(id1 int) partitioned by (`date` int, p0 string)
2024-04-24T01:50:47,513  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:47,513  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:47,513  INFO [main] parse.CalcitePlanner: Creating table default.t3 position=13
2024-04-24T01:50:47,513  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:50:47,515  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852
2024-04-24T01:50:47,515  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:47,515  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:47,516  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:47,516  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getDatabase_(String)=2}
2024-04-24T01:50:47,516  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.004 seconds
2024-04-24T01:50:47,516  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:47,516  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create table t3(id1 int) partitioned by (`date` int, p0 string)
PREHOOK: query: create table t3(id1 int) partitioned by (`date` int, p0 string)
2024-04-24T01:50:47,516  INFO [main] SessionState: PREHOOK: query: create table t3(id1 int) partitioned by (`date` int, p0 string)
PREHOOK: type: CREATETABLE
2024-04-24T01:50:47,517  INFO [main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T01:50:47,517  INFO [main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@t3
2024-04-24T01:50:47,517  INFO [main] SessionState: PREHOOK: Output: default@t3
2024-04-24T01:50:47,517  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:47,518  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:t3, dbName:default, owner:alex, createTime:1713948647, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id1, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:date, type:int, comment:null), FieldSchema(name:p0, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
POSTHOOK: query: create table t3(id1 int) partitioned by (`date` int, p0 string)
2024-04-24T01:50:47,561  INFO [main] SessionState: POSTHOOK: query: create table t3(id1 int) partitioned by (`date` int, p0 string)
POSTHOOK: type: CREATETABLE
2024-04-24T01:50:47,561  INFO [main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T01:50:47,561  INFO [main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@t3
2024-04-24T01:50:47,561  INFO [main] SessionState: POSTHOOK: Output: default@t3
2024-04-24T01:50:47,561  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:47,562  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=43, isCompatibleWith_(Configuration)=0}
2024-04-24T01:50:47,562  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.045 seconds
2024-04-24T01:50:47,563  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create view v1 as select * from t1
2024-04-24T01:50:47,566  INFO [main] create.CreateViewAnalyzer: Creating view default.v1 position=12
2024-04-24T01:50:47,568  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:47,571  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:50:47,571  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:47,572  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:47,655  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:47,658  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:47,658  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:47,663  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:50:47,977  INFO [Finalizer] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:47,977  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T01:50:48,784  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t1	
2024-04-24T01:50:49,278  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t1, projIndxSet: [0, 1], allowMissingStats: true
2024-04-24T01:50:49,290  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t1	
2024-04-24T01:50:49,322  WARN [main] calcite.RelOptHiveTable: No Stats for default@t1, Columns: id1, name1
No Stats for default@t1, Columns: id1, name1
2024-04-24T01:50:49,322  INFO [main] SessionState: No Stats for default@t1, Columns: id1, name1
2024-04-24T01:50:49,429  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:49,429  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:49,429  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:49,464  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/cf65966a-8f9b-454c-876f-c36a263e4d9e/hive_2024-04-24_01-50-47_563_608509944844386826-1/-mr-10001/.hive-staging_hive_2024-04-24_01-50-47_563_608509944844386826-1
2024-04-24T01:50:49,481  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:50:49,501  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:49,506  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:50:49,508  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:49,508  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:id1, type:int, comment:null), FieldSchema(name:name1, type:string, comment:null)], properties:null)
2024-04-24T01:50:49,509  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:49,509  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTableColumnStatistics_(String, String, List, String)=29, getAllTableConstraints_(AllTableConstraintsRequest)=63, getDatabase_(String)=2, getTable_(GetTableRequest)=85, flushCache_()=0, isCompatibleWith_(Configuration)=0}
2024-04-24T01:50:49,509  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 1.946 seconds
2024-04-24T01:50:49,509  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:49,509  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852): create view v1 as select * from t1
PREHOOK: query: create view v1 as select * from t1
2024-04-24T01:50:49,510  INFO [main] SessionState: PREHOOK: query: create view v1 as select * from t1
PREHOOK: type: CREATEVIEW
2024-04-24T01:50:49,510  INFO [main] SessionState: PREHOOK: type: CREATEVIEW
PREHOOK: Input: default@t1
2024-04-24T01:50:49,510  INFO [main] SessionState: PREHOOK: Input: default@t1
PREHOOK: Output: database:default
2024-04-24T01:50:49,510  INFO [main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@v1
2024-04-24T01:50:49,510  INFO [main] SessionState: PREHOOK: Output: default@v1
2024-04-24T01:50:49,510  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:49,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:49,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:v1, dbName:default, owner:alex, createTime:1713948649, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id1, type:int, comment:null), FieldSchema(name:name1, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:select * from t1, viewExpandedText:select `t1`.`id1`, `t1`.`name1` from `default`.`t1`, tableType:VIRTUAL_VIEW, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), catName:hive, ownerType:USER)	
POSTHOOK: query: create view v1 as select * from t1
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: query: create view v1 as select * from t1
POSTHOOK: type: CREATEVIEW
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: type: CREATEVIEW
POSTHOOK: Input: default@t1
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: Input: default@t1
POSTHOOK: Output: database:default
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@v1
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: Output: default@v1
POSTHOOK: Lineage: v1.id1 SIMPLE [(t1)t1.FieldSchema(name:id1, type:int, comment:null), ]
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: Lineage: v1.id1 SIMPLE [(t1)t1.FieldSchema(name:id1, type:int, comment:null), ]
POSTHOOK: Lineage: v1.name1 SIMPLE [(t1)t1.FieldSchema(name:name1, type:string, comment:null), ]
2024-04-24T01:50:49,539  INFO [main] SessionState: POSTHOOK: Lineage: v1.name1 SIMPLE [(t1)t1.FieldSchema(name:name1, type:string, comment:null), ]
2024-04-24T01:50:49,540  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:49,540  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=24, isCompatibleWith_(Configuration)=0}
2024-04-24T01:50:49,540  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015040_45f9979d-2f64-4b33-b872-1d1b911d5852); Time taken: 0.03 seconds
2024-04-24T01:50:49,602  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:49,602  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:49,602  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:49,602  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:50:49,602  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:49,603  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = f79034a2-9f16-4ed5-b335-9c01c66cbdb3
2024-04-24T01:50:49,603  INFO [main] SessionState: Hive Session ID = f79034a2-9f16-4ed5-b335-9c01c66cbdb3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:49,604  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:49,612  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/f79034a2-9f16-4ed5-b335-9c01c66cbdb3
2024-04-24T01:50:49,616  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/f79034a2-9f16-4ed5-b335-9c01c66cbdb3
2024-04-24T01:50:49,619  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/f79034a2-9f16-4ed5-b335-9c01c66cbdb3/_tmp_space.db
2024-04-24T01:50:49,623  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015049_28838d58-23f2-4a80-b023-3cab04a34399): select * from t1
2024-04-24T01:50:49,625  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015049_28838d58-23f2-4a80-b023-3cab04a34399
2024-04-24T01:50:49,625  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:49,625  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f79034a2-9f16-4ed5-b335-9c01c66cbdb3, clientType=HIVECLI]
2024-04-24T01:50:49,626  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T01:50:49,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:49,626  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5103eea2, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7e77678c will be shutdown
2024-04-24T01:50:49,627  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:49,627  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-04-24T01:50:49,628  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:49,629  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:49,629  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:49,630  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e, with PersistenceManager: null will be shutdown
2024-04-24T01:50:49,631  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7c6ab057 created in the thread with id: 1
2024-04-24T01:50:49,639  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e from thread id: 1
2024-04-24T01:50:49,639  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:49,639  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:49,639  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:50:49,640  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:49,641  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:49,641  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:49,641  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7c6ab057 will be shutdown
2024-04-24T01:50:49,642  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@182dcd2b created in the thread with id: 1
2024-04-24T01:50:49,646  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:49,647  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:49,647  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:49,665  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:49,666  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:49,666  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:49,666  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:50:49,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t1	
2024-04-24T01:50:49,690  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t1, projIndxSet: [0, 1], allowMissingStats: true
2024-04-24T01:50:49,691  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t1	
2024-04-24T01:50:49,708  WARN [main] calcite.RelOptHiveTable: No Stats for default@t1, Columns: name1, id1
No Stats for default@t1, Columns: name1, id1
2024-04-24T01:50:49,708  INFO [main] SessionState: No Stats for default@t1, Columns: name1, id1
2024-04-24T01:50:49,764  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:49,764  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:49,765  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:49,766  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/f79034a2-9f16-4ed5-b335-9c01c66cbdb3/hive_2024-04-24_01-50-49_623_2044332429148552256-1/-mr-10001/.hive-staging_hive_2024-04-24_01-50-49_623_2044332429148552256-1
2024-04-24T01:50:49,777  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:50:49,830  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T01:50:49,851  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T01:50:49,852  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015049_28838d58-23f2-4a80-b023-3cab04a34399
2024-04-24T01:50:49,853  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:49,853  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:t1.id1, type:int, comment:null), FieldSchema(name:t1.name1, type:string, comment:null)], properties:null)
2024-04-24T01:50:49,869  INFO [main] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T01:50:49,870  INFO [main] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T01:50:49,875  INFO [main] exec.SelectOperator: SELECT struct<id1:int,name1:string>
2024-04-24T01:50:49,875  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T01:50:49,880  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:49,880  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=8, getTableColumnStatistics_(String, String, List, String)=16}
2024-04-24T01:50:49,880  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015049_28838d58-23f2-4a80-b023-3cab04a34399); Time taken: 0.257 seconds
2024-04-24T01:50:49,935  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:49,935  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T01:50:49,935  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:49,935  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:49,935  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:49,936  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
Hive Session ID = b365696c-3f52-4e7c-931d-673822c1baf4
2024-04-24T01:50:49,937  INFO [main] SessionState: Hive Session ID = b365696c-3f52-4e7c-931d-673822c1baf4
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:49,937  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:49,945  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/b365696c-3f52-4e7c-931d-673822c1baf4
2024-04-24T01:50:49,948  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/b365696c-3f52-4e7c-931d-673822c1baf4
2024-04-24T01:50:49,952  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/b365696c-3f52-4e7c-931d-673822c1baf4/_tmp_space.db
2024-04-24T01:50:49,954  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015049_f9fb5356-59c5-4775-9cdc-c3e68bb99878): select * from t1 join t2 on (t1.id1 = t2.id1)
2024-04-24T01:50:49,958  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T01:50:49,958  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:49,959  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@176e839e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@182dcd2b will be shutdown
2024-04-24T01:50:49,959  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:49,959  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T01:50:49,959  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015049_f9fb5356-59c5-4775-9cdc-c3e68bb99878
2024-04-24T01:50:49,960  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:49,960  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=b365696c-3f52-4e7c-931d-673822c1baf4, clientType=HIVECLI]
2024-04-24T01:50:49,961  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:49,963  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:49,963  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:49,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19d13d04, with PersistenceManager: null will be shutdown
2024-04-24T01:50:49,964  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19d13d04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7957aa57 created in the thread with id: 1
2024-04-24T01:50:49,969  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19d13d04 from thread id: 1
2024-04-24T01:50:49,970  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:49,970  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:49,970  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:50:49,970  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:49,971  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:49,991  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:49,991  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t2	
2024-04-24T01:50:50,009  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,010  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,010  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,010  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:50:50,025  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t1	
2024-04-24T01:50:50,035  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t2	
2024-04-24T01:50:50,221  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t1, projIndxSet: [0, 1], allowMissingStats: true
2024-04-24T01:50:50,221  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t1	
2024-04-24T01:50:50,243  WARN [main] calcite.RelOptHiveTable: No Stats for default@t1, Columns: name1, id1
No Stats for default@t1, Columns: name1, id1
2024-04-24T01:50:50,243  INFO [main] SessionState: No Stats for default@t1, Columns: name1, id1
2024-04-24T01:50:50,244  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t2, projIndxSet: [0, 1, 2], allowMissingStats: true
2024-04-24T01:50:50,245  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t2	
2024-04-24T01:50:50,268  WARN [main] calcite.RelOptHiveTable: No Stats for default@t2, Columns: id1, name2, id2
No Stats for default@t2, Columns: id1, name2, id2
2024-04-24T01:50:50,268  INFO [main] SessionState: No Stats for default@t2, Columns: id1, name2, id2
2024-04-24T01:50:50,391  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,391  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,391  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,391  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,391  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,392  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,392  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,392  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,392  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,408  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/b365696c-3f52-4e7c-931d-673822c1baf4/hive_2024-04-24_01-50-49_954_5783610512070317179-1/-mr-10001/.hive-staging_hive_2024-04-24_01-50-49_954_5783610512070317179-1
2024-04-24T01:50:50,419  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:50:50,444  INFO [main] optimizer.ColumnPrunerProcFactory: JOIN 8 oldExprs: {1=[Column[VALUE._col0], Column[KEY.reducesinkkey0], Column[VALUE._col1]], 0=[Column[KEY.reducesinkkey0], Column[VALUE._col0]]}
2024-04-24T01:50:50,445  INFO [main] optimizer.ColumnPrunerProcFactory: JOIN 8 newExprs: {0=[Column[KEY.reducesinkkey0], Column[VALUE._col0]], 1=[Column[VALUE._col0], Column[KEY.reducesinkkey0], Column[VALUE._col1]]}
2024-04-24T01:50:50,446  INFO [main] optimizer.ColumnPrunerProcFactory: RS 6 oldColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-24T01:50:50,446  INFO [main] optimizer.ColumnPrunerProcFactory: RS 6 newColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-24T01:50:50,446  INFO [main] optimizer.ColumnPrunerProcFactory: RS 7 oldColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1], VALUE._col1=Column[_col2]}
2024-04-24T01:50:50,446  INFO [main] optimizer.ColumnPrunerProcFactory: RS 7 newColExprMap: {VALUE._col1=Column[_col2], VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
2024-04-24T01:50:50,448  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[3] because it has -1<2 buckets 
2024-04-24T01:50:50,449  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T01:50:50,453  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T01:50:50,507  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T01:50:50,508  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T01:50:50,508  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T01:50:50,508  INFO [main] physical.Vectorizer: Map notVectorizedReason: Vectorized map work only works with 1 TableScanOperator
2024-04-24T01:50:50,508  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T01:50:50,508  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Vectorized map work only works with 1 TableScanOperator IS false]
2024-04-24T01:50:50,509  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T01:50:50,509  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T01:50:50,509  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T01:50:50,509  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T01:50:50,509  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T01:50:50,509  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T01:50:50,509  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015049_f9fb5356-59c5-4775-9cdc-c3e68bb99878
2024-04-24T01:50:50,510  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:50,510  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:t1.id1, type:int, comment:null), FieldSchema(name:t1.name1, type:string, comment:null), FieldSchema(name:t2.id2, type:int, comment:null), FieldSchema(name:t2.id1, type:int, comment:null), FieldSchema(name:t2.name2, type:string, comment:null)], properties:null)
2024-04-24T01:50:50,511  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[13]
2024-04-24T01:50:50,512  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:50,512  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=40, getAllTableConstraints_(AllTableConstraintsRequest)=19, getTableColumnStatistics_(String, String, List, String)=43}
2024-04-24T01:50:50,512  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015049_f9fb5356-59c5-4775-9cdc-c3e68bb99878); Time taken: 0.558 seconds
2024-04-24T01:50:50,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:50:50,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:50:50,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:50,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:50,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = 6d97cdd2-b610-48d2-bd6c-575d9f52b5be
2024-04-24T01:50:50,548  INFO [main] SessionState: Hive Session ID = 6d97cdd2-b610-48d2-bd6c-575d9f52b5be
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:50,549  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:50,556  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/6d97cdd2-b610-48d2-bd6c-575d9f52b5be
2024-04-24T01:50:50,559  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/6d97cdd2-b610-48d2-bd6c-575d9f52b5be
2024-04-24T01:50:50,562  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/6d97cdd2-b610-48d2-bd6c-575d9f52b5be/_tmp_space.db
2024-04-24T01:50:50,564  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015050_f9e68413-0bcc-4780-ab8a-4e46b92d9f25): show partitions t3 where `date` > 20011113
2024-04-24T01:50:50,565  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T01:50:50,566  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:50,566  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@19d13d04, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7957aa57 will be shutdown
2024-04-24T01:50:50,566  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:50,566  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-04-24T01:50:50,570  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:50,571  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:50,571  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:50,572  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236206f8, with PersistenceManager: null will be shutdown
2024-04-24T01:50:50,572  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236206f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e5f05f8 created in the thread with id: 1
2024-04-24T01:50:50,576  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236206f8 from thread id: 1
2024-04-24T01:50:50,576  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:50,576  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:50,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t3	
2024-04-24T01:50:50,591  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t3	
2024-04-24T01:50:50,606  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,617  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:50,617  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:partition, type:string, comment:from deserializer)], properties:null)
2024-04-24T01:50:50,618  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[0]
2024-04-24T01:50:50,619  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:50,619  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=31}
2024-04-24T01:50:50,619  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015050_f9e68413-0bcc-4780-ab8a-4e46b92d9f25); Time taken: 0.055 seconds
2024-04-24T01:50:50,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:50,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:50,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:50:50,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:50,657  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = 7ee785fe-85ec-474f-a6eb-ddabb84219c2
2024-04-24T01:50:50,659  INFO [main] SessionState: Hive Session ID = 7ee785fe-85ec-474f-a6eb-ddabb84219c2
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:50,659  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:50,666  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7ee785fe-85ec-474f-a6eb-ddabb84219c2
2024-04-24T01:50:50,669  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/7ee785fe-85ec-474f-a6eb-ddabb84219c2
2024-04-24T01:50:50,672  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7ee785fe-85ec-474f-a6eb-ddabb84219c2/_tmp_space.db
2024-04-24T01:50:50,675  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015050_419cb6cc-5746-4e91-9d5f-71b970b3d383): select * from v1 join t2 on (v1.id1 = t2.id1)
2024-04-24T01:50:50,676  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240424015050_419cb6cc-5746-4e91-9d5f-71b970b3d383
2024-04-24T01:50:50,676  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:50:50,677  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7ee785fe-85ec-474f-a6eb-ddabb84219c2, clientType=HIVECLI]
2024-04-24T01:50:50,677  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-24T01:50:50,677  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:50,677  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@236206f8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@e5f05f8 will be shutdown
2024-04-24T01:50:50,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:50,678  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-04-24T01:50:50,679  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:50,681  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:50,681  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:50,681  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584, with PersistenceManager: null will be shutdown
2024-04-24T01:50:50,682  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e4ead73 created in the thread with id: 1
2024-04-24T01:50:50,686  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584 from thread id: 1
2024-04-24T01:50:50,686  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:50,686  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:50,686  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:50:50,686  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,687  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:50,687  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:50,688  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e4ead73 will be shutdown
2024-04-24T01:50:50,688  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6771fc29 created in the thread with id: 1
2024-04-24T01:50:50,692  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:50,692  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:50,693  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:50,706  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t2	
2024-04-24T01:50:50,726  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,726  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,726  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,727  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:50,739  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:50,740  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,740  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,740  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,740  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:50:50,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t1	
2024-04-24T01:50:50,760  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.t2	
2024-04-24T01:50:50,847  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t1, projIndxSet: [0, 1], allowMissingStats: true
2024-04-24T01:50:50,848  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t1	
2024-04-24T01:50:50,883  WARN [main] calcite.RelOptHiveTable: No Stats for default@t1, Columns: id1, name1
No Stats for default@t1, Columns: id1, name1
2024-04-24T01:50:50,883  INFO [main] SessionState: No Stats for default@t1, Columns: id1, name1
2024-04-24T01:50:50,884  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.t2, projIndxSet: [0, 1, 2], allowMissingStats: true
2024-04-24T01:50:50,885  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.t2	
2024-04-24T01:50:50,900  WARN [main] calcite.RelOptHiveTable: No Stats for default@t2, Columns: id1, name2, id2
No Stats for default@t2, Columns: id1, name2, id2
2024-04-24T01:50:50,900  INFO [main] SessionState: No Stats for default@t2, Columns: id1, name2, id2
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,985  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:50:50,990  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/7ee785fe-85ec-474f-a6eb-ddabb84219c2/hive_2024-04-24_01-50-50_674_5399530482656254555-1/-mr-10001/.hive-staging_hive_2024-04-24_01-50-50_674_5399530482656254555-1
2024-04-24T01:50:50,999  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:50:51,011  INFO [main] optimizer.ColumnPrunerProcFactory: JOIN 8 oldExprs: {1=[Column[VALUE._col0], Column[KEY.reducesinkkey0], Column[VALUE._col1]], 0=[Column[KEY.reducesinkkey0], Column[VALUE._col0]]}
2024-04-24T01:50:51,011  INFO [main] optimizer.ColumnPrunerProcFactory: JOIN 8 newExprs: {0=[Column[KEY.reducesinkkey0], Column[VALUE._col0]], 1=[Column[VALUE._col0], Column[KEY.reducesinkkey0], Column[VALUE._col1]]}
2024-04-24T01:50:51,011  INFO [main] optimizer.ColumnPrunerProcFactory: RS 6 oldColExprMap: {VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-24T01:50:51,011  INFO [main] optimizer.ColumnPrunerProcFactory: RS 6 newColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-24T01:50:51,012  INFO [main] optimizer.ColumnPrunerProcFactory: RS 7 oldColExprMap: {VALUE._col1=Column[_col2], KEY.reducesinkkey0=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T01:50:51,012  INFO [main] optimizer.ColumnPrunerProcFactory: RS 7 newColExprMap: {VALUE._col1=Column[_col2], KEY.reducesinkkey0=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T01:50:51,013  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T01:50:51,013  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[3] because it has -1<2 buckets 
2024-04-24T01:50:51,014  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Map notVectorizedReason: Vectorized map work only works with 1 TableScanOperator
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Vectorized map work only works with 1 TableScanOperator IS false]
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T01:50:51,032  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T01:50:51,032  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T01:50:51,032  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240424015050_419cb6cc-5746-4e91-9d5f-71b970b3d383
2024-04-24T01:50:51,032  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:51,032  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:v1.id1, type:int, comment:null), FieldSchema(name:v1.name1, type:string, comment:null), FieldSchema(name:t2.id2, type:int, comment:null), FieldSchema(name:t2.id1, type:int, comment:null), FieldSchema(name:t2.name2, type:string, comment:null)], properties:null)
2024-04-24T01:50:51,033  INFO [main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[13]
2024-04-24T01:50:51,034  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:51,034  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=13, getTableColumnStatistics_(String, String, List, String)=49}
2024-04-24T01:50:51,034  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015050_419cb6cc-5746-4e91-9d5f-71b970b3d383); Time taken: 0.359 seconds
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:50:51,073  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:50:51,074  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T01:50:51,074  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
Hive Session ID = d7c8291e-deb3-43eb-83cc-6216bdcccdbc
2024-04-24T01:50:51,074  INFO [main] SessionState: Hive Session ID = d7c8291e-deb3-43eb-83cc-6216bdcccdbc
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:51,074  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:50:51,081  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/d7c8291e-deb3-43eb-83cc-6216bdcccdbc
2024-04-24T01:50:51,083  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/d7c8291e-deb3-43eb-83cc-6216bdcccdbc
2024-04-24T01:50:51,086  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/d7c8291e-deb3-43eb-83cc-6216bdcccdbc/_tmp_space.db
2024-04-24T01:50:51,088  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t1
2024-04-24T01:50:51,088  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-24T01:50:51,089  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T01:50:51,089  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4626f584, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6771fc29 will be shutdown
2024-04-24T01:50:51,089  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T01:50:51,089  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -8
2024-04-24T01:50:51,090  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:50:51,091  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:50:51,091  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:50:51,091  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b6b8cea, with PersistenceManager: null will be shutdown
2024-04-24T01:50:51,091  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b6b8cea, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@55a29589 created in the thread with id: 1
2024-04-24T01:50:51,094  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7b6b8cea from thread id: 1
2024-04-24T01:50:51,095  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:50:51,095  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:50:51,095  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:51,111  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,111  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:51,111  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:51,112  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:51,112  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=16}
2024-04-24T01:50:51,112  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.023 seconds
2024-04-24T01:50:51,112  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:51,112  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t1
PREHOOK: query: drop table t1
2024-04-24T01:50:51,112  INFO [main] SessionState: PREHOOK: query: drop table t1
PREHOOK: type: DROPTABLE
2024-04-24T01:50:51,113  INFO [main] SessionState: PREHOOK: type: DROPTABLE
PREHOOK: Input: default@t1
2024-04-24T01:50:51,113  INFO [main] SessionState: PREHOOK: Input: default@t1
PREHOOK: Output: default@t1
2024-04-24T01:50:51,113  INFO [main] SessionState: PREHOOK: Output: default@t1
2024-04-24T01:50:51,113  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:51,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:51,126  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,127  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t1	
2024-04-24T01:50:51,141  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,141  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.t1	
POSTHOOK: query: drop table t1
2024-04-24T01:50:51,415  INFO [main] SessionState: POSTHOOK: query: drop table t1
POSTHOOK: type: DROPTABLE
2024-04-24T01:50:51,415  INFO [main] SessionState: POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@t1
2024-04-24T01:50:51,415  INFO [main] SessionState: POSTHOOK: Input: default@t1
POSTHOOK: Output: default@t1
2024-04-24T01:50:51,415  INFO [main] SessionState: POSTHOOK: Output: default@t1
2024-04-24T01:50:51,416  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:51,416  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=288, getTable_(GetTableRequest)=14, isCompatibleWith_(Configuration)=0}
2024-04-24T01:50:51,416  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.304 seconds
2024-04-24T01:50:51,417  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t2
2024-04-24T01:50:51,417  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t2	
2024-04-24T01:50:51,464  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,464  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:51,464  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:51,464  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:51,464  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=47, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T01:50:51,464  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.047 seconds
2024-04-24T01:50:51,465  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:51,465  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t2
PREHOOK: query: drop table t2
2024-04-24T01:50:51,465  INFO [main] SessionState: PREHOOK: query: drop table t2
PREHOOK: type: DROPTABLE
2024-04-24T01:50:51,465  INFO [main] SessionState: PREHOOK: type: DROPTABLE
PREHOOK: Input: default@t2
2024-04-24T01:50:51,465  INFO [main] SessionState: PREHOOK: Input: default@t2
PREHOOK: Output: default@t2
2024-04-24T01:50:51,465  INFO [main] SessionState: PREHOOK: Output: default@t2
2024-04-24T01:50:51,465  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:51,466  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t2	
2024-04-24T01:50:51,479  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t2	
2024-04-24T01:50:51,492  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,493  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.t2	
POSTHOOK: query: drop table t2
2024-04-24T01:50:51,550  INFO [main] SessionState: POSTHOOK: query: drop table t2
POSTHOOK: type: DROPTABLE
2024-04-24T01:50:51,550  INFO [main] SessionState: POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@t2
2024-04-24T01:50:51,550  INFO [main] SessionState: POSTHOOK: Input: default@t2
POSTHOOK: Output: default@t2
2024-04-24T01:50:51,550  INFO [main] SessionState: POSTHOOK: Output: default@t2
2024-04-24T01:50:51,550  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:51,550  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=70, getTable_(GetTableRequest)=14}
2024-04-24T01:50:51,550  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.085 seconds
2024-04-24T01:50:51,550  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t3
2024-04-24T01:50:51,552  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t3	
2024-04-24T01:50:51,563  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,564  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:51,564  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:51,564  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:51,564  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13, flushCache_()=0}
2024-04-24T01:50:51,564  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.014 seconds
2024-04-24T01:50:51,564  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:51,564  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop table t3
PREHOOK: query: drop table t3
2024-04-24T01:50:51,564  INFO [main] SessionState: PREHOOK: query: drop table t3
PREHOOK: type: DROPTABLE
2024-04-24T01:50:51,565  INFO [main] SessionState: PREHOOK: type: DROPTABLE
PREHOOK: Input: default@t3
2024-04-24T01:50:51,565  INFO [main] SessionState: PREHOOK: Input: default@t3
PREHOOK: Output: default@t3
2024-04-24T01:50:51,565  INFO [main] SessionState: PREHOOK: Output: default@t3
2024-04-24T01:50:51,565  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:51,565  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t3	
2024-04-24T01:50:51,577  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.t3	
2024-04-24T01:50:51,589  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,589  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.t3	
POSTHOOK: query: drop table t3
2024-04-24T01:50:51,632  INFO [main] SessionState: POSTHOOK: query: drop table t3
POSTHOOK: type: DROPTABLE
2024-04-24T01:50:51,632  INFO [main] SessionState: POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@t3
2024-04-24T01:50:51,632  INFO [main] SessionState: POSTHOOK: Input: default@t3
POSTHOOK: Output: default@t3
2024-04-24T01:50:51,632  INFO [main] SessionState: POSTHOOK: Output: default@t3
2024-04-24T01:50:51,632  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:51,632  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=12, dropTable_(String, String, boolean, boolean, boolean)=55}
2024-04-24T01:50:51,633  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.068 seconds
2024-04-24T01:50:51,633  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop view v1
2024-04-24T01:50:51,634  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:51,645  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,646  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:50:51,646  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:50:51,646  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:50:51,646  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=12, flushCache_()=0}
2024-04-24T01:50:51,646  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.013 seconds
2024-04-24T01:50:51,647  INFO [main] ql.Driver: Concurrency mode is disabled, not creating a lock manager
2024-04-24T01:50:51,647  INFO [main] ql.Driver: Executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413): drop view v1
PREHOOK: query: drop view v1
2024-04-24T01:50:51,647  INFO [main] SessionState: PREHOOK: query: drop view v1
PREHOOK: type: DROPVIEW
2024-04-24T01:50:51,647  INFO [main] SessionState: PREHOOK: type: DROPVIEW
PREHOOK: Input: default@v1
2024-04-24T01:50:51,647  INFO [main] SessionState: PREHOOK: Input: default@v1
PREHOOK: Output: default@v1
2024-04-24T01:50:51,647  INFO [main] SessionState: PREHOOK: Output: default@v1
2024-04-24T01:50:51,647  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:50:51,648  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:51,659  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.v1	
2024-04-24T01:50:51,672  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:50:51,672  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.v1	
POSTHOOK: query: drop view v1
2024-04-24T01:50:51,713  INFO [main] SessionState: POSTHOOK: query: drop view v1
POSTHOOK: type: DROPVIEW
2024-04-24T01:50:51,713  INFO [main] SessionState: POSTHOOK: type: DROPVIEW
POSTHOOK: Input: default@v1
2024-04-24T01:50:51,713  INFO [main] SessionState: POSTHOOK: Input: default@v1
POSTHOOK: Output: default@v1
2024-04-24T01:50:51,713  INFO [main] SessionState: POSTHOOK: Output: default@v1
2024-04-24T01:50:51,713  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:50:51,714  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=54, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=12}
2024-04-24T01:50:51,714  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424015051_792de69b-0b43-4d07-bd25-bf04fef03413); Time taken: 0.066 seconds
