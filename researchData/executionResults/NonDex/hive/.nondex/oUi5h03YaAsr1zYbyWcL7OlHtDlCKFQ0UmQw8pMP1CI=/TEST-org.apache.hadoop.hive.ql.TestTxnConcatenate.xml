<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="31.163" tests="3" errors="2" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/warehouse"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter46761498195801186.jar /home/alex/Repositories/hive/ql/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire964249659867797702tmp surefire_2399879056997680200700tmp"/>
    <property name="nondexExecid" value="oUi5h03YaAsr1zYbyWcL7OlHtDlCKFQ0UmQw8pMP1CI="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="basedir" value="/home/alex/Repositories/hive/ql"/>
    <property name="file.separator" value="/"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/ql/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/ql/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/ql/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/ql/target"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="nondexStart" value="0"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/localfs/warehouse"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/ql/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="974622"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter46761498195801186.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/ql"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="test.output.overwrite" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="hive.root" value="/home/alex/Repositories/hive/ql/../"/>
  </properties>
  <testcase name="testConcatenate" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="15.252">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTbl set b = 4 failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-out><![CDATA[log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7ca8d498.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7ca8d498.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
]]></system-out>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,070614 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@3ad83a66
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,019833 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", disableAnsi="null", PatternSelector=null, alwaysWriteExceptions="null", footer="null", header="null", Configuration(HiveLog4j2Test), pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", noConsoleNoAnsi="null", Replace=null)
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", target="SYSTEM_ERR", direct="null", bufferSize="null", immediateFlush="null", bufferedIo="null", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", ignoreExceptions="null", ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", noConsoleNoAnsi="null", footer="null", disableAnsi="null", Replace=null, alwaysWriteExceptions="null", charset="null", header="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", maxRandomDelay="null", modulate="true")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(={}, stopCustomActionsOnError="null", min="null", max="30", fileIndex="null", tempCompressedFilePattern="null", compressionLevel="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(append="null", fileGroup="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), filePermissions="null", advertiseURI="null", advertise="null", fileOwner="null", fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", immediateFlush="null", bufferSize="null", bufferedIo="null", name="DRFA", Configuration(HiveLog4j2Test), ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ={}, Filter=null)
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 964763574
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T01:31:01.207-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-01:31:27.610, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-01:31:27.611, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7c1e2a2d
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@6d60fe40
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40] started OK.
2024-04-24T01:31:27,746  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T01:31:28,086  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T01:31:28,144  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:31:28,144  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:31:28,145  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:31:28,145  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:31:28,145  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T01:31:28,145  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:31:28,145  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:31:28,146  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:31:28,146  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:31:28,146  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:31:28,146  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:31:28,226  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:31:28,231  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T01:31:28,755  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:31:28,758  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T01:31:28,761  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:31:28,763  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T01:31:28,767  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:31:28,768  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T01:31:28,932  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-24T01:31:28,940  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/ql/target/tmp/junit_metastore_db;create=true
Hive Session ID = e3c75583-40e4-49c1-b726-ae07ce5f53c3
2024-04-24T01:31:29,909  INFO [main] SessionState: Hive Session ID = e3c75583-40e4-49c1-b726-ae07ce5f53c3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:31:29,920  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T01:31:30,290  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/e3c75583-40e4-49c1-b726-ae07ce5f53c3
2024-04-24T01:31:30,293  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3
2024-04-24T01:31:30,296  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/e3c75583-40e4-49c1-b726-ae07ce5f53c3/_tmp_space.db
2024-04-24T01:31:30,326  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=e3c75583-40e4-49c1-b726-ae07ce5f53c3, clientType=HIVECLI]
2024-04-24T01:31:30,360  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T01:31:30,485  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T01:31:30,517  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T01:31:30,520  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T01:31:30,520  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T01:31:30,521  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T01:31:30,524  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T01:31:30,526  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T01:31:30,527  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T01:31:30,931  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T01:31:30,932  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066, with PersistenceManager: null will be shutdown
2024-04-24T01:31:30,956  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45c9b3 created in the thread with id: 1
2024-04-24T01:31:33,065  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066 from thread id: 1
2024-04-24T01:31:33,080  INFO [main] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-24T01:31:33,107  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T01:31:33,151  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T01:31:33,178  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T01:31:33,182  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T01:31:33,279  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T01:31:33,284  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T01:31:33,285  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T01:31:33,286  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T01:31:33,287  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T01:31:33,291  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T01:31:33,294  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T01:31:33,298  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T01:31:33,440  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T01:31:33,486  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T01:31:33,516  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996): drop table if exists acidTbl
2024-04-24T01:31:34,386  INFO [main] reflections.Reflections: Reflections took 213 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:31:34,551  INFO [main] reflections.Reflections: Reflections took 132 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:31:34,690  INFO [main] reflections.Reflections: Reflections took 132 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:31:34,719  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-24T01:31:34,732  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-24T01:31:34,742  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:34,891  INFO [main] reflections.Reflections: Reflections took 129 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T01:31:34,927  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:34,928  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:34,931  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:34,931  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=1, openTxn_(String, TxnType)=32, isCompatibleWith_(Configuration)=1, getValidTxns_(long)=7}
2024-04-24T01:31:34,932  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996); Time taken: 1.417 seconds
2024-04-24T01:31:34,934  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996
2024-04-24T01:31:34,934  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:34,937  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996): drop table if exists acidTbl
2024-04-24T01:31:34,940  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:34,941  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:34,957  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:34,957  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:34,958  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996); Time taken: 0.02 seconds
2024-04-24T01:31:34,958  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013133_b4c4f3ec-6ec9-470c-b93a-bc0468769996
2024-04-24T01:31:34,969  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-24T01:31:34,983  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:34,986  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-24T01:31:34,988  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T01:31:34,989  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83): drop table if exists acidTblPart
2024-04-24T01:31:34,993  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-24T01:31:34,994  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-24T01:31:34,995  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:35,000  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,000  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,000  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,001  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=4, commitTxn_(CommitTxnRequest)=29, getValidTxns_(long)=1, flushCache_()=0}
2024-04-24T01:31:35,001  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83); Time taken: 0.012 seconds
2024-04-24T01:31:35,001  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83
2024-04-24T01:31:35,001  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:35,001  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83): drop table if exists acidTblPart
2024-04-24T01:31:35,002  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,002  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:35,007  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,007  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,007  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83); Time taken: 0.005 seconds
2024-04-24T01:31:35,007  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013134_c0749217-81ee-45a0-9f0e-9468c1f94d83
2024-04-24T01:31:35,014  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-24T01:31:35,023  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,023  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-24T01:31:35,025  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T01:31:35,025  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e): drop table if exists acidTbl2
2024-04-24T01:31:35,030  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-24T01:31:35,030  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-24T01:31:35,032  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T01:31:35,037  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,037  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,037  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,037  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=17, flushCache_()=0, openTxn_(String, TxnType)=3, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=2}
2024-04-24T01:31:35,037  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e); Time taken: 0.012 seconds
2024-04-24T01:31:35,038  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e
2024-04-24T01:31:35,038  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:35,038  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e): drop table if exists acidTbl2
2024-04-24T01:31:35,038  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T01:31:35,043  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,043  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,044  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e); Time taken: 0.005 seconds
2024-04-24T01:31:35,044  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_aec5ce40-fa5e-44db-bd18-2e612d9ebf0e
2024-04-24T01:31:35,052  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-24T01:31:35,061  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,062  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-24T01:31:35,063  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T01:31:35,063  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:35,068  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-24T01:31:35,068  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-24T01:31:35,070  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:35,074  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,075  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,075  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,075  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=18, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, flushCache_()=0}
2024-04-24T01:31:35,075  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53); Time taken: 0.012 seconds
2024-04-24T01:31:35,076  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53
2024-04-24T01:31:35,076  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:35,076  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:35,076  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,076  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:35,081  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,081  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,082  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53); Time taken: 0.005 seconds
2024-04-24T01:31:35,082  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_965c1b6f-99c8-43e3-a06a-f4611ad59d53
2024-04-24T01:31:35,090  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-24T01:31:35,099  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,099  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-24T01:31:35,100  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:35,101  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:35,105  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-24T01:31:35,106  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-24T01:31:35,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:35,112  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,112  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,112  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,112  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=1, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=18}
2024-04-24T01:31:35,113  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e); Time taken: 0.011 seconds
2024-04-24T01:31:35,113  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e
2024-04-24T01:31:35,113  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:35,113  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:35,113  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:35,118  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,118  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,119  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e); Time taken: 0.005 seconds
2024-04-24T01:31:35,119  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_282099db-5e40-433a-8d59-f4151da6809e
2024-04-24T01:31:35,127  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-24T01:31:35,136  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,136  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-24T01:31:35,137  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T01:31:35,138  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3): drop table if exists nonAcidNonBucket
2024-04-24T01:31:35,142  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-24T01:31:35,142  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-24T01:31:35,144  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:35,149  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,149  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,149  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,149  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=18, openTxn_(String, TxnType)=3, flushCache_()=0, isCompatibleWith_(Configuration)=2}
2024-04-24T01:31:35,150  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3); Time taken: 0.011 seconds
2024-04-24T01:31:35,150  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3
2024-04-24T01:31:35,150  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:35,150  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3): drop table if exists nonAcidNonBucket
2024-04-24T01:31:35,151  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:35,156  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,156  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,156  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3); Time taken: 0.006 seconds
2024-04-24T01:31:35,156  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_401464a6-98a7-4454-8307-44fbc035cfe3
2024-04-24T01:31:35,164  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-24T01:31:35,173  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,174  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-24T01:31:35,175  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,175  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,251  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-24T01:31:35,252  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-24T01:31:35,253  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:35,256  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:35,273  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-24T01:31:35,314  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:35,325  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:35,325  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,325  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,325  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,326  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=17, getDatabase_(String)=4, getValidWriteIds_(List, String)=11, getValidTxns_(long)=1, flushCache_()=0, isCompatibleWith_(Configuration)=2, openTxn_(String, TxnType)=4}
2024-04-24T01:31:35,326  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff); Time taken: 0.15 seconds
2024-04-24T01:31:35,326  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff
2024-04-24T01:31:35,333  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff
2024-04-24T01:31:35,381  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T01:31:35,381  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:35,384  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,384  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,503  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713947495, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, numFilesErasureCoded=0, numRows=0, totalSize=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, rawDataSize=0, transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T01:31:35,516  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:35,623  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,623  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=120, isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:35,624  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff); Time taken: 0.239 seconds
2024-04-24T01:31:35,624  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_f4198397-89ad-4d7e-a0c7-be13202ffaff
2024-04-24T01:31:35,629  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-24T01:31:35,638  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,639  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-24T01:31:35,640  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,640  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,647  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-24T01:31:35,647  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-24T01:31:35,649  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:35,649  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:35,652  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-24T01:31:35,653  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:35,655  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:35,656  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,656  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,656  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,656  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=15, getDatabase_(String)=3, flushCache_()=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, getValidWriteIds_(List, String)=3}
2024-04-24T01:31:35,656  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd); Time taken: 0.016 seconds
2024-04-24T01:31:35,657  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd
2024-04-24T01:31:35,657  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd
2024-04-24T01:31:35,685  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T01:31:35,685  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:35,687  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,687  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713947495, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{transactional=true, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T01:31:35,698  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart
2024-04-24T01:31:35,727  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,727  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=39}
2024-04-24T01:31:35,728  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd); Time taken: 0.04 seconds
2024-04-24T01:31:35,728  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_900e3bc9-997d-4128-91cc-6a73e775c3cd
2024-04-24T01:31:35,734  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-24T01:31:35,743  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,745  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-24T01:31:35,746  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,747  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,751  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 2
2024-04-24T01:31:35,752  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-24T01:31:35,753  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:35,753  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:35,757  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-24T01:31:35,757  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:35,759  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:35,759  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,760  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,760  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,760  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=2, getValidWriteIds_(List, String)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, flushCache_()=0, commitTxn_(CommitTxnRequest)=18, openTxn_(String, TxnType)=4}
2024-04-24T01:31:35,760  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2); Time taken: 0.013 seconds
2024-04-24T01:31:35,760  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2
2024-04-24T01:31:35,761  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2
2024-04-24T01:31:35,788  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T01:31:35,789  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:35,789  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,789  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,790  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713947495, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false, numFilesErasureCoded=0, numRows=0, numFiles=0, rawDataSize=0, bucketing_version=2, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:35,799  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidorctbl
2024-04-24T01:31:35,831  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,831  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=40, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,831  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2); Time taken: 0.042 seconds
2024-04-24T01:31:35,831  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_50cc6a69-32f7-4b78-be15-84892e64c1e2
2024-04-24T01:31:35,837  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-24T01:31:35,846  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,846  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-24T01:31:35,847  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,847  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,851  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 2
2024-04-24T01:31:35,852  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-24T01:31:35,853  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:35,853  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:35,857  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-24T01:31:35,857  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:35,860  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:35,860  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,860  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,860  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,860  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=16, flushCache_()=0, getDatabase_(String)=3, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getValidWriteIds_(List, String)=4}
2024-04-24T01:31:35,860  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548); Time taken: 0.013 seconds
2024-04-24T01:31:35,861  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548
2024-04-24T01:31:35,861  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548
2024-04-24T01:31:35,888  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T01:31:35,889  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:35,889  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:35,889  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713947495, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFiles=0, rawDataSize=0, totalSize=0, numFilesErasureCoded=0, transactional=false, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:35,899  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidorctbl2
2024-04-24T01:31:35,927  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,927  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=37, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,928  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548); Time taken: 0.038 seconds
2024-04-24T01:31:35,928  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_c4526f29-d6b8-40f7-bc29-fc9dd8401548
2024-04-24T01:31:35,933  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-24T01:31:35,942  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:35,942  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-24T01:31:35,943  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,944  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,948  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 2
2024-04-24T01:31:35,948  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-24T01:31:35,950  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:35,950  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:35,954  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-24T01:31:35,954  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:35,957  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:35,957  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:35,957  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:35,957  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:35,957  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=3, isCompatibleWith_(Configuration)=0, flushCache_()=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=15, getDatabase_(String)=2, getValidTxns_(long)=1}
2024-04-24T01:31:35,957  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510); Time taken: 0.013 seconds
2024-04-24T01:31:35,957  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510
2024-04-24T01:31:35,958  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510
2024-04-24T01:31:35,985  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T01:31:35,985  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:35,986  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:35,986  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:35,988  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/e3c75583-40e4-49c1-b726-ae07ce5f53c3/_tmp_space.db/a8f1b031-02f9-44c8-85b7-bcfc98e20ff5
2024-04-24T01:31:35,992  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:35,992  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=4, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:35,993  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510); Time taken: 0.006 seconds
2024-04-24T01:31:35,993  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013135_1f080891-fc00-4827-8469-fe220641b510
2024-04-24T01:31:35,998  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-24T01:31:36,007  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:36,007  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-24T01:31:36,008  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:36,009  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:36,013  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 3
2024-04-24T01:31:36,013  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-24T01:31:36,014  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:36,014  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:36,018  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-24T01:31:36,018  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:36,021  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:36,021  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:36,021  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:36,021  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:36,021  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=15, flushCache_()=0, isCompatibleWith_(Configuration)=1, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=3, getDatabase_(String)=2}
2024-04-24T01:31:36,021  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2); Time taken: 0.012 seconds
2024-04-24T01:31:36,021  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2
2024-04-24T01:31:36,022  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2
2024-04-24T01:31:36,047  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2 LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T01:31:36,047  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:36,048  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:36,048  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:36,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713947496, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, rawDataSize=0, transactional=false, numFilesErasureCoded=0, numFiles=0, bucketing_version=2, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:36,058  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidnonbucket
2024-04-24T01:31:36,082  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:36,083  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=33}
2024-04-24T01:31:36,083  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2); Time taken: 0.035 seconds
2024-04-24T01:31:36,083  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013136_e998ee87-0577-4ba6-acc0-af736e4fcba2
2024-04-24T01:31:36,088  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-24T01:31:36,097  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:36,097  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-24T01:31:36,098  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Initializing local cache in HiveMetaStoreClient...
2024-04-24T01:31:36,123  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Local cache initialized in HiveMetaStoreClient: com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalManualCache@70ee1963
2024-04-24T01:31:36,123  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTbl values(1,2),(4,5)
2024-04-24T01:31:36,124  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1): insert into acidTbl values(1,2),(4,5)
2024-04-24T01:31:36,130  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 6
2024-04-24T01:31:36,130  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-24T01:31:36,131  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:36,131  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:36,674  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,674  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,674  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,676  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,679  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,682  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,688  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T01:31:36,732  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:36,775  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:36,776  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:31:36,776  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:36,776  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:36,776  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:36,779  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:36,792  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:36,792  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:31:36,793  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-24T01:31:37,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T01:31:38,498  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:38,498  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:38,498  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:38,500  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T01:31:38,503  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:38,503  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:38,505  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:38,506  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:38,519  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:38,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-24T01:31:38,560  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-24T01:31:38,583  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-24T01:31:38,584  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtbl (txnIds: [13])
2024-04-24T01:31:38,591  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:31:38,648  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-24T01:31:38,648  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-24T01:31:38,659  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T01:31:38,671  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T01:31:38,710  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:38,724  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:38,753  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T01:31:38,759  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T01:31:38,761  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T01:31:38,761  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:38,761  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:38,761  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null)], properties:null)
2024-04-24T01:31:38,761  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:38,761  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, getValidTxns_(long)=1, getTable_(GetTableRequest)=86, allocateTableWriteId_(long, String, String)=15, getNotNullConstraints_(NotNullConstraintsRequest)=5, commitTxn_(CommitTxnRequest)=15, flushCache_()=0, getCheckConstraints_(CheckConstraintsRequest)=4, isCompatibleWith_(Configuration)=0, getValidWriteIds_(List, String)=6, getAllTableConstraints_(AllTableConstraintsRequest)=51}
2024-04-24T01:31:38,761  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1); Time taken: 2.637 seconds
2024-04-24T01:31:38,762  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1
2024-04-24T01:31:38,762  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1
2024-04-24T01:31:38,804  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1 LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T01:31:38,804  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-24T01:31:38,809  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1): insert into acidTbl values(1,2),(4,5)
2024-04-24T01:31:38,810  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1
2024-04-24T01:31:38,810  INFO [main] ql.Driver: Query ID = alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1
Total jobs = 1
2024-04-24T01:31:38,810  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T01:31:38,810  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T01:31:38,998  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T01:31:38,999  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T01:31:38,999  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T01:31:38,999  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T01:31:38,999  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T01:31:38,999  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T01:31:38,999  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T01:31:38,999  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T01:31:39,007  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T01:31:39,009  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-24T01:31:39,009  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1/dummy_path
2024-04-24T01:31:39,098  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T01:31:39,121  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,28KB
2024-04-24T01:31:39,128  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T01:31:39,134  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T01:31:39,237  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T01:31:39,251  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T01:31:39,266  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T01:31:39,266  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T01:31:39,279  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1/-mr-10000
2024-04-24T01:31:39,291  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:39,333  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T01:31:39,342  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T01:31:39,347  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-24T01:31:39,347  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-24T01:31:39,347  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1/dummy_path
2024-04-24T01:31:39,347  INFO [main] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-24T01:31:39,352  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T01:31:39,381  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T01:31:39,471  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1841178267_0001
2024-04-24T01:31:39,471  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T01:31:39,634  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T01:31:39,636  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T01:31:39,636  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T01:31:39,637  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T01:31:39,650  INFO [Thread-72] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T01:31:39,654  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1841178267_0001_m_000000_0
2024-04-24T01:31:39,689  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T01:31:39,697  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1/dummy_path/null:0+1
2024-04-24T01:31:39,703  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T01:31:39,728  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,28KB
2024-04-24T01:31:39,736  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T01:31:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T01:31:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T01:31:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T01:31:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T01:31:39,748  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T01:31:39,751  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T01:31:39,756  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T01:31:39,757  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T01:31:39,760  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T01:31:39,760  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T01:31:39,763  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T01:31:39,763  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-24T01:31:39,764  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-24T01:31:39,764  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int>
2024-04-24T01:31:39,764  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[4]
2024-04-24T01:31:39,764  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T01:31:39,784  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [reducesinkkey0] num distributions: 1
2024-04-24T01:31:39,786  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: records written - 1
2024-04-24T01:31:39,786  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T01:31:39,786  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T01:31:39,786  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_UDTF_2:2, 
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_3:2, 
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[4]
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: Total records written - 2. abort - false
2024-04-24T01:31:39,787  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_OPERATOR_RS_4:2, RECORDS_OUT_INTERMEDIATE:2, 
2024-04-24T01:31:39,793  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T01:31:39,793  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T01:31:39,793  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T01:31:39,793  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 32; bufvoid = 104857600
2024-04-24T01:31:39,793  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-24T01:31:39,810  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T01:31:39,822  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1841178267_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T01:31:39,823  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T01:31:39,823  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1841178267_0001_m_000000_0' done.
2024-04-24T01:31:39,825  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1841178267_0001_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=5737
		FILE: Number of bytes written=1188104
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=32
		Map output materialized bytes=48
		Input split bytes=361
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=973602816
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_4=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5332
2024-04-24T01:31:39,826  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1841178267_0001_m_000000_0
2024-04-24T01:31:39,827  INFO [Thread-72] mapred.LocalJobRunner: map task executor complete.
2024-04-24T01:31:39,832  INFO [Thread-72] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T01:31:39,833  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1841178267_0001_r_000000_0
2024-04-24T01:31:39,840  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T01:31:39,842  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55fbab46
2024-04-24T01:31:39,843  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:39,857  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T01:31:39,860  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1841178267_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T01:31:39,885  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1841178267_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T01:31:39,887  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1841178267_0001_m_000000_0
2024-04-24T01:31:39,888  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T01:31:39,889  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T01:31:39,890  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:39,890  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T01:31:39,901  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:39,901  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T01:31:39,904  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T01:31:39,904  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T01:31:39,905  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T01:31:39,905  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:39,905  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T01:31:39,906  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:39,908  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T01:31:39,912  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T01:31:39,914  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T01:31:39,914  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-24T01:31:39,914  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-24T01:31:39,914  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T01:31:39,915  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@5fa24d0b, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1841178267_0001/job_local1841178267_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@28061f56
2024-04-24T01:31:39,919  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-24T01:31:39,919  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_5:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:39,919  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T01:31:39,919  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 0
2024-04-24T01:31:39,920  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:39,920  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:39,920  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse
2024-04-24T01:31:39,943  INFO [pool-8-thread-1] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_6:0, TOTAL_TABLE_ROWS_WRITTEN:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_1_default.acidtbl:0, 
2024-04-24T01:31:39,944  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1841178267_0001_r_000000_0 is done. And is in the process of committing
2024-04-24T01:31:39,945  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T01:31:39,945  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1841178267_0001_r_000000_0' done.
2024-04-24T01:31:39,945  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1841178267_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=11820
		FILE: Number of bytes written=1188163
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=973602816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T01:31:39,945  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1841178267_0001_r_000000_0
2024-04-24T01:31:39,945  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1841178267_0001_r_000001_0
2024-04-24T01:31:39,947  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T01:31:39,947  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9b2593d
2024-04-24T01:31:39,947  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:39,948  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T01:31:39,949  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1841178267_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T01:31:39,952  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1841178267_0001_m_000000_0 decomp: 38 len: 42 to MEMORY
2024-04-24T01:31:39,952  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 38 bytes from map-output for attempt_local1841178267_0001_m_000000_0
2024-04-24T01:31:39,952  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->38
2024-04-24T01:31:39,953  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T01:31:39,953  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:39,953  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T01:31:39,960  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:39,960  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-24T01:31:39,962  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 38 bytes to disk to satisfy reduce memory limit
2024-04-24T01:31:39,963  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 42 bytes from disk
2024-04-24T01:31:39,963  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T01:31:39,963  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:39,963  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-24T01:31:39,963  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:39,964  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T01:31:39,966  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T01:31:39,968  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T01:31:39,968  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-24T01:31:39,968  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-24T01:31:39,968  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T01:31:39,968  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@5fa24d0b, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1841178267_0001/job_local1841178267_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@434336c9
2024-04-24T01:31:39,970  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:39,970  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:39,970  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse
2024-04-24T01:31:39,971  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-24T01:31:39,983  INFO [pool-8-thread-1] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-24T01:31:39,988  INFO [pool-8-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T01:31:40,035  INFO [pool-8-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T01:31:40,049  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-24T01:31:40,049  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_5:2, 
2024-04-24T01:31:40,049  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T01:31:40,049  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-24T01:31:40,088  INFO [pool-8-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-24T01:31:40,102  INFO [pool-8-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.acidtbl:2, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_6:2, TOTAL_TABLE_ROWS_WRITTEN:2, 
2024-04-24T01:31:40,103  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1841178267_0001_r_000001_0 is done. And is in the process of committing
2024-04-24T01:31:40,104  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T01:31:40,104  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1841178267_0001_r_000001_0' done.
2024-04-24T01:31:40,104  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1841178267_0001_r_000001_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=17933
		FILE: Number of bytes written=1189248
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=42
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=973602816
	HIVE
		CREATED_FILES=1
		RECORDS_OUT_1_default.acidtbl=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_5=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T01:31:40,104  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1841178267_0001_r_000001_0
2024-04-24T01:31:40,105  INFO [Thread-72] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 01:31:40,654 Stage-1 map = 100%,  reduce = 100%
2024-04-24T01:31:40,655  INFO [main] exec.Task: 2024-04-24 01:31:40,654 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1841178267_0001
2024-04-24T01:31:40,660  INFO [main] exec.Task: Ended Job = job_local1841178267_0001
2024-04-24T01:31:40,662  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with attemptId 0.
2024-04-24T01:31:40,663  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest
2024-04-24T01:31:40,664  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000
2024-04-24T01:31:40,666  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtbl
2024-04-24T01:31:40,667  INFO [main] exec.Task: Loading data to table default.acidtbl from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:40,667  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,680  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,682  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,696  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-24T01:31:40,761  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T01:31:40,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,775  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,775  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T01:31:40,775  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1/-mr-10000
2024-04-24T01:31:40,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,790  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,806  WARN [main] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T01:31:40,807  INFO [main] FileOperations: Read stats for default.acidtbl/, numRows, true, 2, false: 
2024-04-24T01:31:40,807  INFO [main] FileOperations: Read stats for default.acidtbl/, rawDataSize, true, 0, false: 
2024-04-24T01:31:40,808  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-24T01:31:40,842  INFO [main] FileOperations: Read stats for default.acidtbl/, insertCount, true, 2, false: 
2024-04-24T01:31:40,842  INFO [main] FileOperations: Read stats for default.acidtbl/, updateCount, true, 0, false: 
2024-04-24T01:31:40,842  INFO [main] FileOperations: Read stats for default.acidtbl/, deleteCount, true, 0, false: 
2024-04-24T01:31:40,846  INFO [main] stats.BasicStatsTask: Table default.acidtbl stats: [numFiles=1, numRows=2, totalSize=699, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T01:31:40,846  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:40,847  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=4, alter_table_(String, String, String, Table, EnvironmentContext, String)=98, getTable_(GetTableRequest)=53}
MapReduce Jobs Launched: 
2024-04-24T01:31:40,847  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T01:31:40,853  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T01:31:40,854  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T01:31:40,854  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1); Time taken: 2.037 seconds
2024-04-24T01:31:40,854  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013136_e5fe72e4-9a11-48d7-ba3b-c781a12f98b1
2024-04-24T01:31:40,868  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:40,870  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-24T01:31:40,871  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTbl set b = 4
2024-04-24T01:31:40,871  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1
2024-04-24T01:31:40,872  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/e3c75583-40e4-49c1-b726-ae07ce5f53c3/hive_2024-04-24_01-31-36_123_8132842935204963015-1 on fs with scheme file
2024-04-24T01:31:40,873  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013140_a0d7c089-d5f0-4743-abaf-1505d1e89400): update acidTbl set b = 4
2024-04-24T01:31:40,886  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-24T01:31:40,887  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-24T01:31:40,890  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-24T01:31:40,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:40,902  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,903  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTbl set b = 4> as 
<insert into table `default`.`acidTbl` select ROW__ID,`a`,`b` from `default`.`acidTbl` sort by ROW__ID >
2024-04-24T01:31:40,905  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T01:31:40,910  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:40,923  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,923  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T01:31:40,923  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T01:31:40,924  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,935  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,935  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T01:31:40,935  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T01:31:40,936  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:40,950  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:40,950  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T01:31:40,950  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-24T01:31:40,966  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-24T01:31:40,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-24T01:31:41,112  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtbl, projIndxSet: [0], allowMissingStats: true
2024-04-24T01:31:41,119  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:41,134  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,136  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T01:31:41,150  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.acidtbl	
2024-04-24T01:31:41,172  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtbl, Columns: a
No Stats for default@acidtbl, Columns: a
2024-04-24T01:31:41,172  INFO [main] SessionState: No Stats for default@acidtbl, Columns: a
2024-04-24T01:31:41,238  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T01:31:41,238  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T01:31:41,238  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T01:31:41,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:41,250  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,259 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T01:31:41,260 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-24T01:31:41,260  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T01:31:41,261 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T01:31:41,262  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,262  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=12, getValidTxns_(long)=3, flushCache_()=0, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=17, getValidWriteIds_(List, String)=6, getTableColumnStatistics_(String, String, List, String)=51, getTable_(GetTableRequest)=63, getAllTableConstraints_(AllTableConstraintsRequest)=8, getNotNullConstraints_(NotNullConstraintsRequest)=2, getCheckConstraints_(CheckConstraintsRequest)=2}
2024-04-24T01:31:41,263  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013140_a0d7c089-d5f0-4743-abaf-1505d1e89400); Time taken: 0.39 seconds
2024-04-24T01:31:41,263  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-24T01:31:41,268  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:41,279  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T01:31:41,279  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9): drop table if exists acidTbl
2024-04-24T01:31:41,283  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-24T01:31:41,283  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-24T01:31:41,285  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:41,296  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,296  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:41,296  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:41,296  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,296  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, getValidTxns_(long)=1, flushCache_()=0, rollbackTxn_(long)=15, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=11}
2024-04-24T01:31:41,297  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9); Time taken: 0.017 seconds
2024-04-24T01:31:41,297  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9
2024-04-24T01:31:41,298  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9
2024-04-24T01:31:41,326  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9 LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T01:31:41,326  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:41,326  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9): drop table if exists acidTbl
2024-04-24T01:31:41,327  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:41,327  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:41,340  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,340  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:41,354  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,354  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:41,564  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:41,565  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=224, getTable_(GetTableRequest)=13}
2024-04-24T01:31:41,565  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9); Time taken: 0.238 seconds
2024-04-24T01:31:41,565  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013141_58c8ca8b-edaa-4d4a-a62d-c3cb7ded27d9
2024-04-24T01:31:41,570  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-24T01:31:41,579  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:41,580  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-24T01:31:41,581  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T01:31:41,581  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e): drop table if exists acidTblPart
2024-04-24T01:31:41,586  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-24T01:31:41,586  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-24T01:31:41,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:41,624  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,624  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:41,624  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:41,624  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,625  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=16, flushCache_()=0, getTable_(GetTableRequest)=36, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=2}
2024-04-24T01:31:41,625  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e); Time taken: 0.043 seconds
2024-04-24T01:31:41,625  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e
2024-04-24T01:31:41,626  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e
2024-04-24T01:31:41,657  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T01:31:41,657  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:41,657  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e): drop table if exists acidTblPart
2024-04-24T01:31:41,657  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:41,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:41,670  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:41,682  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,682  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:41,750  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:41,750  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=80, getTable_(GetTableRequest)=13, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:41,750  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e); Time taken: 0.093 seconds
2024-04-24T01:31:41,751  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013141_4771571e-57af-40fe-aa57-49a8b1f2113e
2024-04-24T01:31:41,756  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-24T01:31:41,764  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:41,764  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-24T01:31:41,765  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T01:31:41,765  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de): drop table if exists acidTbl2
2024-04-24T01:31:41,769  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-24T01:31:41,769  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-24T01:31:41,771  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:41,771  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:41,771  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,771  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, getValidTxns_(long)=1, getTable_(GetTableRequest)=1, isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-24T01:31:41,771  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de); Time taken: 0.006 seconds
2024-04-24T01:31:41,772  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de
2024-04-24T01:31:41,772  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:41,772  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de): drop table if exists acidTbl2
2024-04-24T01:31:41,772  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:41,773  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-24T01:31:41,773  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:41,773  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=0, dropTable_(String, String, boolean, boolean, boolean)=1}
2024-04-24T01:31:41,774  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de); Time taken: 0.001 seconds
2024-04-24T01:31:41,774  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013141_84cb2a09-4dc5-4b39-a64c-5b1dce6b67de
2024-04-24T01:31:41,781  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-24T01:31:41,788  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:41,788  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-24T01:31:41,789  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T01:31:41,790  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:41,793  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 14
2024-04-24T01:31:41,794  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-24T01:31:41,795  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:41,829  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,830  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:41,830  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:41,830  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,830  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=15, flushCache_()=0, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=34, openTxn_(String, TxnType)=3}
2024-04-24T01:31:41,830  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937); Time taken: 0.04 seconds
2024-04-24T01:31:41,830  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937
2024-04-24T01:31:41,831  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937
2024-04-24T01:31:41,853  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937 LockResponse(lockid:10, state:ACQUIRED)
2024-04-24T01:31:41,853  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:41,853  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:41,854  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:41,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:41,867  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,868  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:41,881  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,881  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:41,944  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:41,945  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13, dropTable_(String, String, boolean, boolean, boolean)=77}
2024-04-24T01:31:41,945  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937); Time taken: 0.091 seconds
2024-04-24T01:31:41,945  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013141_2b427e4d-ade8-4e9a-9aeb-8397373be937
2024-04-24T01:31:41,950  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-24T01:31:41,958  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:41,958  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-24T01:31:41,959  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:41,960  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:41,963  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-24T01:31:41,963  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-24T01:31:41,964  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:41,978  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:41,978  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:41,978  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:41,978  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:41,978  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, flushCache_()=0, commitTxn_(CommitTxnRequest)=14, getTable_(GetTableRequest)=14}
2024-04-24T01:31:41,978  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff); Time taken: 0.019 seconds
2024-04-24T01:31:41,979  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff
2024-04-24T01:31:41,979  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff
2024-04-24T01:31:42,001  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff LockResponse(lockid:11, state:ACQUIRED)
2024-04-24T01:31:42,001  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:42,001  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:42,002  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,002  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:42,018  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:42,018  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:42,033  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:42,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:42,083  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,084  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=65, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=16}
2024-04-24T01:31:42,084  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff); Time taken: 0.082 seconds
2024-04-24T01:31:42,084  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013141_5a17abc2-deaa-4968-9442-c1a8a2bfbfff
2024-04-24T01:31:42,089  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-24T01:31:42,098  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,098  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-24T01:31:42,099  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,100  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80): drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,103  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-24T01:31:42,104  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-24T01:31:42,105  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,122  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:42,122  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,122  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,122  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,122  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=4, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=15, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=17, flushCache_()=0}
2024-04-24T01:31:42,123  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80); Time taken: 0.022 seconds
2024-04-24T01:31:42,123  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80
2024-04-24T01:31:42,124  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80
2024-04-24T01:31:42,144  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80 LockResponse(lockid:12, state:ACQUIRED)
2024-04-24T01:31:42,144  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:42,144  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80): drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,145  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,145  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,161  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:42,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,176  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:42,177  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,231  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,231  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=16, dropTable_(String, String, boolean, boolean, boolean)=70}
2024-04-24T01:31:42,231  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80); Time taken: 0.087 seconds
2024-04-24T01:31:42,231  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_5ab888a7-63a5-4e49-b3c8-23912240ce80
2024-04-24T01:31:42,236  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-24T01:31:42,244  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,244  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-24T01:31:42,245  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenatePart" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="4.123">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTblPart set b = 4 where p='p1' failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T01:31:42,347  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T01:31:42,348  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T01:31:42,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T01:31:42,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T01:31:42,351  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
Hive Session ID = c0f93960-6913-43d0-94d2-c7b0fae9be2f
2024-04-24T01:31:42,353  INFO [main] SessionState: Hive Session ID = c0f93960-6913-43d0-94d2-c7b0fae9be2f
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:31:42,354  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T01:31:42,359  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/c0f93960-6913-43d0-94d2-c7b0fae9be2f
2024-04-24T01:31:42,361  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f
2024-04-24T01:31:42,364  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/c0f93960-6913-43d0-94d2-c7b0fae9be2f/_tmp_space.db
2024-04-24T01:31:42,364  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c0f93960-6913-43d0-94d2-c7b0fae9be2f, clientType=HIVECLI]
2024-04-24T01:31:42,364  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T01:31:42,365  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f): drop table if exists acidTbl
2024-04-24T01:31:42,375  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-24T01:31:42,375  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-24T01:31:42,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:42,381  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,381  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,381  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,382  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, getValidTxns_(long)=2, openTxn_(String, TxnType)=10, flushCache_()=0, isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:42,382  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f); Time taken: 0.016 seconds
2024-04-24T01:31:42,382  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f
2024-04-24T01:31:42,382  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,382  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f): drop table if exists acidTbl
2024-04-24T01:31:42,382  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,383  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:42,387  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,387  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:42,387  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f); Time taken: 0.005 seconds
2024-04-24T01:31:42,387  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_862f36f8-beb8-4088-baba-898afb458c9f
2024-04-24T01:31:42,393  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-24T01:31:42,399  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,399  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-24T01:31:42,400  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T01:31:42,401  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130): drop table if exists acidTblPart
2024-04-24T01:31:42,404  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-24T01:31:42,404  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-24T01:31:42,405  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:42,409  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,409  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,409  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,409  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=0, flushCache_()=0}
2024-04-24T01:31:42,409  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130); Time taken: 0.008 seconds
2024-04-24T01:31:42,409  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130
2024-04-24T01:31:42,409  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,409  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130): drop table if exists acidTblPart
2024-04-24T01:31:42,410  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,410  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:42,414  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,414  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,414  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130); Time taken: 0.005 seconds
2024-04-24T01:31:42,414  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_b715d9b0-96b8-40bf-9b26-d6401120c130
2024-04-24T01:31:42,420  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-24T01:31:42,427  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,427  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-24T01:31:42,428  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T01:31:42,428  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d): drop table if exists acidTbl2
2024-04-24T01:31:42,431  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-24T01:31:42,431  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-24T01:31:42,432  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T01:31:42,436  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,436  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,436  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,436  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=2, flushCache_()=0}
2024-04-24T01:31:42,437  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d); Time taken: 0.008 seconds
2024-04-24T01:31:42,437  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d
2024-04-24T01:31:42,437  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,437  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d): drop table if exists acidTbl2
2024-04-24T01:31:42,437  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,437  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T01:31:42,441  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,441  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,441  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d); Time taken: 0.004 seconds
2024-04-24T01:31:42,441  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_71c77d63-a337-4967-8e9e-c0e838784d2d
2024-04-24T01:31:42,447  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-24T01:31:42,453  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,453  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-24T01:31:42,453  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T01:31:42,454  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:42,457  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-24T01:31:42,457  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-24T01:31:42,458  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:42,461  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,461  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,462  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,462  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, commitTxn_(CommitTxnRequest)=11, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=1, openTxn_(String, TxnType)=2}
2024-04-24T01:31:42,462  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2); Time taken: 0.008 seconds
2024-04-24T01:31:42,463  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2
2024-04-24T01:31:42,463  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,463  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:42,463  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:42,469  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,469  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,469  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2); Time taken: 0.006 seconds
2024-04-24T01:31:42,469  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_cb70ca23-e44c-47b5-b921-43a1b2562aa2
2024-04-24T01:31:42,475  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-24T01:31:42,485  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,485  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-24T01:31:42,486  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:42,487  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:42,490  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-24T01:31:42,491  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-24T01:31:42,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:42,496  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,496  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,496  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,496  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=16, flushCache_()=0, isCompatibleWith_(Configuration)=2}
2024-04-24T01:31:42,496  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273); Time taken: 0.009 seconds
2024-04-24T01:31:42,496  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273
2024-04-24T01:31:42,497  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,497  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:42,497  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,497  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:42,501  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,501  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,501  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273); Time taken: 0.004 seconds
2024-04-24T01:31:42,501  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_e588492c-b415-4653-99f2-f2685bb5d273
2024-04-24T01:31:42,507  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-24T01:31:42,517  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,517  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-24T01:31:42,518  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,518  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0): drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,522  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-24T01:31:42,523  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-24T01:31:42,524  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,529  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,529  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,529  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,529  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, openTxn_(String, TxnType)=4, flushCache_()=0, commitTxn_(CommitTxnRequest)=16, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,530  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0); Time taken: 0.011 seconds
2024-04-24T01:31:42,530  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0
2024-04-24T01:31:42,530  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:42,530  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0): drop table if exists nonAcidNonBucket
2024-04-24T01:31:42,530  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,531  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:42,536  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,536  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:42,537  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0); Time taken: 0.006 seconds
2024-04-24T01:31:42,537  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_73c504a7-df84-424b-9538-20daba46ebf0
2024-04-24T01:31:42,544  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-24T01:31:42,551  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,551  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-24T01:31:42,552  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,553  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,556  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-24T01:31:42,556  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-24T01:31:42,557  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,557  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,564  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-24T01:31:42,565  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,567  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,567  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,567  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,567  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,567  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=2, flushCache_()=1, getValidWriteIds_(List, String)=7, isCompatibleWith_(Configuration)=0, getDatabase_(String)=2, commitTxn_(CommitTxnRequest)=15, getValidTxns_(long)=0}
2024-04-24T01:31:42,567  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a); Time taken: 0.014 seconds
2024-04-24T01:31:42,568  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a
2024-04-24T01:31:42,568  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a
2024-04-24T01:31:42,593  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T01:31:42,593  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,594  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,594  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713947502, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, bucketing_version=2, rawDataSize=0, numFilesErasureCoded=0, totalSize=0, transactional=true, numFiles=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T01:31:42,605  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtbl
2024-04-24T01:31:42,654  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,654  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=59, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,655  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a); Time taken: 0.06 seconds
2024-04-24T01:31:42,655  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_6d7408b3-2950-41ed-9eeb-ece5a619814a
2024-04-24T01:31:42,659  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-24T01:31:42,667  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,669  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-24T01:31:42,670  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,670  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,674  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-24T01:31:42,674  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-24T01:31:42,675  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,675  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,678  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-24T01:31:42,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,681  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,681  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,681  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,681  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,681  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getValidWriteIds_(List, String)=3, commitTxn_(CommitTxnRequest)=14, openTxn_(String, TxnType)=2, getDatabase_(String)=2, flushCache_()=0, getValidTxns_(long)=1}
2024-04-24T01:31:42,681  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac); Time taken: 0.011 seconds
2024-04-24T01:31:42,682  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac
2024-04-24T01:31:42,682  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac
2024-04-24T01:31:42,701  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T01:31:42,701  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,702  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,702  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,703  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713947502, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{bucketing_version=2, transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T01:31:42,711  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart
2024-04-24T01:31:42,733  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,734  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=30}
2024-04-24T01:31:42,734  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac); Time taken: 0.031 seconds
2024-04-24T01:31:42,734  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_fdb5f5ba-4943-4ebc-a16c-544b9f686eac
2024-04-24T01:31:42,739  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-24T01:31:42,746  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,746  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-24T01:31:42,747  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,747  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,750  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 1
2024-04-24T01:31:42,750  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-24T01:31:42,751  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,751  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,754  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-24T01:31:42,754  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,756  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,756  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,756  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,756  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,757  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=12, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=2, isCompatibleWith_(Configuration)=1, getValidTxns_(long)=0, flushCache_()=0, getDatabase_(String)=2}
2024-04-24T01:31:42,757  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9); Time taken: 0.009 seconds
2024-04-24T01:31:42,757  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9
2024-04-24T01:31:42,757  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9
2024-04-24T01:31:42,775  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T01:31:42,775  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,775  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,775  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,776  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713947502, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, totalSize=0, numRows=0, transactional=false, numFilesErasureCoded=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, rawDataSize=0, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:42,784  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidorctbl
2024-04-24T01:31:42,805  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,806  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=29}
2024-04-24T01:31:42,806  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9); Time taken: 0.03 seconds
2024-04-24T01:31:42,806  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_c88d71d7-8739-4a8a-b0ef-9bc24a66aee9
2024-04-24T01:31:42,811  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-24T01:31:42,818  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,818  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-24T01:31:42,819  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,820  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,822  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 1
2024-04-24T01:31:42,823  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-24T01:31:42,824  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,824  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,826  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-24T01:31:42,827  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,829  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,829  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,829  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,829  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,829  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, openTxn_(String, TxnType)=2, getValidWriteIds_(List, String)=2, getDatabase_(String)=3, isCompatibleWith_(Configuration)=0, flushCache_()=0, getValidTxns_(long)=1}
2024-04-24T01:31:42,829  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e); Time taken: 0.009 seconds
2024-04-24T01:31:42,830  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e
2024-04-24T01:31:42,830  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e
2024-04-24T01:31:42,848  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T01:31:42,848  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,848  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,849  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,850  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713947502, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, totalSize=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false, numFiles=0, numRows=0, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:42,857  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidorctbl2
2024-04-24T01:31:42,879  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,879  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=30, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,879  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e); Time taken: 0.031 seconds
2024-04-24T01:31:42,879  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_29450bf3-6cc9-415d-9778-57fc013b158e
2024-04-24T01:31:42,884  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-24T01:31:42,892  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,893  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-24T01:31:42,893  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,894  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,897  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 1
2024-04-24T01:31:42,898  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-24T01:31:42,899  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,899  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,902  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-24T01:31:42,902  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,905  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,905  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,905  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,905  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,905  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, commitTxn_(CommitTxnRequest)=14, getValidTxns_(long)=1, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=3, getDatabase_(String)=2, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:42,905  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9); Time taken: 0.011 seconds
2024-04-24T01:31:42,905  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9
2024-04-24T01:31:42,906  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9
2024-04-24T01:31:42,925  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T01:31:42,925  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,926  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T01:31:42,926  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,927  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/c0f93960-6913-43d0-94d2-c7b0fae9be2f/_tmp_space.db/7bbac3d3-d8e0-49de-8f5b-7524545c1183
2024-04-24T01:31:42,931  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:42,931  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=3}
2024-04-24T01:31:42,931  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9); Time taken: 0.005 seconds
2024-04-24T01:31:42,931  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_654125b3-d977-4444-abb2-5d14b5c7eaf9
2024-04-24T01:31:42,935  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-24T01:31:42,943  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:42,943  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-24T01:31:42,944  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,944  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,948  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 1
2024-04-24T01:31:42,948  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-24T01:31:42,949  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:42,949  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:42,952  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-24T01:31:42,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T01:31:42,954  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:42,954  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:42,955  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:42,955  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:42,955  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=13, getDatabase_(String)=2, openTxn_(String, TxnType)=3, getValidWriteIds_(List, String)=3}
2024-04-24T01:31:42,955  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77); Time taken: 0.011 seconds
2024-04-24T01:31:42,955  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77
2024-04-24T01:31:42,956  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77
2024-04-24T01:31:42,975  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77 LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T01:31:42,975  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T01:31:42,975  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T01:31:42,975  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:42,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713947502, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFilesErasureCoded=0, bucketing_version=2, numRows=0, transactional=false, rawDataSize=0, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T01:31:42,984  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/nonacidnonbucket
2024-04-24T01:31:43,005  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:43,005  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=29}
2024-04-24T01:31:43,005  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77); Time taken: 0.03 seconds
2024-04-24T01:31:43,005  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013142_1aeafe9c-9f26-45e7-9fb8-ede289650d77
2024-04-24T01:31:43,010  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-24T01:31:43,017  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:43,017  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-24T01:31:43,018  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T01:31:43,018  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T01:31:43,022  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 1
2024-04-24T01:31:43,022  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-24T01:31:43,023  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T01:31:43,023  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T01:31:43,027  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:43,052  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:43,053  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T01:31:43,053  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:43,053  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:43,053  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:43,053  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:43,064  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:43,064  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T01:31:43,064  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-24T01:31:43,088  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T01:31:43,196  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:43,196  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:43,196  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T01:31:43,197  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T01:31:43,201  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T01:31:43,201  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:43,201  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T01:31:43,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:43,213  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:43,217  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-24T01:31:43,218  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-24T01:31:43,228  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-24T01:31:43,229  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtblpart (txnIds: [13])
2024-04-24T01:31:43,230  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T01:31:43,237  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col1=Column[_col2], VALUE._col0=Column[_col1]}
2024-04-24T01:31:43,237  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {VALUE._col1=Column[_col2], VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-24T01:31:43,238  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T01:31:43,240  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T01:31:43,240  INFO [main] optimizer.SortedDynPartitionOptimizer: Removed RS_4 and SEL_5 as it was introduced by enforce bucketing/sorting.
2024-04-24T01:31:43,242  INFO [main] optimizer.SortedDynPartitionOptimizer: Inserted RS_7 and SEL_8 as parent of FS_6 and child of SEL_3
2024-04-24T01:31:43,256  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:43,269  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T01:31:43,270  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T01:31:43,271  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T01:31:43,271  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T01:31:43,271  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T01:31:43,271  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:43,271  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null), FieldSchema(name:col3, type:string, comment:null)], properties:null)
2024-04-24T01:31:43,271  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:43,271  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getNotNullConstraints_(NotNullConstraintsRequest)=1, openTxn_(String, TxnType)=2, getCheckConstraints_(CheckConstraintsRequest)=2, flushCache_()=1, getValidTxns_(long)=0, getValidWriteIds_(List, String)=6, allocateTableWriteId_(long, String, String)=8, getMetaConf_(String)=0, commitTxn_(CommitTxnRequest)=13, getAllTableConstraints_(AllTableConstraintsRequest)=43, isCompatibleWith_(Configuration)=2, getTable_(GetTableRequest)=62}
2024-04-24T01:31:43,271  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707); Time taken: 0.253 seconds
2024-04-24T01:31:43,272  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707
2024-04-24T01:31:43,272  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707
2024-04-24T01:31:43,303  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707 LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T01:31:43,303  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-24T01:31:43,306  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T01:31:43,307  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707
2024-04-24T01:31:43,307  INFO [main] ql.Driver: Query ID = alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707
Total jobs = 1
2024-04-24T01:31:43,307  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T01:31:43,307  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T01:31:43,471  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
2024-04-24T01:31:43,471  INFO [main] exec.Utilities: Not using thread pool for getContentSummary
2024-04-24T01:31:43,478  INFO [main] exec.Utilities: BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=1
Number of reduce tasks not specified. Estimated from input data size: 1
2024-04-24T01:31:43,478  INFO [main] exec.Task: Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
2024-04-24T01:31:43,478  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T01:31:43,478  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T01:31:43,478  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T01:31:43,478  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T01:31:43,478  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T01:31:43,478  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T01:31:43,481  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T01:31:43,481  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-24T01:31:43,481  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1/dummy_path
2024-04-24T01:31:43,491  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T01:31:43,495  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,61KB
2024-04-24T01:31:43,500  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T01:31:43,510  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 6,40KB
2024-04-24T01:31:43,512  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:43,516  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1/-mr-10000
2024-04-24T01:31:43,519  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:43,527  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T01:31:43,532  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T01:31:43,533  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-24T01:31:43,533  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-24T01:31:43,533  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1/dummy_path
2024-04-24T01:31:43,533  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T01:31:43,553  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T01:31:43,574  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local766931729_0002
2024-04-24T01:31:43,574  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T01:31:43,648  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T01:31:43,648  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T01:31:43,648  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T01:31:43,649  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T01:31:43,651  INFO [Thread-173] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T01:31:43,651  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local766931729_0002_m_000000_0
2024-04-24T01:31:43,655  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T01:31:43,655  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1/dummy_path/null:0+1
2024-04-24T01:31:43,658  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T01:31:43,661  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,61KB
2024-04-24T01:31:43,662  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 1
2024-04-24T01:31:43,666  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T01:31:43,666  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T01:31:43,666  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T01:31:43,666  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T01:31:43,666  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T01:31:43,667  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T01:31:43,667  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T01:31:43,667  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T01:31:43,668  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T01:31:43,668  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T01:31:43,668  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T01:31:43,668  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-24T01:31:43,669  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-24T01:31:43,669  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int,col3:string>
2024-04-24T01:31:43,669  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[7]
2024-04-24T01:31:43,669  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T01:31:43,670  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [_col2, _bucket_number, _col0] num distributions: 3
2024-04-24T01:31:43,670  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: records written - 1
2024-04-24T01:31:43,670  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T01:31:43,670  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:3, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_OPERATOR_UDTF_2:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_3:2, 
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[7]
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: Total records written - 2. abort - false
2024-04-24T01:31:43,671  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_OPERATOR_RS_7:2, RECORDS_OUT_INTERMEDIATE:2, 
2024-04-24T01:31:43,674  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T01:31:43,674  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T01:31:43,674  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T01:31:43,674  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 46; bufvoid = 104857600
2024-04-24T01:31:43,674  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-24T01:31:43,685  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T01:31:43,692  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local766931729_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T01:31:43,693  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T01:31:43,693  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local766931729_0002_m_000000_0' done.
2024-04-24T01:31:43,693  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local766931729_0002_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=24384
		FILE: Number of bytes written=2373450
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=46
		Map output materialized bytes=56
		Input split bytes=361
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=969932800
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_7=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5670
2024-04-24T01:31:43,694  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local766931729_0002_m_000000_0
2024-04-24T01:31:43,694  INFO [Thread-173] mapred.LocalJobRunner: map task executor complete.
2024-04-24T01:31:43,695  INFO [Thread-173] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T01:31:43,695  INFO [pool-13-thread-1] mapred.LocalJobRunner: Starting task: attempt_local766931729_0002_r_000000_0
2024-04-24T01:31:43,698  INFO [pool-13-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T01:31:43,698  INFO [pool-13-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@473a8108
2024-04-24T01:31:43,698  WARN [pool-13-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T01:31:43,700  INFO [pool-13-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T01:31:43,700  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local766931729_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T01:31:43,703  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local766931729_0002_m_000000_0 decomp: 52 len: 56 to MEMORY
2024-04-24T01:31:43,704  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local766931729_0002_m_000000_0
2024-04-24T01:31:43,704  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2024-04-24T01:31:43,704  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T01:31:43,705  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:43,705  INFO [pool-13-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T01:31:43,711  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:43,711  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-24T01:31:43,714  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 52 bytes to disk to satisfy reduce memory limit
2024-04-24T01:31:43,714  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 1 files, 56 bytes from disk
2024-04-24T01:31:43,714  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T01:31:43,714  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T01:31:43,714  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-24T01:31:43,715  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T01:31:43,715  INFO [pool-13-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T01:31:43,720  INFO [pool-13-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 6,40KB
2024-04-24T01:31:43,721  INFO [pool-13-thread-1] ExecReducer: 
<SEL>Id =8
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 8 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T01:31:43,721  INFO [pool-13-thread-1] exec.SelectOperator: Initializing Operator: SEL[8]
2024-04-24T01:31:43,721  INFO [pool-13-thread-1] exec.SelectOperator: SELECT struct<key:struct<_col2:string,_bucket_number:string,_col0:int>,value:struct<_col1:int>>
2024-04-24T01:31:43,721  INFO [pool-13-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T01:31:43,722  INFO [pool-13-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@5fa24d0b, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local766931729_0002/job_local766931729_0002.xml], properties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@58361277
2024-04-24T01:31:43,724  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1
2024-04-24T01:31:43,724  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1
2024-04-24T01:31:43,727  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart
2024-04-24T01:31:43,728  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-24T01:31:43,728  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T01:31:43,737  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T01:31:43,746  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2
2024-04-24T01:31:43,746  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2
2024-04-24T01:31:43,748  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart
2024-04-24T01:31:43,749  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T01:31:43,758  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T01:31:43,763  INFO [pool-13-thread-1] exec.SelectOperator: Closing Operator: SEL[8]
2024-04-24T01:31:43,763  INFO [pool-13-thread-1] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_8:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:43,763  INFO [pool-13-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T01:31:43,763  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-24T01:31:43,767  INFO [pool-13-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0, file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-24T01:31:43,781  INFO [pool-13-thread-1] exec.FileSinkOperator: TOTAL_TABLE_ROWS_WRITTEN:2, RECORDS_OUT_OPERATOR_FS_6:2, RECORDS_OUT_1_default.acidtblpart:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T01:31:43,782  INFO [pool-13-thread-1] mapred.Task: Task:attempt_local766931729_0002_r_000000_0 is done. And is in the process of committing
2024-04-24T01:31:43,783  INFO [pool-13-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T01:31:43,783  INFO [pool-13-thread-1] mapred.Task: Task 'attempt_local766931729_0002_r_000000_0' done.
2024-04-24T01:31:43,783  INFO [pool-13-thread-1] mapred.Task: Final Counters for attempt_local766931729_0002_r_000000_0: Counters: 31
	File System Counters
		FILE: Number of bytes read=30995
		FILE: Number of bytes written=2375499
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=56
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=969932800
	HIVE
		CREATED_DYNAMIC_PARTITIONS=2
		CREATED_FILES=2
		RECORDS_OUT_1_default.acidtblpart=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_8=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T01:31:43,784  INFO [pool-13-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local766931729_0002_r_000000_0
2024-04-24T01:31:43,784  INFO [Thread-173] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 01:31:44,661 Stage-1 map = 100%,  reduce = 100%
2024-04-24T01:31:44,661  INFO [main] exec.Task: 2024-04-24 01:31:44,661 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local766931729_0002
2024-04-24T01:31:44,665  INFO [main] exec.Task: Ended Job = job_local766931729_0002
2024-04-24T01:31:44,667  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with attemptId 0.
2024-04-24T01:31:44,667  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest
2024-04-24T01:31:44,668  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000
2024-04-24T01:31:44,672  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtblpart partition (p=null)
2024-04-24T01:31:44,673  INFO [main] exec.Task: Loading data to table default.acidtblpart partition (p=null) from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart
2024-04-24T01:31:44,673  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,695  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:44,695  INFO [main] exec.MoveTask: Partition is: {p=null}


2024-04-24T01:31:44,697  INFO [main] exec.Task: 

2024-04-24T01:31:44,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,708  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:44,710  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,719  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:44,720  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.acidtblpart[]	
2024-04-24T01:31:44,744  INFO [load-dynamic-partitionsToAdd-0] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p1 withPartSpec {p=p1}
2024-04-24T01:31:44,744  INFO [load-dynamic-partitionsToAdd-1] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713947487695/warehouse/acidtblpart/p=p2 withPartSpec {p=p2}
2024-04-24T01:31:44,744  INFO [main] metadata.Hive: Number of partitionsToAdd to be added is 2
2024-04-24T01:31:44,748  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=add_partitions	
2024-04-24T01:31:44,843  INFO [main] metadata.Hive: Loaded 2partitionsToAdd
	 Time taken to load dynamic partitions: 0.146 seconds
2024-04-24T01:31:44,843  INFO [main] exec.Task: 	 Time taken to load dynamic partitions: 0.146 seconds
2024-04-24T01:31:44,843  INFO [main] exec.MoveTask: 	 Time taken to load dynamic partitions: 0.146 seconds
2024-04-24T01:31:44,844  INFO [main] exec.MoveTask: Loading partition {p=p1}
2024-04-24T01:31:44,844  INFO [main] exec.MoveTask: Loading partition {p=p2}
	 Time taken for adding to write entity : 0.001 seconds
2024-04-24T01:31:44,844  INFO [main] exec.Task: 	 Time taken for adding to write entity : 0.001 seconds
2024-04-24T01:31:44,844  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T01:31:44,844  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,854  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:44,854  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T01:31:44,854  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1/-mr-10000
2024-04-24T01:31:44,856  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,866  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:44,877  WARN [stats-updater-thread-0] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T01:31:44,877  WARN [stats-updater-thread-1] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T01:31:44,878  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, numRows, true, 1, false: 
2024-04-24T01:31:44,878  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, rawDataSize, true, 0, false: 
2024-04-24T01:31:44,878  INFO [main] stats.BasicStatsTask: Partition {p=p1} stats: [numFiles=1, numRows=1, totalSize=673, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T01:31:44,878  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, numRows, true, 1, false: 
2024-04-24T01:31:44,878  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, rawDataSize, true, 0, false: 
2024-04-24T01:31:44,878  INFO [main] stats.BasicStatsTask: Partition {p=p2} stats: [numFiles=1, numRows=1, totalSize=678, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T01:31:44,879  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_partitions : tbl=hive.default.acidtblpart	
2024-04-24T01:31:44,879  INFO [main] metastore.HMSHandler: New partition values:[p1]
2024-04-24T01:31:44,879  INFO [main] metastore.HMSHandler: New partition values:[p2]
2024-04-24T01:31:45,014  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, insertCount, true, 1, false: 
2024-04-24T01:31:45,014  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, updateCount, true, 0, false: 
2024-04-24T01:31:45,014  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, deleteCount, true, 0, false: 
2024-04-24T01:31:45,017  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, insertCount, true, 1, false: 
2024-04-24T01:31:45,017  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, updateCount, true, 0, false: 
2024-04-24T01:31:45,017  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, deleteCount, true, 0, false: 
2024-04-24T01:31:45,018  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:45,019  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {alter_partitions_(String, String, List, EnvironmentContext, String, long)=136, listPartitionNamesRequest_(GetPartitionNamesPsRequest)=21, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=4, addDynamicPartitions_(long, long, String, String, List, DataOperationType)=3, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=62, add_partitions_(List)=93, getValidWriteIds_(List, String)=1}
MapReduce Jobs Launched: 
2024-04-24T01:31:45,019  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T01:31:45,019  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T01:31:45,019  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T01:31:45,019  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707); Time taken: 1.712 seconds
2024-04-24T01:31:45,019  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013143_e0be9124-e73b-436e-b147-f5849ef8b707
2024-04-24T01:31:45,032  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:45,033  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-24T01:31:45,034  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTblPart set b = 4 where p='p1'
2024-04-24T01:31:45,034  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1
2024-04-24T01:31:45,035  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/c0f93960-6913-43d0-94d2-c7b0fae9be2f/hive_2024-04-24_01-31-43_018_3281134564859395036-1 on fs with scheme file
2024-04-24T01:31:45,035  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013145_5879e963-904e-4245-b634-0ff4b0047c91): update acidTblPart set b = 4 where p='p1'
2024-04-24T01:31:45,048  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-24T01:31:45,048  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-24T01:31:45,052  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-24T01:31:45,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,064  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,064  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTblPart set b = 4 where p='p1'> as 
<insert into table `default`.`acidTblPart` partition (`p`) select ROW__ID,`a`,`b`, `p` from `default`.`acidTblPart` sort by ROW__ID >
2024-04-24T01:31:45,066  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T01:31:45,070  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,081  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,081  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T01:31:45,081  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T01:31:45,082  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,095  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,095  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T01:31:45,095  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T01:31:45,095  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,107  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,107  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-24T01:31:45,107  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T01:31:45,107  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-24T01:31:45,123  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,137  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,138  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,228  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,238  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,239  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,248  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,249  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_spec_by_expr : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,315  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtblpart, projIndxSet: [0, 2], allowMissingStats: true
2024-04-24T01:31:45,316  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T01:31:45,329  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,330  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_aggr_stats_for: table=hive.default.acidtblpart	
2024-04-24T01:31:45,356  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtblpart, Columns: a
No Stats for default@acidtblpart, Columns: a
2024-04-24T01:31:45,357  INFO [main] SessionState: No Stats for default@acidtblpart, Columns: a
2024-04-24T01:31:45,445  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T01:31:45,445  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T01:31:45,445  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T01:31:45,445  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,457  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,458  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-24T01:31:45,464 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T01:31:45,465 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-24T01:31:45,465  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T01:31:45,465 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,rowid:int,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T01:31:45,466  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:45,466  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=6, getNotNullConstraints_(NotNullConstraintsRequest)=2, flushCache_()=0, commitTxn_(CommitTxnRequest)=14, getValidTxns_(long)=2, getMetaConf_(String)=0, listPartitionsSpecByExpr_(PartitionsByExprRequest, List)=83, getAggrColStatsFor_(String, String, List, List, String, String)=40, getTable_(GetTableRequest)=61, openTxn_(String, TxnType)=11, getAllTableConstraints_(AllTableConstraintsRequest)=9, getCheckConstraints_(CheckConstraintsRequest)=2, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:45,466  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013145_5879e963-904e-4245-b634-0ff4b0047c91); Time taken: 0.431 seconds
2024-04-24T01:31:45,466  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-24T01:31:45,471  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:45,480  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T01:31:45,480  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71): drop table if exists acidTbl
2024-04-24T01:31:45,484  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-24T01:31:45,484  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-24T01:31:45,485  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:45,496  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,496  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:45,496  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:45,496  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:45,497  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=11, isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, flushCache_()=0, rollbackTxn_(long)=14, getValidTxns_(long)=1}
2024-04-24T01:31:45,497  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71); Time taken: 0.016 seconds
2024-04-24T01:31:45,497  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71
2024-04-24T01:31:45,498  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71
2024-04-24T01:31:45,525  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71 LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T01:31:45,525  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:45,525  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71): drop table if exists acidTbl
2024-04-24T01:31:45,526  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:45,526  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:45,536  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,536  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:45,546  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,546  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-24T01:31:45,708  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:45,708  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=172, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=10}
2024-04-24T01:31:45,708  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71); Time taken: 0.183 seconds
2024-04-24T01:31:45,708  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013145_b2163153-d7eb-49ea-b17a-690325880e71
2024-04-24T01:31:45,713  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-24T01:31:45,721  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:45,721  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-24T01:31:45,722  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T01:31:45,722  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02): drop table if exists acidTblPart
2024-04-24T01:31:45,725  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-24T01:31:45,725  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-24T01:31:45,726  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,736  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,736  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:45,736  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:45,737  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:45,737  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, getTable_(GetTableRequest)=10, openTxn_(String, TxnType)=2, getValidTxns_(long)=0, flushCache_()=0, isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:45,737  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02); Time taken: 0.014 seconds
2024-04-24T01:31:45,737  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02
2024-04-24T01:31:45,738  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02
2024-04-24T01:31:45,757  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02 LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T01:31:45,757  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:45,757  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02): drop table if exists acidTblPart
2024-04-24T01:31:45,757  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:45,757  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,766  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,766  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,775  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,775  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-24T01:31:45,879  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:45,879  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=9, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=113}
2024-04-24T01:31:45,879  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02); Time taken: 0.122 seconds
2024-04-24T01:31:45,879  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013145_489326d4-3ee1-42fe-89b2-57d803322f02
2024-04-24T01:31:45,884  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-24T01:31:45,892  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:45,893  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-24T01:31:45,894  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T01:31:45,894  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591): drop table if exists acidTbl2
2024-04-24T01:31:45,904  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-24T01:31:45,904  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-24T01:31:45,907  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:45,907  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:45,907  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:45,908  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getValidTxns_(long)=2, openTxn_(String, TxnType)=9, flushCache_()=0, getTable_(GetTableRequest)=0, commitTxn_(CommitTxnRequest)=14}
2024-04-24T01:31:45,908  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591); Time taken: 0.013 seconds
2024-04-24T01:31:45,908  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591
2024-04-24T01:31:45,908  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T01:31:45,908  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591): drop table if exists acidTbl2
2024-04-24T01:31:45,908  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:45,909  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-24T01:31:45,910  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:45,910  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=0, dropTable_(String, String, boolean, boolean, boolean)=0, isCompatibleWith_(Configuration)=1}
2024-04-24T01:31:45,910  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591); Time taken: 0.001 seconds
2024-04-24T01:31:45,910  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013145_7900ecd8-511a-4e4a-9c39-c72d63fe2591
2024-04-24T01:31:45,916  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-24T01:31:45,922  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:45,922  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-24T01:31:45,923  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T01:31:45,923  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:45,926  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 14
2024-04-24T01:31:45,926  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-24T01:31:45,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:45,971  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:45,971  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:45,971  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:45,971  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:45,971  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=44, flushCache_()=1, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=13, openTxn_(String, TxnType)=2}
2024-04-24T01:31:45,971  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0); Time taken: 0.048 seconds
2024-04-24T01:31:45,971  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0
2024-04-24T01:31:45,972  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0
2024-04-24T01:31:45,996  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0 LockResponse(lockid:10, state:ACQUIRED)
2024-04-24T01:31:45,996  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:45,996  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0): drop table if exists nonAcidOrcTbl
2024-04-24T01:31:45,996  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:45,997  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:46,008  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:46,019  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,019  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T01:31:46,134  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:46,134  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getTable_(GetTableRequest)=11, dropTable_(String, String, boolean, boolean, boolean)=126}
2024-04-24T01:31:46,134  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0); Time taken: 0.138 seconds
2024-04-24T01:31:46,134  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013145_d865a0c1-1182-4ca3-86aa-7f562a4352a0
2024-04-24T01:31:46,139  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-24T01:31:46,146  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:46,147  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-24T01:31:46,148  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:46,149  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:46,151  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-24T01:31:46,152  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-24T01:31:46,153  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:46,165  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,165  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:46,165  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:46,166  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:46,166  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=13, isCompatibleWith_(Configuration)=1, getTable_(GetTableRequest)=12, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-24T01:31:46,166  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0); Time taken: 0.017 seconds
2024-04-24T01:31:46,166  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0
2024-04-24T01:31:46,167  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0
2024-04-24T01:31:46,185  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0 LockResponse(lockid:11, state:ACQUIRED)
2024-04-24T01:31:46,185  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:46,185  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0): drop table if exists nonAcidOrcTbl2
2024-04-24T01:31:46,185  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:46,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:46,198  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:46,210  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,211  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T01:31:46,256  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:46,256  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=13, dropTable_(String, String, boolean, boolean, boolean)=58, isCompatibleWith_(Configuration)=0}
2024-04-24T01:31:46,256  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0); Time taken: 0.071 seconds
2024-04-24T01:31:46,257  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013146_a4bb5e3b-dd92-425a-850e-6075caab34c0
2024-04-24T01:31:46,262  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-24T01:31:46,269  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:46,269  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-24T01:31:46,270  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T01:31:46,271  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8): drop table if exists nonAcidNonBucket
2024-04-24T01:31:46,274  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-24T01:31:46,274  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-24T01:31:46,275  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:46,287  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,287  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T01:31:46,287  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T01:31:46,287  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T01:31:46,287  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=0, isCompatibleWith_(Configuration)=1, openTxn_(String, TxnType)=3, flushCache_()=0, commitTxn_(CommitTxnRequest)=13, getTable_(GetTableRequest)=12}
2024-04-24T01:31:46,287  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8); Time taken: 0.016 seconds
2024-04-24T01:31:46,288  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8
2024-04-24T01:31:46,288  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8
2024-04-24T01:31:46,307  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8 LockResponse(lockid:12, state:ACQUIRED)
2024-04-24T01:31:46,307  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T01:31:46,307  INFO [main] ql.Driver: Executing command(queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8): drop table if exists nonAcidNonBucket
2024-04-24T01:31:46,307  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T01:31:46,307  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:46,318  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,318  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:46,330  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T01:31:46,330  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T01:31:46,369  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T01:31:46,369  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=51, getTable_(GetTableRequest)=11}
2024-04-24T01:31:46,370  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8); Time taken: 0.062 seconds
2024-04-24T01:31:46,370  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424013146_727913d1-fbc6-475b-9b70-51328decc4a8
2024-04-24T01:31:46,374  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-24T01:31:46,381  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-24T01:31:46,381  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-24T01:31:46,382  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenateMM" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="11.776"/>
</testsuite>