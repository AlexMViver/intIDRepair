<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="22.366" tests="3" errors="3" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5508206391423127147.jar /home/alex/Repositories/hive/service/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire7923112100055044299tmp surefire_32965686087532540909584tmp"/>
    <property name="nondexExecid" value="qYpVZDGF5c+VxVnOj1GM6O40xGQfxoeyf4H4jo6qfg="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/service"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/service/target/tmp/derby.log"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/service/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/service/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/service/target"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/service/.nondex"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/service/.nondex"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="nondexStart" value="0"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/service/target/localfs/warehouse"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/service/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/service/target/test-classes:/home/alex/Repositories/hive/service/target/classes:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.4.4-7/zstd-jni-1.4.4-7.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-server/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/Repositories/hive/llap-common/target/test-classes:/home/alex/Repositories/hive/hplsql/target/classes:/home/alex/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/alex/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/alex/.m2/repository/javax/servlet/jsp/javax.servlet.jsp-api/2.3.1/javax.servlet.jsp-api-2.3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-runner/9.3.27.v20190418/jetty-runner-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.27.v20190418/jetty-plus-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-annotations/9.3.27.v20190418/jetty-annotations-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-commons/6.0/asm-commons-6.0.jar:/home/alex/.m2/repository/org/ow2/asm/asm-tree/6.0/asm-tree-6.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jaas/9.3.27.v20190418/jetty-jaas-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-server/9.3.27.v20190418/websocket-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.3.27.v20190418/websocket-common-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.3.27.v20190418/websocket-api-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.3.27.v20190418/websocket-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/websocket/websocket-servlet/9.3.27.v20190418/websocket-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.27.v20190418/jetty-jndi-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jsp/9.3.27.v20190418/apache-jsp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/toolchain/jetty-schemas/3.1/jetty-schemas-3.1.jar:/home/alex/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/alex/.m2/repository/org/eclipse/jetty/apache-jstl/9.3.27.v20190418/apache-jstl-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-spec/1.2.5/taglibs-standard-spec-1.2.5.jar:/home/alex/.m2/repository/org/apache/taglibs/taglibs-standard-impl/1.2.5/taglibs-standard-impl-1.2.5.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-saml-opensamlv3/4.0.3/pac4j-saml-opensamlv3-4.0.3.jar:/home/alex/.m2/repository/org/pac4j/pac4j-core/4.0.3/pac4j-core-4.0.3.jar:/home/alex/.m2/repository/org/opensaml/opensaml-core/3.4.5/opensaml-core-3.4.5.jar:/home/alex/.m2/repository/net/shibboleth/utilities/java-support/7.5.1/java-support-7.5.1.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-api/3.4.5/opensaml-saml-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-api/3.4.5/opensaml-storage-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-saml-impl/3.4.5/opensaml-saml-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-impl/3.4.5/opensaml-soap-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-soap-api/3.4.5/opensaml-soap-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-api/3.4.5/opensaml-xmlsec-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-api/3.4.5/opensaml-security-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-security-impl/3.4.5/opensaml-security-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-api/3.4.5/opensaml-profile-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-profile-impl/3.4.5/opensaml-profile-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-api/3.4.5/opensaml-messaging-api-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-messaging-impl/3.4.5/opensaml-messaging-impl-3.4.5.jar:/home/alex/.m2/repository/org/opensaml/opensaml-storage-impl/3.4.5/opensaml-storage-impl-3.4.5.jar:/home/alex/.m2/repository/org/ldaptive/ldaptive/1.0.13/ldaptive-1.0.13.jar:/home/alex/.m2/repository/javax/json/javax.json-api/1.0/javax.json-api-1.0.jar:/home/alex/.m2/repository/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar:/home/alex/.m2/repository/org/glassfish/javax.json/1.0.4/javax.json-1.0.4.jar:/home/alex/.m2/repository/org/opensaml/opensaml-xmlsec-impl/3.4.5/opensaml-xmlsec-impl-3.4.5.jar:/home/alex/.m2/repository/org/cryptacular/cryptacular/1.2.4/cryptacular-1.2.4.jar:/home/alex/.m2/repository/net/shibboleth/tool/xmlsectool/2.0.0/xmlsectool-2.0.0.jar:/home/alex/.m2/repository/com/beust/jcommander/1.48/jcommander-1.48.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.64/bcprov-jdk15on-1.64.jar:/home/alex/.m2/repository/org/apache/santuario/xmlsec/2.2.1/xmlsec-2.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.4/error_prone_annotations-2.3.4.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-integ/1.5.7/apacheds-server-integ-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-interceptor-kerberos/1.5.7/apacheds-interceptor-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core/1.5.7/apacheds-core-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-api/1.5.7/apacheds-core-api-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-entry/1.5.7/apacheds-core-entry-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-constants/1.5.7/apacheds-core-constants-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-utils/1.5.7/apacheds-utils-1.5.7.jar:/home/alex/.m2/repository/bouncycastle/bcprov-jdk15/140/bcprov-jdk15-140.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-shared/1.5.7/apacheds-kerberos-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-jndi/1.5.7/apacheds-core-jndi-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-shared/1.5.7/apacheds-protocol-shared-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-integ/1.5.7/apacheds-core-integ-1.5.7.jar:/home/alex/.m2/repository/ldapsdk/ldapsdk/4.1/ldapsdk-4.1.jar:/home/alex/.m2/repository/org/apache/directory/client/ldap/ldap-client-api/0.1/ldap-client-api-0.1.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap/0.9.19/shared-ldap-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-i18n/0.9.19/shared-i18n-0.9.19.jar:/home/alex/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema/0.9.19/shared-ldap-schema-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-loader/0.9.19/shared-ldap-schema-loader-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-manager/0.9.19/shared-ldap-schema-manager-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-cursor/0.9.19/shared-cursor-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-jndi/0.9.19/shared-ldap-jndi-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1-codec/0.9.19/shared-asn1-codec-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-asn1/0.9.19/shared-asn1-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-constants/0.9.19/shared-ldap-constants-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-converter/0.9.19/shared-ldap-converter-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldap-schema-dao/0.9.19/shared-ldap-schema-dao-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-ldif/0.9.19/shared-ldif-0.9.19.jar:/home/alex/.m2/repository/org/apache/directory/shared/shared-dsml-parser/0.9.19/shared-dsml-parser-0.9.19.jar:/home/alex/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/alex/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/alex/.m2/repository/xpp3/xpp3/1.1.4c/xpp3-1.1.4c.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-test-framework/1.5.7/apacheds-test-framework-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/1.5.7/apacheds-i18n-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-server-annotations/1.5.7/apacheds-server-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-annotations/1.5.7/apacheds-core-annotations-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-partition/1.5.7/apacheds-jdbm-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm-store/1.5.7/apacheds-jdbm-store-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-jdbm/1.5.7/apacheds-jdbm-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-avl/1.5.7/apacheds-core-avl-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-search/1.5.7/apacheds-xdbm-search-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-ldif-partition/1.5.7/apacheds-ldif-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-avl-partition/1.5.7/apacheds-avl-partition-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-core-mock/1.5.7/apacheds-core-mock-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-ldap/1.5.7/apacheds-protocol-ldap-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-tools/1.5.7/apacheds-xdbm-tools-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-xdbm-base/1.5.7/apacheds-xdbm-base-1.5.7.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-protocol-kerberos/1.5.7/apacheds-protocol-kerberos-1.5.7.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/alex/Repositories/hive/service/target/testconf:/home/alex/Repositories/hive/service/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/service/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="974622"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/service/target/surefire/surefirebooter5508206391423127147.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/service/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/service"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
    <property name="test.output.overwrite" value=""/>
    <property name="hive.root" value="/home/alex/Repositories/hive/service/../"/>
  </properties>
  <testcase name="testAsync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="17.462">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testAsync(TestQueryShutdownHooks.java:130)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,088395 seconds to load 251 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@58e1d9d]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@58e1d9d) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@2d29b4ee
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,033589 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 133 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/service/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/service/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Configuration(HiveLog4j2Test), footer="null", Replace=null, charset="null", noConsoleNoAnsi="null", alwaysWriteExceptions="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", disableAnsi="null", PatternSelector=null, header="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", direct="null", target="SYSTEM_ERR", bufferSize="null", immediateFlush="null", bufferedIo="null", ignoreExceptions="null", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(alwaysWriteExceptions="null", header="null", charset="null", footer="null", disableAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", noConsoleNoAnsi="null", Replace=null, PatternSelector=null, Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", compressionLevel="null", fileIndex="null", Configuration(HiveLog4j2Test), min="null", max="30")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(filePattern="/home/alex/Repositories/hive/service/target/tmp/log/hive.log.%d{yyyy-MM-dd}", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", append="null", fileOwner="null", filePermissions="null", fileName="/home/alex/Repositories/hive/service/target/tmp/log/hive.log", advertiseURI="null", fileGroup="null", immediateFlush="null", bufferedIo="null", bufferSize="null", name="DRFA", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/service/target/tmp/log/hive.log seek to 8390785255
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T07:13:44.757-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-07:13:46.775, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-07:13:46.776, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@68746f22 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@7671cb68...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@7671cb68 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3e14c16d
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@58e1d9d
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/service/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@58e1d9d) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@58e1d9d] started OK.
2024-04-24T07:13:46,935  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/service/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T07:13:47,427  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T07:13:47,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:13:47,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:13:47,518  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:13:47,519  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:13:47,519  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:13:47,519  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:13:47,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:13:47,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:13:47,521  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:13:47,521  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:13:47,521  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:13:47,522  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
Hive Session ID = ee41389c-5b04-47c5-8dcc-1f6edd435825
2024-04-24T07:13:47,576  INFO [main] SessionState: Hive Session ID = ee41389c-5b04-47c5-8dcc-1f6edd435825
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:13:47,599  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:13:48,025  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ee41389c-5b04-47c5-8dcc-1f6edd435825
2024-04-24T07:13:48,032  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/ee41389c-5b04-47c5-8dcc-1f6edd435825
2024-04-24T07:13:48,037  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/ee41389c-5b04-47c5-8dcc-1f6edd435825/_tmp_space.db
2024-04-24T07:13:48,065  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ee41389c-5b04-47c5-8dcc-1f6edd435825, clientType=HIVESERVER2]
2024-04-24T07:13:48,141  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:13:48,378  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:13:48,425  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:13:48,436  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T07:13:48,436  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T07:13:48,465  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:13:48,472  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T07:13:49,334  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:13:49,337  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T07:13:50,091  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T07:13:50,091  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: null will be shutdown
2024-04-24T07:13:50,123  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@100c8b75 created in the thread with id: 1
2024-04-24T07:13:53,500  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-24T07:13:53,500  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T07:13:53,500  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336 from thread id: 1
2024-04-24T07:13:53,673  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T07:13:53,725  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T07:13:53,777  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T07:13:53,781  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T07:13:53,937  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T07:13:53,970  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:13:53,973  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T07:13:53,976  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:13:53,977  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T07:13:53,980  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T07:13:53,983  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T07:13:53,985  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T07:13:53,986  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T07:13:53,991  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T07:13:53,995  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T07:13:53,996  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T07:13:53,997  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T07:13:53,997  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T07:13:53,998  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T07:13:54,001  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:13:54,165  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:13:54,831  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,832  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,834  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,834  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,850  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,852  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,855  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T07:13:54,920  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:13:54,921  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:13:54,922  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:13:54,922  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:13:54,923  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:13:54,926  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
2024-04-24T07:13:54,933  INFO [main] service.AbstractService: Service:OperationManager is inited.
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-2
DEBUG StatusLogger Log4j2 ConfigurationScheduler starting 2 threads
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.NullAppender].
DEBUG StatusLogger createNullAppender()
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-3
2024-04-24T07:13:54,951  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:13:54,951  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:13:54,951  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:13:54,951  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:13:54,952  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:13:54,953  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:13:54,974  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:13:54,980  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:13:54,986  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:13:54,999  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0f72d513-84a7-407f-b29f-7938db981ddb
2024-04-24T07:13:55,003  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb
2024-04-24T07:13:55,008  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0f72d513-84a7-407f-b29f-7938db981ddb/_tmp_space.db
2024-04-24T07:13:55,013  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:13:55,013  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:13:55,016  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:13:55,016  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:13:55,019  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@100c8b75 will be shutdown
2024-04-24T07:13:55,020  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62cf6a84 created in the thread with id: 1
2024-04-24T07:13:55,037  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:13:55,037  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:13:55,040  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T07:13:55,109  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:13:55,109  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@17fa1336, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62cf6a84 will be shutdown
2024-04-24T07:13:55,109  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:13:55,110  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-24T07:13:55,111  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb
2024-04-24T07:13:55,114  INFO [main] service.CompositeService: Session opened, SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb], current sessions:1
2024-04-24T07:13:55,120  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:13:55,126  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:13:55,149  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=68a5685d-adc9-460c-89aa-b4405e25d305] SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb]
2024-04-24T07:13:55,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", noConsoleNoAnsi="null", header="null", disableAnsi="null", Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", alwaysWriteExceptions="null", Replace=null, PatternSelector=null, footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(header="null", charset="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test), footer="null", noConsoleNoAnsi="null", alwaysWriteExceptions="null", PatternSelector=null, disableAnsi="null", Replace=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664.test
2024-04-24T07:13:55,175  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664, startTime=1713968035143, sessionId=0f72d513-84a7-407f-b29f-7938db981ddb, createTime=1713968034983, userName=anonymous, ipAddress=null]
2024-04-24T07:13:55,238  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Compiling command(queryId=alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:13:56,109  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:13:56,112  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: null will be shutdown
2024-04-24T07:13:56,112  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7af1d072 created in the thread with id: 1
2024-04-24T07:13:56,125  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05 from thread id: 1
2024-04-24T07:13:56,501  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] reflections.Reflections: Reflections took 317 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:13:56,722  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] reflections.Reflections: Reflections took 174 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:13:56,899  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] reflections.Reflections: Reflections took 167 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:13:56,998  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
2024-04-24T07:13:57,001  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:13:57,001  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=0f72d513-84a7-407f-b29f-7938db981ddb, clientType=HIVESERVER2]
2024-04-24T07:13:57,004  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:13:57,004  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:13:57,005  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:13:57,010  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:13:57,021  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:13:58,523  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:13:59,348  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:13:59,354  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:13:59,371  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:13:59,371  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:13:59,417  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001/.hive-staging_hive_2024-04-24_07-13-55_203_1728532217282806886-1
2024-04-24T07:13:59,469  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:13:59,573  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:13:59,601  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:13:59,689  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:13:59,697  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:13:59,698  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:13:59,698  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:13:59,698  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:13:59,698  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:13:59,698  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:13:59,700  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:13:59,700  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
2024-04-24T07:13:59,701  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:13:59,704  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:13:59,718  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:13:59,724  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:13:59,724  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=115, isCompatibleWith_(Configuration)=0, flushCache_()=22, getAllFunctions_()=68}
2024-04-24T07:13:59,725  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed compiling command(queryId=alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664); Time taken: 4.488 seconds
2024-04-24T07:13:59,726  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:13:59,728  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:13:59,734  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:13:59,740  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Executing command(queryId=alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:13:59,742  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:13:59,742  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:13:59,742  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001
2024-04-24T07:13:59,742  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001
2024-04-24T07:13:59,745  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
2024-04-24T07:13:59,745  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Query ID = alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
Total jobs = 1
2024-04-24T07:13:59,745  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:13:59,745  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:13:59,977  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:13:59,977  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:13:59,986  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:13:59,991  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:13:59,991  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/dummy_path
2024-04-24T07:14:00,079  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:00,108  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:00,256  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T07:14:00,276  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T07:14:00,298  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T07:14:00,298  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T07:14:00,329  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:00,374  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:00,385  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:00,389  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:00,391  INFO [pool-8-thread-1] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-24T07:14:00,403  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/dummy_path
2024-04-24T07:14:00,456  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:00,487  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:00,489  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:00,524  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:00,619  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1845861441_0001
2024-04-24T07:14:00,619  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:00,851  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:00,853  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:00,854  INFO [Thread-59] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:00,856  INFO [Thread-59] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:00,875  INFO [Thread-59] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:00,880  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1845861441_0001_m_000000_0
2024-04-24T07:14:00,933  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:00,944  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:00,952  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:00,981  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:00,989  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:00,997  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:00,999  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:01,003  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:01,003  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:01,007  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:01,008  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:01,009  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@e3cb4c8, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@3bf9c88b, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@6dcae623
2024-04-24T07:14:01,016  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001/.hive-staging_hive_2024-04-24_07-13-55_203_1728532217282806886-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:01,016  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001/.hive-staging_hive_2024-04-24_07-13-55_203_1728532217282806886-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:01,016  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001/.hive-staging_hive_2024-04-24_07-13-55_203_1728532217282806886-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:01,047  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:3, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:14:01,048  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:01,049  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-24T07:14:01,049  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:01,049  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:01,051  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, RECORDS_OUT_OPERATOR_FS_2:1, 
2024-04-24T07:14:01,056  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:14:01,064  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1845861441_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T07:14:01,065  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:14:01,065  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1845861441_0001_m_000000_0' done.
2024-04-24T07:14:01,067  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1845861441_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=5586
		FILE: Number of bytes written=1157184
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=876085248
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:14:01,067  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1845861441_0001_m_000000_0
2024-04-24T07:14:01,069  INFO [Thread-59] mapred.LocalJobRunner: map task executor complete.
2024-04-24 07:14:01,882 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:14:01,883  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Task: 2024-04-24 07:14:01,882 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1845861441_0001
2024-04-24T07:14:01,893  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.Task: Ended Job = job_local1845861441_0001
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:01,911  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:14:01,912  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:01,912  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001
2024-04-24T07:14:01,912  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1/-mr-10001
2024-04-24T07:14:01,912  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:01,912  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:01,913  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:14:01,921  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:01,921  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:01,921  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed executing command(queryId=alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664); Time taken: 2.173 seconds
2024-04-24T07:14:01,922  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:01,926  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:01,928  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4ab61f8b-96f7-4dc1-ab31-5f4fac61a65e] SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb]
2024-04-24T07:14:01,928  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", Replace=null, Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", noConsoleNoAnsi="null", header="null", charset="null", PatternSelector=null, alwaysWriteExceptions="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071401_0d243214-8176-4518-ab38-db766e394404", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, alwaysWriteExceptions="null", pattern="%-5p : %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", header="null", charset="null", disableAnsi="null", footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071401_0d243214-8176-4518-ab38-db766e394404.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071401_0d243214-8176-4518-ab38-db766e394404.test
2024-04-24T07:14:01,937  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071401_0d243214-8176-4518-ab38-db766e394404, startTime=1713968041926, sessionId=0f72d513-84a7-407f-b29f-7938db981ddb, createTime=1713968034983, userName=anonymous, ipAddress=null]
2024-04-24T07:14:01,939  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Compiling command(queryId=alex_20240424071401_0d243214-8176-4518-ab38-db766e394404): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:01,941  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
2024-04-24T07:14:01,941  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:01,941  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:01,942  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:01,942  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:01,942  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:01,942  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:01,972  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,119  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,119  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,123  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,123  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,125  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1
2024-04-24T07:14:02,132  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:02,139  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:02,140  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:02,154  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:02,155  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:02,155  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
2024-04-24T07:14:02,155  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:02,155  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:02,157  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:02,157  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:02,158  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=6, flushCache_()=1}
2024-04-24T07:14:02,158  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed compiling command(queryId=alex_20240424071401_0d243214-8176-4518-ab38-db766e394404); Time taken: 0.218 seconds
2024-04-24T07:14:02,160  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:02,161  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,161  INFO [HiveServer2-Background-Pool: Thread-114] common.LogUtils: Thread context registration is done.
2024-04-24T07:14:02,161  INFO [HiveServer2-Background-Pool: Thread-114] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:02,163  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9ab73d31-bd01-49e7-94fe-ad304b8456d2] SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb]
2024-04-24T07:14:02,163  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:02,164  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Executing command(queryId=alex_20240424071401_0d243214-8176-4518-ab38-db766e394404): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,164  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", footer="null", alwaysWriteExceptions="null", Replace=null, PatternSelector=null, noConsoleNoAnsi="null", disableAnsi="null", header="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(noConsoleNoAnsi="null", disableAnsi="null", Replace=null, Configuration(HiveLog4j2Test), charset="null", footer="null", header="null", PatternSelector=null, pattern="%-5p : %m%n", alwaysWriteExceptions="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326.test
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,176  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326, startTime=1713968042161, sessionId=0f72d513-84a7-407f-b29f-7938db981ddb, createTime=1713968034983, userName=anonymous, ipAddress=null]
2024-04-24T07:14:02,176  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:14:02,176  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:02,177  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001
2024-04-24T07:14:02,177  INFO [HiveServer2-Background-Pool: Thread-114] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001
2024-04-24T07:14:02,177  WARN [HiveServer2-Background-Pool: Thread-114] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
2024-04-24T07:14:02,177  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Query ID = alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
Total jobs = 1
2024-04-24T07:14:02,177  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Total jobs = 1
2024-04-24T07:14:02,178  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Compiling command(queryId=alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326): select reflect("java.lang.Thread", "sleep", bigint(1000))
Launching Job 1 out of 1
2024-04-24T07:14:02,178  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,180  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:02,217  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,318  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,319  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,327  INFO [HiveServer2-Background-Pool: Thread-114] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:02,328  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:02,328  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/dummy_path
2024-04-24T07:14:02,346  INFO [HiveServer2-Background-Pool: Thread-114] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:02,349  INFO [HiveServer2-Background-Pool: Thread-114] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:02,352  WARN [HiveServer2-Background-Pool: Thread-114] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,355  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,356  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,361  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,362  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,363  WARN [HiveServer2-Background-Pool: Thread-114] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,363  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1
2024-04-24T07:14:02,373  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:02,377  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:02,379  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:02,381  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:02,382  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:02,383  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:02,385  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/dummy_path
2024-04-24T07:14:02,392  INFO [HiveServer2-Background-Pool: Thread-114] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:02,393  INFO [HiveServer2-Background-Pool: Thread-114] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:02,394  INFO [HiveServer2-Background-Pool: Thread-114] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:02,400  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:02,401  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:02,401  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:02,401  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:02,401  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:02,402  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:02,405  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:02,405  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:02,406  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, isCompatibleWith_(Configuration)=0}
2024-04-24T07:14:02,406  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed compiling command(queryId=alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326); Time taken: 0.228 seconds
2024-04-24T07:14:02,407  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:02,407  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,410  INFO [HiveServer2-Background-Pool: Thread-139] common.LogUtils: Thread context registration is done.
2024-04-24T07:14:02,410  INFO [HiveServer2-Background-Pool: Thread-139] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:02,410  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=07783508-a90b-454b-833a-c1f4cba7fa7d] SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb]
2024-04-24T07:14:02,411  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:02,412  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Executing command(queryId=alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,412  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", noConsoleNoAnsi="null", Replace=null, alwaysWriteExceptions="null", Configuration(HiveLog4j2Test), header="null", pattern="%-5p : %m%n", PatternSelector=null, footer="null", disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(disableAnsi="null", footer="null", charset="null", Replace=null, pattern="%-5p : %m%n", noConsoleNoAnsi="null", header="null", PatternSelector=null, alwaysWriteExceptions="null", Configuration(HiveLog4j2Test))
2024-04-24T07:14:02,421  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: number of splits:1
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248.test
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))2024-04-24T07:14:02,424  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248, startTime=1713968042408, sessionId=0f72d513-84a7-407f-b29f-7938db981ddb, createTime=1713968034983, userName=anonymous, ipAddress=null]

2024-04-24T07:14:02,424  INFO [HiveServer2-Background-Pool: Thread-139] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:14:02,424  INFO [HiveServer2-Background-Pool: Thread-139] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:02,424  INFO [HiveServer2-Background-Pool: Thread-139] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001
2024-04-24T07:14:02,424  INFO [HiveServer2-Background-Pool: Thread-139] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001
2024-04-24T07:14:02,425  WARN [HiveServer2-Background-Pool: Thread-139] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
2024-04-24T07:14:02,425  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Query ID = alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
Total jobs = 1
2024-04-24T07:14:02,425  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Compiling command(queryId=alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,425  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:02,425  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:02,428  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
2024-04-24T07:14:02,428  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:02,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:02,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:02,453  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: Submitting tokens for job: job_local271898436_0002
2024-04-24T07:14:02,453  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:02,466  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,556  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,557  INFO [HiveServer2-Background-Pool: Thread-139] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,568  INFO [HiveServer2-Background-Pool: Thread-139] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:02,568  INFO [HiveServer2-Background-Pool: Thread-114] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T07:14:02,569  INFO [Thread-107] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:02,569  INFO [HiveServer2-Background-Pool: Thread-139] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:02,569  INFO [Thread-107] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:02,569  INFO [HiveServer2-Background-Pool: Thread-139] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/dummy_path
Job running in-process (local Hadoop)
2024-04-24T07:14:02,576  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:02,578  INFO [Thread-107] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:02,578  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local271898436_0002_m_000000_0
2024-04-24T07:14:02,580  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:02,582  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:02,588  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:02,594  INFO [HiveServer2-Background-Pool: Thread-139] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:02,596  INFO [HiveServer2-Background-Pool: Thread-139] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T07:14:02,598  WARN [HiveServer2-Background-Pool: Thread-139] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,608  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:02,609  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:02,610  WARN [HiveServer2-Background-Pool: Thread-139] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,610  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:02,611  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:02,612  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:02,613  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:02,613  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:02,613  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:02,614  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@2431b1d4, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@6d187b02, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@230ba0e5
2024-04-24T07:14:02,621  WARN [HiveServer2-Background-Pool: Thread-139] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:02,628  WARN [HiveServer2-Background-Pool: Thread-139] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:02,629  INFO [HiveServer2-Background-Pool: Thread-139] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:02,630  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,631  INFO [HiveServer2-Background-Pool: Thread-139] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/dummy_path
2024-04-24T07:14:02,631  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,636  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,636  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,638  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1
2024-04-24T07:14:02,638  INFO [HiveServer2-Background-Pool: Thread-139] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:02,639  INFO [HiveServer2-Background-Pool: Thread-139] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:02,639  INFO [HiveServer2-Background-Pool: Thread-139] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:02,645  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:02,651  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:02,652  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:02,662  INFO [HiveServer2-Background-Pool: Thread-139] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:02,665  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:02,666  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:02,669  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:02,669  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:02,669  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=11, isCompatibleWith_(Configuration)=1, flushCache_()=0}
2024-04-24T07:14:02,669  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed compiling command(queryId=alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248); Time taken: 0.244 seconds
2024-04-24T07:14:02,671  INFO [HiveServer2-Background-Pool: Thread-186] common.LogUtils: Thread context registration is done.
2024-04-24T07:14:02,671  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:02,671  INFO [HiveServer2-Background-Pool: Thread-186] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:02,671  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,672  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:02,672  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Executing command(queryId=alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,673  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6197f71e-43b9-4797-b4f8-0232f9987d40] SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb]
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,673  INFO [HiveServer2-Background-Pool: Thread-186] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:14:02,673  INFO [HiveServer2-Background-Pool: Thread-186] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:02,673  INFO [HiveServer2-Background-Pool: Thread-186] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:02,673  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Thread context registration is done.
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001
2024-04-24T07:14:02,673  INFO [HiveServer2-Background-Pool: Thread-186] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(footer="null", alwaysWriteExceptions="null", charset="null", disableAnsi="null", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, noConsoleNoAnsi="null", header="null", pattern="%-5p : %m%n")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, charset="null", alwaysWriteExceptions="null", footer="null", Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", header="null", Replace=null, pattern="%-5p : %m%n", disableAnsi="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32.test
2024-04-24T07:14:02,682  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32, startTime=1713968042671, sessionId=0f72d513-84a7-407f-b29f-7938db981ddb, createTime=1713968034983, userName=anonymous, ipAddress=null]
2024-04-24T07:14:02,683  WARN [HiveServer2-Background-Pool: Thread-186] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
2024-04-24T07:14:02,683  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Query ID = alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
Total jobs = 1
2024-04-24T07:14:02,683  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:02,683  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:02,683  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Compiling command(queryId=alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32): select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,685  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
2024-04-24T07:14:02,685  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:02,686  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:02,686  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,686  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,686  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,686  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:02,690  INFO [HiveServer2-Background-Pool: Thread-139] mapreduce.JobSubmitter: Submitting tokens for job: job_local1045512545_0003
2024-04-24T07:14:02,690  INFO [HiveServer2-Background-Pool: Thread-139] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:02,714  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,801  INFO [HiveServer2-Background-Pool: Thread-139] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:02,802  INFO [HiveServer2-Background-Pool: Thread-139] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:02,802  INFO [Thread-144] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:02,803  INFO [Thread-144] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:02,806  INFO [Thread-144] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:02,806  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1045512545_0003_m_000000_0
2024-04-24T07:14:02,807  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:02,808  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:02,809  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:02,811  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,12KB
2024-04-24T07:14:02,811  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:02,812  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:02,812  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:02,813  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:02,813  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:02,813  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:02,813  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:02,814  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@6d631656, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@120791fe, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@15e06a30
2024-04-24T07:14:02,817  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,817  INFO [HiveServer2-Background-Pool: Thread-186] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,823  INFO [HiveServer2-Background-Pool: Thread-186] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:02,824  INFO [HiveServer2-Background-Pool: Thread-186] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:02,824  INFO [HiveServer2-Background-Pool: Thread-186] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/dummy_path
2024-04-24T07:14:02,840  INFO [HiveServer2-Background-Pool: Thread-186] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:02,841  INFO [HiveServer2-Background-Pool: Thread-186] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:02,842  WARN [HiveServer2-Background-Pool: Thread-186] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,850  WARN [HiveServer2-Background-Pool: Thread-186] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:02,853  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:02,853  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:02,857  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:02,857  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:02,859  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1
2024-04-24T07:14:02,860  WARN [HiveServer2-Background-Pool: Thread-186] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:02,866  WARN [HiveServer2-Background-Pool: Thread-186] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:02,867  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:02,867  INFO [HiveServer2-Background-Pool: Thread-186] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:02,869  INFO [HiveServer2-Background-Pool: Thread-186] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/dummy_path
2024-04-24T07:14:02,872  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:02,873  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:02,874  INFO [HiveServer2-Background-Pool: Thread-186] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:02,875  INFO [HiveServer2-Background-Pool: Thread-186] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:02,875  INFO [HiveServer2-Background-Pool: Thread-186] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:02,885  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:02,886  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:02,886  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
2024-04-24T07:14:02,886  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:02,886  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:02,887  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:02,887  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:02,887  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] metadata.Hive: Total time spent in each metastore function (ms): {getAllTableConstraints_(AllTableConstraintsRequest)=10, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-24T07:14:02,888  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Completed compiling command(queryId=alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32); Time taken: 0.204 seconds
2024-04-24T07:14:02,889  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:02,889  INFO [HiveServer2-Background-Pool: Thread-221] common.LogUtils: Thread context registration is done.
2024-04-24T07:14:02,889  INFO [HiveServer2-Background-Pool: Thread-221] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:02,890  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:02,891  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Executing command(queryId=alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32): select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
2024-04-24T07:14:02,892  INFO [HiveServer2-Background-Pool: Thread-221] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(1000))
PREHOOK: type: QUERY
2024-04-24T07:14:02,892  INFO [HiveServer2-Background-Pool: Thread-221] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:02,892  INFO [HiveServer2-Background-Pool: Thread-221] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001
2024-04-24T07:14:02,892  INFO [HiveServer2-Background-Pool: Thread-221] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001
2024-04-24T07:14:02,893  WARN [HiveServer2-Background-Pool: Thread-221] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
2024-04-24T07:14:02,893  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Query ID = alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
Total jobs = 1
2024-04-24T07:14:02,893  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:02,893  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:02,897  INFO [HiveServer2-Background-Pool: Thread-186] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:02,919  INFO [HiveServer2-Background-Pool: Thread-186] mapreduce.JobSubmitter: Submitting tokens for job: job_local575378341_0004
2024-04-24T07:14:02,919  INFO [HiveServer2-Background-Pool: Thread-186] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:02,988  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,988  INFO [HiveServer2-Background-Pool: Thread-221] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:02,994  INFO [HiveServer2-Background-Pool: Thread-186] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)2024-04-24T07:14:02,995  INFO [Thread-181] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter

2024-04-24T07:14:02,995  INFO [HiveServer2-Background-Pool: Thread-186] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:02,995  INFO [Thread-181] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:02,995  INFO [HiveServer2-Background-Pool: Thread-221] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:02,995  INFO [HiveServer2-Background-Pool: Thread-221] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:02,995  INFO [HiveServer2-Background-Pool: Thread-221] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/dummy_path
2024-04-24T07:14:02,997  INFO [Thread-181] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:02,997  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local575378341_0004_m_000000_0
2024-04-24T07:14:02,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:02,999  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:03,000  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:03,002  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:03,003  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:03,004  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:03,004  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:03,005  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:03,006  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:03,006  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:03,006  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:03,007  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@28c88528, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@3baf294a, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@7934870e
2024-04-24T07:14:03,009  INFO [HiveServer2-Background-Pool: Thread-221] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:03,010  INFO [HiveServer2-Background-Pool: Thread-221] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:03,011  WARN [HiveServer2-Background-Pool: Thread-221] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:03,017  WARN [HiveServer2-Background-Pool: Thread-221] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:03,024  WARN [HiveServer2-Background-Pool: Thread-221] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:03,030  WARN [HiveServer2-Background-Pool: Thread-221] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:03,030  INFO [HiveServer2-Background-Pool: Thread-221] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:03,031  INFO [HiveServer2-Background-Pool: Thread-221] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/dummy_path
2024-04-24T07:14:03,038  INFO [HiveServer2-Background-Pool: Thread-221] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:03,038  INFO [HiveServer2-Background-Pool: Thread-221] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:03,038  INFO [HiveServer2-Background-Pool: Thread-221] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:03,059  INFO [HiveServer2-Background-Pool: Thread-221] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:03,091  INFO [HiveServer2-Background-Pool: Thread-221] mapreduce.JobSubmitter: Submitting tokens for job: job_local1422447575_0005
2024-04-24T07:14:03,091  INFO [HiveServer2-Background-Pool: Thread-221] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:03,161  INFO [HiveServer2-Background-Pool: Thread-221] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:03,161  INFO [HiveServer2-Background-Pool: Thread-221] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:03,161  INFO [Thread-211] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:03,161  INFO [Thread-211] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:03,163  INFO [Thread-211] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:03,163  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1422447575_0005_m_000000_0
2024-04-24T07:14:03,164  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:03,165  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:03,166  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:03,168  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,13KB
2024-04-24T07:14:03,169  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:03,169  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:03,170  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:03,171  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:03,171  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:03,171  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:03,171  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:03,172  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@ac3cfe5, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@8c1a721, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@725a6daf
2024-04-24T07:14:03,415  INFO [main] service.CompositeService: Session closed, SessionHandle [0f72d513-84a7-407f-b29f-7938db981ddb], current sessions:0
2024-04-24T07:14:03,416  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4ab61f8b-96f7-4dc1-ab31-5f4fac61a65e]
2024-04-24T07:14:03,417  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Removed queryId: alex_20240424071401_0d243214-8176-4518-ab38-db766e394404 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=4ab61f8b-96f7-4dc1-ab31-5f4fac61a65e] with tag: null
2024-04-24T07:14:03,418  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424071401_0d243214-8176-4518-ab38-db766e394404
2024-04-24T07:14:03,418  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Shutting down task : Stage-1:MAPRED
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:14:03,419  WARN [Thread-107] mapred.LocalJobRunner: job_local271898436_0002
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:14:03,420  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,420  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:03,420  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24 07:14:03,420 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,420  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,420  INFO [HiveServer2-Background-Pool: Thread-114] exec.Task: 2024-04-24 07:14:03,420 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,420  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-2
2024-04-24T07:14:03,421  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-2 operation was queued
2024-04-24T07:14:03,421  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:03,421  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1
2024-04-24T07:14:03,422  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1 operation was queued
Ended Job = job_local271898436_0002 with errors2024-04-24T07:14:03,422  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-2

2024-04-24T07:14:03,423 ERROR [HiveServer2-Background-Pool: Thread-114] exec.Task: Ended Job = job_local271898436_0002 with errors
2024-04-24T07:14:03,423  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:03,423  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1
2024-04-24T07:14:03,423  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:14:03,424  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071401_0d243214-8176-4518-ab38-db766e394404 without delay
2024-04-24T07:14:03,424  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9ab73d31-bd01-49e7-94fe-ad304b8456d2]
2024-04-24T07:14:03,424  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Removed queryId: alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=9ab73d31-bd01-49e7-94fe-ad304b8456d2] with tag: null
2024-04-24T07:14:03,425  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326
2024-04-24T07:14:03,425  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Shutting down task : Stage-1:MAPRED
Error during job, obtaining debugging information...
2024-04-24T07:14:03,427  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1
2024-04-24T07:14:03,426  WARN [Thread-144] mapred.LocalJobRunner: job_local1045512545_0003
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:14:03,427  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1 operation was queued
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:14:03,427  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-3
2024-04-24T07:14:03,427  WARN [HiveServer2-Background-Pool: Thread-139] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:03,427  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-3 operation was queued
2024-04-24 07:14:03,427 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,427  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,427  INFO [HiveServer2-Background-Pool: Thread-139] exec.Task: 2024-04-24 07:14:03,427 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,427  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,427  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,427 ERROR [Thread-216] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:14:03,428  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1
2024-04-24T07:14:03,428  WARN [HiveServer2-Background-Pool: Thread-139] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:03,429  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-3
2024-04-24T07:14:03,428  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:03,429  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
Ended Job = job_local1045512545_0003 with errors
2024-04-24T07:14:03,434 ERROR [HiveServer2-Background-Pool: Thread-139] exec.Task: Ended Job = job_local1045512545_0003 with errors
2024-04-24T07:14:03,435  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326 without delay
2024-04-24T07:14:03,435  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=68a5685d-adc9-460c-89aa-b4405e25d305]
Error during job, obtaining debugging information...
2024-04-24T07:14:03,435  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Removed queryId: alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=68a5685d-adc9-460c-89aa-b4405e25d305] with tag: null
2024-04-24T07:14:03,435 ERROR [Thread-220] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:14:03,436  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1 operation was queued
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 without delay
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=07783508-a90b-454b-833a-c1f4cba7fa7d]
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Removed queryId: alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=07783508-a90b-454b-833a-c1f4cba7fa7d] with tag: null
2024-04-24T07:14:03,437  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248
2024-04-24T07:14:03,437  INFO [HiveServer2-Background-Pool: Thread-114] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:14:03,438 ERROR [HiveServer2-Background-Pool: Thread-114] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:14:03,438  INFO [HiveServer2-Background-Pool: Thread-114] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:03,439  INFO [HiveServer2-Background-Pool: Thread-114] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-24T07:14:03,439  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-13-55_203_1728532217282806886-1
MapReduce Jobs Launched: 
2024-04-24T07:14:03,439  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T07:14:03,439  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:14:03,440  WARN [HiveServer2-Background-Pool: Thread-114] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-04-24T07:14:03,440  INFO [HiveServer2-Background-Pool: Thread-139] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL2024-04-24T07:14:03,440 ERROR [HiveServer2-Background-Pool: Thread-139] ql.Driver: FAILED: Operation cancelled

2024-04-24T07:14:03,440  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:03,440  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:03,441  INFO [HiveServer2-Background-Pool: Thread-114] ql.Driver: Executing command(queryId=alex_20240424071401_0d243214-8176-4518-ab38-db766e394404) has been interrupted after 1.274 seconds
2024-04-24T07:14:03,441  INFO [HiveServer2-Background-Pool: Thread-139] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:03,441  INFO [HiveServer2-Background-Pool: Thread-139] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:03,441  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:14:03,443  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-4
2024-04-24T07:14:03,443  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-4 operation was queued
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:14:03,443  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:14:03,443  WARN [HiveServer2-Background-Pool: Thread-186] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:03,443  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24 07:14:03,443 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,443  INFO [HiveServer2-Background-Pool: Thread-186] exec.Task: 2024-04-24 07:14:03,443 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,443  INFO [HiveServer2-Background-Pool: Thread-139] ql.Driver: Executing command(queryId=alex_20240424071402_c5c0e7ae-d7ca-4ee3-82a6-2e168d1fd326) has been interrupted after 1.028 seconds
2024-04-24T07:14:03,443  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1 operation was queued
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:14:03,444  WARN [Thread-181] mapred.LocalJobRunner: job_local575378341_0004
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:14:03,444  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,444  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,444  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248 without delay
2024-04-24T07:14:03,444  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-4
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6197f71e-43b9-4797-b4f8-0232f9987d40]
2024-04-24T07:14:03,444  WARN [HiveServer2-Background-Pool: Thread-114] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:14:03,444  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.OperationManager: Removed queryId: alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=6197f71e-43b9-4797-b4f8-0232f9987d40] with tag: null
2024-04-24T07:14:03,445  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32
2024-04-24T07:14:03,445  INFO [HiveServer2-Background-Pool: Thread-114] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:03,445  WARN [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T07:14:03,445  WARN [HiveServer2-Background-Pool: Thread-139] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:14:03,445  WARN [EventualCleanupService thread 5] fs.FileUtil: Failed to delete file or dir [/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1]: it still exists.
2024-04-24T07:14:03,446  INFO [HiveServer2-Background-Pool: Thread-139] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:03,446  INFO [EventualCleanupService thread 5] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1
2024-04-24T07:14:03,446  WARN [Thread-211] mapred.LocalJobRunner: job_local1422447575_0005
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [1000]
2024-04-24T07:14:03,448  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,448  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,448  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,447  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1
2024-04-24T07:14:03,451  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1 operation was queued
2024-04-24T07:14:03,452  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-5
2024-04-24T07:14:03,452  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-5 operation was queued
2024-04-24T07:14:03,452  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:03,452  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:14:03,452  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32 without delay
2024-04-24T07:14:03,452  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1
2024-04-24T07:14:03,453  INFO [0f72d513-84a7-407f-b29f-7938db981ddb main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb
2024-04-24T07:14:03,453  INFO [EventualCleanupService thread 7] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-5
2024-04-24T07:14:03,447  WARN [HiveServer2-Background-Pool: Thread-221] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24 07:14:03,446 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,454  INFO [HiveServer2-Background-Pool: Thread-221] exec.Task: 2024-04-24 07:14:03,446 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:03,455  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0f72d513-84a7-407f-b29f-7938db981ddb operation was queued
2024-04-24T07:14:03,455  WARN [HiveServer2-Background-Pool: Thread-221] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:03,455  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb operation was queued
2024-04-24T07:14:03,455  INFO [EventualCleanupService thread 9] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/0f72d513-84a7-407f-b29f-7938db981ddb
Ended Job = job_local1422447575_0005 with errors
2024-04-24T07:14:03,456 ERROR [HiveServer2-Background-Pool: Thread-221] exec.Task: Ended Job = job_local1422447575_0005 with errors
2024-04-24T07:14:03,456  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb
Error during job, obtaining debugging information...
2024-04-24T07:14:03,456 ERROR [Thread-226] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:14:03,465  INFO [HiveServer2-Background-Pool: Thread-221] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:14:03,465 ERROR [HiveServer2-Background-Pool: Thread-221] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:14:03,465  INFO [HiveServer2-Background-Pool: Thread-221] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:03,465  INFO [HiveServer2-Background-Pool: Thread-221] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:03,466  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:14:03,466  WARN [HiveServer2-Background-Pool: Thread-221] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:14:03,466  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:03,466  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:03,466  INFO [HiveServer2-Background-Pool: Thread-221] ql.Driver: Executing command(queryId=alex_20240424071402_3ee030f5-5c17-4c45-9d70-549e688b5e32) has been interrupted after 0.574 seconds
2024-04-24T07:14:03,466 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:239)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:1, RECORDS_IN:0, 
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:03,467  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:14:03,468 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:1, RECORDS_IN:0, 
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,468  WARN [HiveServer2-Background-Pool: Thread-221] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:14:03,469  INFO [HiveServer2-Background-Pool: Thread-221] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:03,469 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_task_tmp.-ext-10002/_tmp.000000_0': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:239)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:03,468  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_425_5809753058348140754-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_425_5809753058348140754-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, DESERIALIZE_ERRORS:1, RECORDS_IN:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T07:14:03,469 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: ExitCodeException exitCode=1: chmod: cannot access '/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_task_tmp.-ext-10002': No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)
	at org.apache.hadoop.util.Shell.run(Shell.java:902)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:522)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:562)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:698)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,470  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_177_561663517757432663-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_177_561663517757432663-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:14:03,471  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7ac48f05, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7af1d072 will be shutdown
2024-04-24T07:14:03,471  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:03,471  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:14:03,471  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,471  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,471  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-02_683_5637515660008810744-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-02_683_5637515660008810744-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,471  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:14:03,472  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-24T07:14:03,469  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:14:03,474  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:0, RECORDS_OUT_INTERMEDIATE:0, DESERIALIZE_ERRORS:1, 
2024-04-24T07:14:03,474  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:03,474  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:14:03,474  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:03,474  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,475  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:03,475  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 0
2024-04-24T07:14:03,476  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:03,476  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:03,476  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/0f72d513-84a7-407f-b29f-7938db981ddb/hive_2024-04-24_07-14-01_938_1555620043622068148-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-01_938_1555620043622068148-1/_tmp.-ext-10002/000000_0
]]></system-err>
  </testcase>
  <testcase name="testSync" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.343">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testSync(TestQueryShutdownHooks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T07:14:03,498  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_0:0, 
2024-04-24T07:14:03,501  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_0:0, 
2024-04-24T07:14:03,501  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_0:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_2:1, 
2024-04-24T07:14:03,501  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_0:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:03,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:14:03,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:14:03,563  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:14:03,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:14:03,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:14:03,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = a984e20a-048a-482f-bfe5-17f04573e2f5
2024-04-24T07:14:03,565  INFO [main] SessionState: Hive Session ID = a984e20a-048a-482f-bfe5-17f04573e2f5
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:03,565  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:03,572  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a984e20a-048a-482f-bfe5-17f04573e2f5
2024-04-24T07:14:03,575  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/a984e20a-048a-482f-bfe5-17f04573e2f5
2024-04-24T07:14:03,578  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/a984e20a-048a-482f-bfe5-17f04573e2f5/_tmp_space.db
2024-04-24T07:14:03,579  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=a984e20a-048a-482f-bfe5-17f04573e2f5, clientType=HIVESERVER2]
2024-04-24T07:14:03,580  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:14:03,581  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:14:03,581  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:14:03,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@123d0816, with PersistenceManager: null will be shutdown
2024-04-24T07:14:03,582  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@123d0816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4601a148 created in the thread with id: 1
2024-04-24T07:14:03,587  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@123d0816 from thread id: 1
2024-04-24T07:14:03,588  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:14:03,588  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:14:03,588  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:14:03,589  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:14:03,589  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:14:03,589  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:14:03,589  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:14:03,590  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T07:14:03,593  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T07:14:03,593  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:14:03,593  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:14:03,593  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:14:03,593  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:14:03,594  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:14:03,594  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:14:03,604  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:14:03,604  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:03,606  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:03,612  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:03,616  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:03,619  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7cbf4374-f02a-41c9-af74-9359a56683b4/_tmp_space.db
2024-04-24T07:14:03,619  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:14:03,619  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:14:03,620  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:14:03,620  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@123d0816, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4601a148 will be shutdown
2024-04-24T07:14:03,620  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:14:03,620  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-24T07:14:03,620  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:03,620  INFO [main] service.CompositeService: Session opened, SessionHandle [7cbf4374-f02a-41c9-af74-9359a56683b4], current sessions:1
2024-04-24T07:14:03,620  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:14:03,620  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:03,621  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bf3dd772-3135-44b1-b927-43090df5ad34] SessionHandle [7cbf4374-f02a-41c9-af74-9359a56683b4]
2024-04-24T07:14:03,622  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(noConsoleNoAnsi="null", Configuration(HiveLog4j2Test), pattern="%-5p : %m%n", header="null", alwaysWriteExceptions="null", PatternSelector=null, Replace=null, footer="null", disableAnsi="null", charset="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", header="null", pattern="%-5p : %m%n", footer="null", noConsoleNoAnsi="null", Replace=null, alwaysWriteExceptions="null", disableAnsi="null", Configuration(HiveLog4j2Test), PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8.test
2024-04-24T07:14:03,629  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8, startTime=1713968043620, sessionId=7cbf4374-f02a-41c9-af74-9359a56683b4, createTime=1713968043604, userName=anonymous, ipAddress=null]
2024-04-24T07:14:03,630  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Compiling command(queryId=alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:03,633  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:14:03,634  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:14:03,635  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:14:03,635  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4113d9ab, with PersistenceManager: null will be shutdown
2024-04-24T07:14:03,636  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4113d9ab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@448fa659 created in the thread with id: 1
2024-04-24T07:14:03,642  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4113d9ab from thread id: 1
2024-04-24T07:14:03,642  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:14:03,642  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:14:03,643  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8
2024-04-24T07:14:03,643  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:03,643  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7cbf4374-f02a-41c9-af74-9359a56683b4, clientType=HIVESERVER2]
2024-04-24T07:14:03,644  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:03,644  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:03,644  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:03,644  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:03,644  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:03,674  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:03,759  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:03,760  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:03,762  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:03,762  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:03,763  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-03_630_7486453194571533115-1
2024-04-24T07:14:03,769  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:03,772  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:03,773  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:03,787  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:03,788  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:03,790  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:03,790  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:03,790  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=8}
2024-04-24T07:14:03,790  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Completed compiling command(queryId=alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8); Time taken: 0.16 seconds
2024-04-24T07:14:03,790  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:03,791  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:14:03,791  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:03,791  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Executing command(queryId=alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:03,791  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001
2024-04-24T07:14:03,792  WARN [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Query ID = alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8
Total jobs = 1
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:03,792  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:03,988  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:03,988  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:03,991  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:03,991  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:03,992  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/dummy_path
2024-04-24T07:14:04,003  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:04,004  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:04,005  WARN [7cbf4374-f02a-41c9-af74-9359a56683b4 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:04,013  WARN [7cbf4374-f02a-41c9-af74-9359a56683b4 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:04,024  WARN [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:04,029  WARN [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:04,029  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:04,031  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/dummy_path
2024-04-24T07:14:04,037  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:04,037  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:04,037  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:04,059  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:04,087  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1942700417_0006
2024-04-24T07:14:04,088  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:04,187  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:04,188  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:04,188  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:04,188  INFO [Thread-295] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:04,190  INFO [Thread-295] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:04,191  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1942700417_0006_m_000000_0
2024-04-24T07:14:04,194  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:04,195  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:04,198  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:04,199  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:04,200  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:04,203  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:04,203  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:04,204  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:04,204  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:04,204  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:04,204  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:04,205  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@35b5d585, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@4284ac25, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@5a30336d
2024-04-24T07:14:04,206  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-03_630_7486453194571533115-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:04,206  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-03_630_7486453194571533115-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:04,206  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-03_630_7486453194571533115-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:04,219  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:04,219  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:14:04,219  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:04,220  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_0:1, 
2024-04-24T07:14:04,221  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:14:04,224  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1942700417_0006_m_000000_0 is done. And is in the process of committing
2024-04-24T07:14:04,225  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:14:04,225  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1942700417_0006_m_000000_0' done.
2024-04-24T07:14:04,225  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1942700417_0006_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=33474
		FILE: Number of bytes written=6933392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=956301312
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:14:04,225  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1942700417_0006_m_000000_0
2024-04-24T07:14:04,225  INFO [Thread-295] mapred.LocalJobRunner: map task executor complete.
2024-04-24T07:14:04,445  WARN [HiveServer2-Background-Pool: Thread-186] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_local575378341_0004 with errors
2024-04-24T07:14:04,447 ERROR [HiveServer2-Background-Pool: Thread-186] exec.Task: Ended Job = job_local575378341_0004 with errors
Error during job, obtaining debugging information...
2024-04-24T07:14:04,449 ERROR [Thread-302] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:14:04,454  INFO [HiveServer2-Background-Pool: Thread-186] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:14:04,455 ERROR [HiveServer2-Background-Pool: Thread-186] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:14:04,455  INFO [HiveServer2-Background-Pool: Thread-186] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:04,456  INFO [HiveServer2-Background-Pool: Thread-186] metadata.Hive: Total time spent in each metastore function (ms): {close_()=2}
MapReduce Jobs Launched: 
2024-04-24T07:14:04,456  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:14:04,457  WARN [HiveServer2-Background-Pool: Thread-186] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:14:04,458  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:04,458  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:04,458  INFO [HiveServer2-Background-Pool: Thread-186] ql.Driver: Executing command(queryId=alex_20240424071402_3aeb339d-e0c5-4b5a-863c-38ebd1f02248) has been interrupted after 1.783 seconds
2024-04-24T07:14:04,459  WARN [HiveServer2-Background-Pool: Thread-186] operation.SQLOperation: Ignore exception in terminal state: CLOSED
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.ql.Driver.getPlanMapper(Driver.java:607) ~[classes/:?]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:169) ~[classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:233) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation.access$500(SQLOperation.java:88) [classes/:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:336) [classes/:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_402]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_402]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) [hadoop-common-3.1.0.jar:?]
	at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:356) [classes/:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_402]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_402]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_402]
2024-04-24T07:14:04,460  INFO [HiveServer2-Background-Pool: Thread-186] common.LogUtils: Unregistered logging context.
2024-04-24 07:14:05,191 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:14:05,191  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Task: 2024-04-24 07:14:05,191 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1942700417_0006
2024-04-24T07:14:05,192  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.Task: Ended Job = job_local1942700417_0006
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1/-mr-10001
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:05,195  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:05,196  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:14:05,196  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:05,196  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:05,196  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Completed executing command(queryId=alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8); Time taken: 1.404 seconds
2024-04-24T07:14:05,197  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:05,197  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] session.HiveSessionImpl: executing CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:14:05,199  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=e786da0a-44bc-4f53-ae30-46d898d3ba4d] SessionHandle [7cbf4374-f02a-41c9-af74-9359a56683b4]
2024-04-24T07:14:05,200  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, header="null", noConsoleNoAnsi="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test), alwaysWriteExceptions="null", charset="null", footer="null", disableAnsi="null", PatternSelector=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, alwaysWriteExceptions="null", footer="null", charset="null", noConsoleNoAnsi="null", PatternSelector=null, header="null", disableAnsi="null", pattern="%-5p : %m%n", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9.test
2024-04-24T07:14:05,208  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9, startTime=1713968045197, sessionId=7cbf4374-f02a-41c9-af74-9359a56683b4, createTime=1713968043604, userName=anonymous, ipAddress=null]
2024-04-24T07:14:05,209  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Compiling command(queryId=alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:14:05,211  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9
2024-04-24T07:14:05,211  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:05,212  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Creating table default.sample_shutdown_hook position=13
2024-04-24T07:14:05,214  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T07:14:05,416  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] reflections.Reflections: Reflections took 187 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T07:14:05,493  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9
2024-04-24T07:14:05,493  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:05,493  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T07:14:05,493  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:05,493  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, getDatabase_(String)=13}
2024-04-24T07:14:05,494  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Completed compiling command(queryId=alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9); Time taken: 0.284 seconds
2024-04-24T07:14:05,494  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:05,494  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T07:14:05,494  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Executing command(queryId=alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9): CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:14:05,495  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
PREHOOK: type: CREATETABLE
2024-04-24T07:14:05,495  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
2024-04-24T07:14:05,495  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: Output: database:default
PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:14:05,495  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: PREHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:14:05,496  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T07:14:05,615  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:sample_shutdown_hook, dbName:default, owner:alex, createTime:1713968045, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:sample_id, type:int, comment:null), FieldSchema(name:sample_value, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"sample_id":"true","sample_value":"true"}}, numFilesErasureCoded=0, numFiles=0, totalSize=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
2024-04-24T07:14:05,832  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: query: CREATE TABLE sample_shutdown_hook (sample_id int, sample_value string)
POSTHOOK: type: CREATETABLE
2024-04-24T07:14:05,832  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
2024-04-24T07:14:05,832  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: Output: database:default
POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:14:05,832  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] SessionState: POSTHOOK: Output: default@sample_shutdown_hook
2024-04-24T07:14:05,832  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:05,833  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=218}
2024-04-24T07:14:05,833  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Driver: Completed executing command(queryId=alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9); Time taken: 0.338 seconds
2024-04-24T07:14:05,833  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:05,834  INFO [main] service.CompositeService: Session closed, SessionHandle [7cbf4374-f02a-41c9-af74-9359a56683b4], current sessions:0
2024-04-24T07:14:05,834  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bf3dd772-3135-44b1-b927-43090df5ad34]
2024-04-24T07:14:05,834  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Removed queryId: alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=bf3dd772-3135-44b1-b927-43090df5ad34] with tag: null
2024-04-24T07:14:05,834  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1
2024-04-24T07:14:05,834  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1 operation was queued
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] exec.ListSinkOperator: RECORDS_OUT_OPERATOR_LIST_SINK_3:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071403_7e7134db-3d7a-49d3-b98a-471e3d80a1b8 without delay
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=e786da0a-44bc-4f53-ae30-46d898d3ba4d]
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.OperationManager: Removed queryId: alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=e786da0a-44bc-4f53-ae30-46d898d3ba4d] with tag: null
2024-04-24T07:14:05,835  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4/alex_20240424071405_2beeff65-65d2-47f2-a3d1-e1c75ec16ea9 without delay
2024-04-24T07:14:05,835  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4/hive_2024-04-24_07-14-03_630_7486453194571533115-1
2024-04-24T07:14:05,836  INFO [7cbf4374-f02a-41c9-af74-9359a56683b4 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:05,837  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7cbf4374-f02a-41c9-af74-9359a56683b4 operation was queued
2024-04-24T07:14:05,837  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4 operation was queued
2024-04-24T07:14:05,837  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:05,837  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/7cbf4374-f02a-41c9-af74-9359a56683b4
2024-04-24T07:14:05,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:14:05,838  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4113d9ab, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@448fa659 will be shutdown
2024-04-24T07:14:05,838  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:14:05,838  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
]]></system-err>
  </testcase>
  <testcase name="testShutdownHookManagerIsRegistered" classname="org.apache.hive.service.cli.operation.TestQueryShutdownHooks" time="2.539">
    <error type="java.lang.NoSuchFieldError"><![CDATA[java.lang.NoSuchFieldError: OBJECT_MAPPER
	at org.apache.hive.service.cli.operation.SQLOperation.getTaskStatus(SQLOperation.java:509)
	at org.apache.hive.service.cli.operation.Operation.getStatus(Operation.java:144)
	at org.apache.hive.service.cli.CLIService.getOperationStatus(CLIService.java:478)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.GetOperationStatus(ThriftCLIService.java:793)
	at org.apache.hive.service.cli.thrift.ThriftCLIServiceClient.getOperationStatus(ThriftCLIServiceClient.java:378)
	at org.apache.hive.service.cli.operation.TestQueryShutdownHooks.testShutdownHookManagerIsRegistered(TestQueryShutdownHooks.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T07:14:05,906  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T07:14:05,907  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T07:14:05,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T07:14:05,907  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T07:14:05,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T07:14:05,907  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hiveserver2site does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T07:14:05,908  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
Hive Session ID = 5488fbf7-6ae6-442b-8619-5eeeb9ab091f
2024-04-24T07:14:05,909  INFO [main] SessionState: Hive Session ID = 5488fbf7-6ae6-442b-8619-5eeeb9ab091f
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:05,911  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:05,919  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5488fbf7-6ae6-442b-8619-5eeeb9ab091f
2024-04-24T07:14:05,922  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/5488fbf7-6ae6-442b-8619-5eeeb9ab091f
2024-04-24T07:14:05,926  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/5488fbf7-6ae6-442b-8619-5eeeb9ab091f/_tmp_space.db
2024-04-24T07:14:05,926  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5488fbf7-6ae6-442b-8619-5eeeb9ab091f, clientType=HIVESERVER2]
2024-04-24T07:14:05,928  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:14:05,930  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:14:05,930  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:14:05,931  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f11d889, with PersistenceManager: null will be shutdown
2024-04-24T07:14:05,932  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f11d889, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d1973e8 created in the thread with id: 1
2024-04-24T07:14:05,944  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f11d889 from thread id: 1
2024-04-24T07:14:05,944  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:14:05,944  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:14:05,945  INFO [main] service.CompositeService: Operation log root directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs
2024-04-24T07:14:05,946  INFO [main] service.CompositeService: HiveServer2: Background operation thread pool size: 100
2024-04-24T07:14:05,946  INFO [main] service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
2024-04-24T07:14:05,946  INFO [main] service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
2024-04-24T07:14:05,946  INFO [main] service.CompositeService: Connections limit are user: 0 ipaddress: 0 user-ipaddress: 0
2024-04-24T07:14:05,949  INFO [main] cleanup.EventualCleanupService: EventualCleanupService started with 10 threads and queue of size 10000
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
ERROR StatusLogger Log4j2 ConfigurationScheduler attempted to increment scheduled items after start
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:OperationManager is inited.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:SessionManager is inited.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:CLIService is inited.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:OperationManager is started.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:SessionManager is started.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:CLIService is started.
2024-04-24T07:14:05,953  INFO [main] service.AbstractService: Service:ThriftBinaryCLIService is inited.
2024-04-24T07:14:05,969  INFO [main] thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
2024-04-24T07:14:05,970  INFO [main] thrift.ThriftCLIService: Creating Hive session handle for user [anonymous] from IP null
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:05,971  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T07:14:05,979  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:05,983  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:05,987  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/55aa0e77-d8c1-4e09-b576-af8f76858e19/_tmp_space.db
2024-04-24T07:14:05,987  INFO [main] session.SessionState: Reloading auxiliary JAR files
2024-04-24T07:14:05,987  WARN [main] session.SessionState: Configuration hive.reloadable.aux.jars.path not specified
2024-04-24T07:14:05,987  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:14:05,987  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2f11d889, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d1973e8 will be shutdown
2024-04-24T07:14:05,988  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:14:05,988  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-24T07:14:05,988  INFO [main] session.HiveSessionImpl: Operation log session directory is created: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:05,988  INFO [main] service.CompositeService: Session opened, SessionHandle [55aa0e77-d8c1-4e09-b576-af8f76858e19], current sessions:1
2024-04-24T07:14:05,988  INFO [main] thrift.ThriftCLIService: Login attempt is successful for user : anonymous
2024-04-24T07:14:05,988  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] session.HiveSessionImpl: executing select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:05,989  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=baa2ae80-e40b-40d9-a946-c3d713d8219b] SessionHandle [55aa0e77-d8c1-4e09-b576-af8f76858e19]
2024-04-24T07:14:05,990  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, footer="null", header="null", pattern="%-5p : %m%n", disableAnsi="null", alwaysWriteExceptions="null", PatternSelector=null, charset="null", noConsoleNoAnsi="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", pattern="%-5p : %m%n", footer="null", disableAnsi="null", alwaysWriteExceptions="null", header="null", PatternSelector=null, Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", Replace=null)
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7.test
2024-04-24T07:14:05,998  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7, startTime=1713968045988, sessionId=55aa0e77-d8c1-4e09-b576-af8f76858e19, createTime=1713968045970, userName=anonymous, ipAddress=null]
2024-04-24T07:14:05,999  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Compiling command(queryId=alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7): select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:06,001  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T07:14:06,003  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T07:14:06,003  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T07:14:06,003  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e111e08, with PersistenceManager: null will be shutdown
2024-04-24T07:14:06,004  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e111e08, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e0e3048 created in the thread with id: 1
2024-04-24T07:14:06,009  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e111e08 from thread id: 1
2024-04-24T07:14:06,009  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T07:14:06,009  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=55aa0e77-d8c1-4e09-b576-af8f76858e19, clientType=HIVESERVER2]
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:06,010  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:06,040  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:06,220  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:06,221  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:06,237  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:06,237  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:06,238  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-05_999_5034210599687712058-1
2024-04-24T07:14:06,246  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:06,253  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:06,254  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7
2024-04-24T07:14:06,265  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:06,266  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:06,267  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:06,267  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:06,267  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=82, isCompatibleWith_(Configuration)=0}
2024-04-24T07:14:06,268  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Completed compiling command(queryId=alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7); Time taken: 0.268 seconds
2024-04-24T07:14:06,268  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:06,268  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.EmbeddedLockManager
2024-04-24T07:14:06,268  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:06,268  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Executing command(queryId=alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7): select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:06,269  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: PREHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
PREHOOK: type: QUERY
2024-04-24T07:14:06,269  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:06,269  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001
2024-04-24T07:14:06,269  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001
2024-04-24T07:14:06,270  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7
2024-04-24T07:14:06,270  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Query ID = alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7
Total jobs = 1
2024-04-24T07:14:06,270  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:06,270  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:06,463  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:06,463  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:06,465  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:06,466  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:06,466  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/dummy_path
2024-04-24T07:14:06,479  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:06,480  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:06,481  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:06,489  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:06,499  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:06,504  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:06,504  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:06,506  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/dummy_path
2024-04-24T07:14:06,512  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:06,513  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:06,513  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:06,535  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:06,559  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1397908547_0007
2024-04-24T07:14:06,559  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:06,645  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:06,646  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:06,646  INFO [Thread-345] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:06,646  INFO [Thread-345] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:06,649  INFO [Thread-345] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:06,649  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1397908547_0007_m_000000_0
2024-04-24T07:14:06,653  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:06,654  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:06,657  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:06,658  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,14KB
2024-04-24T07:14:06,658  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:06,662  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:06,662  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:06,663  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:06,663  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:06,663  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:06,663  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:06,664  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@3e177f63, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@7ae66393, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@5641645b
2024-04-24T07:14:06,664  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-05_999_5034210599687712058-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:06,664  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-05_999_5034210599687712058-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:06,664  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-05_999_5034210599687712058-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing Operator: FS[2]
2024-04-24T07:14:06,675  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[2]: records written - 1
2024-04-24T07:14:06,676  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_0:1, RECORDS_OUT_OPERATOR_FS_2:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:06,677  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T07:14:06,681  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1397908547_0007_m_000000_0 is done. And is in the process of committing
2024-04-24T07:14:06,683  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T07:14:06,683  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1397908547_0007_m_000000_0' done.
2024-04-24T07:14:06,683  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1397908547_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=39060
		FILE: Number of bytes written=8090576
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=341
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=956301312
	HIVE
		CREATED_FILES=1
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_0=1
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_2=1
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_TS_0=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T07:14:06,683  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1397908547_0007_m_000000_0
2024-04-24T07:14:06,683  INFO [Thread-345] mapred.LocalJobRunner: map task executor complete.
DEBUG StatusLogger Removing appender alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
DEBUG StatusLogger Deleting route with alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 key 
DEBUG StatusLogger Removing appender alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
DEBUG StatusLogger Stopping route with alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 key
DEBUG StatusLogger Deleting route with alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 key 
DEBUG StatusLogger Stopping appender query-file-appender
DEBUG StatusLogger Stopping route with alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664 key
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664
DEBUG StatusLogger Stopping appender test-query-file-appender
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664, all resources released: true
DEBUG StatusLogger Appender query-file-appender stopped with status true
DEBUG StatusLogger Shutting down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664.test
DEBUG StatusLogger Shut down RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/0f72d513-84a7-407f-b29f-7938db981ddb/alex_20240424071355_beaf057e-fe20-4340-beaa-a4efd29cc664.test, all resources released: true
DEBUG StatusLogger Appender test-query-file-appender stopped with status true
2024-04-24 07:14:07,656 Stage-1 map = 100%,  reduce = 0%
2024-04-24T07:14:07,657  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Task: 2024-04-24 07:14:07,656 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1397908547_0007
2024-04-24T07:14:07,661  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.Task: Ended Job = job_local1397908547_0007
POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
2024-04-24T07:14:07,671  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: POSTHOOK: query: select reflect("java.lang.System", "currentTimeMillis")
POSTHOOK: type: QUERY
2024-04-24T07:14:07,671  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:07,672  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001
2024-04-24T07:14:07,672  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] SessionState: POSTHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1/-mr-10001
2024-04-24T07:14:07,673  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:07,673  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:07,674  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T07:14:07,674  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:07,674  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:07,674  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Completed executing command(queryId=alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7); Time taken: 1.405 seconds
2024-04-24T07:14:07,677  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:07,678  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] session.HiveSessionImpl: executing select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:14:07,681  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Adding operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=7aced0b7-5488-4077-8fa3-c97a57868c7c] SessionHandle [55aa0e77-d8c1-4e09-b576-af8f76858e19]
2024-04-24T07:14:07,682  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.LogUtils: Thread context registration is done.
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter].
DEBUG StatusLogger createFilter(loggingLevel="EXECUTION")
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, header="null", Replace=null, charset="null", alwaysWriteExceptions="null", pattern="%-5p : %m%n", noConsoleNoAnsi="null", disableAnsi="null", Configuration(HiveLog4j2Test), footer="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36", append="null", name="query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), NameFilter(org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter with name NameFilter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
DEBUG StatusLogger Building Plugin[name=, class=org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter].
DEBUG StatusLogger createFilter()
DEBUG StatusLogger Building Plugin[name=, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(footer="null", noConsoleNoAnsi="null", Configuration(HiveLog4j2Test), Replace=null, alwaysWriteExceptions="null", disableAnsi="null", PatternSelector=null, header="null", charset="null", pattern="%-5p : %m%n")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender].
DEBUG StatusLogger createAppender(fileName="/home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36.test", append="null", name="test-query-file-appender", immediateFlush="null", bufferSize="null", ignoreExceptions="null", PatternLayout(org.apache.logging.log4j.core.layout.PatternLayout with name PatternLayout), test-filter(org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter with name test-filter), advertise="null", advertiseURI="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Starting RandomAccessFileManager /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36.test
2024-04-24T07:14:07,695  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.SQLOperation: [opType=EXECUTE_STATEMENT, queryId=alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36, startTime=1713968047678, sessionId=55aa0e77-d8c1-4e09-b576-af8f76858e19, createTime=1713968045970, userName=anonymous, ipAddress=null]
2024-04-24T07:14:07,697  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Compiling command(queryId=alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36): select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Starting caching scope for: alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:07,699  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T07:14:07,730  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:07,835  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T07:14:07,835  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T07:14:07,838  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T07:14:07,838  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T07:14:07,839  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1
2024-04-24T07:14:07,846  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T07:14:07,852  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T07:14:07,853  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorized: false
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T07:14:07,865  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T07:14:07,866  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T07:14:07,866  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Completed plan generation
2024-04-24T07:14:07,866  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] parse.CalcitePlanner: Ending caching scope for: alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
2024-04-24T07:14:07,866  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T07:14:07,866  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:_c0, type:string, comment:null)], properties:null)
2024-04-24T07:14:07,867  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: Initializing Operator: LIST_SINK[3]
2024-04-24T07:14:07,867  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T07:14:07,868  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, isCompatibleWith_(Configuration)=1}
2024-04-24T07:14:07,868  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Completed compiling command(queryId=alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36); Time taken: 0.17 seconds
2024-04-24T07:14:07,868  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] common.LogUtils: Unregistered logging context.
2024-04-24T07:14:07,868  INFO [HiveServer2-Background-Pool: Thread-439] common.LogUtils: Thread context registration is done.
2024-04-24T07:14:07,869  INFO [HiveServer2-Background-Pool: Thread-439] reexec.ReExecDriver: Execution #1 of query
2024-04-24T07:14:07,870  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Operation QUERY obtained 2 locks
2024-04-24T07:14:07,870  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Executing command(queryId=alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36): select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
2024-04-24T07:14:07,870  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: query: select reflect("java.lang.Thread", "sleep", bigint(5000))
PREHOOK: type: QUERY
2024-04-24T07:14:07,870  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
2024-04-24T07:14:07,871  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001
2024-04-24T07:14:07,871  INFO [HiveServer2-Background-Pool: Thread-439] SessionState: PREHOOK: Output: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001
2024-04-24T07:14:07,871  WARN [HiveServer2-Background-Pool: Thread-439] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
2024-04-24T07:14:07,871  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Query ID = alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
Total jobs = 1
2024-04-24T07:14:07,871  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T07:14:07,871  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Launching Job 1 out of 1
2024-04-24T07:14:07,957  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:07,957  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T07:14:07,964  INFO [HiveServer2-Background-Pool: Thread-439] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2024-04-24T07:14:07,964  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Processing alias _dummy_table
2024-04-24T07:14:07,964  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/dummy_path
2024-04-24T07:14:07,977  INFO [HiveServer2-Background-Pool: Thread-439] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T07:14:07,979  INFO [HiveServer2-Background-Pool: Thread-439] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,11KB
2024-04-24T07:14:07,980  WARN [HiveServer2-Background-Pool: Thread-439] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:07,987  WARN [HiveServer2-Background-Pool: Thread-439] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T07:14:07,994  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T07:14:07,999  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T07:14:08,000  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
2024-04-24T07:14:08,000  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/dummy_path; using filter path file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/dummy_path
2024-04-24T07:14:08,005  INFO [HiveServer2-Background-Pool: Thread-439] input.FileInputFormat: Total input files to process : 1
2024-04-24T07:14:08,005  INFO [HiveServer2-Background-Pool: Thread-439] input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
2024-04-24T07:14:08,005  INFO [HiveServer2-Background-Pool: Thread-439] io.CombineHiveInputFormat: Number of all splits 1
2024-04-24T07:14:08,026  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: number of splits:1
2024-04-24T07:14:08,049  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: Submitting tokens for job: job_local1729424653_0008
2024-04-24T07:14:08,049  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T07:14:08,127  INFO [HiveServer2-Background-Pool: Thread-439] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T07:14:08,128  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: Job running in-process (local Hadoop)
2024-04-24T07:14:08,128  INFO [Thread-384] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:08,128  INFO [Thread-384] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T07:14:08,130  INFO [Thread-384] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T07:14:08,130  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1729424653_0008_m_000000_0
2024-04-24T07:14:08,131  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T07:14:08,132  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: Paths:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/dummy_path/dummy_file:0+1InputFormatClass: org.apache.hadoop.hive.ql.io.NullRowsInputFormat

2024-04-24T07:14:08,133  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T07:14:08,134  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,11KB
2024-04-24T07:14:08,134  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T07:14:08,135  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T07:14:08,135  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T07:14:08,136  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T07:14:08,137  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T07:14:08,137  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T07:14:08,137  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing Operator: FS[2]
2024-04-24T07:14:08,138  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe [serdeParams=org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters@ae58a78, cachedObjectInspector=org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector<org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector@6f785a27>, serializedSize=0, stats=org.apache.hadoop.hive.serde2.SerDeStats@19b2a469, lastOperationSerialize=false, lastOperationDeserialize=false [1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1] : [_col0] : [string]] and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@d62042d
2024-04-24T07:14:08,370  INFO [main] service.CompositeService: Session closed, SessionHandle [55aa0e77-d8c1-4e09-b576-af8f76858e19], current sessions:0
2024-04-24T07:14:08,370  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=baa2ae80-e40b-40d9-a946-c3d713d8219b]
2024-04-24T07:14:08,370  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Removed queryId: alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=baa2ae80-e40b-40d9-a946-c3d713d8219b] with tag: null
2024-04-24T07:14:08,370  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1
2024-04-24T07:14:08,370  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1 operation was queued
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071405_71cef7d2-e2ab-4287-9465-9c387c54d9b7 without delay
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Closing operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=7aced0b7-5488-4077-8fa3-c97a57868c7c]
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.OperationManager: Removed queryId: alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36 corresponding to operation: OperationHandle [opType=EXECUTE_STATEMENT, getHandleIdentifier()=7aced0b7-5488-4077-8fa3-c97a57868c7c] with tag: null
2024-04-24T07:14:08,371  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.SQLOperation: The running operation has been successfully interrupted: alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36
2024-04-24T07:14:08,372  WARN [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Driver: Shutting down task : Stage-1:MAPRED
2024-04-24T07:14:08,372  INFO [EventualCleanupService thread 0] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-05_999_5034210599687712058-1
UDFReflect evaluate java.lang.reflect.InvocationTargetException method = public static native void java.lang.Thread.sleep(long) throws java.lang.InterruptedException args = [5000]
2024-04-24T07:14:08,372  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_tmp.-ext-10002/000000_0
2024-04-24T07:14:08,372  WARN [Thread-384] mapred.LocalJobRunner: job_local1729424653_0008
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_402]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) ~[?:1.8.0_402]
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475) ~[?:1.8.0_402]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:479) ~[hadoop-mapreduce-client-common-3.1.0.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552) [hadoop-mapreduce-client-common-3.1.0.jar:?]
2024-04-24T07:14:08,372  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1
2024-04-24T07:14:08,372  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T07:14:08,372  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:08,372  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_tmp.-ext-10002/000000_0
2024-04-24 07:14:08,372 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:08,373  INFO [HiveServer2-Background-Pool: Thread-439] exec.Task: 2024-04-24 07:14:08,372 Stage-1 map = 0%,  reduce = 0%
2024-04-24T07:14:08,372  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1 operation was queued
2024-04-24T07:14:08,373  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2024-04-24T07:14:08,373  INFO [EventualCleanupService thread 1] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1
2024-04-24T07:14:08,373  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-6
2024-04-24T07:14:08,373  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] cleanup.EventualCleanupService: Delete file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-6 operation was queued
2024-04-24T07:14:08,373  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: Closing Operator: LIST_SINK[3]
2024-04-24T07:14:08,374  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] exec.ListSinkOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_LIST_SINK_3:0, 
Ended Job = job_local1729424653_0008 with errors
2024-04-24T07:14:08,374  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] operation.SQLOperation: Closing operation log /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19/alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36 without delay
2024-04-24T07:14:08,374 ERROR [HiveServer2-Background-Pool: Thread-439] exec.Task: Ended Job = job_local1729424653_0008 with errors
2024-04-24T07:14:08,374  INFO [EventualCleanupService thread 2] cleanup.EventualCleanupService: Deleted file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-6
Error during job, obtaining debugging information...
2024-04-24T07:14:08,374 ERROR [Thread-389] exec.Task: Error during job, obtaining debugging information...
2024-04-24T07:14:08,374  INFO [55aa0e77-d8c1-4e09-b576-af8f76858e19 main] session.HiveSessionImpl: Operation log session directory is deleted: /home/alex/Repositories/hive/service/target/tmp/alex/operation_logs/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:08,375  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/55aa0e77-d8c1-4e09-b576-af8f76858e19 operation was queued
2024-04-24T07:14:08,376  INFO [main] cleanup.EventualCleanupService: Delete /home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19 operation was queued
2024-04-24T07:14:08,376  INFO [EventualCleanupService thread 3] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/scratchdir/alex/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:08,376  INFO [EventualCleanupService thread 4] cleanup.EventualCleanupService: Deleted /home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19
2024-04-24T07:14:08,376  INFO [HiveServer2-Background-Pool: Thread-439] reexec.ReOptimizePlugin: ReOptimization: retryPossible: false
FAILED: Operation cancelled
2024-04-24T07:14:08,377 ERROR [HiveServer2-Background-Pool: Thread-439] ql.Driver: FAILED: Operation cancelled
2024-04-24T07:14:08,377  INFO [HiveServer2-Background-Pool: Thread-439] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T07:14:08,377  INFO [HiveServer2-Background-Pool: Thread-439] metadata.Hive: Total time spent in each metastore function (ms): {}
MapReduce Jobs Launched: 
2024-04-24T07:14:08,377  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T07:14:08,377  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: MapReduce Jobs Launched: 
2024-04-24T07:14:08,377  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4e111e08, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3e0e3048 will be shutdown
2024-04-24T07:14:08,377  WARN [HiveServer2-Background-Pool: Thread-439] mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2024-04-24T07:14:08,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T07:14:08,378  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-04-24T07:14:08,378 ERROR [LocalJobRunner Map Task Executor #0] mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing writable
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:566)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:148)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.hive.ql.exec.mr.ExecMapRunner.run(ExecMapRunner.java:37)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:895)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:1065)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:94)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:888)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:173)
	at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:154)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:552)
	... 11 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:287)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketForFileIdx(FileSinkOperator.java:936)
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:890)
	... 18 more
Caused by: java.io.IOException: Mkdirs failed to create file:/home/alex/Repositories/hive/service/target/tmp/localscratchdir/55aa0e77-d8c1-4e09-b576-af8f76858e19/hive_2024-04-24_07-14-07_697_19338466840721283-1/-mr-10001/.hive-staging_hive_2024-04-24_07-14-07_697_19338466840721283-1/_task_tmp.-ext-10002 (exists=false, cwd=file:/home/alex/Repositories/hive/service)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:458)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:981)
	at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)
	at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:284)
	... 20 more

2024-04-24T07:14:08,378  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T07:14:08,378  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 0. abort - true
2024-04-24T07:14:08,378  INFO [HiveServer2-Background-Pool: Thread-439] ql.Driver: Executing command(queryId=alex_20240424071407_b085337d-5618-489f-aca9-29fdd78bae36) has been interrupted after 0.507 seconds
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:0, DESERIALIZE_ERRORS:1, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_OPERATOR_TS_0:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T07:14:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
]]></system-err>
  </testcase>
</testsuite>