<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="60.825" tests="6" errors="3" skipped="0" failures="2">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="nondexStart" value="0"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="Europe/Lisbon"/>
    <property name="user.country.format" value="PT"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire4207260125553728606tmp surefire_3976495820043613801448tmp"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="nondexExecid" value="gPIn3SsWQS7Kp2I+NagCg1oJoSn7PTHIlfMhEIBX4k8="/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="metastore.schema.verification" value="false"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="line.separator" value="&#10;"/>
    <property name="metastore.warehouse.dir" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/warehouse"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="974622"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="javax.jdo.option.ConnectionURL" value="jdbc:derby:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/junit_metastore_db;create=true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="user.language.format" value="pt"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value=""/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="datanucleus.schema.autoCreateAll" value="true"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpgradeExternalTableNoReadPermissionForTable" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="10.004">
    <failure type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForTable(TestPreUpgradeTool.java:338)
]]></failure>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
2024-04-24T20:43:46,023  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-site.xml
2024-04-24T20:43:46,393  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:46,394  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:46,394  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:46,394  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:46,394  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:46,394  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:46,395  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:46,395  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:46,395  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:46,395  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:46,395  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:46,396  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:46,396  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:46,396  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:46,396  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:46,396  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:46,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:46,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:46,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:46,397  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:46,458  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:46,459  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:46,459  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:46,459  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:46,459  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:46,459  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:46,460  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:46,461  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:46,461  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:46,461  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:46,461  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:46,462  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:46,462  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:46,462  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:46,462  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:47,857  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:47,857  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:47,858  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:47,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:48,208  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T20:43:48,241  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497
2024-04-24T20:43:48,243  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497
2024-04-24T20:43:48,246  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db
2024-04-24T20:43:48,264  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c8920f15-a41b-42e8-95c2-8748decaa497, clientType=HIVECLI]
2024-04-24T20:43:48,266  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:43:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:48,759  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:48,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:48,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:48,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:48,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:48,762  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:48,780  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:49,183  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:49,184  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:49,184  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:49,184  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:49,184  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:49,184  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:49,185  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:49,186  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:49,186  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:49,187  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T20:43:50,129  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:50,131  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:50,198  WARN [main] metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2024-04-24T20:43:50,198  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-24T20:43:50,279  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2024-04-24T20:43:50,283  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2024-04-24T20:43:50,480  INFO [main] metastore.HiveMetaStore: 0: get_all_functions
2024-04-24T20:43:50,481  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-24T20:43:50,549  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): drop table if exists TExternal
2024-04-24T20:43:51,057  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:51,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:51,083  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:51,085  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:51,090  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:51,091  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 0.561 seconds
2024-04-24T20:43:51,094  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:51,095  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): drop table if exists TExternal
2024-04-24T20:43:51,102  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:51,103  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:51,103  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:51,105 ERROR [main] metadata.Hive: Table TExternal not found: default.TExternal table not found
2024-04-24T20:43:51,117  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:51,117  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:51,120  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:51,121  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 0.025 seconds
OK
2024-04-24T20:43:51,121  INFO [main] ql.Driver: OK
2024-04-24T20:43:51,121  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:51,122  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): create table TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:51,146  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:51,151  INFO [main] parse.CalcitePlanner: Creating table default.TExternal position=13
2024-04-24T20:43:51,161  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:51,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:51,165  INFO [main] metadata.HiveUtils: Adding metastore authorization provider: org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
2024-04-24T20:43:51,181  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:51,184  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:51,184  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:51,185  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 0.062 seconds
2024-04-24T20:43:51,185  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:51,188  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7)
2024-04-24T20:43:51,200  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:51,250  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:51,250  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:51,250  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:51,250  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:51,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:51,252  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:51,272  INFO [main] txn.TxnHandler: START========"HiveConf()"========
hiveDefaultUrl=null
hiveSiteURL=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-site.xml
hiveServer2SiteUrl=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hiveserver2-site.xml
hivemetastoreSiteUrl=file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hivemetastore-site.xml
Values omitted for security reason if present: [fs.s3n.awsSecretAccessKey, javax.jdo.option.ConnectionPassword, fs.s3n.awsAccessKeyId, fs.s3a.access.key, fs.s3.awsAccessKeyId, fs.s3.awsSecretAccessKey, fs.s3a.secret.key, hive.server2.keystore.password, fs.s3a.proxy.password]
_hive.hdfs.session.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497:
_hive.local.session.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497:
_hive.tmp_table_space=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db
datanucleus.autoStartMechanismMode=ignored
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPool.maxPoolSize=4
datanucleus.connectionPoolingType=BONECP
datanucleus.identifierFactory=datanucleus1
datanucleus.plugin.pluginRegistryBundleCheck=LOG
datanucleus.rdbms.initializeColumnInfo=NONE
datanucleus.rdbms.useLegacyNativeValueStrategy=true
datanucleus.schema.autoCreateAll=true
datanucleus.schema.validateColumns=false
datanucleus.schema.validateConstraints=false
datanucleus.schema.validateTables=false
datanucleus.storeManagerType=rdbms
datanucleus.transactionIsolation=read-committed
dfs.ha.fencing.ssh.connect-timeout=30000
file.blocksize=67108864
file.bytes-per-checksum=512
file.client-write-packet-size=65536
file.replication=1
file.stream-buffer-size=4096
fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
fs.AbstractFileSystem.ftp.impl=org.apache.hadoop.fs.ftp.FtpFs
fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
fs.automatic.close=true
fs.client.resolve.remote.symlinks=true
fs.defaultFS=file:///
fs.df.interval=60000
fs.du.interval=600000
fs.ftp.host=0.0.0.0
fs.ftp.host.port=21
fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem
fs.har.impl.disable.cache=true
fs.permissions.umask-mode=022
fs.pfile.impl=org.apache.hadoop.fs.ProxyLocalFileSystem
fs.s3.block.size=67108864
fs.s3.buffer.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/s3
fs.s3.maxRetries=4
fs.s3.sleepTimeSeconds=10
fs.s3a.attempts.maximum=10
fs.s3a.buffer.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/s3a
fs.s3a.connection.establish.timeout=5000
fs.s3a.connection.maximum=15
fs.s3a.connection.ssl.enabled=true
fs.s3a.connection.timeout=50000
fs.s3a.fast.buffer.size=1048576
fs.s3a.fast.upload=false
fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
fs.s3a.max.total.tasks=1000
fs.s3a.multipart.purge=false
fs.s3a.multipart.purge.age=86400
fs.s3a.multipart.size=104857600
fs.s3a.multipart.threshold=2147483647
fs.s3a.paging.maximum=5000
fs.s3a.threads.core=15
fs.s3a.threads.keepalivetime=60
fs.s3a.threads.max=256
fs.s3n.block.size=67108864
fs.s3n.multipart.copy.block.size=5368709120
fs.s3n.multipart.uploads.block.size=67108864
fs.s3n.multipart.uploads.enabled=false
fs.scheme.class=dfs
fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
fs.trash.checkpoint.interval=0
fs.trash.interval=0
ftp.blocksize=67108864
ftp.bytes-per-checksum=512
ftp.client-write-packet-size=65536
ftp.replication=3
ftp.stream-buffer-size=4096
ha.failover-controller.cli-check.rpc-timeout.ms=20000
ha.failover-controller.graceful-fence.connection.retries=1
ha.failover-controller.graceful-fence.rpc-timeout.ms=5000
ha.failover-controller.new-active.rpc-timeout.ms=60000
ha.health-monitor.check-interval.ms=1000
ha.health-monitor.connect-retry-interval.ms=1000
ha.health-monitor.rpc-timeout.ms=45000
ha.health-monitor.sleep-after-disconnect.ms=1000
ha.zookeeper.acl=world:anyone:rwcda
ha.zookeeper.parent-znode=/hadoop-ha
ha.zookeeper.session-timeout.ms=5000
hadoop.bin.path=
    /usr/bin/hadoop:
hadoop.common.configuration.version=0.23.0
hadoop.http.authentication.kerberos.keytab=/home/alex/hadoop.keytab
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
hadoop.http.authentication.signature.secret.file=/home/alex/hadoop-http-auth-signature-secret
hadoop.http.authentication.simple.anonymous.allowed=true
hadoop.http.authentication.token.validity=36000
hadoop.http.authentication.type=simple
hadoop.http.cross-origin.allowed-headers=X-Requested-With,Content-Type,Accept,Origin
hadoop.http.cross-origin.allowed-methods=GET,POST,HEAD
hadoop.http.cross-origin.allowed-origins=*
hadoop.http.cross-origin.enabled=false
hadoop.http.cross-origin.max-age=1800
hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
hadoop.http.staticuser.user=dr.who
hadoop.jetty.logs.serve.aliases=true
hadoop.kerberos.kinit.command=kinit
hadoop.registry.jaas.context=Client
hadoop.registry.rm.enabled=false
hadoop.registry.secure=false
hadoop.registry.system.acls=sasl:yarn@, sasl:mapred@, sasl:hdfs@
hadoop.registry.zk.connection.timeout.ms=15000
hadoop.registry.zk.quorum=localhost:2181
hadoop.registry.zk.retry.ceiling.ms=60000
hadoop.registry.zk.retry.interval.ms=1000
hadoop.registry.zk.retry.times=5
hadoop.registry.zk.root=/registry
hadoop.registry.zk.session.timeout.ms=60000
hadoop.rpc.protection=authentication
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
hadoop.security.authentication=simple
hadoop.security.authorization=false
hadoop.security.crypto.buffer.size=8192
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
hadoop.security.group.mapping.ldap.directory.search.timeout=10000
hadoop.security.group.mapping.ldap.search.attr.group.name=cn
hadoop.security.group.mapping.ldap.search.attr.member=member
hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
hadoop.security.group.mapping.ldap.search.filter.user=(&(objectClass=user)(sAMAccountName={0}))
hadoop.security.group.mapping.ldap.ssl=false
hadoop.security.groups.cache.secs=300
hadoop.security.groups.cache.warn.after.ms=5000
hadoop.security.groups.negative-cache.secs=30
hadoop.security.instrumentation.requires.admin=false
hadoop.security.java.secure.random.algorithm=SHA1PRNG
hadoop.security.kms.client.authentication.retry-count=1
hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
hadoop.security.kms.client.encrypted.key.cache.size=500
hadoop.security.random.device.file.path=
    /dev/urandom:
hadoop.security.uid.cache.secs=14400
hadoop.ssl.client.conf=ssl-client.xml
hadoop.ssl.enabled=false
hadoop.ssl.enabled.protocols=TLSv1
hadoop.ssl.hostname.verifier=DEFAULT
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
hadoop.ssl.require.client.cert=false
hadoop.ssl.server.conf=ssl-server.xml
hadoop.tmp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp
hadoop.user.group.static.mapping.overrides=dr.who=;
hadoop.util.hash.type=murmur
hadoop.work.around.non.threadsafe.getpwuid=false
hive.allow.udf.load.on.demand=false
hive.analyze.stmt.collect.partlevel.stats=true
hive.archive.enabled=false
hive.async.log.enabled=true
hive.ats.hook.queue.capacity=64
hive.auto.convert.join=false
hive.auto.convert.join.hashtable.max.entries=40000000
hive.auto.convert.join.noconditionaltask=true
hive.auto.convert.join.noconditionaltask.size=10000000
hive.auto.convert.join.use.nonstaged=false
hive.auto.convert.sortmerge.join=false
hive.auto.convert.sortmerge.join.bigtable.selection.policy=org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
hive.auto.convert.sortmerge.join.reduce.side=true
hive.auto.convert.sortmerge.join.to.mapjoin=false
hive.auto.progress.timeout=0s
hive.autogen.columnalias.prefix.includefuncname=false
hive.autogen.columnalias.prefix.label=_c
hive.binary.record.max.length=1000
hive.blobstore.optimizations.enabled=true
hive.blobstore.supported.schemes=s3,s3a,s3n
hive.blobstore.use.blobstore.as.scratchdir=false
hive.cache.expr.evaluation=true
hive.cbo.cnf.maxnodes=-1
hive.cbo.costmodel.cpu=0.000001
hive.cbo.costmodel.extended=false
hive.cbo.costmodel.hdfs.read=1.5
hive.cbo.costmodel.hdfs.write=10.0
hive.cbo.costmodel.local.fs.read=4.0
hive.cbo.costmodel.local.fs.write=4.0
hive.cbo.costmodel.network=150.0
hive.cbo.enable=true
hive.cbo.fallback.strategy=TEST
hive.cbo.returnpath.hiveop=
    false:
hive.cbo.show.warnings=true
hive.cli.errors.ignore=false
hive.cli.pretty.output.num.cols=-1
hive.cli.print.current.db=false
hive.cli.print.header=false
hive.cli.prompt=hive
hive.cli.tez.session.async=true
hive.cluster.delegation.token.store.class=org.apache.hadoop.hive.thrift.MemoryTokenStore
hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
hive.compactor.abortedtxn.threshold=1000
hive.compactor.check.interval=300s
hive.compactor.cleaner.run.interval=5000ms
hive.compactor.delta.num.threshold=10
hive.compactor.delta.pct.threshold=0.1
hive.compactor.history.reaper.interval=2m
hive.compactor.history.retention.attempted=2
hive.compactor.history.retention.failed=3
hive.compactor.history.retention.succeeded=3
hive.compactor.initiator.failed.compacts.threshold=2
hive.compactor.initiator.on=false
hive.compactor.max.num.delta=500
hive.compactor.worker.threads=0
hive.compactor.worker.timeout=86400s
hive.compat=0.12
hive.compute.query.using.stats=true
hive.compute.splits.in.am=true
hive.conf.hidden.list=javax.jdo.option.ConnectionPassword,hive.server2.keystore.password,fs.s3.awsAccessKeyId,fs.s3.awsSecretAccessKey,fs.s3n.awsAccessKeyId,fs.s3n.awsSecretAccessKey,fs.s3a.access.key,fs.s3a.secret.key,fs.s3a.proxy.password
hive.conf.internal.variable.list=hive.added.files.path,hive.added.jars.path,hive.added.archives.path
hive.conf.restricted.list=from.hivemetastore-site.xml
hive.conf.validation=true
hive.convert.join.bucket.mapjoin.tez=false
hive.count.open.txns.interval=1s
hive.counters.group.name=HIVE
hive.debug.localtask=false
hive.decode.partition.name=false
hive.default.fileformat=TextFile
hive.default.fileformat.managed=none
hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
hive.default.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.direct.sql.max.elements.in.clause=1000
hive.direct.sql.max.elements.values.clause=1000
hive.direct.sql.max.query.length=100
hive.display.partition.cols.separately=true
hive.downloaded.resources.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/c8920f15-a41b-42e8-95c2-8748decaa497_resources
hive.driver.parallel.compilation=false
hive.druid.broker.address.default=localhost:8082
hive.druid.coordinator.address.default=localhost:8081
hive.druid.http.numConnection=20
hive.druid.http.read.timeout=PT1M
hive.druid.indexer.memory.rownum.max=75000
hive.druid.indexer.partition.size.max=5000000
hive.druid.indexer.segments.granularity=DAY
hive.druid.maxTries=5
hive.druid.metadata.base=druid
hive.druid.metadata.db.type=mysql
hive.druid.passiveWaitTimeMs=30000
hive.druid.select.distribute=true
hive.druid.select.threshold=10000
hive.druid.sleep.time=PT10S
hive.druid.storage.storageDirectory=/druid/segments
hive.druid.working.directory=/tmp/workingDirectory
hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml
hive.dummyparam.test.server.specific.config.metastoresite=from.hivemetastore-site.xml
hive.dummyparam.test.server.specific.config.override=from.hivemetastore-site.xml
hive.enforce.bucketmapjoin=false
hive.enforce.sortmergebucketmapjoin=false
hive.entity.capture.transform=false
hive.entity.separator=@
hive.error.on.empty.partition=false
hive.exec.check.crossproducts=true
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
hive.exec.concatenate.check.index=true
hive.exec.copyfile.maxnumfiles=1
hive.exec.copyfile.maxsize=33554432
hive.exec.counters.pull.interval=1000
hive.exec.default.partition.name=__HIVE_DEFAULT_PARTITION__
hive.exec.drop.ignorenonexistent=true
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=strict
hive.exec.infer.bucket.sort=false
hive.exec.infer.bucket.sort.num.buckets.power.two=false
hive.exec.input.listing.max.threads=0
hive.exec.job.debug.capture.stacktraces=true
hive.exec.job.debug.timeout=30000
hive.exec.local.scratchdir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/
hive.exec.max.created.files=100000
hive.exec.max.dynamic.partitions=1000
hive.exec.max.dynamic.partitions.pernode=100
hive.exec.mode.local.auto=false
hive.exec.mode.local.auto.input.files.max=4
hive.exec.mode.local.auto.inputbytes.max=134217728
hive.exec.orc.base.delta.ratio=8
hive.exec.orc.split.strategy=HYBRID
hive.exec.parallel=false
hive.exec.parallel.thread.number=8
hive.exec.perf.logger=org.apache.hadoop.hive.ql.log.PerfLogger
hive.exec.post.hooks=
hive.exec.pre.hooks=
hive.exec.rcfile.use.explicit.header=true
hive.exec.rcfile.use.sync.cache=true
hive.exec.reducers.bytes.per.reducer=256000000
hive.exec.reducers.max=1009
hive.exec.rowoffset=false
hive.exec.schema.evolution=true
hive.exec.scratchdir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir
hive.exec.script.allow.partial.consumption=false
hive.exec.script.maxerrsize=100000
hive.exec.script.trust=false
hive.exec.show.job.failure.debug.info=true
hive.exec.stagingdir=.hive-staging
hive.exec.submit.local.task.via.child=false
hive.exec.submitviachild=false
hive.exec.tasklog.debug.timeout=20000
hive.exec.temporary.table.storage=default
hive.execution.engine=mr
hive.execution.mode=container
hive.exim.strict.repl.tables=true
hive.exim.uri.scheme.whitelist=hdfs,pfile,file,s3,s3a
hive.explain.dependency.append.tasktype=false
hive.explain.user=true
hive.fetch.output.serde=org.apache.hadoop.hive.serde2.DelimitedJSONSerDe
hive.fetch.task.aggr=false
hive.fetch.task.conversion=minimal
hive.fetch.task.conversion.threshold=1073741824
hive.file.max.footer=100
hive.fileformat.check=true
hive.groupby.limit.extrastep=true
hive.groupby.mapaggr.checkinterval=100000
hive.groupby.orderby.position.alias=false
hive.groupby.position.alias=false
hive.groupby.skewindata=false
hive.hash.table.inflation.factor=2.0
hive.hashtable.initialCapacity=100000
hive.hashtable.key.count.adjustment=1.0
hive.hashtable.loadfactor=0.75
hive.hbase.generatehfiles=false
hive.hbase.snapshot.restoredir=/tmp
hive.hbase.wal.enabled=true
hive.heartbeat.interval=1000
hive.hmshandler.force.reload.conf=false
hive.hmshandler.retry.attempts=10
hive.hmshandler.retry.interval=2000ms
hive.ignore.mapjoin.hint=false
hive.in.test=true
hive.in.tez.test=false
hive.index.compact.binary.search=true
hive.index.compact.file.ignore.hdfs=false
hive.index.compact.query.max.entries=10000000
hive.index.compact.query.max.size=10737418240
hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.insert.into.external.tables=true
hive.insert.into.multilevel.dirs=false
hive.int.timestamp.conversion.in.seconds=false
hive.io.rcfile.column.number.conf=0
hive.io.rcfile.record.buffer.size=4194304
hive.io.rcfile.record.interval=2147483647
hive.io.rcfile.tolerate.corruptions=false
hive.io.sarg.cache.max.weight.mb=10
hive.jar.path=
    ${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar:
hive.jobname.length=50
hive.join.cache.size=25000
hive.join.emit.interval=1000
hive.lazysimple.extended_boolean_literal=false
hive.limit.optimize.enable=false
hive.limit.optimize.fetch.max=50000
hive.limit.optimize.limit.file=10
hive.limit.pushdown.memory.usage=0.1
hive.limit.query.max.table.partition=-1
hive.limit.row.max.size=100000
hive.llap.allow.permanent.fns=true
hive.llap.am.liveness.connection.sleep.between.retries.ms=2000ms
hive.llap.am.liveness.connection.timeout.ms=10000ms
hive.llap.am.use.fqdn=false
hive.llap.auto.allow.uber=false
hive.llap.auto.auth=false
hive.llap.auto.enforce.stats=true
hive.llap.auto.enforce.tree=true
hive.llap.auto.enforce.vectorized=true
hive.llap.auto.max.input.size=10737418240
hive.llap.auto.max.output.size=1073741824
hive.llap.cache.allow.synthetic.fileid=true
hive.llap.client.consistent.splits=false
hive.llap.daemon.acl=*
hive.llap.daemon.am-reporter.max.threads=4
hive.llap.daemon.am.liveness.heartbeat.interval.ms=10000ms
hive.llap.daemon.communicator.num.threads=10
hive.llap.daemon.delegation.token.lifetime=14d
hive.llap.daemon.download.permanent.fns=false
hive.llap.daemon.logger=query-routing
hive.llap.daemon.memory.per.instance.mb=4096
hive.llap.daemon.num.executors=4
hive.llap.daemon.num.file.cleaner.threads=1
hive.llap.daemon.output.service.max.pending.writes=8
hive.llap.daemon.output.service.port=15003
hive.llap.daemon.output.service.send.buffer.size=131072
hive.llap.daemon.output.stream.timeout=120s
hive.llap.daemon.rpc.num.handlers=5
hive.llap.daemon.rpc.port=0
hive.llap.daemon.service.refresh.interval.sec=60s
hive.llap.daemon.shuffle.dir.watcher.enabled=false
hive.llap.daemon.task.preemption.metrics.intervals=30,60,300
hive.llap.daemon.task.scheduler.enable.preemption=true
hive.llap.daemon.task.scheduler.wait.queue.size=10
hive.llap.daemon.vcpus.per.instance=4
hive.llap.daemon.wait.queue.comparator.class.name=org.apache.hadoop.hive.llap.daemon.impl.comparator.ShortestJobFirstComparator
hive.llap.daemon.web.port=15002
hive.llap.daemon.web.ssl=false
hive.llap.daemon.xmx.headroom=5%
hive.llap.daemon.yarn.container.mb=-1
hive.llap.daemon.yarn.shuffle.port=15551
hive.llap.enable.grace.join.in.llap=false
hive.llap.execution.mode=none
hive.llap.file.cleanup.delay.seconds=300s
hive.llap.hs2.coordinator.enabled=true
hive.llap.io.allocator.alloc.max=16Mb
hive.llap.io.allocator.alloc.min=256Kb
hive.llap.io.allocator.arena.count=8
hive.llap.io.allocator.direct=false
hive.llap.io.allocator.mmap=false
hive.llap.io.allocator.mmap.path=
    /tmp:
hive.llap.io.cache.orc.alloc.max=2097152
hive.llap.io.cache.orc.alloc.min=32768
hive.llap.io.cache.orc.arena.size=8388608
hive.llap.io.cache.orc.size=8388608
hive.llap.io.decoding.metrics.percentiles.intervals=30
hive.llap.io.encode.alloc.size=256Kb
hive.llap.io.encode.enabled=true
hive.llap.io.encode.formats=org.apache.hadoop.mapred.TextInputFormat,
hive.llap.io.encode.slice.lrr=true
hive.llap.io.encode.slice.row.count=100000
hive.llap.io.encode.vector.serde.async.enabled=true
hive.llap.io.encode.vector.serde.enabled=true
hive.llap.io.lrfu.lambda=0.01
hive.llap.io.memory.mode=cache
hive.llap.io.memory.size=1Gb
hive.llap.io.metadata.fraction=0.1
hive.llap.io.nonvector.wrapper.enabled=true
hive.llap.io.orc.time.counters=true
hive.llap.io.threadpool.size=10
hive.llap.io.use.fileid.path=
    true:
hive.llap.io.use.lrfu=true
hive.llap.management.acl=*
hive.llap.management.rpc.port=15004
hive.llap.object.cache.enabled=true
hive.llap.orc.gap.cache=true
hive.llap.remote.token.requires.signing=true
hive.llap.skip.compile.udf.check=false
hive.llap.task.communicator.connection.sleep.between.retries.ms=2000ms
hive.llap.task.communicator.connection.timeout.ms=16000ms
hive.llap.task.communicator.listener.thread-count=30
hive.llap.task.scheduler.locality.delay=0ms
hive.llap.task.scheduler.node.disable.backoff.factor=1.5
hive.llap.task.scheduler.node.reenable.max.timeout.ms=10000ms
hive.llap.task.scheduler.node.reenable.min.timeout.ms=200ms
hive.llap.task.scheduler.num.schedulable.tasks.per.node=0
hive.llap.task.scheduler.timeout.seconds=60s
hive.llap.validate.acls=true
hive.load.dynamic.partitions.thread=15
hive.localize.resource.num.wait.attempts=5
hive.localize.resource.wait.interval=5000ms
hive.lock.manager=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
hive.lock.mapred.only.operation=false
hive.lock.numretries=100
hive.lock.sleep.between.retries=60s
hive.lockmgr.zookeeper.default.partition.name=__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
hive.log.every.n.records=0
hive.log.explain.output=false
hive.map.aggr=true
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.map.aggr.hash.min.reduction=0.5
hive.map.aggr.hash.percentmemory=0.5
hive.map.groupby.sorted=true
hive.mapjoin.bucket.cache.size=100
hive.mapjoin.check.memory.rows=100000
hive.mapjoin.followby.gby.localtask.max.memory.usage=0.55
hive.mapjoin.followby.map.aggr.hash.percentmemory=0.3
hive.mapjoin.hybridgrace.bloomfilter=true
hive.mapjoin.hybridgrace.hashtable=true
hive.mapjoin.hybridgrace.memcheckfrequency=1024
hive.mapjoin.hybridgrace.minnumpartitions=16
hive.mapjoin.hybridgrace.minwbsize=524288
hive.mapjoin.localtask.max.memory.usage=0.9
hive.mapjoin.max.gc.time.percentage=0.99
hive.mapjoin.optimized.hashtable=true
hive.mapjoin.optimized.hashtable.probe.percent=0.5
hive.mapjoin.optimized.hashtable.wbsize=8388608
hive.mapjoin.smalltable.filesize=25000000
hive.mapper.cannot.span.multiple.partitions=false
hive.mapred.local.mem=0
hive.mapred.partitioner=org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
hive.mapred.reduce.tasks.speculative.execution=true
hive.materializedview.fileformat=ORC
hive.materializedview.rewriting=true
hive.materializedview.serde=org.apache.hadoop.hive.ql.io.orc.OrcSerde
hive.max.open.txns=100000
hive.merge.cardinality.check=true
hive.merge.mapfiles=true
hive.merge.mapredfiles=false
hive.merge.nway.joins=true
hive.merge.orcfile.stripe.level=true
hive.merge.rcfile.block.level=true
hive.merge.size.per.task=256000000
hive.merge.smallfiles.avgsize=16000000
hive.merge.sparkfiles=false
hive.merge.tezfiles=false
hive.metadata.move.exported.metadata.to.trash=true
hive.metastore.aggregate.stats.cache.clean.until=0.8
hive.metastore.aggregate.stats.cache.enabled=true
hive.metastore.aggregate.stats.cache.fpp=0.01
hive.metastore.aggregate.stats.cache.max.full=0.9
hive.metastore.aggregate.stats.cache.max.partitions=10000
hive.metastore.aggregate.stats.cache.max.reader.wait=1000ms
hive.metastore.aggregate.stats.cache.max.variance=0.01
hive.metastore.aggregate.stats.cache.max.writer.wait=5000ms
hive.metastore.aggregate.stats.cache.size=10000
hive.metastore.aggregate.stats.cache.ttl=600s
hive.metastore.archive.intermediate.archived=_INTERMEDIATE_ARCHIVED
hive.metastore.archive.intermediate.extracted=_INTERMEDIATE_EXTRACTED
hive.metastore.archive.intermediate.original=_INTERMEDIATE_ORIGINAL
hive.metastore.authorization.storage.check.externaltable.drop=true
hive.metastore.authorization.storage.checks=false
hive.metastore.batch.retrieve.max=300
hive.metastore.batch.retrieve.table.partition.max=1000
hive.metastore.cache.pinobjtypes=Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
hive.metastore.client.cache.enabled=true
hive.metastore.client.cache.maxSize=10Mb
hive.metastore.client.cache.recordStats=true
hive.metastore.client.capability.check=true
hive.metastore.client.connect.retry.delay=1s
hive.metastore.client.drop.partitions.using.expressions=true
hive.metastore.client.socket.lifetime=0s
hive.metastore.client.socket.timeout=600s
hive.metastore.connect.retries=3
hive.metastore.direct.sql.batch.size=0
hive.metastore.disallow.incompatible.col.type.changes=true
hive.metastore.dml.events=false
hive.metastore.event.clean.freq=0s
hive.metastore.event.db.listener.timetolive=86400s
hive.metastore.event.expiry.duration=0s
hive.metastore.event.message.factory=org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory
hive.metastore.execute.setugi=true
hive.metastore.expression.proxy=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
hive.metastore.failure.retries=1
hive.metastore.fastpath=
    false:
hive.metastore.filter.hook=org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
hive.metastore.fs.handler.class=org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
hive.metastore.fshandler.threads=15
hive.metastore.hbase.aggr.stats.cache.entries=10000
hive.metastore.hbase.aggr.stats.hbase.ttl=604800s
hive.metastore.hbase.aggr.stats.invalidator.frequency=5s
hive.metastore.hbase.aggr.stats.memory.ttl=60s
hive.metastore.hbase.aggregate.stats.cache.size=10000
hive.metastore.hbase.aggregate.stats.false.positive.probability=0.01
hive.metastore.hbase.aggregate.stats.max.partitions=10000
hive.metastore.hbase.aggregate.stats.max.variance=0.1
hive.metastore.hbase.cache.clean.until=0.8
hive.metastore.hbase.cache.max.full=0.9
hive.metastore.hbase.cache.max.reader.wait=1000ms
hive.metastore.hbase.cache.max.writer.wait=5000ms
hive.metastore.hbase.cache.ttl=600s
hive.metastore.hbase.catalog.cache.size=50000
hive.metastore.hbase.connection.class=org.apache.hadoop.hive.metastore.hbase.VanillaHBaseConnection
hive.metastore.hbase.file.metadata.threads=1
hive.metastore.initial.metadata.count.enabled=true
hive.metastore.integral.jdo.pushdown=false
hive.metastore.kerberos.principal=hive-metastore/_HOST@EXAMPLE.COM
hive.metastore.limit.partition.request=-1
hive.metastore.metadb.dir=file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/metadb/
hive.metastore.metrics.enabled=false
hive.metastore.orm.retrieveMapNullsAsEmptyStrings=false
hive.metastore.port=9083
hive.metastore.pre.event.listeners=org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore
hive.metastore.sasl.enabled=false
hive.metastore.schema.verification=false
hive.metastore.schema.verification.record.version=false
hive.metastore.server.max.message.size=104857600
hive.metastore.server.max.threads=1000
hive.metastore.server.min.threads=200
hive.metastore.server.tcp.keepalive=true
hive.metastore.stats.ndv.densityfunction=false
hive.metastore.stats.ndv.tuner=0.0
hive.metastore.thrift.compact.protocol.enabled=false
hive.metastore.thrift.framed.transport.enabled=false
hive.metastore.try.direct.sql=true
hive.metastore.try.direct.sql.ddl=true
hive.metastore.txn.store.impl=org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
hive.metastore.use.SSL=false
hive.metastore.warehouse.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse
hive.msck.path.validation=
    throw:
hive.msck.repair.batch.size=0
hive.multi.insert.move.tasks.share.dependencies=false
hive.multigroupby.singlereducer=true
hive.mv.files.thread=15
hive.new.job.grouping.set.cardinality=30
hive.optimize.bucketingsorting=true
hive.optimize.bucketmapjoin=false
hive.optimize.bucketmapjoin.sortedmerge=false
hive.optimize.constant.propagation=true
hive.optimize.correlation=false
hive.optimize.cte.materialize.threshold=-1
hive.optimize.distinct.rewrite=true
hive.optimize.dynamic.partition.hashjoin=false
hive.optimize.filter.stats.reduction=false
hive.optimize.groupby=true
hive.optimize.index.autoupdate=false
hive.optimize.index.filter=false
hive.optimize.index.filter.compact.maxsize=-1
hive.optimize.index.filter.compact.minsize=5368709120
hive.optimize.index.groupby=false
hive.optimize.limittranspose=false
hive.optimize.limittranspose.reductionpercentage=1.0
hive.optimize.limittranspose.reductiontuples=0
hive.optimize.listbucketing=false
hive.optimize.metadataonly=false
hive.optimize.null.scan=true
hive.optimize.partition.columns.separate=true
hive.optimize.point.lookup=true
hive.optimize.point.lookup.min=31
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.optimize.ppd.windowing=true
hive.optimize.reducededuplication=true
hive.optimize.reducededuplication.min.reducer=4
hive.optimize.remove.identity.project=true
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
hive.optimize.semijoin.conversion=true
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.sort.dynamic.partition=false
hive.optimize.union.remove=false
hive.orc.cache.stripe.details.mem.size=256Mb
hive.orc.cache.use.soft.references=false
hive.orc.compute.splits.num.threads=10
hive.orc.splits.allow.synthetic.fileid=true
hive.orc.splits.directory.batch.ms=0
hive.orc.splits.include.file.footer=false
hive.orc.splits.include.fileid=true
hive.orc.splits.ms.footer.cache.enabled=false
hive.orc.splits.ms.footer.cache.ppd.enabled=true
hive.order.columnalignment=true
hive.orderby.position.alias=true
hive.parquet.timestamp.skip.conversion=true
hive.ppd.recognizetransivity=true
hive.ppd.remove.duplicatefilters=true
hive.prewarm.enabled=false
hive.prewarm.numcontainers=10
hive.query.reexecution.stats.persist.scope=query
hive.query.result.fileformat=SequenceFile
hive.query.results.cache.enabled=false
hive.query.timeout.seconds=0s
hive.querylog.enable.plan.progress=true
hive.querylog.location=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/tmp
hive.querylog.plan.progress.interval=60000ms
hive.reorder.nway.joins=true
hive.repl.cm.enabled=false
hive.repl.cm.interval=3600s
hive.repl.cm.retain=24h
hive.repl.cmrootdir=/user/hive/cmroot/
hive.repl.rootdir=/user/hive/repl/
hive.repl.task.factory=org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
hive.resultset.use.unique.column.names=true
hive.rework.mapredwork=false
hive.rpc.query.plan=false
hive.sample.seednumber=0
hive.scheduled.queries.executor.enabled=false
hive.scratch.dir.permission=700
hive.scratchdir.lock=false
hive.script.auto.progress=false
hive.script.operator.env.blacklist=hive.txn.valid.txns,hive.script.operator.env.blacklist
hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID
hive.script.operator.truncate.env=false
hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader
hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter
hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
hive.security.authorization.createtable.owner.grants=INSERT,SELECT,UPDATE,DELETE
hive.security.authorization.enabled=false
hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory
hive.security.authorization.sqlstd.confwhitelist=hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.thrift\.resultset\.default\.fetch\.size|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.strict\..*|hive\.tez\..*|hive\.vectorized\..*|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queuename|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.transpose\.aggr\.join|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketmapjoin|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.query\.result\.fileformat|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.cli\.tez\.session\.async|hive\.compat|hive\.exec\.concatenate\.check\.index|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.schema\.evolution|hive\.server2\.logging\.operation\.level|hive\.server2\.thrift\.resultset\.serialize\.in\.tasks|hive\.support\.special\.characters\.tablename|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.llap\.io\.enabled|hive\.llap\.io\.use\.fileid\.path|hive\.llap\.daemon\.service\.hosts|hive\.llap\.execution\.mode|hive\.llap\.auto\.allow\.uber|hive\.llap\.auto\.enforce\.tree|hive\.llap\.auto\.enforce\.vectorized|hive\.llap\.auto\.enforce\.stats|hive\.llap\.auto\.max\.input\.size|hive\.llap\.auto\.max\.output\.size|hive\.llap\.skip\.compile\.udf\.check|hive\.llap\.client\.consistent\.splits|hive\.llap\.enable\.grace\.join\.in\.llap|hive\.llap\.allow\.permanent\.fns|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id
hive.security.authorization.task.factory=org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
hive.security.command.whitelist=set,reset,dfs,add,list,delete,reload,compile
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.security.metastore.authorization.auth.reads=true
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
hive.serdes.using.metastore.for.schema=org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
hive.server.read.socket.timeout=10s
hive.server.tcp.keepalive=true
hive.server2.allow.user.substitution=true
hive.server2.async.exec.async.compile=false
hive.server2.async.exec.keepalive.time=10s
hive.server2.async.exec.shutdown.timeout=10s
hive.server2.async.exec.threads=100
hive.server2.async.exec.wait.queue.size=100
hive.server2.authentication=NONE
hive.server2.authentication.ldap.groupClassKey=groupOfNames
hive.server2.authentication.ldap.groupMembershipKey=member
hive.server2.authentication.ldap.guidKey=uid
hive.server2.clear.dangling.scratchdir=false
hive.server2.clear.dangling.scratchdir.interval=1800s
hive.server2.close.session.on.disconnect=true
hive.server2.compile.lock.timeout=0s
hive.server2.enable.doAs=true
hive.server2.global.init.file.location=${env:HIVE_CONF_DIR}
hive.server2.idle.operation.timeout=5d
hive.server2.idle.session.check.operation=true
hive.server2.idle.session.timeout=7d
hive.server2.in.place.progress=true
hive.server2.llap.concurrent.queries=-1
hive.server2.logging.operation.enabled=true
hive.server2.logging.operation.level=EXECUTION
hive.server2.logging.operation.log.location=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/alex/operation_logs
hive.server2.long.polling.timeout=5000ms
hive.server2.map.fair.scheduler.queue=true
hive.server2.max.start.attempts=30
hive.server2.metrics.enabled=false
hive.server2.operation.log.purgePolicy.timeToLive=5s
hive.server2.parallel.ops.in.session=true
hive.server2.session.check.interval=6h
hive.server2.sleep.interval.between.start.attempts=60s
hive.server2.support.dynamic.service.discovery=false
hive.server2.table.type.mapping=CLASSIC
hive.server2.tez.initialize.default.sessions=false
hive.server2.tez.session.lifetime=162h
hive.server2.tez.session.lifetime.jitter=3h
hive.server2.tez.sessions.custom.queue.allowed=true
hive.server2.tez.sessions.init.threads=16
hive.server2.tez.sessions.per.default.queue=1
hive.server2.thrift.client.connect.retry.limit=1
hive.server2.thrift.client.password=anonymous
hive.server2.thrift.client.retry.delay.seconds=1s
hive.server2.thrift.client.retry.limit=1
hive.server2.thrift.client.user=anonymous
hive.server2.thrift.exponential.backoff.slot.length=100ms
hive.server2.thrift.http.cookie.auth.enabled=true
hive.server2.thrift.http.cookie.is.httponly=true
hive.server2.thrift.http.cookie.is.secure=true
hive.server2.thrift.http.cookie.max.age=86400s
hive.server2.thrift.http.max.idle.time=1800s
hive.server2.thrift.http.path=
    cliservice:
hive.server2.thrift.http.port=10001
hive.server2.thrift.http.request.header.size=6144
hive.server2.thrift.http.response.header.size=6144
hive.server2.thrift.http.worker.keepalive.time=60s
hive.server2.thrift.login.timeout=20s
hive.server2.thrift.max.message.size=104857600
hive.server2.thrift.max.worker.threads=500
hive.server2.thrift.min.worker.threads=5
hive.server2.thrift.port=10000
hive.server2.thrift.resultset.default.fetch.size=1000
hive.server2.thrift.resultset.max.fetch.size=10000
hive.server2.thrift.resultset.serialize.in.tasks=false
hive.server2.thrift.sasl.qop=auth
hive.server2.thrift.worker.keepalive.time=60s
hive.server2.transport.mode=binary
hive.server2.use.SSL=false
hive.server2.webui.host=0.0.0.0
hive.server2.webui.max.historic.queries=25
hive.server2.webui.max.threads=50
hive.server2.webui.port=10002
hive.server2.webui.spnego.principal=HTTP/_HOST@EXAMPLE.COM
hive.server2.webui.use.spnego=false
hive.server2.webui.use.ssl=false
hive.server2.xsrf.filter.enabled=false
hive.server2.zookeeper.namespace=hiveserver2
hive.server2.zookeeper.publish.configs=true
hive.service.metrics.class=org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
hive.service.metrics.file.frequency=5s
hive.service.metrics.file.location=/tmp/report.json
hive.service.metrics.hadoop2.component=hive
hive.service.metrics.hadoop2.frequency=30s
hive.service.metrics.reporter=JSON_FILE, JMX
hive.session.history.enabled=false
hive.session.id=c8920f15-a41b-42e8-95c2-8748decaa497
hive.session.silent=false
hive.skewjoin.key=100000
hive.skewjoin.mapjoin.map.tasks=10000
hive.skewjoin.mapjoin.min.split=33554432
hive.smbjoin.cache.rows=10000
hive.spark.client.connect.timeout=1000ms
hive.spark.client.future.timeout=60s
hive.spark.client.rpc.max.size=52428800
hive.spark.client.rpc.sasl.mechanisms=DIGEST-MD5
hive.spark.client.rpc.threads=8
hive.spark.client.secret.bits=256
hive.spark.client.server.connect.timeout=90000ms
hive.spark.dynamic.partition.pruning=false
hive.spark.dynamic.partition.pruning.max.data.size=104857600
hive.spark.exec.inplace.progress=true
hive.spark.job.monitor.timeout=60s
hive.spark.use.file.size.for.mapjoin=false
hive.spark.use.groupby.shuffle=true
hive.spark.use.op.stats=true
hive.ssl.protocol.blacklist=SSLv2,SSLv3
hive.stageid.rearrange=none
hive.start.cleanup.scratchdir=false
hive.stats.atomic=false
hive.stats.autogather=true
hive.stats.collect.scancols=false
hive.stats.collect.tablekeys=false
hive.stats.column.autogather=false
hive.stats.dbclass=fs
hive.stats.deserialization.factor=1.0
hive.stats.fetch.bitvector=true
hive.stats.fetch.column.stats=false
hive.stats.fetch.partition.stats=true
hive.stats.filter.in.factor=1.0
hive.stats.gather.num.threads=10
hive.stats.join.factor=1.1
hive.stats.key.prefix.reserve.length=0
hive.stats.list.num.entries=10
hive.stats.map.num.entries=10
hive.stats.max.variable.length=100
hive.stats.ndv.error=20.0
hive.stats.reliable=false
hive.strict.checks.bucketing=true
hive.strict.checks.cartesian.product=true
hive.strict.checks.large.query=false
hive.strict.checks.type.safety=true
hive.strict.timestamp.conversion=false
hive.support.concurrency=true
hive.support.quoted.identifiers=column
hive.support.special.characters.tablename=true
hive.test.authz.sstd.hs2.mode=false
hive.test.dummystats.aggregator=value2
hive.test.fail.compaction=false
hive.test.fail.heartbeater=false
hive.test.mode=false
hive.test.mode.prefix=test_
hive.test.mode.samplefreq=32
hive.test.rollbacktxn=false
hive.tez.auto.reducer.parallelism=false
hive.tez.bigtable.minsize.semijoin.reduction=1000000
hive.tez.bloom.filter.factor=2.0
hive.tez.bucket.pruning=false
hive.tez.bucket.pruning.compat=true
hive.tez.container.max.java.heap.fraction=0.8
hive.tez.container.size=-1
hive.tez.cpu.vcores=-1
hive.tez.dynamic.partition.pruning=true
hive.tez.dynamic.partition.pruning.max.data.size=104857600
hive.tez.dynamic.partition.pruning.max.event.size=1048576
hive.tez.dynamic.semijoin.reduction=true
hive.tez.dynamic.semijoin.reduction.threshold=0.5
hive.tez.enable.memory.manager=true
hive.tez.exec.inplace.progress=true
hive.tez.exec.print.summary=false
hive.tez.hs2.user.access=true
hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.tez.input.generate.consistent.splits=true
hive.tez.log.level=INFO
hive.tez.max.bloom.filter.entries=100000000
hive.tez.max.partition.factor=2.0
hive.tez.min.bloom.filter.entries=1000000
hive.tez.min.partition.factor=0.25
hive.tez.smb.number.waves=0.5
hive.tez.task.scale.memory.reserve-fraction.min=0.3
hive.tez.task.scale.memory.reserve.fraction=-1.0
hive.tez.task.scale.memory.reserve.fraction.max=0.5
hive.timedout.txn.reaper.interval=180s
hive.timedout.txn.reaper.start=100s
hive.transactional.events.mem=10000000
hive.transactional.table.scan=false
hive.transform.escape.input=false
hive.transpose.aggr.join=false
hive.txn.heartbeat.threadpool.size=5
hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
hive.txn.manager.dump.lock.state.on.acquire.timeout=false
hive.txn.max.open.batch=1000
hive.txn.operational.properties=0
hive.txn.strict.locking.mode=true
hive.txn.timeout=300s
hive.typecheck.on.insert=true
hive.udtf.auto.progress=false
hive.unlock.numretries=10
hive.user.install.directory=/user/
hive.users.in.admin.role=hive_admin_user
hive.variable.substitute=true
hive.variable.substitute.depth=40
hive.vectorized.adaptor.usage.mode=all
hive.vectorized.execution.enabled=false
hive.vectorized.execution.mapjoin.minmax.enabled=false
hive.vectorized.execution.mapjoin.native.enabled=true
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=false
hive.vectorized.execution.mapjoin.native.multikey.only.enabled=false
hive.vectorized.execution.mapjoin.overflow.repeated.threshold=-1
hive.vectorized.execution.reduce.enabled=true
hive.vectorized.execution.reduce.groupby.enabled=true
hive.vectorized.execution.reducesink.new.enabled=true
hive.vectorized.groupby.checkinterval=100000
hive.vectorized.groupby.flush.percent=0.1
hive.vectorized.groupby.maxentries=1000000
hive.vectorized.use.row.serde.deserialize=false
hive.vectorized.use.vector.serde.deserialize=true
hive.vectorized.use.vectorized.input.format=true
hive.warehouse.subdir.inherit.perms=true
hive.writeset.reaper.interval=60s
hive.zookeeper.clean.extra.nodes=false
hive.zookeeper.client.port=2181
hive.zookeeper.connection.basesleeptime=1000ms
hive.zookeeper.connection.max.retries=3
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.zookeeper.session.timeout=1200000ms
iceberg.hive.keep.stats=true
io.bytes.per.checksum=512
io.compression.codec.bzip2.library=system-native
io.file.buffer.size=4096
io.map.index.interval=128
io.map.index.skip=0
io.mapfile.bloom.error.rate=0.005
io.mapfile.bloom.size=1048576
io.native.lib.available=true
io.seqfile.compress.blocksize=1000000
io.seqfile.lazydecompress=true
io.seqfile.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/io/local
io.seqfile.sorter.recordlimit=1000000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
io.skip.checksum.errors=false
ipc.client.connect.max.retries=10
ipc.client.connect.max.retries.on.timeouts=45
ipc.client.connect.retry.interval=1000
ipc.client.connect.timeout=20000
ipc.client.connection.maxidletime=10000
ipc.client.fallback-to-simple-auth-allowed=false
ipc.client.idlethreshold=4000
ipc.client.kill.max=10
ipc.server.listen.queue.size=128
ipc.server.max.connections=0
javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.api.jdo.JDOPersistenceManagerFactory
javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver
javax.jdo.option.ConnectionPassword=
javax.jdo.option.ConnectionURL=jdbc:derby:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/junit_metastore_db;create=true
javax.jdo.option.ConnectionUserName=APP
javax.jdo.option.DetachAllOnCommit=true
javax.jdo.option.Multithreaded=true
javax.jdo.option.NonTransactionalRead=true
map.sort.class=org.apache.hadoop.util.QuickSort
mapred.child.java.opts=-Xmx200m
mapred.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/local
mapred.system.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/system
mapred.temp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/temp
mapreduce.am.max-attempts=2
mapreduce.app-submission.cross-platform=false
mapreduce.client.completion.pollinterval=5000
mapreduce.client.output.filter=FAILED
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.client.submit.file.replication=10
mapreduce.cluster.acls.enabled=false
mapreduce.cluster.local.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/local
mapreduce.cluster.temp.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/temp
mapreduce.fileoutputcommitter.algorithm.version=1
mapreduce.framework.name=local
mapreduce.ifile.readahead=true
mapreduce.ifile.readahead.bytes=4194304
mapreduce.input.fileinputformat.list-status.num-threads=1
mapreduce.input.fileinputformat.split.maxsize=256000000
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.minsize.per.node=1
mapreduce.input.fileinputformat.split.minsize.per.rack=1
mapreduce.input.lineinputformat.linespermap=1
mapreduce.job.acl-modify-job= 
mapreduce.job.acl-view-job= 
mapreduce.job.classloader=false
mapreduce.job.committer.setup.cleanup.needed=true
mapreduce.job.complete.cancel.delegation.tokens=true
mapreduce.job.counters.max=120
mapreduce.job.emit-timeline-data=false
mapreduce.job.end-notification.max.attempts=5
mapreduce.job.end-notification.max.retry.interval=5000
mapreduce.job.end-notification.retry.attempts=0
mapreduce.job.end-notification.retry.interval=1000
mapreduce.job.hdfs-servers=file:///
mapreduce.job.jvm.numtasks=1
mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
mapreduce.job.maps=2
mapreduce.job.max.split.locations=10
mapreduce.job.maxtaskfailures.per.tracker=3
mapreduce.job.queuename=default
mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
mapreduce.job.reduce.slowstart.completedmaps=0.05
mapreduce.job.reducer.preempt.delay.sec=0
mapreduce.job.reduces=-1
mapreduce.job.running.map.limit=0
mapreduce.job.running.reduce.limit=0
mapreduce.job.speculative.minimum-allowed-tasks=10
mapreduce.job.speculative.retry-after-no-speculate=1000
mapreduce.job.speculative.retry-after-speculate=15000
mapreduce.job.speculative.slowtaskthreshold=1.0
mapreduce.job.speculative.speculative-cap-running-tasks=0.1
mapreduce.job.speculative.speculative-cap-total-tasks=0.01
mapreduce.job.split.metainfo.maxsize=10000000
mapreduce.job.token.tracking.ids.enabled=false
mapreduce.job.ubertask.enable=false
mapreduce.job.ubertask.maxmaps=9
mapreduce.job.ubertask.maxreduces=1
mapreduce.job.userlog.retain.hours=24
mapreduce.jobhistory.address=0.0.0.0:10020
mapreduce.jobhistory.admin.acl=*
mapreduce.jobhistory.admin.address=0.0.0.0:10033
mapreduce.jobhistory.cleaner.enable=true
mapreduce.jobhistory.cleaner.interval-ms=86400000
mapreduce.jobhistory.client.thread-count=10
mapreduce.jobhistory.datestring.cache.size=200000
mapreduce.jobhistory.done-dir=/tmp/hadoop-yarn/staging/history/done
mapreduce.jobhistory.http.policy=HTTP_ONLY
mapreduce.jobhistory.intermediate-done-dir=/tmp/hadoop-yarn/staging/history/done_intermediate
mapreduce.jobhistory.joblist.cache.size=20000
mapreduce.jobhistory.keytab=/etc/security/keytab/jhs.service.keytab
mapreduce.jobhistory.loadedjobs.cache.size=5
mapreduce.jobhistory.max-age-ms=604800000
mapreduce.jobhistory.minicluster.fixed.ports=false
mapreduce.jobhistory.move.interval-ms=180000
mapreduce.jobhistory.move.thread-count=3
mapreduce.jobhistory.principal=jhs/_HOST@REALM.TLD
mapreduce.jobhistory.recovery.enable=false
mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
mapreduce.jobhistory.recovery.store.fs.uri=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/mapred/history/recoverystore
mapreduce.jobhistory.recovery.store.leveldb.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/mapred/history/recoverystore:
mapreduce.jobhistory.webapp.address=0.0.0.0:19888
mapreduce.jobtracker.address=local
mapreduce.jobtracker.expire.trackers.interval=600000
mapreduce.jobtracker.handler.count=10
mapreduce.jobtracker.heartbeats.in.second=100
mapreduce.jobtracker.http.address=0.0.0.0:50030
mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapreduce.jobtracker.jobhistory.block.size=3145728
mapreduce.jobtracker.jobhistory.lru.cache.size=5
mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
mapreduce.jobtracker.maxtasks.perjob=-1
mapreduce.jobtracker.persist.jobstatus.active=true
mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapreduce.jobtracker.persist.jobstatus.hours=1
mapreduce.jobtracker.restart.recover=false
mapreduce.jobtracker.retiredjobs.cache.size=1000
mapreduce.jobtracker.staging.root.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/staging
mapreduce.jobtracker.system.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/TestPreUpgradeTool/mapred/system
mapreduce.jobtracker.taskcache.levels=2
mapreduce.jobtracker.taskscheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapreduce.jobtracker.tasktracker.maxblacklists=4
mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
mapreduce.map.cpu.vcores=1
mapreduce.map.log.level=INFO
mapreduce.map.maxattempts=4
mapreduce.map.memory.mb=1024
mapreduce.map.output.compress=false
mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.map.skip.maxrecords=0
mapreduce.map.skip.proc.count.autoincr=true
mapreduce.map.sort.spill.percent=0.80
mapreduce.map.speculative=true
mapreduce.output.fileoutputformat.compress=false
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.output.fileoutputformat.compress.type=RECORD
mapreduce.reduce.cpu.vcores=1
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.reduce.log.level=INFO
mapreduce.reduce.markreset.buffer.percent=0.0
mapreduce.reduce.maxattempts=4
mapreduce.reduce.memory.mb=1024
mapreduce.reduce.merge.inmem.threshold=1000
mapreduce.reduce.shuffle.connect.timeout=180000
mapreduce.reduce.shuffle.fetch.retry.enabled=false
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
mapreduce.reduce.shuffle.input.buffer.percent=0.70
mapreduce.reduce.shuffle.memory.limit.percent=0.25
mapreduce.reduce.shuffle.merge.percent=0.66
mapreduce.reduce.shuffle.parallelcopies=5
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
mapreduce.reduce.skip.maxgroups=0
mapreduce.reduce.skip.proc.count.autoincr=true
mapreduce.reduce.speculative=true
mapreduce.shuffle.connection-keep-alive.enable=false
mapreduce.shuffle.connection-keep-alive.timeout=5
mapreduce.shuffle.max.connections=0
mapreduce.shuffle.max.threads=0
mapreduce.shuffle.port=13562
mapreduce.shuffle.ssl.enabled=false
mapreduce.shuffle.ssl.file.buffer.size=65536
mapreduce.shuffle.transfer.buffer.size=131072
mapreduce.task.combine.progress.records=10000
mapreduce.task.files.preserve.failedtasks=false
mapreduce.task.io.sort.factor=10
mapreduce.task.io.sort.mb=100
mapreduce.task.merge.progress.records=10000
mapreduce.task.profile=false
mapreduce.task.profile.map.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.maps=0-2
mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.reduce.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.reduces=0-2
mapreduce.task.skip.start.attempts=2
mapreduce.task.timeout=600000
mapreduce.task.userlog.limit.kb=0
mapreduce.tasktracker.dns.interface=default
mapreduce.tasktracker.dns.nameserver=default
mapreduce.tasktracker.healthchecker.interval=60000
mapreduce.tasktracker.healthchecker.script.timeout=600000
mapreduce.tasktracker.http.address=0.0.0.0:50060
mapreduce.tasktracker.http.threads=40
mapreduce.tasktracker.indexcache.mb=10
mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapreduce.tasktracker.local.dir.minspacekill=0
mapreduce.tasktracker.local.dir.minspacestart=0
mapreduce.tasktracker.map.tasks.maximum=2
mapreduce.tasktracker.outofband.heartbeat=false
mapreduce.tasktracker.reduce.tasks.maximum=2
mapreduce.tasktracker.report.address=127.0.0.1:0
mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
metastore.metadata.transformer.class=  
net.topology.impl=org.apache.hadoop.net.NetworkTopology
net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
net.topology.script.number.args=100
nfs.exports.allowed.hosts=* rw
parquet.memory.pool.ratio=0.5
rpc.metrics.quantile.enable=false
s3.blocksize=67108864
s3.bytes-per-checksum=512
s3.client-write-packet-size=65536
s3.replication=3
s3.stream-buffer-size=4096
s3native.blocksize=67108864
s3native.bytes-per-checksum=512
s3native.client-write-packet-size=65536
s3native.replication=3
s3native.stream-buffer-size=4096
stream.stderr.reporter.enabled=true
stream.stderr.reporter.prefix=reporter:
test.data.files=${hive.root}/data/files
test.data.scripts=${hive.root}/data/scripts
test.log.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/log/
test.property1=value1
test.var.hiveconf.property=__HIVE_DEFAULT_PARTITION__
tfile.fs.input.buffer.size=262144
tfile.fs.output.buffer.size=262144
tfile.io.chunk.size=1048576
yarn.acl.enable=false
yarn.admin.acl=*
yarn.am.liveness-monitor.expiry-interval-ms=600000
yarn.app.mapreduce.am.command-opts=-Xmx1024m
yarn.app.mapreduce.am.container.log.backups=0
yarn.app.mapreduce.am.container.log.limit.kb=0
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
yarn.app.mapreduce.am.hard-kill-timeout-ms=10000
yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
yarn.app.mapreduce.am.job.committer.commit-window=10000
yarn.app.mapreduce.am.job.task.listener.thread-count=30
yarn.app.mapreduce.am.resource.cpu-vcores=1
yarn.app.mapreduce.am.resource.mb=1536
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
yarn.app.mapreduce.am.staging-dir=/tmp/hadoop-yarn/staging
yarn.app.mapreduce.client-am.ipc.max-retries=3
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
yarn.app.mapreduce.client.job.max-retries=0
yarn.app.mapreduce.client.job.retry-interval=2000
yarn.app.mapreduce.client.max-retries=3
yarn.app.mapreduce.shuffle.log.backups=0
yarn.app.mapreduce.shuffle.log.limit.kb=0
yarn.app.mapreduce.shuffle.log.separate=true
yarn.app.mapreduce.task.container.log.backups=0
yarn.bin.path=
    yarn:
yarn.client.application-client-protocol.poll-interval-ms=200
yarn.client.failover-proxy-provider=org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
yarn.client.failover-retries=0
yarn.client.failover-retries-on-socket-timeouts=0
yarn.client.max-cached-nodemanagers-proxies=0
yarn.client.nodemanager-client-async.thread-pool-max-size=500
yarn.client.nodemanager-connect.max-wait-ms=180000
yarn.client.nodemanager-connect.retry-interval-ms=10000
yarn.dispatcher.drain-events.timeout=300000
yarn.fail-fast=false
yarn.http.policy=HTTP_ONLY
yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
yarn.log-aggregation-enable=false
yarn.log-aggregation.retain-check-interval-seconds=-1
yarn.log-aggregation.retain-seconds=-1
yarn.nm.liveness-monitor.expiry-interval-ms=600000
yarn.nodemanager.address=0.0.0.0:0
yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
yarn.nodemanager.container-manager.thread-count=20
yarn.nodemanager.container-metrics.unregister-delay-ms=10000
yarn.nodemanager.container-monitor.interval-ms=3000
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled=false
yarn.nodemanager.delete.debug-delay-sec=0
yarn.nodemanager.delete.thread-count=4
yarn.nodemanager.disk-health-checker.interval-ms=120000
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=99
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb=0
yarn.nodemanager.disk-health-checker.min-healthy-disks=0.25
yarn.nodemanager.docker-container-executor.exec-name=/usr/bin/docker
yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME
yarn.nodemanager.health-checker.interval-ms=600000
yarn.nodemanager.health-checker.script.timeout-ms=1200000
yarn.nodemanager.hostname=0.0.0.0
yarn.nodemanager.keytab=/etc/krb5.keytab
yarn.nodemanager.linux-container-executor.cgroups.hierarchy=/hadoop-yarn
yarn.nodemanager.linux-container-executor.cgroups.mount=false
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage=false
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users=true
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user=nobody
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern=^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
yarn.nodemanager.linux-container-executor.resources-handler.class=org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
yarn.nodemanager.local-cache.max-files-per-directory=8192
yarn.nodemanager.local-dirs=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/nm-local-dir
yarn.nodemanager.localizer.address=0.0.0.0:8040
yarn.nodemanager.localizer.cache.cleanup.interval-ms=600000
yarn.nodemanager.localizer.cache.target-size-mb=10240
yarn.nodemanager.localizer.client.thread-count=5
yarn.nodemanager.localizer.fetch.thread-count=4
yarn.nodemanager.log-aggregation.compression-type=none
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds=-1
yarn.nodemanager.log-dirs=${yarn.log.dir}/userlogs
yarn.nodemanager.log.retain-seconds=10800
yarn.nodemanager.pmem-check-enabled=true
yarn.nodemanager.process-kill-wait.ms=2000
yarn.nodemanager.recovery.dir=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn-nm-recovery
yarn.nodemanager.recovery.enabled=false
yarn.nodemanager.remote-app-log-dir=/tmp/logs
yarn.nodemanager.remote-app-log-dir-suffix=logs
yarn.nodemanager.resource.cpu-vcores=8
yarn.nodemanager.resource.memory-mb=8192
yarn.nodemanager.resource.percentage-physical-cpu-limit=100
yarn.nodemanager.resourcemanager.minimum.version=NONE
yarn.nodemanager.sleep-delay-before-sigkill.ms=250
yarn.nodemanager.vmem-check-enabled=true
yarn.nodemanager.vmem-pmem-ratio=2.1
yarn.nodemanager.webapp.address=0.0.0.0:8042
yarn.nodemanager.webapp.cross-origin.enabled=false
yarn.nodemanager.windows-container.cpu-limit.enabled=false
yarn.nodemanager.windows-container.memory-limit.enabled=false
yarn.resourcemanager.address=0.0.0.0:8032
yarn.resourcemanager.admin.address=0.0.0.0:8033
yarn.resourcemanager.admin.client.thread-count=1
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.am.max-attempts=2
yarn.resourcemanager.amlauncher.thread-count=50
yarn.resourcemanager.client.thread-count=50
yarn.resourcemanager.configuration.provider-class=org.apache.hadoop.yarn.LocalConfigurationProvider
yarn.resourcemanager.connect.max-wait.ms=900000
yarn.resourcemanager.connect.retry-interval.ms=30000
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.container.liveness-monitor.interval-ms=600000
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000
yarn.resourcemanager.fail-fast=false
yarn.resourcemanager.fs.state-store.num-retries=0
yarn.resourcemanager.fs.state-store.retry-interval-ms=1000
yarn.resourcemanager.fs.state-store.retry-policy-spec=2000, 500
yarn.resourcemanager.fs.state-store.uri=/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/system/rmstore
yarn.resourcemanager.ha.automatic-failover.embedded=true
yarn.resourcemanager.ha.automatic-failover.enabled=true
yarn.resourcemanager.ha.automatic-failover.zk-base-path=
    /yarn-leader-election:
yarn.resourcemanager.ha.enabled=false
yarn.resourcemanager.hostname=0.0.0.0
yarn.resourcemanager.keytab=/etc/krb5.keytab
yarn.resourcemanager.leveldb-state-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/system/rmstore:
yarn.resourcemanager.max-completed-applications=10000
yarn.resourcemanager.nodemanager-connect-retries=10
yarn.resourcemanager.nodemanager.minimum.version=NONE
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms=1000
yarn.resourcemanager.proxy-user-privileges.enabled=false
yarn.resourcemanager.recovery.enabled=false
yarn.resourcemanager.resource-tracker.address=0.0.0.0:8031
yarn.resourcemanager.resource-tracker.client.thread-count=50
yarn.resourcemanager.scheduler.address=0.0.0.0:8030
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.resourcemanager.scheduler.client.thread-count=50
yarn.resourcemanager.scheduler.monitor.enable=false
yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.state-store.max-completed-applications=10000
yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size=10
yarn.resourcemanager.system-metrics-publisher.enabled=false
yarn.resourcemanager.webapp.address=0.0.0.0:8088
yarn.resourcemanager.webapp.cross-origin.enabled=false
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled=true
yarn.resourcemanager.webapp.https.address=0.0.0.0:8090
yarn.resourcemanager.work-preserving-recovery.enabled=true
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms=10000
yarn.resourcemanager.zk-acl=world:anyone:rwcda
yarn.resourcemanager.zk-num-retries=1000
yarn.resourcemanager.zk-retry-interval-ms=1000
yarn.resourcemanager.zk-state-store.parent-path=
    /rmstore:
yarn.resourcemanager.zk-timeout-ms=10000
yarn.scheduler.maximum-allocation-mb=8192
yarn.scheduler.maximum-allocation-vcores=32
yarn.scheduler.minimum-allocation-mb=1024
yarn.scheduler.minimum-allocation-vcores=1
yarn.sharedcache.admin.address=0.0.0.0:8047
yarn.sharedcache.admin.thread-count=1
yarn.sharedcache.app-checker.class=org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
yarn.sharedcache.checksum.algo.impl=org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
yarn.sharedcache.cleaner.initial-delay-mins=10
yarn.sharedcache.cleaner.period-mins=1440
yarn.sharedcache.cleaner.resource-sleep-ms=0
yarn.sharedcache.client-server.address=0.0.0.0:8045
yarn.sharedcache.client-server.thread-count=50
yarn.sharedcache.enabled=false
yarn.sharedcache.nested-level=3
yarn.sharedcache.nm.uploader.replication.factor=10
yarn.sharedcache.nm.uploader.thread-count=20
yarn.sharedcache.root-dir=/sharedcache
yarn.sharedcache.store.class=org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
yarn.sharedcache.store.in-memory.check-period-mins=720
yarn.sharedcache.store.in-memory.initial-delay-mins=10
yarn.sharedcache.store.in-memory.staleness-period-mins=10080
yarn.sharedcache.uploader.server.address=0.0.0.0:8046
yarn.sharedcache.uploader.server.thread-count=50
yarn.sharedcache.webapp.address=0.0.0.0:8788
yarn.timeline-service.address=0.0.0.0:10200
yarn.timeline-service.client.best-effort=false
yarn.timeline-service.client.max-retries=30
yarn.timeline-service.client.retry-interval-ms=1000
yarn.timeline-service.enabled=false
yarn.timeline-service.generic-application-history.max-applications=10000
yarn.timeline-service.handler-thread-count=10
yarn.timeline-service.hostname=0.0.0.0
yarn.timeline-service.http-authentication.simple.anonymous.allowed=true
yarn.timeline-service.http-authentication.type=simple
yarn.timeline-service.keytab=/etc/krb5.keytab
yarn.timeline-service.leveldb-state-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/timeline:
yarn.timeline-service.leveldb-timeline-store.path=
    /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/hadoop-tmp/yarn/timeline:
yarn.timeline-service.leveldb-timeline-store.read-cache-size=104857600
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
yarn.timeline-service.recovery.enabled=false
yarn.timeline-service.state-store-class=org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
yarn.timeline-service.ttl-enable=true
yarn.timeline-service.ttl-ms=604800000
yarn.timeline-service.webapp.address=0.0.0.0:8188
yarn.timeline-service.webapp.https.address=0.0.0.0:8190
END========"new HiveConf()"========

2024-04-24T20:43:51,479  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:43:51,480  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:51,481  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): create table TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:51,482  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:51,630  INFO [main] exec.DDLTask: creating table default.TExternal on null
2024-04-24T20:43:51,642  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExternal, dbName:default, owner:alex, createTime:1713987831, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, transactional=false, numFiles=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:51,642  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExternal, dbName:default, owner:alex, createTime:1713987831, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, transactional=false, numFiles=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:51,643  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:43:51,658  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal
2024-04-24T20:43:51,899  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:51,899  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 0.418 seconds
OK
2024-04-24T20:43:51,899  INFO [main] ql.Driver: OK
2024-04-24T20:43:51,900  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:51,900  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 txnid:0]
2024-04-24T20:43:51,909  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): insert into TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:43:51,914  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:51,916  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:51,916  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:52,045  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:52,073  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:52,074  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:52,074  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:52,074  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:52,075  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:52,075  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:52,094  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:52,762  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:43:52,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:43:52,770  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:43:52,770  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:43:52,787  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:52,787  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:52,821  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:52,821  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:52,821  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:52,822  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:43:52,822  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:43:52,875  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1
2024-04-24T20:43:52,903  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:43:52,937  INFO [main] ppd.OpProcFactory: Processing for FS(3)
2024-04-24T20:43:52,937  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:43:52,937  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:43:52,938  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:43:53,011  INFO [main] optimizer.GenMRFileSink1: using CombineHiveInputformat for the merge job
2024-04-24T20:43:53,015  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:43:53,015  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:43:53,052  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:43:53,052  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:53,052  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:43:53,052  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:53,052  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 1.143 seconds
2024-04-24T20:43:53,053  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:53,053  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texternal, operationType:INSERT, isAcid:false, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7)
2024-04-24T20:43:53,075  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:43:53,075  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:53,076  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7): insert into TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:43:53,076  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:43:53,076  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:53,078  INFO [main] ql.Driver: Query ID = alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
Total jobs = 1
2024-04-24T20:43:53,078  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:43:53,089  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:43:53,091  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:43:53,091  INFO [main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:43:53,095  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:43:53,099  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:43:53,100  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:53,166  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:43:53,189  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,71KB
2024-04-24T20:43:53,203  INFO [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2024-04-24T20:43:53,210  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10001
2024-04-24T20:43:53,219  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:53,224  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10004/3b8ca67c-8b02-44ae-9d7a-3eca5b06b38d/map.xml
2024-04-24T20:43:53,250  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:43:53,333  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10004/3b8ca67c-8b02-44ae-9d7a-3eca5b06b38d/map.xml
2024-04-24T20:43:53,336  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:43:53,336  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:43:53,336  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:53,352  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:43:53,357  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:43:53,379  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:43:53,440  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1962447515_0001
2024-04-24T20:43:53,528  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-24T20:43:53,530  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
2024-04-24T20:43:53,531  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:43:53,531  INFO [Thread-49] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:53,538  INFO [Thread-49] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:43:53,541  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1962447515_0001_m_000000_0
2024-04-24T20:43:53,563  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:53,568  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:53,572  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10004/3b8ca67c-8b02-44ae-9d7a-3eca5b06b38d/map.xml
2024-04-24T20:43:53,572  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:43:53,594  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,71KB
2024-04-24T20:43:53,600  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T20:43:53,605  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:53,605  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:53,605  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10004/3b8ca67c-8b02-44ae-9d7a-3eca5b06b38d/map.xml
2024-04-24T20:43:53,607  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:43:53,609  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:43:53,611  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:43:53,611  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:43:53,614  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:43:53,616  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing operator FS[3]
2024-04-24T20:43:53,617  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@5197cb43 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@bc657c0
2024-04-24T20:43:53,619  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10004/3b8ca67c-8b02-44ae-9d7a-3eca5b06b38d/map.xml
2024-04-24T20:43:53,621  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_tmp.-ext-10002/000000_0
2024-04-24T20:43:53,621  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T20:43:53,621  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_tmp.-ext-10002/000000_0
2024-04-24T20:43:53,633  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 1
2024-04-24T20:43:53,645  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:43:53,677  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing operator FS[3]
2024-04-24T20:43:53,678  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 3
2024-04-24T20:43:53,712  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_1_default.texternal:3, 
2024-04-24T20:43:53,714  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:43:53,714  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1962447515_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T20:43:53,718  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/c8920f15-a41b-42e8-95c2-8748decaa497/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:53,718  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1962447515_0001_m_000000_0' done.
2024-04-24T20:43:53,718  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1962447515_0001_m_000000_0
2024-04-24T20:43:53,719  INFO [Thread-49] mapred.LocalJobRunner: map task executor complete.
2024-04-24 20:43:54,546 Stage-1 map = 100%,  reduce = 0%
2024-04-24T20:43:54,546  INFO [main] exec.Task: 2024-04-24 20:43:54,546 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1962447515_0001
2024-04-24T20:43:54,549  INFO [main] exec.Task: Ended Job = job_local1962447515_0001
2024-04-24T20:43:54,551  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/_tmp.-ext-10002 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/-ext-10002
2024-04-24T20:43:54,552  INFO [main] ql.Driver: Starting task [Stage-7:CONDITIONAL] in serial mode
Stage-4 is selected by condition resolver.
2024-04-24T20:43:54,554  INFO [main] exec.Task: Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
2024-04-24T20:43:54,554  INFO [main] exec.Task: Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
2024-04-24T20:43:54,554  INFO [main] exec.Task: Stage-5 is filtered out by condition resolver.
2024-04-24T20:43:54,554  INFO [main] ql.Driver: Starting task [Stage-4:MOVE] in serial mode
2024-04-24T20:43:54,556  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:54,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:54,556  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:54,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/-ext-10000
2024-04-24T20:43:54,557  INFO [main] exec.Task: Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/-ext-10000 from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/-ext-10002
2024-04-24T20:43:54,557  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:54,557  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:54,573  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.texternal
2024-04-24T20:43:54,573  INFO [main] exec.Task: Loading data to table default.texternal from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal/.hive-staging_hive_2024-04-24_20-43-51_910_1742442297749973778-1/-ext-10000
2024-04-24T20:43:54,574  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:43:54,575  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:54,616  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:54,617  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:54,618  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:54,619  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:54,623  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:54,623  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:54,644  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:43:54,644  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:43:54,665  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:54,665  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:54,677  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=texternal newtbl=texternal
2024-04-24T20:43:54,678  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=texternal newtbl=texternal	
2024-04-24T20:43:54,729  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:43:54,729  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:43:54,729  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:54,729  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:54,730  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:54,730  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:54,731  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:43:54,731  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:54,767  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:54,770  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:54,770  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:54,770  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:54,770  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:54,771  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:54,773  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:54,773  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:54,790  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/c8920f15-a41b-42e8-95c2-8748decaa497/hive_2024-04-24_20-43-51_910_1742442297749973778-1/-mr-10001
2024-04-24T20:43:54,792  INFO [main] fs.FSStatsAggregator: Read stats : {default.texternal/={numRows=3, rawDataSize=24}}
2024-04-24T20:43:54,792  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=texternal
2024-04-24T20:43:54,792  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=texternal	
2024-04-24T20:43:54,810  INFO [main] fs.FSStatsAggregator: Read stats for : default.texternal/	numRows	3
2024-04-24T20:43:54,810  INFO [main] fs.FSStatsAggregator: Read stats for : default.texternal/	rawDataSize	24
2024-04-24T20:43:54,810  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:54,810  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:54,811  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:54,811  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:54,813  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=texternal newtbl=texternal
2024-04-24T20:43:54,813  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=texternal newtbl=texternal	
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:54,847  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:54,848  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:54,848  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:54,849  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:54,851  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:54,851  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:54,880  INFO [main] hive.log: Updating table stats fast for texternal
2024-04-24T20:43:54,880  INFO [main] hive.log: Updated size of table texternal to 244
2024-04-24T20:43:54,894  INFO [main] exec.StatsTask: Table default.texternal stats: [numFiles=1, numRows=3, totalSize=244, rawDataSize=24]
2024-04-24T20:43:54,895  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:43:54,895  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:43:54,895  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:54,895  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:54,895  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7); Time taken: 1.818 seconds
OK
2024-04-24T20:43:54,895  INFO [main] ql.Driver: OK
2024-04-24T20:43:54,895  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7
2024-04-24T20:43:54,895  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204350_559fe4b2-f1a1-4758-a693-9b55338a88a7 txnid:0]
2024-04-24T20:43:54,910  INFO [main] acid.PreUpgradeTool: Starting with RunOptions{outputDir='/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955', execute=true, dbRegex='.*', tableRegex='.*', tableType=null, tablePoolSize=8}
2024-04-24T20:43:54,910  INFO [main] acid.PreUpgradeTool: Using Hive Version: 2.3.3 build: 2.3.3 from 8a511e3f79b43d4be41cd231cf5c99e43b248383 by daijy source checksum fb9b95d9baaf3f968c457dee42d015d4
2024-04-24T20:43:54,911  INFO [main] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:43:54,913  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:54,915  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:54,915  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:54,920  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c8920f15-a41b-42e8-95c2-8748decaa497, clientType=HIVECLI]
2024-04-24T20:43:54,920  INFO [main] metastore.HiveMetaStore: 0: get_databases: .*
2024-04-24T20:43:54,920  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: .*	
2024-04-24T20:43:54,927  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
2024-04-24T20:43:54,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
2024-04-24T20:43:54,946  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:43:54,946  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:43:54,949  INFO [main] acid.PreUpgradeTool: No compaction is necessary
2024-04-24T20:43:54,950  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:54,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:54,950  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:54,950  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
]]></system-err>
  </testcase>
  <testcase name="testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.61">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TInclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
]]></error>
    <system-err><![CDATA[2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:55,022  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:55,023  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:55,061  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:55,061  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:55,062  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:55,263  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:55,429  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8
2024-04-24T20:43:55,435  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8
2024-04-24T20:43:55,441  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/_tmp_space.db
2024-04-24T20:43:55,442  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2c59a600-ca2f-40a2-818e-2881fd2a9cf8, clientType=HIVECLI]
2024-04-24T20:43:55,442  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:43:55,443  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TInclude
2024-04-24T20:43:55,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:55,517  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:55,518  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:55,518  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:55,518  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:55,518  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:55,518  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:55,519  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:55,522  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:55,522  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:55,522  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,523  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,525  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:55,525  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:55,525  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:55,526  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.082 seconds
2024-04-24T20:43:55,526  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,526  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TInclude
2024-04-24T20:43:55,526  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:55,527  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,529 ERROR [main] metadata.Hive: Table TInclude not found: default.TInclude table not found
2024-04-24T20:43:55,529  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,530  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,532  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:55,533  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.006 seconds
OK
2024-04-24T20:43:55,533  INFO [main] ql.Driver: OK
2024-04-24T20:43:55,533  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:55,533  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TExclude
2024-04-24T20:43:55,534  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:55,534  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:55,537  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:55,537  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:55,537  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:55,538  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.004 seconds
2024-04-24T20:43:55,538  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,538  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TExclude
2024-04-24T20:43:55,538  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:55,539  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:55,539  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:55,542 ERROR [main] metadata.Hive: Table TExclude not found: default.TExclude table not found
2024-04-24T20:43:55,542  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:55,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:55,545  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:55,545  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.006 seconds
OK
2024-04-24T20:43:55,545  INFO [main] ql.Driver: OK
2024-04-24T20:43:55,545  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:55,545  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:55,547  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:55,547  INFO [main] parse.CalcitePlanner: Creating table default.TInclude position=13
2024-04-24T20:43:55,547  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:55,548  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:55,552  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:55,552  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:55,552  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:55,552  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.007 seconds
2024-04-24T20:43:55,553  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,553  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11)
2024-04-24T20:43:55,578  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:43:55,578  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,578  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:55,579  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:55,580  INFO [main] exec.DDLTask: creating table default.TInclude on null
2024-04-24T20:43:55,580  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987835, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:55,581  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987835, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:55,588  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude
2024-04-24T20:43:55,623  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:55,623  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.045 seconds
OK
2024-04-24T20:43:55,623  INFO [main] ql.Driver: OK
2024-04-24T20:43:55,623  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,623  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 txnid:0]
2024-04-24T20:43:55,628  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:55,629  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:55,629  INFO [main] parse.CalcitePlanner: Creating table default.TExclude position=13
2024-04-24T20:43:55,629  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:55,629  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:55,634  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:55,634  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:55,634  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:55,634  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.006 seconds
2024-04-24T20:43:55,635  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,635  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11)
2024-04-24T20:43:55,649  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:43:55,650  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,650  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:55,650  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:55,651  INFO [main] exec.DDLTask: creating table default.TExclude on null
2024-04-24T20:43:55,652  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987835, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:55,652  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987835, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:55,662  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texclude
2024-04-24T20:43:55,691  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:55,691  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.041 seconds
OK
2024-04-24T20:43:55,691  INFO [main] ql.Driver: OK
2024-04-24T20:43:55,691  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,691  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 txnid:0]
2024-04-24T20:43:55,696  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:43:55,698  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:55,698  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,698  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,717  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:55,723  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:55,723  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:55,723  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:55,723  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:55,723  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,723  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,738  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:55,804  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:43:55,804  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:43:55,806  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:43:55,806  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:43:55,809  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:55,810  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:55,826  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:55,826  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:55,826  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:55,826  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:55,826  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:55,847  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1
2024-04-24T20:43:55,864  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:43:55,865  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:43:55,867  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:43:55,867  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:43:55,867  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tinclude
2024-04-24T20:43:55,876  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:43:55,876  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:55,876  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:43:55,877  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:55,877  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.181 seconds
2024-04-24T20:43:55,879  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:55,911  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:55,912  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:55,913  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:55,913  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:55,924  INFO [main] compactor.HouseKeeperServiceBase: Started org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService with delay/interval = 100/1000 MILLISECONDS
2024-04-24T20:43:55,933  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:43:55,933  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,933  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11)
2024-04-24T20:43:55,961  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:43:55,967  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:43:55,968  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:43:55,968  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:55,968  INFO [main] ql.Driver: Query ID = alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
Total jobs = 1
2024-04-24T20:43:55,968  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:43:55,968  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:43:55,969  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:43:55,969  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:43:55,969  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:43:55,969  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:43:55,969  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:43:55,970  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:43:55,970  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:43:55,970  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:43:55,970  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:43:55,970  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:43:55,970  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:55,975  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:43:55,980  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:55,985  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:43:55,989  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:43:55,991  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:55,991  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10001
2024-04-24T20:43:55,995  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:55,996  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/map.xml
2024-04-24T20:43:55,996  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/reduce.xml
2024-04-24T20:43:55,999  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:43:56,030  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.AcidOpenTxnsCounterService: OpenTxnsCounter ran for 0seconds.  isAliveCounter=-2147483647
2024-04-24T20:43:56,080  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/map.xml
2024-04-24T20:43:56,081  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:43:56,081  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:43:56,081  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:56,085  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:43:56,086  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:43:56,099  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:43:56,112  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1270302882_0002
2024-04-24T20:43:56,156  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:43:56,157  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:43:56,157  INFO [Thread-125] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:56,157  INFO [Thread-125] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:56,159  INFO [Thread-125] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:43:56,159  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1270302882_0002_m_000000_0
2024-04-24T20:43:56,164  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:56,165  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:56,166  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/map.xml
2024-04-24T20:43:56,167  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:43:56,170  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:56,171  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:43:56,189  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:43:56,190  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:43:56,190  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:43:56,190  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:43:56,190  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:43:56,192  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:43:56,192  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,192  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,192  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/map.xml
2024-04-24T20:43:56,193  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:43:56,194  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:43:56,194  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:43:56,194  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:43:56,194  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:43:56,194  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:43:56,195  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:43:56,203  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/map.xml
2024-04-24T20:43:56,204  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:43:56,205  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:43:56,205  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:43:56,206  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:43:56,207  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:43:56,207  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:43:56,207  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:43:56,207  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:43:56,208  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:43:56,212  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:43:56,214  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1270302882_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T20:43:56,216  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:56,216  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1270302882_0002_m_000000_0' done.
2024-04-24T20:43:56,216  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1270302882_0002_m_000000_0
2024-04-24T20:43:56,217  INFO [Thread-125] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:43:56,219  INFO [Thread-125] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:43:56,219  INFO [pool-19-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1270302882_0002_r_000000_0
2024-04-24T20:43:56,226  INFO [pool-19-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:56,228  INFO [pool-19-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f982e10
2024-04-24T20:43:56,239  INFO [pool-19-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:56,242  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1270302882_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:56,262  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1270302882_0002_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:43:56,263  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local1270302882_0002_m_000000_0
2024-04-24T20:43:56,265  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:43:56,266  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:56,266  INFO [pool-19-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:56,266  INFO [pool-19-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:56,271  INFO [pool-19-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:56,271  INFO [pool-19-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:56,272  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:56,272  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:43:56,272  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:56,272  INFO [pool-19-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:56,272  INFO [pool-19-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:56,273  INFO [pool-19-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:56,274  INFO [pool-19-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,274  INFO [pool-19-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,274  INFO [pool-19-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/reduce.xml
2024-04-24T20:43:56,275  INFO [pool-19-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:56,279  INFO [pool-19-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:43:56,279  INFO [pool-19-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:56,279  INFO [pool-19-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:56,279  INFO [pool-19-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:56,280  INFO [pool-19-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:56,281  INFO [pool-19-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@18f66f64 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@b2764a9
2024-04-24T20:43:56,283  INFO [pool-19-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:56,283  INFO [pool-19-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:43:56,283  INFO [pool-19-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:56,292  INFO [pool-19-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:43:56,292  INFO [pool-19-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:56,297  INFO [pool-19-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:56,298  INFO [pool-19-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:56,298  INFO [pool-19-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:56,298  INFO [pool-19-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:43:56,308  INFO [pool-19-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:3, 
2024-04-24T20:43:56,308  INFO [pool-19-thread-1] mapred.Task: Task:attempt_local1270302882_0002_r_000000_0 is done. And is in the process of committing
2024-04-24T20:43:56,309  INFO [pool-19-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:56,309  INFO [pool-19-thread-1] mapred.Task: Task 'attempt_local1270302882_0002_r_000000_0' done.
2024-04-24T20:43:56,309  INFO [pool-19-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1270302882_0002_r_000000_0
2024-04-24T20:43:56,309  INFO [pool-19-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1270302882_0002_r_000001_0
2024-04-24T20:43:56,310  INFO [pool-19-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:56,310  INFO [pool-19-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d2c107a
2024-04-24T20:43:56,310  INFO [pool-19-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:56,311  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1270302882_0002_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:56,312  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1270302882_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:43:56,313  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1270302882_0002_m_000000_0
2024-04-24T20:43:56,313  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:43:56,313  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:56,313  INFO [pool-19-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:56,313  INFO [pool-19-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:56,314  INFO [pool-19-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:56,315  INFO [pool-19-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:56,316  INFO [pool-19-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:56,316  INFO [pool-19-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,316  INFO [pool-19-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:56,316  INFO [pool-19-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10003/fc7edcd7-fb53-441d-a376-80f6bf59c10d/reduce.xml
2024-04-24T20:43:56,317  INFO [pool-19-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:56,320  INFO [pool-19-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:43:56,321  INFO [pool-19-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:56,321  INFO [pool-19-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:56,321  INFO [pool-19-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:56,322  INFO [pool-19-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:56,323  INFO [pool-19-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@a2d3af8 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@67fe3397
2024-04-24T20:43:56,323  INFO [pool-19-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:56,323  INFO [pool-19-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:56,323  INFO [pool-19-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:43:56,324  INFO [pool-19-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:56,324  INFO [pool-19-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:43:56,324  INFO [pool-19-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:56,329  INFO [pool-19-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:56,333  INFO [pool-19-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:56,339  INFO [pool-19-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:0, 
2024-04-24T20:43:56,339  INFO [pool-19-thread-1] mapred.Task: Task:attempt_local1270302882_0002_r_000001_0 is done. And is in the process of committing
2024-04-24T20:43:56,340  INFO [pool-19-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:56,340  INFO [pool-19-thread-1] mapred.Task: Task 'attempt_local1270302882_0002_r_000001_0' done.
2024-04-24T20:43:56,340  INFO [pool-19-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1270302882_0002_r_000001_0
2024-04-24T20:43:56,340  INFO [Thread-125] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:43:57,168 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:43:57,168  INFO [main] exec.Task: 2024-04-24 20:43:57,168 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1270302882_0002
2024-04-24T20:43:57,170  INFO [main] exec.Task: Ended Job = job_local1270302882_0002
2024-04-24T20:43:57,172  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/-ext-10000
2024-04-24T20:43:57,172  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:43:57,173  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:57,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:57,173  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:57,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tinclude
2024-04-24T20:43:57,174  INFO [main] exec.Task: Loading data to table default.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/-ext-10000
2024-04-24T20:43:57,175  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:43:57,175  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:57,202  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:57,203  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:57,203  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:57,204  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:57,206  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:57,206  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:57,224  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:43:57,224  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:43:57,240  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:43:57,241  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-55_696_1538553646963810051-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:43:57,242  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:43:57,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:43:57,273  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:43:57,273  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:43:57,273  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:57,273  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:57,274  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:57,274  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:57,275  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:43:57,275  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:43:57,300  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:57,300  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:57,300  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:57,300  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:57,300  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:57,301  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:57,302  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:57,303  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:57,305  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:57,305  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:57,318  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2c59a600-ca2f-40a2-818e-2881fd2a9cf8/hive_2024-04-24_20-43-55_696_1538553646963810051-1/-mr-10001
2024-04-24T20:43:57,318  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={}}
2024-04-24T20:43:57,319  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={numRows=3, rawDataSize=0}}
2024-04-24T20:43:57,319  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:43:57,319  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:43:57,333  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:43:57,333  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:43:57,334  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:43:57,334  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:43:57,335  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:43:57,336  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:57,373  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:57,374  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:57,374  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:43:57,375  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:43:57,376  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:43:57,376  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:43:57,399  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:43:57,399  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:43:57,413  INFO [main] exec.StatsTask: Table default.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:43:57,414  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:43:57,414  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:43:57,414  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:57,414  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:43:57,414  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 1.447 seconds
OK
2024-04-24T20:43:57,414  INFO [main] ql.Driver: OK
2024-04-24T20:43:57,414  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:57,431  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): update TInclude set a = 1 where b = 2
2024-04-24T20:43:57,434  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,434  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,448  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `default`.`TInclude` select ROW__ID,`a`,`b` from `default`.`TInclude` sort by ROW__ID >
2024-04-24T20:43:57,450  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:43:57,450  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,450  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,464  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:57,465  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:57,465  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:43:57,465  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:43:57,465  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:43:57,479  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:43:57,479  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:43:57,479  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,492  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:57,519  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-43-57_448_6161252556209778103-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:43:57,531 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:43:57,531  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:57,532  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.102 seconds
2024-04-24T20:43:57,532  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:57,533  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TInclude
2024-04-24T20:43:57,534  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,534  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,546  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:57,546  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:57,547  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:57,547  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.013 seconds
2024-04-24T20:43:57,547  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:57,547  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tinclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11)
2024-04-24T20:43:57,562  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:43:57,562  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:57,562  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TInclude
2024-04-24T20:43:57,563  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:57,563  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,563  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,578  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:43:57,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:43:57,595  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TInclude
2024-04-24T20:43:57,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TInclude	
2024-04-24T20:43:58,324  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:43:58,324  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:58,355  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:58,356  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:58,384  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,385  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.822 seconds
OK
2024-04-24T20:43:58,385  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,385  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:58,385  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 txnid:0]
2024-04-24T20:43:58,390  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TExclude
2024-04-24T20:43:58,391  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:58,391  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:58,411  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,412  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,412  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,412  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.022 seconds
2024-04-24T20:43:58,413  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:58,413  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11)
2024-04-24T20:43:58,430  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:43:58,430  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:58,430  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11): drop table if exists TExclude
2024-04-24T20:43:58,430  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:58,431  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:58,431  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:58,447  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:43:58,447  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:43:58,464  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExclude
2024-04-24T20:43:58,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExclude	
2024-04-24T20:43:58,518  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:43:58,518  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:58,545  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:58,546  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:58,569  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,569  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11); Time taken: 0.138 seconds
OK
2024-04-24T20:43:58,569  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,569  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11
2024-04-24T20:43:58,569  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:5 queryId=alex_20240424204355_0f133f23-9365-4bcb-bf28-f3fc379ddc11 txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgrade" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.253">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TAcid set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
]]></error>
    <system-err><![CDATA[2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:58,607  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:58,608  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:58,639  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:58,640  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:58,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:58,784  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:43:58,784  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:43:58,784  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:43:58,785  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:43:58,941  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70
2024-04-24T20:43:58,943  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70
2024-04-24T20:43:58,946  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70/_tmp_space.db
2024-04-24T20:43:58,946  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=e7578857-3aa5-4df1-9080-3c92231ffa70, clientType=HIVECLI]
2024-04-24T20:43:58,946  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:43:58,947  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcid
2024-04-24T20:43:58,948  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:58,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:58,951  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,951  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,951  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,951  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.004 seconds
2024-04-24T20:43:58,952  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:58,952  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcid
2024-04-24T20:43:58,952  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:58,952  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:58,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:58,955 ERROR [main] metadata.Hive: Table TAcid not found: default.TAcid table not found
2024-04-24T20:43:58,955  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:58,955  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:58,957  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,958  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.005 seconds
OK
2024-04-24T20:43:58,958  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,958  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:58,958  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcidPart
2024-04-24T20:43:58,959  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:43:58,959  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:43:58,962  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,962  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,962  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,962  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.004 seconds
2024-04-24T20:43:58,962  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:58,963  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcidPart
2024-04-24T20:43:58,963  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:58,963  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:43:58,963  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:43:58,965 ERROR [main] metadata.Hive: Table TAcidPart not found: default.TAcidPart table not found
2024-04-24T20:43:58,965  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:43:58,965  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:43:58,968  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,968  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.005 seconds
OK
2024-04-24T20:43:58,968  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,968  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:58,968  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlat
2024-04-24T20:43:58,969  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:43:58,969  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:43:58,971  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,971  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,971  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,971  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.003 seconds
2024-04-24T20:43:58,972  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:58,972  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlat
2024-04-24T20:43:58,972  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:58,972  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:43:58,972  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:43:58,974 ERROR [main] metadata.Hive: Table TFlat not found: default.TFlat table not found
2024-04-24T20:43:58,974  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:43:58,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:43:58,976  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,977  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.004 seconds
OK
2024-04-24T20:43:58,977  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,977  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:58,977  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlatText
2024-04-24T20:43:58,978  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:43:58,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:43:58,980  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,980  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,980  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,980  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.003 seconds
2024-04-24T20:43:58,980  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:58,981  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlatText
2024-04-24T20:43:58,981  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:58,981  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:43:58,981  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:43:58,983 ERROR [main] metadata.Hive: Table TFlatText not found: default.TFlatText table not found
2024-04-24T20:43:58,983  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:43:58,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:43:58,985  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:58,985  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.005 seconds
OK
2024-04-24T20:43:58,985  INFO [main] ql.Driver: OK
2024-04-24T20:43:58,985  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:43:58,986  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:58,987  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:58,987  INFO [main] parse.CalcitePlanner: Creating table default.TAcid position=13
2024-04-24T20:43:58,988  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:58,988  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:58,992  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:58,993  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:58,993  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:58,993  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.007 seconds
2024-04-24T20:43:58,993  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:58,993  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:43:59,014  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:43:59,014  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,015  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:59,015  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:59,016  INFO [main] exec.DDLTask: creating table default.TAcid on null
2024-04-24T20:43:59,017  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numFiles=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:59,017  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numFiles=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:59,029  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid
2024-04-24T20:43:59,099  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:59,099  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.084 seconds
OK
2024-04-24T20:43:59,099  INFO [main] ql.Driver: OK
2024-04-24T20:43:59,099  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,099  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:43:59,105  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:59,106  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:59,106  INFO [main] parse.CalcitePlanner: Creating table default.TAcidPart position=13
2024-04-24T20:43:59,107  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:59,107  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:59,111  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:59,111  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:59,112  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:59,112  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.007 seconds
2024-04-24T20:43:59,112  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,112  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:43:59,128  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:43:59,128  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,128  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:43:59,128  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:59,129  INFO [main] exec.DDLTask: creating table default.TAcidPart on null
2024-04-24T20:43:59,130  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:59,130  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:59,140  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacidpart
2024-04-24T20:43:59,174  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:59,174  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.045 seconds
OK
2024-04-24T20:43:59,174  INFO [main] ql.Driver: OK
2024-04-24T20:43:59,174  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,174  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:43:59,178  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:59,179  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:59,179  INFO [main] parse.CalcitePlanner: Creating table default.TFlat position=13
2024-04-24T20:43:59,179  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:59,179  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:59,184  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:59,184  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:59,184  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:59,184  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.006 seconds
2024-04-24T20:43:59,184  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,185  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:43:59,198  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:43:59,198  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,198  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:43:59,198  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:59,199  INFO [main] exec.DDLTask: creating table default.TFlat on null
2024-04-24T20:43:59,200  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, numRows=0, transactional=false, totalSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:59,200  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, numRows=0, transactional=false, totalSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:59,200  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:43:59,210  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tflat
2024-04-24T20:43:59,241  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:59,241  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.042 seconds
OK
2024-04-24T20:43:59,241  INFO [main] ql.Driver: OK
2024-04-24T20:43:59,241  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,241  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:43:59,245  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:43:59,246  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:59,246  INFO [main] parse.CalcitePlanner: Creating table default.TFlatText position=13
2024-04-24T20:43:59,246  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:43:59,246  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:43:59,251  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:59,251  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:43:59,251  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:59,251  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.006 seconds
2024-04-24T20:43:59,251  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,252  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:43:59,265  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:43:59,265  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,266  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:43:59,266  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:43:59,270  INFO [main] exec.DDLTask: creating table default.TFlatText on null
2024-04-24T20:43:59,271  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, numFiles=0, rawDataSize=0, transactional=false, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:43:59,271  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987839, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numRows=0, numFiles=0, rawDataSize=0, transactional=false, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:43:59,272  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:43:59,286  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tflattext
2024-04-24T20:43:59,316  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:43:59,317  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.05 seconds
OK
2024-04-24T20:43:59,317  INFO [main] ql.Driver: OK
2024-04-24T20:43:59,317  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,317  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:43:59,322  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:43:59,323  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:43:59,323  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:59,323  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:59,390  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:43:59,395  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:43:59,395  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:59,395  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:59,395  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:59,396  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:59,396  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:59,409  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:43:59,476  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:43:59,476  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:43:59,479  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:43:59,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:43:59,486  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:43:59,486  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:43:59,502  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:43:59,502  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:43:59,502  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:43:59,502  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:43:59,502  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:43:59,516  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1
2024-04-24T20:43:59,530  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:43:59,530  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:43:59,531  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:43:59,531  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:43:59,532  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tacid
2024-04-24T20:43:59,550  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:43:59,550  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:43:59,550  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:43:59,550  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:43:59,550  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.228 seconds
2024-04-24T20:43:59,557  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:43:59,557  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,557  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tacid, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:43:59,575  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:43:59,579  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:43:59,579  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:43:59,579  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:43:59,579  INFO [main] ql.Driver: Query ID = alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
Total jobs = 1
2024-04-24T20:43:59,579  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:43:59,579  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:43:59,580  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:43:59,580  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:43:59,580  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:43:59,580  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:43:59,580  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:43:59,580  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:43:59,580  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:43:59,580  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:43:59,580  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:43:59,580  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:43:59,581  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:59,586  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:43:59,589  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:59,593  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:43:59,597  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:43:59,598  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:59,599  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10001
2024-04-24T20:43:59,601  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:43:59,601  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/map.xml
2024-04-24T20:43:59,602  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/reduce.xml
2024-04-24T20:43:59,605  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:43:59,665  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/map.xml
2024-04-24T20:43:59,666  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:43:59,666  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:43:59,666  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:43:59,669  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:43:59,670  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:43:59,682  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:43:59,694  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1136317048_0003
2024-04-24T20:43:59,734  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:43:59,734  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:43:59,735  INFO [Thread-241] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:59,735  INFO [Thread-241] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:43:59,737  INFO [Thread-241] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:43:59,737  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1136317048_0003_m_000000_0
2024-04-24T20:43:59,740  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:59,740  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:59,742  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/map.xml
2024-04-24T20:43:59,742  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:43:59,744  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:43:59,745  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:43:59,750  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:43:59,750  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:43:59,750  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:43:59,750  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:43:59,750  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:43:59,751  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:43:59,751  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,751  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,752  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/map.xml
2024-04-24T20:43:59,752  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:43:59,753  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:43:59,753  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:43:59,753  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:43:59,754  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:43:59,754  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:43:59,754  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:43:59,754  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/map.xml
2024-04-24T20:43:59,754  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:43:59,755  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:43:59,757  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:43:59,757  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:43:59,757  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:43:59,757  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:43:59,757  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:43:59,758  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:43:59,759  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1136317048_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T20:43:59,761  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/e7578857-3aa5-4df1-9080-3c92231ffa70/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:43:59,761  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1136317048_0003_m_000000_0' done.
2024-04-24T20:43:59,761  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1136317048_0003_m_000000_0
2024-04-24T20:43:59,761  INFO [Thread-241] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:43:59,762  INFO [Thread-241] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:43:59,762  INFO [pool-25-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1136317048_0003_r_000000_0
2024-04-24T20:43:59,765  INFO [pool-25-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:59,765  INFO [pool-25-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fe9a90c
2024-04-24T20:43:59,765  INFO [pool-25-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:59,766  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1136317048_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:59,768  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1136317048_0003_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:43:59,769  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local1136317048_0003_m_000000_0
2024-04-24T20:43:59,769  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:43:59,769  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:59,770  INFO [pool-25-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:59,770  INFO [pool-25-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:59,770  INFO [pool-25-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:43:59,771  INFO [pool-25-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:59,772  INFO [pool-25-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,772  INFO [pool-25-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,772  INFO [pool-25-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/reduce.xml
2024-04-24T20:43:59,772  INFO [pool-25-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:59,776  INFO [pool-25-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:43:59,777  INFO [pool-25-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:59,777  INFO [pool-25-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:59,777  INFO [pool-25-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:59,777  INFO [pool-25-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:59,778  INFO [pool-25-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@1b8b8458 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@3908ffec
2024-04-24T20:43:59,778  INFO [pool-25-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:59,778  INFO [pool-25-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:43:59,778  INFO [pool-25-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_tmp.-ext-10000/000000_0
2024-04-24T20:43:59,783  INFO [pool-25-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:43:59,783  INFO [pool-25-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:59,787  INFO [pool-25-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:59,787  INFO [pool-25-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:59,787  INFO [pool-25-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:59,787  INFO [pool-25-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:43:59,794  INFO [pool-25-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:3, 
2024-04-24T20:43:59,794  INFO [pool-25-thread-1] mapred.Task: Task:attempt_local1136317048_0003_r_000000_0 is done. And is in the process of committing
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.Task: Task 'attempt_local1136317048_0003_r_000000_0' done.
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1136317048_0003_r_000000_0
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1136317048_0003_r_000001_0
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:43:59,795  INFO [pool-25-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@94bb118
2024-04-24T20:43:59,796  INFO [pool-25-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:43:59,797  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1136317048_0003_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:43:59,798  INFO [localfetcher#4] reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1136317048_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:43:59,798  INFO [localfetcher#4] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1136317048_0003_m_000000_0
2024-04-24T20:43:59,798  INFO [localfetcher#4] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:43:59,798  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:43:59,799  INFO [pool-25-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:59,799  INFO [pool-25-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:43:59,800  INFO [pool-25-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:59,800  INFO [pool-25-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:43:59,801  INFO [pool-25-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:43:59,802  INFO [pool-25-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,802  INFO [pool-25-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:43:59,802  INFO [pool-25-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10003/e06cced8-baf1-454c-85dd-b784c741a9bd/reduce.xml
2024-04-24T20:43:59,802  INFO [pool-25-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:43:59,805  INFO [pool-25-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:43:59,806  INFO [pool-25-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:43:59,806  INFO [pool-25-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:43:59,806  INFO [pool-25-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:43:59,807  INFO [pool-25-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:43:59,807  INFO [pool-25-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@4993074a and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@7a0a559d
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:43:59,808  INFO [pool-25-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_tmp.-ext-10000/000001_0
2024-04-24T20:43:59,813  INFO [pool-25-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:59,818  INFO [pool-25-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:43:59,823  INFO [pool-25-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:0, 
2024-04-24T20:43:59,823  INFO [pool-25-thread-1] mapred.Task: Task:attempt_local1136317048_0003_r_000001_0 is done. And is in the process of committing
2024-04-24T20:43:59,824  INFO [pool-25-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:43:59,824  INFO [pool-25-thread-1] mapred.Task: Task 'attempt_local1136317048_0003_r_000001_0' done.
2024-04-24T20:43:59,824  INFO [pool-25-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1136317048_0003_r_000001_0
2024-04-24T20:43:59,824  INFO [Thread-241] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:44:00,748 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:44:00,748  INFO [main] exec.Task: 2024-04-24 20:44:00,748 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1136317048_0003
2024-04-24T20:44:00,749  INFO [main] exec.Task: Ended Job = job_local1136317048_0003
2024-04-24T20:44:00,751  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/-ext-10000
2024-04-24T20:44:00,751  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:44:00,751  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:00,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:00,752  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:00,752  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tacid
2024-04-24T20:44:00,752  INFO [main] exec.Task: Loading data to table default.tacid from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/-ext-10000
2024-04-24T20:44:00,753  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:44:00,753  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:00,780  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:00,781  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:00,782  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:00,782  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:00,793  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:00,793  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:00,805  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:44:00,805  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:44:00,818  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:44:00,819  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-43-59_322_8256371979032026599-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:44:00,820  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:44:00,820  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:44:00,853  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:44:00,853  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:44:00,853  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:00,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:00,854  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:00,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:00,855  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:44:00,855  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:00,881  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:00,882  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:00,882  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:00,884  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:00,885  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:00,885  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:00,899  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/e7578857-3aa5-4df1-9080-3c92231ffa70/hive_2024-04-24_20-43-59_322_8256371979032026599-1/-mr-10001
2024-04-24T20:44:00,900  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={numRows=3, rawDataSize=0}}
2024-04-24T20:44:00,900  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={}}
2024-04-24T20:44:00,900  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:44:00,900  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:44:00,914  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:00,914  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:00,914  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:00,915  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:00,916  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:44:00,916  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:00,942  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:00,943  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:00,944  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:00,944  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:00,946  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:00,946  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:00,969  INFO [main] hive.log: Updating table stats fast for tacid
2024-04-24T20:44:00,969  INFO [main] hive.log: Updated size of table tacid to 802
2024-04-24T20:44:00,983  INFO [main] exec.StatsTask: Table default.tacid stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:44:00,984  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:44:00,984  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:44:00,984  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:00,984  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:00,984  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 1.405 seconds
OK
2024-04-24T20:44:00,984  INFO [main] ql.Driver: OK
2024-04-24T20:44:00,984  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,000  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): update TAcid set a = 1 where b = 2
2024-04-24T20:44:01,001  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,001  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,023  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TAcid set a = 1 where b = 2> as 
<insert into table `default`.`TAcid` select ROW__ID,`a`,`b` from `default`.`TAcid` sort by ROW__ID >
2024-04-24T20:44:01,024  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:44:01,024  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,024  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,038  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:01,038  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:01,038  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:44:01,038  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:44:01,038  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:44:01,051  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:44:01,051  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:44:01,051  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,051  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,064  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:01,066  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/tacid/.hive-staging_hive_2024-04-24_20-44-01_023_4202697961706764413-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:44:01,076 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:44:01,076  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:01,077  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.078 seconds
2024-04-24T20:44:01,077  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:01,077  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcid
2024-04-24T20:44:01,078  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,078  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,098  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:01,098  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:01,098  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:01,099  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.021 seconds
2024-04-24T20:44:01,099  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,099  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacid, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:44:01,113  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T20:44:01,113  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,113  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcid
2024-04-24T20:44:01,114  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:01,114  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,114  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,127  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:44:01,127  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:44:01,140  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcid
2024-04-24T20:44:01,140  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcid	
2024-04-24T20:44:01,290  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:01,291  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:01,318  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:01,319  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:01,342  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:01,342  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.228 seconds
OK
2024-04-24T20:44:01,342  INFO [main] ql.Driver: OK
2024-04-24T20:44:01,342  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,342  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:6 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:44:01,346  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcidPart
2024-04-24T20:44:01,347  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:44:01,347  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:44:01,359  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:01,359  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:01,359  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:01,359  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.013 seconds
2024-04-24T20:44:01,360  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,360  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacidpart, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:44:01,459  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T20:44:01,460  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,460  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TAcidPart
2024-04-24T20:44:01,460  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:01,460  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:44:01,460  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:44:01,472  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:44:01,472  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:44:01,484  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcidPart
2024-04-24T20:44:01,484  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcidPart	
2024-04-24T20:44:01,547  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:01,547  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:01,575  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:01,576  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:01,576  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:01,597  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:01,597  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.137 seconds
OK
2024-04-24T20:44:01,597  INFO [main] ql.Driver: OK
2024-04-24T20:44:01,597  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,597  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:7 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:44:01,601  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlat
2024-04-24T20:44:01,602  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:44:01,602  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:44:01,614  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:01,614  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:01,614  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:01,615  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.013 seconds
2024-04-24T20:44:01,615  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,615  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflat, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:44:01,632  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T20:44:01,632  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,632  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlat
2024-04-24T20:44:01,633  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:01,633  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:44:01,633  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:44:01,646  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:44:01,647  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:44:01,659  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlat
2024-04-24T20:44:01,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlat	
2024-04-24T20:44:01,709  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:01,709  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:01,710  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.077 seconds
OK
2024-04-24T20:44:01,710  INFO [main] ql.Driver: OK
2024-04-24T20:44:01,710  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,710  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:8 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
2024-04-24T20:44:01,714  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlatText
2024-04-24T20:44:01,714  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:44:01,715  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:44:01,726  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:01,726  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:01,727  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:01,727  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.013 seconds
2024-04-24T20:44:01,727  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,728  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflattext, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3)
2024-04-24T20:44:01,744  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T20:44:01,744  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,744  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3): drop table if exists TFlatText
2024-04-24T20:44:01,744  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:01,745  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:44:01,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:44:01,761  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:44:01,761  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:44:01,776  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlatText
2024-04-24T20:44:01,777  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlatText	
2024-04-24T20:44:01,822  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:01,823  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:01,823  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3); Time taken: 0.079 seconds
OK
2024-04-24T20:44:01,823  INFO [main] ql.Driver: OK
2024-04-24T20:44:01,823  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3
2024-04-24T20:44:01,823  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:9 queryId=alex_20240424204358_c68fff55-8c9d-4d14-8680-379260a1e7c3 txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgradeExternalTableNoReadPermissionForDatabase" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="2.58">
    <failure type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:303)
]]></failure>
    <system-err><![CDATA[2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:01,858  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:01,859  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:01,859  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:01,859  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:01,859  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:01,859  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:01,882  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:01,883  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:02,028  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.TxnHandler: Failed to update number of open transactions
2024-04-24T20:44:02,029  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.TxnHandler: Non-retryable error in countOpenTxns() : Table/View 'TXNS' does not exist. (SQLState=42X05, ErrorCode=20000)
2024-04-24T20:44:02,064  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:02,064  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:02,064  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:02,064  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:02,064  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:02,065  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:02,194  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676
2024-04-24T20:44:02,196  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676
2024-04-24T20:44:02,198  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/_tmp_space.db
2024-04-24T20:44:02,198  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=9c9e5d1d-13b1-4fe2-a194-ed18c3cef676, clientType=HIVECLI]
2024-04-24T20:44:02,198  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:44:02,198  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): drop database if exists test cascade
2024-04-24T20:44:02,199  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:44:02,199  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:44:02,204  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:44:02,204  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:44:02,212  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:02,212  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:02,233  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:02,233  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:02,233  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:02,233  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.035 seconds
2024-04-24T20:44:02,233  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,233  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2)
2024-04-24T20:44:02,253  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:44:02,254  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,254  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): drop database if exists test cascade
2024-04-24T20:44:02,254  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:02,254  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:44:02,254  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:44:02,258  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:44:02,259  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:44:02,262  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:02,262  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:02,277  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=test tbl=texternal
2024-04-24T20:44:02,277  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=test tbl=texternal	
2024-04-24T20:44:02,407  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal does not exist; Force to delete it.
2024-04-24T20:44:02,407 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db/texternal
2024-04-24T20:44:02,407  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:44:02,407  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:44:02,409  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:44:02,409  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:44:02,412  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:44:02,412  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:44:02,418  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:44:02,500  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db does not exist; Force to delete it.
2024-04-24T20:44:02,500 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987758179/warehouse/test.db
2024-04-24T20:44:02,500  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:02,526  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:02,527  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:02,527  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:02,554  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:02,554  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.3 seconds
OK
2024-04-24T20:44:02,554  INFO [main] ql.Driver: OK
2024-04-24T20:44:02,554  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,554  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 txnid:0]
2024-04-24T20:44:02,560  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): drop table if exists TExternal
2024-04-24T20:44:02,561  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:44:02,561  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:44:02,577  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:02,577  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:02,577  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:02,577  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.017 seconds
2024-04-24T20:44:02,577  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,578  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texternal, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2)
2024-04-24T20:44:02,590  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:44:02,590  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,590  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): drop table if exists TExternal
2024-04-24T20:44:02,590  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:02,591  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:44:02,591  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:44:02,603  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:44:02,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:44:02,615  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExternal
2024-04-24T20:44:02,616  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExternal	
2024-04-24T20:44:02,663  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal does not exist; Force to delete it.
2024-04-24T20:44:02,663 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/texternal
2024-04-24T20:44:02,664  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:02,664  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.074 seconds
OK
2024-04-24T20:44:02,664  INFO [main] ql.Driver: OK
2024-04-24T20:44:02,664  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,664  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 txnid:0]
2024-04-24T20:44:02,669  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): create database test
2024-04-24T20:44:02,670  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:02,671  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:02,671  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:02,671  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.002 seconds
2024-04-24T20:44:02,671  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,671  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): create database test
2024-04-24T20:44:02,671  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:02,673  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:44:02,673  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:44:02,674  WARN [main] metastore.ObjectStore: Failed to get database test, returning NoSuchObjectException
2024-04-24T20:44:02,677  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db
2024-04-24T20:44:02,701  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:02,701  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.03 seconds
OK
2024-04-24T20:44:02,701  INFO [main] ql.Driver: OK
2024-04-24T20:44:02,701  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:02,701  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:44:02,703  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:02,703  INFO [main] parse.CalcitePlanner: Creating table test.TExternal position=13
2024-04-24T20:44:02,703  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:44:02,703  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:44:02,707  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:02,708  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:02,708  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:02,708  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.007 seconds
2024-04-24T20:44:02,708  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,709  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2)
2024-04-24T20:44:02,721  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:44:02,721  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,721  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:44:02,721  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:02,722  INFO [main] exec.DDLTask: creating table test.TExternal on null
2024-04-24T20:44:02,723  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987842, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, numFiles=0, totalSize=0, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:44:02,723  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987842, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=false, numFiles=0, totalSize=0, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:44:02,723  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:44:02,732  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal
2024-04-24T20:44:02,776  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:02,776  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.055 seconds
OK
2024-04-24T20:44:02,776  INFO [main] ql.Driver: OK
2024-04-24T20:44:02,776  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,776  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 txnid:0]
2024-04-24T20:44:02,780  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:44:02,780  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:02,780  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:44:02,780  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:44:02,793  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:02,798  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:02,798  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:02,798  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:02,798  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:02,798  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:44:02,798  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:44:02,810  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:02,871  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:44:02,871  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:44:02,874  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:44:02,874  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:44:02,880  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:44:02,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:44:02,895  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:02,895  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:02,895  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:02,895  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:44:02,896  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:44:02,909  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1
2024-04-24T20:44:02,924  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:44:02,924  INFO [main] ppd.OpProcFactory: Processing for FS(3)
2024-04-24T20:44:02,924  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:44:02,924  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:44:02,924  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:44:02,932  INFO [main] optimizer.GenMRFileSink1: using CombineHiveInputformat for the merge job
2024-04-24T20:44:02,932  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:02,932  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:02,946  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:44:02,946  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:02,946  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:44:02,946  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:02,946  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 0.166 seconds
2024-04-24T20:44:02,947  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,947  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:test, tablename:texternal, operationType:INSERT, isAcid:false, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2)
2024-04-24T20:44:02,959  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:44:02,959  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,959  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:44:02,960  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:44:02,960  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:02,960  INFO [main] ql.Driver: Query ID = alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
Total jobs = 1
2024-04-24T20:44:02,960  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:44:02,960  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:44:02,961  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:44:02,961  INFO [main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:44:02,961  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:44:02,961  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:44:02,961  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:44:02,966  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:44:02,968  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:02,969  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:02,970  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10001
2024-04-24T20:44:02,972  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:02,972  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10004/d46a56fd-9641-4101-af16-830bb9585a2e/map.xml
2024-04-24T20:44:02,976  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:44:03,041  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10004/d46a56fd-9641-4101-af16-830bb9585a2e/map.xml
2024-04-24T20:44:03,042  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:44:03,042  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:44:03,042  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:44:03,045  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:44:03,045  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:44:03,058  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:44:03,070  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1050995045_0004
2024-04-24T20:44:03,111  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:44:03,111  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:44:03,112  INFO [Thread-364] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:03,112  INFO [Thread-364] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:03,114  INFO [Thread-364] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:44:03,114  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1050995045_0004_m_000000_0
2024-04-24T20:44:03,116  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:03,117  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:44:03,118  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10004/d46a56fd-9641-4101-af16-830bb9585a2e/map.xml
2024-04-24T20:44:03,119  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:44:03,120  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:03,121  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T20:44:03,122  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:03,122  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:03,122  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10004/d46a56fd-9641-4101-af16-830bb9585a2e/map.xml
2024-04-24T20:44:03,122  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:44:03,123  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:44:03,124  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:44:03,124  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:44:03,124  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:44:03,124  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing operator FS[3]
2024-04-24T20:44:03,125  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@650f1eed and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@379a9015
2024-04-24T20:44:03,125  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10004/d46a56fd-9641-4101-af16-830bb9585a2e/map.xml
2024-04-24T20:44:03,125  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_tmp.-ext-10002/000000_0
2024-04-24T20:44:03,125  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T20:44:03,126  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_tmp.-ext-10002/000000_0
2024-04-24T20:44:03,127  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 1
2024-04-24T20:44:03,127  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing operator FS[3]
2024-04-24T20:44:03,132  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 3
2024-04-24T20:44:03,138  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_1_test.texternal:3, 
2024-04-24T20:44:03,139  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:44:03,139  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1050995045_0004_m_000000_0 is done. And is in the process of committing
2024-04-24T20:44:03,140  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:44:03,140  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1050995045_0004_m_000000_0' done.
2024-04-24T20:44:03,140  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1050995045_0004_m_000000_0
2024-04-24T20:44:03,141  INFO [Thread-364] mapred.LocalJobRunner: map task executor complete.
2024-04-24 20:44:04,116 Stage-1 map = 100%,  reduce = 0%
2024-04-24T20:44:04,116  INFO [main] exec.Task: 2024-04-24 20:44:04,116 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1050995045_0004
2024-04-24T20:44:04,118  INFO [main] exec.Task: Ended Job = job_local1050995045_0004
2024-04-24T20:44:04,119  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/_tmp.-ext-10002 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/-ext-10002
2024-04-24T20:44:04,119  INFO [main] ql.Driver: Starting task [Stage-7:CONDITIONAL] in serial mode
Stage-4 is selected by condition resolver.
2024-04-24T20:44:04,119  INFO [main] exec.Task: Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
2024-04-24T20:44:04,119  INFO [main] exec.Task: Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
2024-04-24T20:44:04,119  INFO [main] exec.Task: Stage-5 is filtered out by condition resolver.
2024-04-24T20:44:04,119  INFO [main] ql.Driver: Starting task [Stage-4:MOVE] in serial mode
2024-04-24T20:44:04,120  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:04,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:04,120  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:04,120  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/-ext-10000
2024-04-24T20:44:04,120  INFO [main] exec.Task: Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/-ext-10000 from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/-ext-10002
2024-04-24T20:44:04,120  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:04,120  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:04,137  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table test.texternal
2024-04-24T20:44:04,137  INFO [main] exec.Task: Loading data to table test.texternal from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-44-02_780_9002135074624950201-1/-ext-10000
2024-04-24T20:44:04,138  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:04,138  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:04,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:04,180  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:04,180  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:04,181  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:04,190  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:04,190  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:04,202  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:04,202  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:04,215  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:04,215  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:04,223  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:44:04,223  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:44:04,254  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:44:04,254  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:44:04,254  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:04,254  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:04,255  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:04,255  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:04,256  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:04,256  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:04,285  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:04,286  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:04,286  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:04,287  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:04,288  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:04,288  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:04,300  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/9c9e5d1d-13b1-4fe2-a194-ed18c3cef676/hive_2024-04-24_20-44-02_780_9002135074624950201-1/-mr-10001
2024-04-24T20:44:04,301  INFO [main] fs.FSStatsAggregator: Read stats : {test.texternal/={numRows=3, rawDataSize=24}}
2024-04-24T20:44:04,301  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:44:04,301  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:44:04,324  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	numRows	3
2024-04-24T20:44:04,324  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	rawDataSize	24
2024-04-24T20:44:04,324  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:04,324  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:04,325  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:04,325  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:04,326  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:44:04,326  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:04,353  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:04,354  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:04,354  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:04,354  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:04,356  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:04,356  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:04,375  INFO [main] hive.log: Updating table stats fast for texternal
2024-04-24T20:44:04,375  INFO [main] hive.log: Updated size of table texternal to 244
2024-04-24T20:44:04,385  INFO [main] exec.StatsTask: Table test.texternal stats: [numFiles=1, numRows=3, totalSize=244, rawDataSize=24]
2024-04-24T20:44:04,386  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:44:04,386  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:44:04,386  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:04,386  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:04,386  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2); Time taken: 1.427 seconds
OK
2024-04-24T20:44:04,386  INFO [main] ql.Driver: OK
2024-04-24T20:44:04,386  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2
2024-04-24T20:44:04,386  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204402_3187f6ea-c1b0-476a-bd84-93d8942508e2 txnid:0]
2024-04-24T20:44:04,390  INFO [main] acid.PreUpgradeTool: Starting with RunOptions{outputDir='/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955', execute=true, dbRegex='.*', tableRegex='.*', tableType=null, tablePoolSize=8}
2024-04-24T20:44:04,390  INFO [main] acid.PreUpgradeTool: Using Hive Version: 2.3.3 build: 2.3.3 from 8a511e3f79b43d4be41cd231cf5c99e43b248383 by daijy source checksum fb9b95d9baaf3f968c457dee42d015d4
2024-04-24T20:44:04,390  INFO [main] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:44:04,391  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:04,393  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:04,393  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:04,397  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=9c9e5d1d-13b1-4fe2-a194-ed18c3cef676, clientType=HIVECLI]
2024-04-24T20:44:04,397  INFO [main] metastore.HiveMetaStore: 0: get_databases: .*
2024-04-24T20:44:04,397  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: .*	
2024-04-24T20:44:04,400  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
2024-04-24T20:44:04,400  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
2024-04-24T20:44:04,403  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:44:04,403  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:44:04,406  INFO [main] acid.PreUpgradeTool: No compaction is necessary
2024-04-24T20:44:04,406  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:04,406  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:04,406  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:04,406  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
]]></system-err>
  </testcase>
  <testcase name="testConcurrency" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="35.821"/>
  <testcase name="testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="5.543">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update DExclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:186)
]]></error>
    <system-err><![CDATA[2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:40,257  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:40,286  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:40,286  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:40,287  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:40,412  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:40,525  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e
2024-04-24T20:44:40,527  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e
2024-04-24T20:44:40,529  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db
2024-04-24T20:44:40,530  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f7d21985-4863-4b4e-bc64-2a53cf0c999e, clientType=HIVECLI]
2024-04-24T20:44:40,530  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:44:40,530  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DInclude cascade
2024-04-24T20:44:40,530  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:40,530  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:40,531  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:44:40,532  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,532  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:40,532  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,532  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.002 seconds
2024-04-24T20:44:40,532  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,532  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DInclude cascade
2024-04-24T20:44:40,532  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:40,533  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.0 seconds
OK
2024-04-24T20:44:40,533  INFO [main] ql.Driver: OK
2024-04-24T20:44:40,533  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:40,533  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DExclude cascade
2024-04-24T20:44:40,533  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:40,534  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:40,534  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:44:40,534  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,534  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:40,534  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,535  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.001 seconds
2024-04-24T20:44:40,535  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,535  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DExclude cascade
2024-04-24T20:44:40,535  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:40,535  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.0 seconds
OK
2024-04-24T20:44:40,535  INFO [main] ql.Driver: OK
2024-04-24T20:44:40,535  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:40,536  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create database DInclude
2024-04-24T20:44:40,536  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,536  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:40,536  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,536  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.0 seconds
2024-04-24T20:44:40,536  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,536  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create database DInclude
2024-04-24T20:44:40,537  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:40,537  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:44:40,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:44:40,538  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:44:40,541  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db
2024-04-24T20:44:40,555  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:40,555  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.018 seconds
OK
2024-04-24T20:44:40,555  INFO [main] ql.Driver: OK
2024-04-24T20:44:40,555  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:40,555  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): use DInclude
2024-04-24T20:44:40,556  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:40,556  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:40,562  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,562  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:40,562  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,563  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.007 seconds
2024-04-24T20:44:40,563  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,563  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): use DInclude
2024-04-24T20:44:40,563  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:40,563  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:40,563  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:40,567  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:40,567  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:40,571  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:40,572  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.008 seconds
OK
2024-04-24T20:44:40,572  INFO [main] ql.Driver: OK
2024-04-24T20:44:40,572  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:40,572  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:44:40,572  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:40,572  INFO [main] parse.CalcitePlanner: Creating table DInclude.TInclude position=13
2024-04-24T20:44:40,573  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:40,573  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:40,576  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,577  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:40,577  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,577  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.005 seconds
2024-04-24T20:44:40,577  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,577  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:40,593  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:44:40,593  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,594  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:44:40,594  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:40,595  INFO [main] exec.DDLTask: creating table DInclude.TInclude on null
2024-04-24T20:44:40,595  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987880, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, totalSize=0, rawDataSize=0, transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:44:40,595  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987880, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, totalSize=0, rawDataSize=0, transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:44:40,606  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude
2024-04-24T20:44:40,652  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:40,652  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.059 seconds
OK
2024-04-24T20:44:40,652  INFO [main] ql.Driver: OK
2024-04-24T20:44:40,653  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,653  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b txnid:0]
2024-04-24T20:44:40,658  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:44:40,659  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:40,659  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:40,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:40,690  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:40,695  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:40,695  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:40,695  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:40,695  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:40,695  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:40,695  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:40,705  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:40,762  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:44:40,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:44:40,764  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:44:40,764  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:44:40,769  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:44:40,769  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:44:40,772  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:44:40,772  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:44:40,784  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:40,784  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:40,784  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:40,785  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:40,785  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:40,795  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1
2024-04-24T20:44:40,805  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:44:40,806  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:44:40,806  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:44:40,806  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:44:40,806  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) dinclude.tinclude
2024-04-24T20:44:40,822  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:44:40,822  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:40,822  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:44:40,822  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:40,822  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.164 seconds
2024-04-24T20:44:40,828  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:44:40,828  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,828  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:dinclude, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:40,841  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:44:40,845  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:44:40,845  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:44:40,845  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:40,845  INFO [main] ql.Driver: Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
Total jobs = 1
2024-04-24T20:44:40,845  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:44:40,845  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:44:40,846  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:44:40,846  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:44:40,846  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:44:40,846  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:44:40,846  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:44:40,846  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:44:40,846  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:44:40,846  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:44:40,846  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:44:40,846  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:44:40,846  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:44:40,851  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:44:40,854  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:44:40,858  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:44:40,863  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:40,864  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:40,865  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10001
2024-04-24T20:44:40,867  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:40,868  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/map.xml
2024-04-24T20:44:40,868  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/reduce.xml
2024-04-24T20:44:40,871  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:44:40,934  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/map.xml
2024-04-24T20:44:40,935  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:44:40,935  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:44:40,935  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:44:40,938  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:44:40,938  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:44:40,950  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:44:40,961  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2096720835_0025
2024-04-24T20:44:40,999  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:44:40,999  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:44:41,000  INFO [Thread-3793] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:41,000  INFO [Thread-3793] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:41,001  INFO [Thread-3793] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:44:41,001  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2096720835_0025_m_000000_0
2024-04-24T20:44:41,003  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:41,004  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:44:41,005  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/map.xml
2024-04-24T20:44:41,005  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:44:41,006  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:44:41,006  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:44:41,025  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:44:41,025  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:44:41,025  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:44:41,025  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:44:41,025  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:44:41,026  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:44:41,027  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,027  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,027  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/map.xml
2024-04-24T20:44:41,027  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:44:41,028  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:44:41,028  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:44:41,028  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/map.xml
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:44:41,029  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:44:41,030  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:44:41,030  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:44:41,030  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:44:41,031  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:44:41,031  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:44:41,031  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:44:41,031  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:44:41,031  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:44:41,032  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:44:41,032  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2096720835_0025_m_000000_0 is done. And is in the process of committing
2024-04-24T20:44:41,034  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:44:41,034  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2096720835_0025_m_000000_0' done.
2024-04-24T20:44:41,034  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2096720835_0025_m_000000_0
2024-04-24T20:44:41,034  INFO [Thread-3793] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:44:41,035  INFO [Thread-3793] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:44:41,035  INFO [pool-167-thread-1] mapred.LocalJobRunner: Starting task: attempt_local2096720835_0025_r_000000_0
2024-04-24T20:44:41,037  INFO [pool-167-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:41,037  INFO [pool-167-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e197254
2024-04-24T20:44:41,037  INFO [pool-167-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:41,038  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local2096720835_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:41,040  INFO [localfetcher#205] reduce.LocalFetcher: localfetcher#205 about to shuffle output of map attempt_local2096720835_0025_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:44:41,040  INFO [localfetcher#205] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local2096720835_0025_m_000000_0
2024-04-24T20:44:41,040  INFO [localfetcher#205] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:44:41,040  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:41,040  INFO [pool-167-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:41,040  INFO [pool-167-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:41,040  INFO [pool-167-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/reduce.xml
2024-04-24T20:44:41,041  INFO [pool-167-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:41,043  INFO [pool-167-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:41,044  INFO [pool-167-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:41,044  INFO [pool-167-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:44:41,044  INFO [pool-167-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:44:41,044  INFO [pool-167-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:44:41,044  INFO [pool-167-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@7a1ad205 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@3f5494c0
2024-04-24T20:44:41,045  INFO [pool-167-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:41,045  INFO [pool-167-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:44:41,045  INFO [pool-167-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:41,049  INFO [pool-167-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:44:41,049  INFO [pool-167-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:41,054  INFO [pool-167-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:41,054  INFO [pool-167-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:44:41,054  INFO [pool-167-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:44:41,054  INFO [pool-167-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:44:41,060  INFO [pool-167-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:3, 
2024-04-24T20:44:41,060  INFO [pool-167-thread-1] mapred.Task: Task:attempt_local2096720835_0025_r_000000_0 is done. And is in the process of committing
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.Task: Task 'attempt_local2096720835_0025_r_000000_0' done.
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local2096720835_0025_r_000000_0
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.LocalJobRunner: Starting task: attempt_local2096720835_0025_r_000001_0
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:41,061  INFO [pool-167-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44c0d0dd
2024-04-24T20:44:41,062  INFO [pool-167-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:41,062  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local2096720835_0025_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:41,063  INFO [localfetcher#206] reduce.LocalFetcher: localfetcher#206 about to shuffle output of map attempt_local2096720835_0025_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:44:41,063  INFO [localfetcher#206] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2096720835_0025_m_000000_0
2024-04-24T20:44:41,063  INFO [localfetcher#206] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:44:41,063  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:41,063  INFO [pool-167-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:41,063  INFO [pool-167-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:41,064  INFO [pool-167-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10003/3157366a-0874-4b63-9fd1-458224ff10bd/reduce.xml
2024-04-24T20:44:41,065  INFO [pool-167-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:41,067  INFO [pool-167-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:41,067  INFO [pool-167-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:41,067  INFO [pool-167-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:44:41,067  INFO [pool-167-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@6d9e07ff and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@2f9a74a9
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:44:41,068  INFO [pool-167-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:41,074  INFO [pool-167-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:41,078  INFO [pool-167-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:41,083  INFO [pool-167-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:0, 
2024-04-24T20:44:41,083  INFO [pool-167-thread-1] mapred.Task: Task:attempt_local2096720835_0025_r_000001_0 is done. And is in the process of committing
2024-04-24T20:44:41,083  INFO [pool-167-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:41,083  INFO [pool-167-thread-1] mapred.Task: Task 'attempt_local2096720835_0025_r_000001_0' done.
2024-04-24T20:44:41,083  INFO [pool-167-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local2096720835_0025_r_000001_0
2024-04-24T20:44:41,084  INFO [Thread-3793] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:44:42,002 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:44:42,002  INFO [main] exec.Task: 2024-04-24 20:44:42,002 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local2096720835_0025
2024-04-24T20:44:42,003  INFO [main] exec.Task: Ended Job = job_local2096720835_0025
2024-04-24T20:44:42,006  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/-ext-10000
2024-04-24T20:44:42,007  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:44:42,007  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:42,007  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:42,008  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:42,008  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table dinclude.tinclude
2024-04-24T20:44:42,009  INFO [main] exec.Task: Loading data to table dinclude.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/-ext-10000
2024-04-24T20:44:42,011  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:42,011  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:42,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:42,035  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:42,036  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:42,044  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:42,044  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:42,054  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:42,054  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:42,068  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:44:42,069  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-40_658_2675364537116256466-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:44:42,069  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:44:42,069  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:44:42,097  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:44:42,097  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:44:42,097  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:42,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:42,098  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:42,098  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:42,099  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:42,099  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:42,119  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:42,119  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:42,119  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:42,119  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:42,119  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:42,120  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:42,120  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:42,120  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:42,121  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:42,121  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:42,131  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-40_658_2675364537116256466-1/-mr-10001
2024-04-24T20:44:42,131  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={}}
2024-04-24T20:44:42,131  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={rawDataSize=0, numRows=3}}
2024-04-24T20:44:42,131  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:42,132  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:42,141  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:42,141  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:42,141  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:42,142  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:42,142  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:44:42,142  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:44:42,163  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:42,163  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:42,163  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:42,163  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:42,164  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:42,164  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:42,164  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:42,165  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:42,165  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:42,180  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:44:42,180  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:44:42,189  INFO [main] exec.StatsTask: Table dinclude.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:44:42,190  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:44:42,190  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:44:42,190  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:42,190  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:42,190  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 1.344 seconds
OK
2024-04-24T20:44:42,190  INFO [main] ql.Driver: OK
2024-04-24T20:44:42,190  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:42,199  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): update TInclude set a = 1 where b = 2
2024-04-24T20:44:42,200  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:42,200  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:42,209  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `DInclude`.`TInclude` select ROW__ID,`a`,`b` from `DInclude`.`TInclude` sort by ROW__ID >
2024-04-24T20:44:42,210  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:44:42,210  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:42,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:42,220  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:42,220  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:42,221  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:44:42,221  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:42,221  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:42,232  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:44:42,232  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:44:42,232  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:44:42,232  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:44:42,243  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:42,244  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for FS(7)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for SEL(6)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for RS(5)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for RS(3)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:44:42,268  INFO [main] ppd.OpProcFactory: Processing for FIL(1)
2024-04-24T20:44:42,271  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 5 oldColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Const int 1, VALUE._col2=Const int 2}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 5 newColExprMap: {VALUE._col0=Column[_col0]}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 5 oldColExprMap: {VALUE._col0=Column[_col0]}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 5 newColExprMap: {VALUE._col0=Column[_col0]}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 3 oldColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Const int 2}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 3 newColExprMap: {KEY.reducesinkkey0=Column[_col0]}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 3 oldColExprMap: {KEY.reducesinkkey0=Column[_col0]}
2024-04-24T20:44:42,277  INFO [main] optimizer.ColumnPrunerProcFactory: RS 3 newColExprMap: {KEY.reducesinkkey0=Column[_col0]}
2024-04-24T20:44:42,278  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) dinclude.tinclude
2024-04-24T20:44:42,286  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed plan generation
2024-04-24T20:44:42,286  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:42,286  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:row__id, type:struct<transactionid:bigint,bucketid:int,rowid:bigint>, comment:null), FieldSchema(name:_c1, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], properties:null)
2024-04-24T20:44:42,286  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:42,287  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.088 seconds
2024-04-24T20:44:42,291  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:44:42,291  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:42,291  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:SHARED_WRITE, level:TABLE, dbname:dinclude, tablename:tinclude, operationType:UPDATE, isAcid:true, isDynamicPartitionWrite:false)], txnid:2, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:42,304  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:44:42,305  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): update TInclude set a = 1 where b = 2
2024-04-24T20:44:42,305  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:44:42,305  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:42,305  INFO [main] ql.Driver: Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
Total jobs = 1
2024-04-24T20:44:42,305  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:44:42,306  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:44:42,306  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:44:42,306  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:44:42,306  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:44:42,306  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:44:42,306  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:44:42,306  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:44:42,306  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:44:42,306  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:44:42,309  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:44:42,309  INFO [main] exec.Utilities: Processing alias tinclude
2024-04-24T20:44:42,309  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude
2024-04-24T20:44:42,313  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:44:42,317  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,22KB
2024-04-24T20:44:42,321  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:44:42,324  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,11KB
2024-04-24T20:44:42,325  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:42,325  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_209_5300852078385355527-1/-mr-10001
2024-04-24T20:44:42,327  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:42,327  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,327  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/reduce.xml
2024-04-24T20:44:42,330  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:44:42,390  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,390  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 1
2024-04-24T20:44:42,390  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = b
2024-04-24T20:44:42,391  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude
2024-04-24T20:44:42,395  INFO [main] orc.OrcInputFormat: ORC pushdown predicate: null
2024-04-24T20:44:42,398  INFO [main] orc.OrcInputFormat: Using schema evolution configuration variables schema.evolution.columns [a, b] / schema.evolution.columns.types [int, int] (isAcidRead false)
2024-04-24T20:44:42,398 ERROR [ORC_GET_SPLITS #0] io.AcidUtils: Failed to get files with ID; using regular API: org/apache/hadoop/hdfs/DistributedFileSystem
2024-04-24T20:44:42,407  INFO [main] orc.OrcInputFormat: FooterCacheHitRatio: 0/0
2024-04-24T20:44:42,407  INFO [main] io.HiveInputFormat: number of splits 2
2024-04-24T20:44:42,419  INFO [main] mapreduce.JobSubmitter: number of splits:2
2024-04-24T20:44:42,430  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1054739306_0026
2024-04-24T20:44:42,466  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:44:42,466  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:44:42,467  INFO [Thread-3857] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:42,467  INFO [Thread-3857] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:42,468  INFO [Thread-3857] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:44:42,468  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1054739306_0026_m_000000_0
2024-04-24T20:44:42,469  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:42,469  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat:OrcSplit [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude, start=0, length=0, isOriginal=false, fileLength=9223372036854775807, hasFooter=false, hasBase=false, deltas=[{ minTxnId: 1 maxTxnId: 1 stmtIds: [0] }]]
2024-04-24T20:44:42,469  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,470  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:44:42,478  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,22KB
2024-04-24T20:44:42,481  INFO [LocalJobRunner Map Task Executor #0] orc.OrcInputFormat: Using schema evolution configuration variables schema.evolution.columns [a, b] / schema.evolution.columns.types [int, int] (isAcidRead true)
2024-04-24T20:44:42,485  INFO [LocalJobRunner Map Task Executor #0] orc.OrcInputFormat: Using schema evolution configuration variables schema.evolution.columns [a, b] / schema.evolution.columns.types [int, int] (isAcidRead true)
2024-04-24T20:44:42,487  INFO [LocalJobRunner Map Task Executor #0] orc.ReaderImpl: Reading ORC rows from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00000 with {include: [true, false, true], offset: 0, length: 9223372036854775807, schema: struct<a:int,b:int>}
2024-04-24T20:44:42,496  WARN [LocalJobRunner Map Task Executor #0] impl.SchemaEvolution: Column names are missing from this file. This is caused by a writer earlier than HIVE-4243. The reader will reconcile schemas based on index. File type: struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint,row:struct<_col0:int,_col1:int>>, reader type: struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint,row:struct<a:int,b:int>>
2024-04-24T20:44:42,512  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:44:42,517  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:44:42,517  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:44:42,517  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:44:42,517  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:44:42,517  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:44:42,518  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:44:42,518  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,518  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,518  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,518  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:44:42,519  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.FilterOperator: Initializing operator FIL[8]
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[2]
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<a:int,b:int,row__id:struct<transactionid:bigint,bucketid:int,rowid:bigint>>
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[3]
2024-04-24T20:44:42,520  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:44:42,521  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,522  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:44:42,522  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [reducesinkkey0] num distributions: 1
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[3]: records written - 1
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.FilterOperator: Closing operator FIL[8]
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[2]
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[3]
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[3]: records written - 1
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:1, 
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:44:42,523  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:44:42,524  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:44:42,524  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 33; bufvoid = 104857600
2024-04-24T20:44:42,524  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2024-04-24T20:44:42,524  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:44:42,525  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1054739306_0026_m_000000_0 is done. And is in the process of committing
2024-04-24T20:44:42,525  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: OrcSplit [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude, start=0, length=0, isOriginal=false, fileLength=9223372036854775807, hasFooter=false, hasBase=false, deltas=[{ minTxnId: 1 maxTxnId: 1 stmtIds: [0] }]]
2024-04-24T20:44:42,525  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1054739306_0026_m_000000_0' done.
2024-04-24T20:44:42,525  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1054739306_0026_m_000000_0
2024-04-24T20:44:42,525  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1054739306_0026_m_000001_0
2024-04-24T20:44:42,526  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:42,526  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat:OrcSplit [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude, start=1, length=0, isOriginal=false, fileLength=9223372036854775807, hasFooter=false, hasBase=false, deltas=[{ minTxnId: 1 maxTxnId: 1 stmtIds: [0] }]]
2024-04-24T20:44:42,526  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,527  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:44:42,529  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,22KB
2024-04-24T20:44:42,529  INFO [LocalJobRunner Map Task Executor #0] orc.OrcInputFormat: Using schema evolution configuration variables schema.evolution.columns [a, b] / schema.evolution.columns.types [int, int] (isAcidRead true)
2024-04-24T20:44:42,529  INFO [LocalJobRunner Map Task Executor #0] orc.OrcInputFormat: Using schema evolution configuration variables schema.evolution.columns [a, b] / schema.evolution.columns.types [int, int] (isAcidRead true)
2024-04-24T20:44:42,530  INFO [LocalJobRunner Map Task Executor #0] orc.ReaderImpl: Reading ORC rows from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00001 with {include: [true, false, true], offset: 0, length: 9223372036854775807, schema: struct<a:int,b:int>}
2024-04-24T20:44:42,530  WARN [LocalJobRunner Map Task Executor #0] impl.SchemaEvolution: Column names are missing from this file. This is caused by a writer earlier than HIVE-4243. The reader will reconcile schemas based on index. File type: struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint,row:struct<_col0:int,_col1:int>>, reader type: struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint,row:struct<a:int,b:int>>
2024-04-24T20:44:42,531  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:44:42,536  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,537  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,537  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/map.xml
2024-04-24T20:44:42,537  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:44:42,537  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.FilterOperator: Initializing operator FIL[8]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[2]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<a:int,b:int,row__id:struct<transactionid:bigint,bucketid:int,rowid:bigint>>
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[3]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:0, DESERIALIZE_ERRORS:0, 
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.FilterOperator: Closing operator FIL[8]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[2]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[3]
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[3]: records written - 0
2024-04-24T20:44:42,538  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T20:44:42,539  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:44:42,539  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:44:42,539  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1054739306_0026_m_000001_0 is done. And is in the process of committing
2024-04-24T20:44:42,540  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: OrcSplit [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude, start=1, length=0, isOriginal=false, fileLength=9223372036854775807, hasFooter=false, hasBase=false, deltas=[{ minTxnId: 1 maxTxnId: 1 stmtIds: [0] }]]
2024-04-24T20:44:42,540  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1054739306_0026_m_000001_0' done.
2024-04-24T20:44:42,540  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1054739306_0026_m_000001_0
2024-04-24T20:44:42,540  INFO [Thread-3857] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:44:42,541  INFO [Thread-3857] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:44:42,541  INFO [pool-174-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1054739306_0026_r_000000_0
2024-04-24T20:44:42,542  INFO [pool-174-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:42,542  INFO [pool-174-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1358413f
2024-04-24T20:44:42,542  INFO [pool-174-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:42,542  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1054739306_0026_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.LocalFetcher: localfetcher#207 about to shuffle output of map attempt_local1054739306_0026_m_000001_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1054739306_0026_m_000001_0
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.LocalFetcher: localfetcher#207 about to shuffle output of map attempt_local1054739306_0026_m_000000_0 decomp: 37 len: 41 to MEMORY
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.InMemoryMapOutput: Read 37 bytes from map-output for attempt_local1054739306_0026_m_000000_0
2024-04-24T20:44:42,543  INFO [localfetcher#207] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 37, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->39
2024-04-24T20:44:42,544  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.LocalJobRunner: 2 / 2 copied.
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.Merger: Merging 2 sorted segments
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merged 2 segments, 39 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merging 1 files, 41 bytes from disk
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2024-04-24T20:44:42,544  INFO [pool-174-thread-1] mapred.LocalJobRunner: 2 / 2 copied.
2024-04-24T20:44:42,545  INFO [pool-174-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,545  INFO [pool-174-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,545  INFO [pool-174-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/reduce.xml
2024-04-24T20:44:42,545  INFO [pool-174-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:42,547  INFO [pool-174-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,11KB
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] ExecReducer: 
<SEL>Id =4
  <Children>
    <FS>Id =7
      <Children>
      <\Children>
      <Parent>Id = 4 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.SelectOperator: Initializing operator SEL[4]
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:struct<transactionid:bigint,bucketid:int,rowid:bigint>>,value:struct<>>
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.FileSinkOperator: Initializing operator FS[7]
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@3c8d4850 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@239061e0
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:44:42,548  INFO [pool-174-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:42,549  INFO [pool-174-thread-1] exec.FileSinkOperator: FS[7]: records written - 1
2024-04-24T20:44:42,554  INFO [pool-174-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000002_0000002_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:42,558  INFO [pool-174-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000002_0000002_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:42,558  INFO [pool-174-thread-1] exec.SelectOperator: Closing operator SEL[4]
2024-04-24T20:44:42,558  INFO [pool-174-thread-1] exec.FileSinkOperator: Closing operator FS[7]
2024-04-24T20:44:42,558  INFO [pool-174-thread-1] exec.FileSinkOperator: FS[7]: records written - 1
2024-04-24T20:44:42,564  INFO [pool-174-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:1, 
2024-04-24T20:44:42,564  INFO [pool-174-thread-1] mapred.Task: Task:attempt_local1054739306_0026_r_000000_0 is done. And is in the process of committing
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.Task: Task 'attempt_local1054739306_0026_r_000000_0' done.
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1054739306_0026_r_000000_0
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1054739306_0026_r_000001_0
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@728f4932
2024-04-24T20:44:42,565  INFO [pool-174-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:42,566  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1054739306_0026_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.LocalFetcher: localfetcher#208 about to shuffle output of map attempt_local1054739306_0026_m_000001_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1054739306_0026_m_000001_0
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.LocalFetcher: localfetcher#208 about to shuffle output of map attempt_local1054739306_0026_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1054739306_0026_m_000000_0
2024-04-24T20:44:42,567  INFO [localfetcher#208] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2024-04-24T20:44:42,568  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] mapred.LocalJobRunner: 2 / 2 copied.
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] mapred.Merger: Merging 2 sorted segments
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merged 2 segments, 4 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:42,568  INFO [pool-174-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] mapred.LocalJobRunner: 2 / 2 copied.
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_199_701135707677313268-1/-mr-10001/78ec25fd-447c-4398-ad29-ab2bab63ebc9/reduce.xml
2024-04-24T20:44:42,569  INFO [pool-174-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:42,571  INFO [pool-174-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,11KB
2024-04-24T20:44:42,571  INFO [pool-174-thread-1] ExecReducer: 
<SEL>Id =4
  <Children>
    <FS>Id =7
      <Children>
      <\Children>
      <Parent>Id = 4 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.SelectOperator: Initializing operator SEL[4]
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:struct<transactionid:bigint,bucketid:int,rowid:bigint>>,value:struct<>>
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: Initializing operator FS[7]
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@4f75ebee and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@1965f24a
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.SelectOperator: Closing operator SEL[4]
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: Closing operator FS[7]
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: FS[7]: records written - 0
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:44:42,572  INFO [pool-174-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:42,577  INFO [pool-174-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:0, 
2024-04-24T20:44:42,577  INFO [pool-174-thread-1] mapred.Task: Task:attempt_local1054739306_0026_r_000001_0 is done. And is in the process of committing
2024-04-24T20:44:42,577  INFO [pool-174-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:42,577  INFO [pool-174-thread-1] mapred.Task: Task 'attempt_local1054739306_0026_r_000001_0' done.
2024-04-24T20:44:42,577  INFO [pool-174-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1054739306_0026_r_000001_0
2024-04-24T20:44:42,577  INFO [Thread-3857] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:44:43,469 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:44:43,469  INFO [main] exec.Task: 2024-04-24 20:44:43,469 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1054739306_0026
2024-04-24T20:44:43,471  INFO [main] exec.Task: Ended Job = job_local1054739306_0026
2024-04-24T20:44:43,477  INFO [main] exec.Utilities: created empty bucket for enforcing bucketing at file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:43,477  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/-ext-10000
2024-04-24T20:44:43,478  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:44:43,478  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:43,478  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:43,478  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:43,478  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table dinclude.tinclude
2024-04-24T20:44:43,478  INFO [main] exec.Task: Loading data to table dinclude.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/-ext-10000
2024-04-24T20:44:43,479  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:43,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:43,503  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:43,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:43,504  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:43,504  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:43,505  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:43,505  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:43,515  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:43,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:43,525  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-44-42_209_5300852078385355527-1/-ext-10000/000000_0/delta_0000002_0000002_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dinclude.db/tinclude/delta_0000002_0000002_0000/bucket_00000
2024-04-24T20:44:43,526  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:44:43,526  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:44:43,547  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:44:43,547  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:44:43,547  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:43,547  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:43,548  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:43,548  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:43,549  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:43,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:43,570  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:43,570  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:43,571  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:43,571  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:43,572  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:43,581  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-42_209_5300852078385355527-1/-mr-10001
2024-04-24T20:44:43,581  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={}}
2024-04-24T20:44:43,582  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={numRows=0, rawDataSize=0}}
2024-04-24T20:44:43,582  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:44:43,582  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:44:43,592  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:43,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:43,592  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:43,592  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:43,593  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:44:43,593  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:43,614  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:43,614  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:43,615  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:43,616  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:43,616  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:43,631  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:44:43,631  INFO [main] hive.log: Updated size of table tinclude to 1380
2024-04-24T20:44:43,640  INFO [main] exec.StatsTask: Table dinclude.tinclude stats: [numFiles=3, numRows=0, totalSize=1380, rawDataSize=0]
2024-04-24T20:44:43,640  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:44:43,640  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:44:43,640  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:43,640  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:43,640  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 1.335 seconds
OK
2024-04-24T20:44:43,640  INFO [main] ql.Driver: OK
2024-04-24T20:44:43,641  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,655  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create database DExclude
2024-04-24T20:44:43,656  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:43,656  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:43,656  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:43,656  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.001 seconds
2024-04-24T20:44:43,656  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,656  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create database DExclude
2024-04-24T20:44:43,656  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:43,657  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:DExclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:44:43,657  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:DExclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:44:43,658  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:44:43,661  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db
2024-04-24T20:44:43,670  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:43,670  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.014 seconds
OK
2024-04-24T20:44:43,670  INFO [main] ql.Driver: OK
2024-04-24T20:44:43,670  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:43,671  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): use DExclude
2024-04-24T20:44:43,671  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:43,671  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:43,675  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:43,675  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:43,675  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:43,675  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.004 seconds
2024-04-24T20:44:43,675  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,675  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): use DExclude
2024-04-24T20:44:43,675  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:43,675  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:43,675  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:43,679  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:43,679  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:43,683  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:43,683  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.008 seconds
OK
2024-04-24T20:44:43,683  INFO [main] ql.Driver: OK
2024-04-24T20:44:43,683  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:43,684  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create table DExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:44:43,684  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:43,684  INFO [main] parse.CalcitePlanner: Creating table DExclude.DExclude position=13
2024-04-24T20:44:43,684  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:43,684  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:43,688  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:43,688  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:43,688  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:43,688  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.004 seconds
2024-04-24T20:44:43,688  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,689  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:dexclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:43,698  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:44:43,698  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,699  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): create table DExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:44:43,699  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:43,699  INFO [main] exec.DDLTask: creating table DExclude.DExclude on null
2024-04-24T20:44:43,700  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:DExclude, dbName:DExclude, owner:alex, createTime:1713987883, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:44:43,700  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:DExclude, dbName:DExclude, owner:alex, createTime:1713987883, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:44:43,707  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude
2024-04-24T20:44:43,726  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:43,727  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.028 seconds
OK
2024-04-24T20:44:43,727  INFO [main] ql.Driver: OK
2024-04-24T20:44:43,727  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,727  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b txnid:0]
2024-04-24T20:44:43,730  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): insert into DExclude values(1,2),(3,4),(5,6)
2024-04-24T20:44:43,730  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:44:43,731  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:43,731  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:43,740  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:43,744  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:43,745  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:43,745  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:43,745  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:43,745  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:43,745  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:43,754  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:43,803  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:44:43,803  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:44:43,804  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:44:43,804  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:44:43,806  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dexclude
2024-04-24T20:44:43,806  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dexclude	
2024-04-24T20:44:43,809  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:44:43,809  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:44:43,811  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:44:43,811  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:44:43,824  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:44:43,824  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:44:43,824  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:44:43,824  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:43,824  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:43,835  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1
2024-04-24T20:44:43,846  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:44:43,847  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:44:43,847  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:44:43,847  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:44:43,847  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) dexclude.dexclude
2024-04-24T20:44:43,854  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:44:43,854  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:43,854  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:44:43,854  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:43,855  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.124 seconds
2024-04-24T20:44:43,859  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:44:43,859  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,859  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:dexclude, tablename:dexclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:3, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:43,873  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:44:43,874  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): insert into DExclude values(1,2),(3,4),(5,6)
2024-04-24T20:44:43,875  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:44:43,875  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:43,875  INFO [main] ql.Driver: Query ID = alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
Total jobs = 1
2024-04-24T20:44:43,875  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:44:43,875  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:44:43,875  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:44:43,875  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:44:43,875  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:44:43,875  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:44:43,875  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:44:43,875  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:44:43,875  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:44:43,875  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:44:43,876  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:44:43,876  INFO [main] exec.Utilities: Processing alias values__tmp__table__2
2024-04-24T20:44:43,876  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__2
2024-04-24T20:44:43,880  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:44:43,882  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:44:43,887  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:44:43,890  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:43,891  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:43,891  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10001
2024-04-24T20:44:43,893  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:44:43,893  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/map.xml
2024-04-24T20:44:43,893  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/reduce.xml
2024-04-24T20:44:43,896  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:44:43,956  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/map.xml
2024-04-24T20:44:43,956  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:44:43,956  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:44:43,956  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__2
2024-04-24T20:44:43,959  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:44:43,959  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:44:43,977  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:44:43,988  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1469886576_0027
2024-04-24T20:44:44,024  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:44:44,024  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:44:44,024  INFO [Thread-3934] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:44,024  INFO [Thread-3934] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:44:44,025  INFO [Thread-3934] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:44:44,026  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1469886576_0027_m_000000_0
2024-04-24T20:44:44,026  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:44,027  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__2/data_file:0+12
2024-04-24T20:44:44,027  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/map.xml
2024-04-24T20:44:44,027  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:44:44,028  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:44:44,028  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/map.xml
2024-04-24T20:44:44,033  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:44:44,034  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/map.xml
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:44:44,035  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:44:44,036  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:44:44,037  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:44:44,037  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1469886576_0027_m_000000_0 is done. And is in the process of committing
2024-04-24T20:44:44,037  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f7d21985-4863-4b4e-bc64-2a53cf0c999e/_tmp_space.db/Values__Tmp__Table__2/data_file:0+12
2024-04-24T20:44:44,038  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1469886576_0027_m_000000_0' done.
2024-04-24T20:44:44,038  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1469886576_0027_m_000000_0
2024-04-24T20:44:44,038  INFO [Thread-3934] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:44:44,038  INFO [Thread-3934] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:44:44,039  INFO [pool-180-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1469886576_0027_r_000000_0
2024-04-24T20:44:44,039  INFO [pool-180-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:44,039  INFO [pool-180-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28aa5e4e
2024-04-24T20:44:44,039  INFO [pool-180-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:44,040  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1469886576_0027_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:44,040  INFO [localfetcher#209] reduce.LocalFetcher: localfetcher#209 about to shuffle output of map attempt_local1469886576_0027_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:44:44,040  INFO [localfetcher#209] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local1469886576_0027_m_000000_0
2024-04-24T20:44:44,040  INFO [localfetcher#209] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:44:44,041  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:44,041  INFO [pool-180-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:44,041  INFO [pool-180-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:44,041  INFO [pool-180-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:44,041  INFO [pool-180-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,042  INFO [pool-180-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/reduce.xml
2024-04-24T20:44:44,043  INFO [pool-180-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:44,045  INFO [pool-180-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:44,045  INFO [pool-180-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:44,045  INFO [pool-180-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:44:44,045  INFO [pool-180-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:44:44,046  INFO [pool-180-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:44:44,046  INFO [pool-180-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@6750bf10 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@1df2c59a
2024-04-24T20:44:44,046  INFO [pool-180-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:44,046  INFO [pool-180-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:44:44,046  INFO [pool-180-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_tmp.-ext-10000/000000_0
2024-04-24T20:44:44,051  INFO [pool-180-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:44:44,051  INFO [pool-180-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000003_0000003_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:44,055  INFO [pool-180-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000003_0000003_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:44,055  INFO [pool-180-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:44:44,055  INFO [pool-180-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:44:44,055  INFO [pool-180-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:44:44,060  INFO [pool-180-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dexclude.dexclude:3, 
2024-04-24T20:44:44,060  INFO [pool-180-thread-1] mapred.Task: Task:attempt_local1469886576_0027_r_000000_0 is done. And is in the process of committing
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.Task: Task 'attempt_local1469886576_0027_r_000000_0' done.
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1469886576_0027_r_000000_0
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1469886576_0027_r_000001_0
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:44:44,061  INFO [pool-180-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e3171b8
2024-04-24T20:44:44,062  INFO [pool-180-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:44:44,062  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1469886576_0027_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:44:44,063  INFO [localfetcher#210] reduce.LocalFetcher: localfetcher#210 about to shuffle output of map attempt_local1469886576_0027_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:44:44,063  INFO [localfetcher#210] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1469886576_0027_m_000000_0
2024-04-24T20:44:44,063  INFO [localfetcher#210] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:44:44,063  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:44:44,063  INFO [pool-180-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:44,063  INFO [pool-180-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter7420771294674377983.jar]
2024-04-24T20:44:44,064  INFO [pool-180-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10003/eb176043-6fd0-4b9f-9a50-310cae908043/reduce.xml
2024-04-24T20:44:44,065  INFO [pool-180-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:44:44,067  INFO [pool-180-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:44:44,067  INFO [pool-180-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:44:44,067  INFO [pool-180-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:44:44,067  INFO [pool-180-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@618c43a8 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@14c55290
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:44:44,068  INFO [pool-180-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_tmp.-ext-10000/000001_0
2024-04-24T20:44:44,072  INFO [pool-180-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000003_0000003_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:44,077  INFO [pool-180-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000003_0000003_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:44:44,081  INFO [pool-180-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dexclude.dexclude:0, 
2024-04-24T20:44:44,081  INFO [pool-180-thread-1] mapred.Task: Task:attempt_local1469886576_0027_r_000001_0 is done. And is in the process of committing
2024-04-24T20:44:44,081  INFO [pool-180-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:44:44,081  INFO [pool-180-thread-1] mapred.Task: Task 'attempt_local1469886576_0027_r_000001_0' done.
2024-04-24T20:44:44,081  INFO [pool-180-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1469886576_0027_r_000001_0
2024-04-24T20:44:44,082  INFO [Thread-3934] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:44:45,026 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:44:45,027  INFO [main] exec.Task: 2024-04-24 20:44:45,026 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1469886576_0027
2024-04-24T20:44:45,028  INFO [main] exec.Task: Ended Job = job_local1469886576_0027
2024-04-24T20:44:45,031  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/-ext-10000
2024-04-24T20:44:45,032  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:44:45,032  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:45,032  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:45,033  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:45,034  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table dexclude.dexclude
2024-04-24T20:44:45,034  INFO [main] exec.Task: Loading data to table dexclude.dexclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/-ext-10000
2024-04-24T20:44:45,036  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dexclude tbl=dexclude
2024-04-24T20:44:45,036  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dexclude tbl=dexclude	
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,085  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,086  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,086  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,086  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,086  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:45,086  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:45,087  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:45,087  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:45,097  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dexclude tbl=dexclude
2024-04-24T20:44:45,097  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dexclude tbl=dexclude	
2024-04-24T20:44:45,110  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/-ext-10000/000000_0/delta_0000003_0000003_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/delta_0000003_0000003_0000/bucket_00000
2024-04-24T20:44:45,110  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-43_730_4201315256869529089-1/-ext-10000/000001_0/delta_0000003_0000003_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/delta_0000003_0000003_0000/bucket_00001
2024-04-24T20:44:45,111  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dexclude tbl=dexclude newtbl=dexclude
2024-04-24T20:44:45,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dexclude tbl=dexclude newtbl=dexclude	
2024-04-24T20:44:45,134  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:44:45,134  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:44:45,134  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:45,134  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:45,134  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:45,134  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:45,135  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dexclude tbl=dexclude
2024-04-24T20:44:45,135  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dexclude tbl=dexclude	
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,157  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,157  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:45,158  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:45,159  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:45,159  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:45,172  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f7d21985-4863-4b4e-bc64-2a53cf0c999e/hive_2024-04-24_20-44-43_730_4201315256869529089-1/-mr-10001
2024-04-24T20:44:45,173  INFO [main] fs.FSStatsAggregator: Read stats : {dexclude.dexclude/={}}
2024-04-24T20:44:45,173  INFO [main] fs.FSStatsAggregator: Read stats : {dexclude.dexclude/={numRows=3, rawDataSize=0}}
2024-04-24T20:44:45,173  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dexclude tbl=dexclude
2024-04-24T20:44:45,173  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dexclude tbl=dexclude	
2024-04-24T20:44:45,183  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:44:45,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:44:45,183  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:44:45,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:44:45,184  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dexclude tbl=dexclude newtbl=dexclude
2024-04-24T20:44:45,184  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dexclude tbl=dexclude newtbl=dexclude	
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:44:45,206  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,206  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:44:45,207  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:44:45,208  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:44:45,208  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:44:45,223  INFO [main] hive.log: Updating table stats fast for dexclude
2024-04-24T20:44:45,223  INFO [main] hive.log: Updated size of table dexclude to 798
2024-04-24T20:44:45,231  INFO [main] exec.StatsTask: Table dexclude.dexclude stats: [numFiles=2, numRows=0, totalSize=798, rawDataSize=0]
2024-04-24T20:44:45,232  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:44:45,232  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:44:45,232  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:45,232  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:44:45,232  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 1.358 seconds
OK
2024-04-24T20:44:45,232  INFO [main] ql.Driver: OK
2024-04-24T20:44:45,232  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,241  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): update DExclude set a = 1 where b = 2
2024-04-24T20:44:45,242  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:45,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:45,251  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update DExclude set a = 1 where b = 2> as 
<insert into table `DExclude`.`DExclude` select ROW__ID,`a`,`b` from `DExclude`.`DExclude` sort by ROW__ID >
2024-04-24T20:44:45,251  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:44:45,252  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:45,252  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:45,261  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:44:45,261  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:44:45,261  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:44:45,261  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dexclude tbl=dexclude
2024-04-24T20:44:45,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dexclude tbl=dexclude	
2024-04-24T20:44:45,272  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:44:45,272  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:44:45,272  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=DExclude
2024-04-24T20:44:45,272  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=DExclude	
2024-04-24T20:44:45,282  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:44:45,283  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/dexclude.db/dexclude/.hive-staging_hive_2024-04-24_20-44-45_251_2728788944174876990-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:44:45,292 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:bigint,transactionid:bigint,bucketid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:186)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:44:45,292  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:45,293  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.052 seconds
2024-04-24T20:44:45,293  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:44:45,293  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DInclude cascade
2024-04-24T20:44:45,293  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:45,294  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:45,297  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=DInclude pat=.*
2024-04-24T20:44:45,297  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=DInclude pat=.*	
2024-04-24T20:44:45,300  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=tinclude
2024-04-24T20:44:45,300  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=tinclude	
2024-04-24T20:44:45,310  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:45,310  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:45,310  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:45,310  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.017 seconds
2024-04-24T20:44:45,311  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,311  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:45,321  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T20:44:45,321  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,321  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DInclude cascade
2024-04-24T20:44:45,321  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:45,321  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:44:45,321  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:44:45,325  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=DInclude
2024-04-24T20:44:45,325  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=DInclude	
2024-04-24T20:44:45,328  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=tinclude
2024-04-24T20:44:45,328  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=tinclude	
2024-04-24T20:44:45,338  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=DInclude tbl=tinclude
2024-04-24T20:44:45,338  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=DInclude tbl=tinclude	
2024-04-24T20:44:45,453  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:45,454  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,481  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,501  INFO [main] metastore.HiveMetaStore: 0: drop_database: DInclude
2024-04-24T20:44:45,501  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: DInclude	
2024-04-24T20:44:45,507  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:44:45,507  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:44:45,509  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=dinclude pat=*
2024-04-24T20:44:45,509  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=dinclude pat=*	
2024-04-24T20:44:45,514  INFO [main] metastore.ObjectStore: Dropping database DInclude along with all tables
2024-04-24T20:44:45,524  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:45,524  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,548  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,565  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:45,565  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.244 seconds
OK
2024-04-24T20:44:45,565  INFO [main] ql.Driver: OK
2024-04-24T20:44:45,565  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,565  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:6 queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b txnid:0]
2024-04-24T20:44:45,569  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DExclude cascade
2024-04-24T20:44:45,569  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:45,569  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:45,573  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=DExclude pat=.*
2024-04-24T20:44:45,573  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=DExclude pat=.*	
2024-04-24T20:44:45,575  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=dexclude
2024-04-24T20:44:45,576  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=dexclude	
2024-04-24T20:44:45,585  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:44:45,585  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:44:45,585  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:44:45,586  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.016 seconds
2024-04-24T20:44:45,586  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,586  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:dexclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b)
2024-04-24T20:44:45,597  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T20:44:45,597  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,597  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b): drop database if exists DExclude cascade
2024-04-24T20:44:45,598  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:44:45,598  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:44:45,598  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:44:45,606  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=DExclude
2024-04-24T20:44:45,607  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=DExclude	
2024-04-24T20:44:45,610  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DExclude tbl=dexclude
2024-04-24T20:44:45,610  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DExclude tbl=dexclude	
2024-04-24T20:44:45,623  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=DExclude tbl=dexclude
2024-04-24T20:44:45,623  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=DExclude tbl=dexclude	
2024-04-24T20:44:45,664  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:45,665  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,691  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,692  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,712  INFO [main] metastore.HiveMetaStore: 0: drop_database: DExclude
2024-04-24T20:44:45,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: DExclude	
2024-04-24T20:44:45,718  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dexclude
2024-04-24T20:44:45,718  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dexclude	
2024-04-24T20:44:45,720  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=dexclude pat=*
2024-04-24T20:44:45,720  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=dexclude pat=*	
2024-04-24T20:44:45,723  INFO [main] metastore.ObjectStore: Dropping database DExclude along with all tables
2024-04-24T20:44:45,726  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:44:45,726  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:44:45,751  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:44:45,767  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:44:45,768  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b); Time taken: 0.17 seconds
OK
2024-04-24T20:44:45,768  INFO [main] ql.Driver: OK
2024-04-24T20:44:45,768  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b
2024-04-24T20:44:45,768  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:7 queryId=alex_20240424204440_e2b4da71-36c9-4372-a98d-13b455d9f34b txnid:0]
]]></system-err>
  </testcase>
</testsuite>