<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="32.29" tests="3" errors="2" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/warehouse"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter8177440168931698638.jar /home/alex/Repositories/hive/ql/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire8426745256593451493tmp surefire_19259062259244896898466tmp"/>
    <property name="nondexExecid" value="P8gC2Wt6DD1QwiZ4NJDRegC4uh59IgmR4jnrq+hRsc="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="basedir" value="/home/alex/Repositories/hive/ql"/>
    <property name="file.separator" value="/"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/ql/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/ql/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/ql/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/ql/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="nondexStart" value="0"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/localfs/warehouse"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/ql/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="933178"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter8177440168931698638.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/ql"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="test.output.overwrite" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="hive.root" value="/home/alex/Repositories/hive/ql/../"/>
  </properties>
  <testcase name="testConcatenate" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="15.963">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTbl set b = 4 failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-out><![CDATA[log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7ca8d498.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7ca8d498.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
]]></system-out>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,070756 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@3ad83a66
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,018816 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", footer="null", header="null", Configuration(HiveLog4j2Test), Replace=null, disableAnsi="null", charset="null", noConsoleNoAnsi="null", PatternSelector=null, alwaysWriteExceptions="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", target="SYSTEM_ERR", direct="null", immediateFlush="null", bufferSize="null", bufferedIo="null", ignoreExceptions="null", Configuration(HiveLog4j2Test), name="console", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, footer="null", header="null", noConsoleNoAnsi="null", disableAnsi="null", alwaysWriteExceptions="null", Replace=null, Configuration(HiveLog4j2Test), charset="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(modulate="true", interval="1", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(stopCustomActionsOnError="null", min="null", fileIndex="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test), max="30", compressionLevel="null", ={})
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), advertiseURI="null", fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", filePermissions="null", fileOwner="null", fileGroup="null", append="null", advertise="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), bufferSize="null", bufferedIo="null", immediateFlush="null", name="DRFA", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", ={}, Filter=null)
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 2967863671
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-23T21:26:38.085-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/23-21:27:04.992, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=2024/04/23-00:00:00.000, current=2024/04/23-21:27:04.992, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7c1e2a2d
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@6d60fe40
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40] started OK.
2024-04-23T21:27:05,128  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-23T21:27:05,514  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-23T21:27:05,574  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:27:05,574  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:27:05,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:27:05,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:27:05,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:27:05,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:27:05,576  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:27:05,576  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:27:05,576  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:27:05,576  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:27:05,577  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:27:05,662  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:27:05,669  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-23T21:27:06,221  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:27:06,225  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-23T21:27:06,227  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:27:06,231  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-23T21:27:06,235  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:27:06,236  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-23T21:27:06,385  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-23T21:27:06,393  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/ql/target/tmp/junit_metastore_db;create=true
Hive Session ID = eea6eed9-86b5-4beb-967b-344e353af9ee
2024-04-23T21:27:07,394  INFO [main] SessionState: Hive Session ID = eea6eed9-86b5-4beb-967b-344e353af9ee
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:27:07,405  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-23T21:27:07,765  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/eea6eed9-86b5-4beb-967b-344e353af9ee
2024-04-23T21:27:07,769  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee
2024-04-23T21:27:07,773  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/eea6eed9-86b5-4beb-967b-344e353af9ee/_tmp_space.db
2024-04-23T21:27:07,804  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=eea6eed9-86b5-4beb-967b-344e353af9ee, clientType=HIVECLI]
2024-04-23T21:27:07,839  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:27:07,963  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:27:07,995  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:27:07,998  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-23T21:27:07,998  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-23T21:27:08,001  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:27:08,005  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-23T21:27:08,007  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:27:08,008  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-23T21:27:08,437  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-23T21:27:08,438  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066, with PersistenceManager: null will be shutdown
2024-04-23T21:27:08,465  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@45c9b3 created in the thread with id: 1
2024-04-23T21:27:10,705  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@479b5066 from thread id: 1
2024-04-23T21:27:10,719  INFO [main] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-23T21:27:10,746  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-23T21:27:10,791  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-23T21:27:10,811  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-23T21:27:10,815  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-23T21:27:10,905  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-23T21:27:10,911  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-23T21:27:10,912  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-23T21:27:10,915  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-23T21:27:10,916  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-23T21:27:10,920  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-23T21:27:10,921  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-23T21:27:10,924  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:27:11,060  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:27:11,105  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-23T21:27:11,137  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2): drop table if exists acidTbl
2024-04-23T21:27:12,030  INFO [main] reflections.Reflections: Reflections took 225 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:27:12,202  INFO [main] reflections.Reflections: Reflections took 137 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:27:12,350  INFO [main] reflections.Reflections: Reflections took 140 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:27:12,379  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-23T21:27:12,393  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-23T21:27:12,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:12,552  INFO [main] reflections.Reflections: Reflections took 128 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:27:12,589  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,590  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,593  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,593  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=34, flushCache_()=1, isCompatibleWith_(Configuration)=1, getValidTxns_(long)=7}
2024-04-23T21:27:12,594  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2); Time taken: 1.459 seconds
2024-04-23T21:27:12,596  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2
2024-04-23T21:27:12,596  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,599  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2): drop table if exists acidTbl
2024-04-23T21:27:12,602  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,604  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:12,621  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,621  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,621  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2); Time taken: 0.022 seconds
2024-04-23T21:27:12,622  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212711_22fb37c0-6be3-4456-be00-183ad02e3ad2
2024-04-23T21:27:12,633  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-23T21:27:12,649  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,652  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-23T21:27:12,654  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-23T21:27:12,655  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28): drop table if exists acidTblPart
2024-04-23T21:27:12,660  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-23T21:27:12,661  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-23T21:27:12,662  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:12,668  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,669  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,669  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,669  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=31, isCompatibleWith_(Configuration)=1, flushCache_()=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=4}
2024-04-23T21:27:12,670  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28); Time taken: 0.014 seconds
2024-04-23T21:27:12,670  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28
2024-04-23T21:27:12,670  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,670  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28): drop table if exists acidTblPart
2024-04-23T21:27:12,671  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,671  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:12,676  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,676  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,676  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28); Time taken: 0.006 seconds
2024-04-23T21:27:12,677  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_a2dd7cfa-3c4e-41e1-a6f3-bdffd8239e28
2024-04-23T21:27:12,685  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-23T21:27:12,696  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,696  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-23T21:27:12,698  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-23T21:27:12,699  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb): drop table if exists acidTbl2
2024-04-23T21:27:12,705  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-23T21:27:12,706  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-23T21:27:12,708  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-23T21:27:12,714  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,714  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,715  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,715  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=2, openTxn_(String, TxnType)=6, commitTxn_(CommitTxnRequest)=20, isCompatibleWith_(Configuration)=0, flushCache_()=0}
2024-04-23T21:27:12,715  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb); Time taken: 0.016 seconds
2024-04-23T21:27:12,716  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb
2024-04-23T21:27:12,716  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,716  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb): drop table if exists acidTbl2
2024-04-23T21:27:12,716  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,717  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-23T21:27:12,721  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,722  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,722  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb); Time taken: 0.005 seconds
2024-04-23T21:27:12,722  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_891b4943-f67b-4278-9838-049db4d667eb
2024-04-23T21:27:12,733  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-23T21:27:12,742  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,742  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-23T21:27:12,743  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-23T21:27:12,744  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:12,748  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-23T21:27:12,749  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-23T21:27:12,751  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:12,755  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,755  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,756  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,756  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=20, isCompatibleWith_(Configuration)=1, getValidTxns_(long)=1, flushCache_()=0, openTxn_(String, TxnType)=4}
2024-04-23T21:27:12,756  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86); Time taken: 0.011 seconds
2024-04-23T21:27:12,756  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86
2024-04-23T21:27:12,756  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,757  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:12,757  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,757  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:12,762  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,762  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,762  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86); Time taken: 0.005 seconds
2024-04-23T21:27:12,763  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_ae073ba7-352a-4c0b-8c07-bf307455de86
2024-04-23T21:27:12,771  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-23T21:27:12,781  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,781  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-23T21:27:12,782  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:12,783  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:12,788  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-23T21:27:12,789  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-23T21:27:12,792  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:12,798  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,798  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,798  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,799  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=1, openTxn_(String, TxnType)=5, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=19}
2024-04-23T21:27:12,799  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490); Time taken: 0.015 seconds
2024-04-23T21:27:12,799  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490
2024-04-23T21:27:12,800  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,800  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:12,800  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,801  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:12,807  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,807  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,808  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490); Time taken: 0.007 seconds
2024-04-23T21:27:12,808  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_863d8905-c0ac-46e7-be90-03be22e43490
2024-04-23T21:27:12,818  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-23T21:27:12,828  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,828  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-23T21:27:12,829  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-23T21:27:12,830  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2): drop table if exists nonAcidNonBucket
2024-04-23T21:27:12,834  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-23T21:27:12,835  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-23T21:27:12,837  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:12,841  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:12,841  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:12,841  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:12,841  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=4, flushCache_()=0, commitTxn_(CommitTxnRequest)=21}
2024-04-23T21:27:12,842  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2); Time taken: 0.011 seconds
2024-04-23T21:27:12,842  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2
2024-04-23T21:27:12,842  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:12,842  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2): drop table if exists nonAcidNonBucket
2024-04-23T21:27:12,843  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:12,843  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:12,850  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:12,851  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:12,851  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2); Time taken: 0.008 seconds
2024-04-23T21:27:12,851  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_72e91e7b-5c77-46e1-af59-65c7afa665d2
2024-04-23T21:27:12,859  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-23T21:27:12,868  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:12,868  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-23T21:27:12,869  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:12,870  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:12,940  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-23T21:27:12,941  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-23T21:27:12,942  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:12,944  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:12,961  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-23T21:27:13,001  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,012  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,012  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,012  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,013  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,013  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, getDatabase_(String)=4, openTxn_(String, TxnType)=4, getValidWriteIds_(List, String)=11, commitTxn_(CommitTxnRequest)=18, flushCache_()=0}
2024-04-23T21:27:13,013  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86); Time taken: 0.143 seconds
2024-04-23T21:27:13,014  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86
2024-04-23T21:27:13,021  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86
2024-04-23T21:27:13,069  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86 LockResponse(lockid:1, state:ACQUIRED)
2024-04-23T21:27:13,069  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,072  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,073  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,174  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713932833, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, rawDataSize=0, numRows=0, numFilesErasureCoded=0, transactional=true, bucketing_version=2, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-23T21:27:13,185  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:13,307  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,307  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=134}
2024-04-23T21:27:13,308  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86); Time taken: 0.235 seconds
2024-04-23T21:27:13,308  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212712_85a8ecd9-43ba-4a5b-9db5-624d73b5af86
2024-04-23T21:27:13,314  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-23T21:27:13,323  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,324  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-23T21:27:13,324  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,325  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,333  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-23T21:27:13,334  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-23T21:27:13,335  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,335  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:13,339  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-23T21:27:13,340  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,344  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,344  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,344  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,344  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,344  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=3, commitTxn_(CommitTxnRequest)=16, openTxn_(String, TxnType)=4, isCompatibleWith_(Configuration)=1, flushCache_()=1, getDatabase_(String)=3, getValidTxns_(long)=1}
2024-04-23T21:27:13,344  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583); Time taken: 0.019 seconds
2024-04-23T21:27:13,345  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583
2024-04-23T21:27:13,345  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583
2024-04-23T21:27:13,374  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583 LockResponse(lockid:2, state:ACQUIRED)
2024-04-23T21:27:13,374  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,376  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,376  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713932833, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{transactional=true, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-23T21:27:13,388  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart
2024-04-23T21:27:13,417  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,417  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=39}
2024-04-23T21:27:13,417  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583); Time taken: 0.041 seconds
2024-04-23T21:27:13,417  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_07419206-7ef9-464b-9b37-b6665b91d583
2024-04-23T21:27:13,423  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-23T21:27:13,432  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,434  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-23T21:27:13,435  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,436  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,441  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 2
2024-04-23T21:27:13,442  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-23T21:27:13,443  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,443  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:13,447  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-23T21:27:13,448  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,451  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,451  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,451  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,451  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,451  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=3, commitTxn_(CommitTxnRequest)=18, flushCache_()=0, getDatabase_(String)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=4}
2024-04-23T21:27:13,452  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59); Time taken: 0.015 seconds
2024-04-23T21:27:13,452  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59
2024-04-23T21:27:13,452  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59
2024-04-23T21:27:13,481  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59 LockResponse(lockid:3, state:ACQUIRED)
2024-04-23T21:27:13,481  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,481  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,482  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713932833, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFilesErasureCoded=0, totalSize=0, numFiles=0, transactional=false, numRows=0, bucketing_version=2, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:13,492  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidorctbl
2024-04-23T21:27:13,535  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,536  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=52, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:13,536  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59); Time taken: 0.054 seconds
2024-04-23T21:27:13,536  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_d2bd89ac-fb0b-49c9-9acf-e45161274e59
2024-04-23T21:27:13,542  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-23T21:27:13,551  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,551  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-23T21:27:13,552  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,553  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,557  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 2
2024-04-23T21:27:13,557  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-23T21:27:13,559  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,559  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:13,562  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-23T21:27:13,563  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,565  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,565  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,565  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,565  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,565  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=3, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=16, flushCache_()=0, getValidWriteIds_(List, String)=3, getValidTxns_(long)=1, openTxn_(String, TxnType)=3}
2024-04-23T21:27:13,566  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d); Time taken: 0.012 seconds
2024-04-23T21:27:13,566  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d
2024-04-23T21:27:13,566  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d
2024-04-23T21:27:13,594  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d LockResponse(lockid:4, state:ACQUIRED)
2024-04-23T21:27:13,594  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,594  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,595  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713932833, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=false, totalSize=0, numFilesErasureCoded=0, bucketing_version=2, numRows=0, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFiles=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:13,604  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidorctbl2
2024-04-23T21:27:13,632  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,632  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=35, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:13,632  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d); Time taken: 0.038 seconds
2024-04-23T21:27:13,632  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_5f24398e-da3f-46e8-a5e7-5c6d36dea39d
2024-04-23T21:27:13,638  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-23T21:27:13,646  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,647  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-23T21:27:13,648  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,648  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,653  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 2
2024-04-23T21:27:13,653  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-23T21:27:13,654  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,654  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:13,658  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-23T21:27:13,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,661  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,661  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,661  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,661  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,661  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=15, getValidWriteIds_(List, String)=3, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, getDatabase_(String)=3, isCompatibleWith_(Configuration)=1, flushCache_()=0}
2024-04-23T21:27:13,662  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08); Time taken: 0.013 seconds
2024-04-23T21:27:13,662  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08
2024-04-23T21:27:13,662  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08
2024-04-23T21:27:13,689  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08 LockResponse(lockid:5, state:ACQUIRED)
2024-04-23T21:27:13,689  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,690  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:13,691  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,693  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/eea6eed9-86b5-4beb-967b-344e353af9ee/_tmp_space.db/fca9424f-a3c6-4dff-8f9d-a3147f13ade4
2024-04-23T21:27:13,697  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,697  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=4, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:13,697  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08); Time taken: 0.006 seconds
2024-04-23T21:27:13,697  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_eb8ac19b-3ce0-4a5c-b26d-a81737ee3f08
2024-04-23T21:27:13,702  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-23T21:27:13,711  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,711  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-23T21:27:13,713  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,714  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,719  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 4
2024-04-23T21:27:13,720  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-23T21:27:13,721  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,722  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:13,726  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-23T21:27:13,726  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:13,729  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:13,729  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:13,729  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:13,729  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:13,729  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=4, flushCache_()=0, getDatabase_(String)=3, getValidTxns_(long)=1, openTxn_(String, TxnType)=5, commitTxn_(CommitTxnRequest)=15, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:13,729  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1); Time taken: 0.015 seconds
2024-04-23T21:27:13,730  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1
2024-04-23T21:27:13,730  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1
2024-04-23T21:27:13,757  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1 LockResponse(lockid:6, state:ACQUIRED)
2024-04-23T21:27:13,757  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:13,757  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:13,757  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:13,759  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713932833, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, numFiles=0, numFilesErasureCoded=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:13,768  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidnonbucket
2024-04-23T21:27:13,793  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:13,793  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=34, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:13,793  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1); Time taken: 0.036 seconds
2024-04-23T21:27:13,793  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_17c89209-f1fc-4232-b920-7f15358b82e1
2024-04-23T21:27:13,799  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-23T21:27:13,807  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:13,808  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-23T21:27:13,808  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Initializing local cache in HiveMetaStoreClient...
2024-04-23T21:27:13,834  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Local cache initialized in HiveMetaStoreClient: com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalManualCache@ca2be53
2024-04-23T21:27:13,834  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTbl values(1,2),(4,5)
2024-04-23T21:27:13,834  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091): insert into acidTbl values(1,2),(4,5)
2024-04-23T21:27:13,840  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 7
2024-04-23T21:27:13,841  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-23T21:27:13,842  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:13,842  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:14,380  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,384  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,384  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,384  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,385  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,385  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,388  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:27:14,438  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:14,490  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:14,490  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-23T21:27:14,491  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:14,491  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:14,491  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:14,494  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:14,514  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:14,515  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-23T21:27:14,515  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-23T21:27:15,836  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-23T21:27:16,481  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:16,481  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:16,481  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:16,483  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-23T21:27:16,487  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:16,487  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:16,489  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:16,490  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:16,503  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:16,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-23T21:27:16,540  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-23T21:27:16,562  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-23T21:27:16,563  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtbl (txnIds: [13])
2024-04-23T21:27:16,570  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-23T21:27:16,623  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-23T21:27:16,623  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-23T21:27:16,632  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-23T21:27:16,644  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-23T21:27:16,676  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:16,690  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:16,720  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-23T21:27:16,726  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-23T21:27:16,728  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-23T21:27:16,728  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:16,728  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:16,728  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null)], properties:null)
2024-04-23T21:27:16,728  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:16,729  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=100, allocateTableWriteId_(long, String, String)=14, getCheckConstraints_(CheckConstraintsRequest)=3, isCompatibleWith_(Configuration)=3, getValidTxns_(long)=1, getValidWriteIds_(List, String)=6, flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=70, commitTxn_(CommitTxnRequest)=15, getNotNullConstraints_(NotNullConstraintsRequest)=3, openTxn_(String, TxnType)=3}
2024-04-23T21:27:16,729  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091); Time taken: 2.894 seconds
2024-04-23T21:27:16,730  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091
2024-04-23T21:27:16,730  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091
2024-04-23T21:27:16,762  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091 LockResponse(lockid:7, state:ACQUIRED)
2024-04-23T21:27:16,762  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-23T21:27:16,766  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091): insert into acidTbl values(1,2),(4,5)
2024-04-23T21:27:16,766  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091
2024-04-23T21:27:16,767  INFO [main] ql.Driver: Query ID = alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091
Total jobs = 1
2024-04-23T21:27:16,767  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-23T21:27:16,767  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-23T21:27:16,943  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-23T21:27:16,944  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-23T21:27:16,944  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-23T21:27:16,944  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-23T21:27:16,944  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-23T21:27:16,944  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-23T21:27:16,944  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-23T21:27:16,944  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-23T21:27:16,953  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-23T21:27:16,956  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-23T21:27:16,956  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1/dummy_path
2024-04-23T21:27:17,047  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-23T21:27:17,070  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,28KB
2024-04-23T21:27:17,077  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-23T21:27:17,083  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,91KB
2024-04-23T21:27:17,209  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-23T21:27:17,223  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-23T21:27:17,238  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-23T21:27:17,239  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-23T21:27:17,253  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1/-mr-10000
2024-04-23T21:27:17,267  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:17,316  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-23T21:27:17,324  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-23T21:27:17,330  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-23T21:27:17,330  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-23T21:27:17,330  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1/dummy_path
2024-04-23T21:27:17,330  INFO [main] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-23T21:27:17,334  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-23T21:27:17,364  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-23T21:27:17,441  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1469549705_0001
2024-04-23T21:27:17,441  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-23T21:27:17,585  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-23T21:27:17,586  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-23T21:27:17,587  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-23T21:27:17,589  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-23T21:27:17,602  INFO [Thread-72] mapred.LocalJobRunner: Waiting for map tasks
2024-04-23T21:27:17,605  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1469549705_0001_m_000000_0
2024-04-23T21:27:17,640  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-23T21:27:17,647  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1/dummy_path/null:0+1
2024-04-23T21:27:17,653  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-23T21:27:17,678  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,28KB
2024-04-23T21:27:17,686  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-23T21:27:17,700  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-23T21:27:17,700  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-23T21:27:17,700  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-23T21:27:17,700  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-23T21:27:17,700  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-23T21:27:17,702  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-23T21:27:17,707  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-23T21:27:17,709  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-23T21:27:17,712  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-23T21:27:17,712  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-23T21:27:17,714  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-23T21:27:17,715  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-23T21:27:17,715  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-23T21:27:17,715  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int>
2024-04-23T21:27:17,716  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[4]
2024-04-23T21:27:17,716  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-23T21:27:17,735  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [reducesinkkey0] num distributions: 1
2024-04-23T21:27:17,736  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: records written - 1
2024-04-23T21:27:17,736  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-23T21:27:17,737  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-23T21:27:17,737  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-23T21:27:17,737  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:17,737  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-23T21:27:17,737  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_OPERATOR_UDTF_2:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_3:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[4]
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: Total records written - 2. abort - false
2024-04-23T21:27:17,738  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:2, RECORDS_OUT_OPERATOR_RS_4:2, 
2024-04-23T21:27:17,743  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-23T21:27:17,743  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-23T21:27:17,743  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-23T21:27:17,743  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 32; bufvoid = 104857600
2024-04-23T21:27:17,743  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-23T21:27:17,759  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-23T21:27:17,770  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1469549705_0001_m_000000_0 is done. And is in the process of committing
2024-04-23T21:27:17,771  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-23T21:27:17,772  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1469549705_0001_m_000000_0' done.
2024-04-23T21:27:17,773  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1469549705_0001_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=5737
		FILE: Number of bytes written=1188104
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=32
		Map output materialized bytes=48
		Input split bytes=361
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=977797120
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_4=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5332
2024-04-23T21:27:17,773  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1469549705_0001_m_000000_0
2024-04-23T21:27:17,774  INFO [Thread-72] mapred.LocalJobRunner: map task executor complete.
2024-04-23T21:27:17,778  INFO [Thread-72] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-23T21:27:17,779  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1469549705_0001_r_000000_0
2024-04-23T21:27:17,785  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-23T21:27:17,788  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2cb6c5bb
2024-04-23T21:27:17,789  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:17,804  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-23T21:27:17,806  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1469549705_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-23T21:27:17,833  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469549705_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-23T21:27:17,835  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1469549705_0001_m_000000_0
2024-04-23T21:27:17,837  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-23T21:27:17,838  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-23T21:27:17,838  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:17,838  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-23T21:27:17,849  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:17,849  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-23T21:27:17,852  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-23T21:27:17,853  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-23T21:27:17,853  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-23T21:27:17,853  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:17,854  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-23T21:27:17,854  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:17,857  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-23T21:27:17,861  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-23T21:27:17,863  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-23T21:27:17,863  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-23T21:27:17,864  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-23T21:27:17,864  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-23T21:27:17,865  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@637d340f, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1469549705_0001/job_local1469549705_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@12ba1819
2024-04-23T21:27:17,869  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-23T21:27:17,869  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_5:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:17,869  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-23T21:27:17,869  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 0
2024-04-23T21:27:17,870  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:17,870  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:17,870  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse
2024-04-23T21:27:17,897  INFO [pool-8-thread-1] exec.FileSinkOperator: RECORDS_OUT_INTERMEDIATE:0, TOTAL_TABLE_ROWS_WRITTEN:0, RECORDS_OUT_1_default.acidtbl:0, RECORDS_OUT_OPERATOR_FS_6:0, 
2024-04-23T21:27:17,898  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1469549705_0001_r_000000_0 is done. And is in the process of committing
2024-04-23T21:27:17,899  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-23T21:27:17,899  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1469549705_0001_r_000000_0' done.
2024-04-23T21:27:17,900  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1469549705_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=11820
		FILE: Number of bytes written=1188163
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=977797120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-23T21:27:17,900  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1469549705_0001_r_000000_0
2024-04-23T21:27:17,900  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1469549705_0001_r_000001_0
2024-04-23T21:27:17,901  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-23T21:27:17,901  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e111022
2024-04-23T21:27:17,902  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:17,903  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-23T21:27:17,904  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1469549705_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-23T21:27:17,907  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1469549705_0001_m_000000_0 decomp: 38 len: 42 to MEMORY
2024-04-23T21:27:17,908  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 38 bytes from map-output for attempt_local1469549705_0001_m_000000_0
2024-04-23T21:27:17,908  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->38
2024-04-23T21:27:17,909  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-23T21:27:17,909  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:17,909  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-23T21:27:17,916  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:17,916  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-23T21:27:17,919  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 38 bytes to disk to satisfy reduce memory limit
2024-04-23T21:27:17,919  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 42 bytes from disk
2024-04-23T21:27:17,919  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-23T21:27:17,919  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:17,919  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-23T21:27:17,920  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:17,921  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-23T21:27:17,922  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-23T21:27:17,924  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-23T21:27:17,924  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-23T21:27:17,924  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-23T21:27:17,924  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-23T21:27:17,924  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@637d340f, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1469549705_0001/job_local1469549705_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@3dd93e76
2024-04-23T21:27:17,926  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:17,926  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:17,926  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse
2024-04-23T21:27:17,927  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-23T21:27:17,942  INFO [pool-8-thread-1] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-23T21:27:17,946  INFO [pool-8-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-23T21:27:17,995  INFO [pool-8-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-23T21:27:18,009  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-23T21:27:18,010  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_5:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:18,010  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-23T21:27:18,010  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-23T21:27:18,047  INFO [pool-8-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-23T21:27:18,061  INFO [pool-8-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.acidtbl:2, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_FS_6:2, TOTAL_TABLE_ROWS_WRITTEN:2, 
2024-04-23T21:27:18,062  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1469549705_0001_r_000001_0 is done. And is in the process of committing
2024-04-23T21:27:18,063  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-23T21:27:18,063  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1469549705_0001_r_000001_0' done.
2024-04-23T21:27:18,063  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1469549705_0001_r_000001_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=17933
		FILE: Number of bytes written=1189248
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=42
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=977797120
	HIVE
		CREATED_FILES=1
		RECORDS_OUT_1_default.acidtbl=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_5=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-23T21:27:18,063  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1469549705_0001_r_000001_0
2024-04-23T21:27:18,063  INFO [Thread-72] mapred.LocalJobRunner: reduce task executor complete.
2024-04-23 21:27:18,602 Stage-1 map = 100%,  reduce = 100%
2024-04-23T21:27:18,602  INFO [main] exec.Task: 2024-04-23 21:27:18,602 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1469549705_0001
2024-04-23T21:27:18,606  INFO [main] exec.Task: Ended Job = job_local1469549705_0001
2024-04-23T21:27:18,608  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with attemptId 0.
2024-04-23T21:27:18,608  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest
2024-04-23T21:27:18,609  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000
2024-04-23T21:27:18,612  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtbl
2024-04-23T21:27:18,613  INFO [main] exec.Task: Loading data to table default.acidtbl from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:18,613  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,625  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,637  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,638  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-23T21:27:18,697  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-23T21:27:18,697  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,708  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,709  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-23T21:27:18,709  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1/-mr-10000
2024-04-23T21:27:18,713  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,724  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,739  WARN [main] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-23T21:27:18,740  INFO [main] FileOperations: Read stats for default.acidtbl/, numRows, true, 2, false: 
2024-04-23T21:27:18,740  INFO [main] FileOperations: Read stats for default.acidtbl/, rawDataSize, true, 0, false: 
2024-04-23T21:27:18,741  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-23T21:27:18,776  INFO [main] FileOperations: Read stats for default.acidtbl/, insertCount, true, 2, false: 
2024-04-23T21:27:18,776  INFO [main] FileOperations: Read stats for default.acidtbl/, updateCount, true, 0, false: 
2024-04-23T21:27:18,776  INFO [main] FileOperations: Read stats for default.acidtbl/, deleteCount, true, 0, false: 
2024-04-23T21:27:18,779  INFO [main] stats.BasicStatsTask: Table default.acidtbl stats: [numFiles=1, numRows=2, totalSize=699, rawDataSize=0, numFilesErasureCoded=0]
2024-04-23T21:27:18,780  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:18,780  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=45, alter_table_(String, String, String, Table, EnvironmentContext, String)=92, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=3}
MapReduce Jobs Launched: 
2024-04-23T21:27:18,780  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-23T21:27:18,787  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-23T21:27:18,787  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-23T21:27:18,787  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091); Time taken: 2.014 seconds
2024-04-23T21:27:18,787  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212713_747d2e49-c159-432b-96f0-0a83677f9091
2024-04-23T21:27:18,800  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:18,802  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-23T21:27:18,803  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTbl set b = 4
2024-04-23T21:27:18,803  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1
2024-04-23T21:27:18,804  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/eea6eed9-86b5-4beb-967b-344e353af9ee/hive_2024-04-23_21-27-13_834_3511197350406459202-1 on fs with scheme file
2024-04-23T21:27:18,804  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212718_9f25f598-6740-4b15-a1fe-7ebd0b33b318): update acidTbl set b = 4
2024-04-23T21:27:18,818  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-23T21:27:18,818  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-23T21:27:18,821  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-23T21:27:18,822  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:18,833  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,834  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTbl set b = 4> as 
<insert into table `default`.`acidTbl` select ROW__ID,`a`,`b` from `default`.`acidTbl` sort by ROW__ID >
2024-04-23T21:27:18,836  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-23T21:27:18,841  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:18,853  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,853  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-23T21:27:18,853  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-23T21:27:18,854  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,865  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,865  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-23T21:27:18,865  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-23T21:27:18,865  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:18,877  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:18,877  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-23T21:27:18,877  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-23T21:27:18,893  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,904  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-23T21:27:18,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-23T21:27:19,051  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtbl, projIndxSet: [0], allowMissingStats: true
2024-04-23T21:27:19,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:19,074  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,075  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-23T21:27:19,090  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,091  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.acidtbl	
2024-04-23T21:27:19,112  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtbl, Columns: a
No Stats for default@acidtbl, Columns: a
2024-04-23T21:27:19,112  INFO [main] SessionState: No Stats for default@acidtbl, Columns: a
2024-04-23T21:27:19,182  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-23T21:27:19,182  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-23T21:27:19,182  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-23T21:27:19,182  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:19,195  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,205 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-23T21:27:19,206 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-23T21:27:19,206  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-23T21:27:19,208 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:27:19,208  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:19,209  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTableColumnStatistics_(String, String, List, String)=52, isCompatibleWith_(Configuration)=0, flushCache_()=0, commitTxn_(CommitTxnRequest)=15, getNotNullConstraints_(NotNullConstraintsRequest)=2, getTable_(GetTableRequest)=59, getAllTableConstraints_(AllTableConstraintsRequest)=8, getValidTxns_(long)=3, getCheckConstraints_(CheckConstraintsRequest)=1, openTxn_(String, TxnType)=12, getValidWriteIds_(List, String)=8}
2024-04-23T21:27:19,209  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212718_9f25f598-6740-4b15-a1fe-7ebd0b33b318); Time taken: 0.404 seconds
2024-04-23T21:27:19,209  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-23T21:27:19,214  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:19,225  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-23T21:27:19,226  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691): drop table if exists acidTbl
2024-04-23T21:27:19,230  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-23T21:27:19,230  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-23T21:27:19,232  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:19,245  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,245  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:19,246  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:19,246  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:19,246  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, rollbackTxn_(long)=15, flushCache_()=0, openTxn_(String, TxnType)=3, getTable_(GetTableRequest)=13, getValidTxns_(long)=1}
2024-04-23T21:27:19,246  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691); Time taken: 0.02 seconds
2024-04-23T21:27:19,247  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691
2024-04-23T21:27:19,247  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691
2024-04-23T21:27:19,280  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691 LockResponse(lockid:8, state:ACQUIRED)
2024-04-23T21:27:19,280  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:19,280  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691): drop table if exists acidTbl
2024-04-23T21:27:19,280  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:19,281  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:19,295  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,296  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:19,311  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,312  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:19,559  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:19,559  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=262, getTable_(GetTableRequest)=15}
2024-04-23T21:27:19,560  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691); Time taken: 0.279 seconds
2024-04-23T21:27:19,560  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212719_60c65776-f41e-4ba9-8bf0-63e7a3c79691
2024-04-23T21:27:19,566  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-23T21:27:19,576  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:19,576  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-23T21:27:19,578  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-23T21:27:19,578  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565): drop table if exists acidTblPart
2024-04-23T21:27:19,584  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-23T21:27:19,584  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-23T21:27:19,587  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:19,632  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,632  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:19,632  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:19,633  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:19,633  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=5, getTable_(GetTableRequest)=45, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=17, getValidTxns_(long)=2, flushCache_()=1}
2024-04-23T21:27:19,633  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565); Time taken: 0.054 seconds
2024-04-23T21:27:19,633  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565
2024-04-23T21:27:19,634  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565
2024-04-23T21:27:19,669  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565 LockResponse(lockid:9, state:ACQUIRED)
2024-04-23T21:27:19,670  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:19,670  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565): drop table if exists acidTblPart
2024-04-23T21:27:19,670  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:19,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:19,684  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:19,702  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,702  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:19,793  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:19,794  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=109, getTable_(GetTableRequest)=14, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:19,794  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565); Time taken: 0.123 seconds
2024-04-23T21:27:19,794  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212719_07a5fee5-a23a-42e5-8ec2-0d36f7a12565
2024-04-23T21:27:19,801  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-23T21:27:19,808  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:19,808  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-23T21:27:19,809  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-23T21:27:19,810  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b): drop table if exists acidTbl2
2024-04-23T21:27:19,814  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-23T21:27:19,814  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-23T21:27:19,816  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:19,816  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:19,816  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:19,817  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=15, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, getTable_(GetTableRequest)=0, isCompatibleWith_(Configuration)=1, flushCache_()=0}
2024-04-23T21:27:19,817  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b); Time taken: 0.006 seconds
2024-04-23T21:27:19,817  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b
2024-04-23T21:27:19,817  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:19,817  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b): drop table if exists acidTbl2
2024-04-23T21:27:19,817  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:19,818  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-23T21:27:19,819  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:19,819  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=0, dropTable_(String, String, boolean, boolean, boolean)=0, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:19,819  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b); Time taken: 0.002 seconds
2024-04-23T21:27:19,819  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212719_2acc1286-edf8-4754-8ebb-fc8ff5eaaf1b
2024-04-23T21:27:19,826  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-23T21:27:19,835  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:19,835  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-23T21:27:19,836  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-23T21:27:19,836  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:19,841  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 15
2024-04-23T21:27:19,841  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-23T21:27:19,843  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:19,878  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,879  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:19,879  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:19,879  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:19,879  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=1, openTxn_(String, TxnType)=4, getTable_(GetTableRequest)=36, commitTxn_(CommitTxnRequest)=16, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1}
2024-04-23T21:27:19,880  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705); Time taken: 0.043 seconds
2024-04-23T21:27:19,880  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705
2024-04-23T21:27:19,881  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705
2024-04-23T21:27:19,906  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705 LockResponse(lockid:10, state:ACQUIRED)
2024-04-23T21:27:19,906  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:19,906  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:19,906  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:19,907  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:19,922  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,922  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:19,936  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:19,936  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:20,001  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,001  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=15, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=79}
2024-04-23T21:27:20,001  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705); Time taken: 0.095 seconds
2024-04-23T21:27:20,002  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212719_6ffc6837-3892-43d8-a8fb-b2a03f37a705
2024-04-23T21:27:20,007  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-23T21:27:20,015  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,015  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-23T21:27:20,016  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,017  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,020  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-23T21:27:20,021  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-23T21:27:20,022  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,037  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,037  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,037  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,037  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,037  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=15, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=14, flushCache_()=0, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:20,038  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674); Time taken: 0.02 seconds
2024-04-23T21:27:20,038  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674
2024-04-23T21:27:20,039  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674
2024-04-23T21:27:20,060  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674 LockResponse(lockid:11, state:ACQUIRED)
2024-04-23T21:27:20,060  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:20,060  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,060  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,060  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,075  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,075  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,091  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,092  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,152  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,152  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=15, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=76}
2024-04-23T21:27:20,152  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674); Time taken: 0.091 seconds
2024-04-23T21:27:20,152  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_9ebcb93f-0a5c-42b6-8307-34fec4e3b674
2024-04-23T21:27:20,159  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-23T21:27:20,168  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,168  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-23T21:27:20,169  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,170  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59): drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,174  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-23T21:27:20,174  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-23T21:27:20,175  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,192  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,192  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,192  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,192  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,193  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, isCompatibleWith_(Configuration)=2, commitTxn_(CommitTxnRequest)=16, getTable_(GetTableRequest)=17, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-23T21:27:20,193  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59); Time taken: 0.022 seconds
2024-04-23T21:27:20,193  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59
2024-04-23T21:27:20,194  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59
2024-04-23T21:27:20,219  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59 LockResponse(lockid:12, state:ACQUIRED)
2024-04-23T21:27:20,219  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:20,219  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59): drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,220  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,220  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,241  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,242  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,262  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:20,262  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,318  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,318  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=22, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=76}
2024-04-23T21:27:20,318  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59); Time taken: 0.099 seconds
2024-04-23T21:27:20,319  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_846a071d-1e93-4234-b8d4-570e138d0a59
2024-04-23T21:27:20,323  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-23T21:27:20,333  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,333  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-23T21:27:20,335  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenatePart" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="4.263">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTblPart set b = 4 where p='p1' failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:27:20,434  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:27:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:27:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:27:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:27:20,435  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:27:20,437  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
Hive Session ID = bfd7de85-9242-400f-9518-754382913d0f
2024-04-23T21:27:20,440  INFO [main] SessionState: Hive Session ID = bfd7de85-9242-400f-9518-754382913d0f
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:27:20,440  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:27:20,446  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/bfd7de85-9242-400f-9518-754382913d0f
2024-04-23T21:27:20,449  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f
2024-04-23T21:27:20,451  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/bfd7de85-9242-400f-9518-754382913d0f/_tmp_space.db
2024-04-23T21:27:20,452  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=bfd7de85-9242-400f-9518-754382913d0f, clientType=HIVECLI]
2024-04-23T21:27:20,452  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-23T21:27:20,453  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91): drop table if exists acidTbl
2024-04-23T21:27:20,465  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-23T21:27:20,465  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-23T21:27:20,468  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:20,472  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,472  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,472  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,473  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=12, flushCache_()=0, getValidTxns_(long)=2, isCompatibleWith_(Configuration)=1, commitTxn_(CommitTxnRequest)=15}
2024-04-23T21:27:20,473  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91); Time taken: 0.019 seconds
2024-04-23T21:27:20,473  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91
2024-04-23T21:27:20,473  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,473  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91): drop table if exists acidTbl
2024-04-23T21:27:20,473  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,474  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:20,478  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,478  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:20,479  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91); Time taken: 0.005 seconds
2024-04-23T21:27:20,479  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_395b67f2-95bb-473a-a269-77504b53fe91
2024-04-23T21:27:20,485  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-23T21:27:20,492  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,492  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-23T21:27:20,493  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-23T21:27:20,494  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03): drop table if exists acidTblPart
2024-04-23T21:27:20,498  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-23T21:27:20,499  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-23T21:27:20,500  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:20,505  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,506  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,506  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,506  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=14, flushCache_()=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:20,506  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03); Time taken: 0.012 seconds
2024-04-23T21:27:20,507  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03
2024-04-23T21:27:20,507  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,507  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03): drop table if exists acidTblPart
2024-04-23T21:27:20,507  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,508  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:20,513  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,513  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,513  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03); Time taken: 0.006 seconds
2024-04-23T21:27:20,514  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_e4638976-0462-4bc4-882c-b62344ec5a03
2024-04-23T21:27:20,521  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-23T21:27:20,530  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,530  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-23T21:27:20,531  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-23T21:27:20,532  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff): drop table if exists acidTbl2
2024-04-23T21:27:20,535  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-23T21:27:20,536  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-23T21:27:20,537  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-23T21:27:20,543  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,544  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,544  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,544  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=17, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, flushCache_()=0, openTxn_(String, TxnType)=4}
2024-04-23T21:27:20,544  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff); Time taken: 0.013 seconds
2024-04-23T21:27:20,545  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff
2024-04-23T21:27:20,545  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,545  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff): drop table if exists acidTbl2
2024-04-23T21:27:20,545  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,546  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-23T21:27:20,550  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,550  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,550  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff); Time taken: 0.005 seconds
2024-04-23T21:27:20,550  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_f758ad6b-b59f-4ff1-920e-4ab109488aff
2024-04-23T21:27:20,557  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-23T21:27:20,565  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,565  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-23T21:27:20,566  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-23T21:27:20,566  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:20,570  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-23T21:27:20,570  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-23T21:27:20,571  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:20,576  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,576  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,576  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,576  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getValidTxns_(long)=0, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=1, commitTxn_(CommitTxnRequest)=16}
2024-04-23T21:27:20,577  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e); Time taken: 0.01 seconds
2024-04-23T21:27:20,577  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e
2024-04-23T21:27:20,577  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,577  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:20,577  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:20,584  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,584  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,584  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e); Time taken: 0.007 seconds
2024-04-23T21:27:20,585  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_c2e3d85c-7614-4444-9da5-f99545e7a87e
2024-04-23T21:27:20,594  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-23T21:27:20,608  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,608  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-23T21:27:20,609  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,610  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,613  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-23T21:27:20,614  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-23T21:27:20,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,621  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,621  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,622  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,622  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, commitTxn_(CommitTxnRequest)=24, getValidTxns_(long)=1, openTxn_(String, TxnType)=4, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,622  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2); Time taken: 0.013 seconds
2024-04-23T21:27:20,623  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2
2024-04-23T21:27:20,623  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,623  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:20,623  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,623  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:20,629  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,630  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,630  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2); Time taken: 0.006 seconds
2024-04-23T21:27:20,630  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_e7d7874d-2d8d-4d39-8492-ada5fa311ad2
2024-04-23T21:27:20,639  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-23T21:27:20,650  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,650  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-23T21:27:20,651  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,653  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192): drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,657  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-23T21:27:20,658  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-23T21:27:20,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,666  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,666  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,666  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,667  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=4, getValidTxns_(long)=1, flushCache_()=0, commitTxn_(CommitTxnRequest)=21}
2024-04-23T21:27:20,667  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192); Time taken: 0.013 seconds
2024-04-23T21:27:20,667  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192
2024-04-23T21:27:20,667  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:20,668  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192): drop table if exists nonAcidNonBucket
2024-04-23T21:27:20,668  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,668  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:20,674  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,674  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,674  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192); Time taken: 0.006 seconds
2024-04-23T21:27:20,674  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_a3e0abf3-68f4-4570-b47b-141ef5779192
2024-04-23T21:27:20,684  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-23T21:27:20,694  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,695  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-23T21:27:20,696  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,697  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,702  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-23T21:27:20,703  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-23T21:27:20,704  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:20,704  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:20,715  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-23T21:27:20,715  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:20,719  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:20,719  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,719  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,719  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,720  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=4, commitTxn_(CommitTxnRequest)=20, getValidWriteIds_(List, String)=11, flushCache_()=0, openTxn_(String, TxnType)=4, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:20,720  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f); Time taken: 0.023 seconds
2024-04-23T21:27:20,720  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f
2024-04-23T21:27:20,721  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f
2024-04-23T21:27:20,759  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f LockResponse(lockid:1, state:ACQUIRED)
2024-04-23T21:27:20,759  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:20,760  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,761  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,762  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713932840, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=true, rawDataSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFiles=0, numRows=0, totalSize=0, bucketing_version=2, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-23T21:27:20,771  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtbl
2024-04-23T21:27:20,825  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,826  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=63, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:20,826  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f); Time taken: 0.065 seconds
2024-04-23T21:27:20,826  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_73a73539-bee8-4096-b0bc-97d584157e9f
2024-04-23T21:27:20,830  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-23T21:27:20,838  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,840  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-23T21:27:20,841  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,841  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,845  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-23T21:27:20,845  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-23T21:27:20,846  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:20,846  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:20,849  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-23T21:27:20,849  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:20,852  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:20,852  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,852  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,852  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,853  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=0, commitTxn_(CommitTxnRequest)=15, flushCache_()=0, openTxn_(String, TxnType)=2, getValidWriteIds_(List, String)=3, getDatabase_(String)=3, isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:20,853  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5); Time taken: 0.011 seconds
2024-04-23T21:27:20,853  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5
2024-04-23T21:27:20,854  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5
2024-04-23T21:27:20,873  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5 LockResponse(lockid:2, state:ACQUIRED)
2024-04-23T21:27:20,873  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:20,874  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:20,874  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,875  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713932840, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{transactional=true, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-23T21:27:20,883  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart
2024-04-23T21:27:20,905  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,905  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=30}
2024-04-23T21:27:20,906  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5); Time taken: 0.031 seconds
2024-04-23T21:27:20,906  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_35a53561-b7b8-48a9-95ee-a2deae8859e5
2024-04-23T21:27:20,911  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-23T21:27:20,917  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,918  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-23T21:27:20,918  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:20,919  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:20,922  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 1
2024-04-23T21:27:20,922  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-23T21:27:20,923  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:20,923  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:20,926  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-23T21:27:20,926  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:20,928  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:20,928  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:20,928  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:20,928  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:20,928  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, flushCache_()=0, getValidWriteIds_(List, String)=3, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, getDatabase_(String)=2, commitTxn_(CommitTxnRequest)=12}
2024-04-23T21:27:20,929  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37); Time taken: 0.009 seconds
2024-04-23T21:27:20,929  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37
2024-04-23T21:27:20,929  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37
2024-04-23T21:27:20,947  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37 LockResponse(lockid:3, state:ACQUIRED)
2024-04-23T21:27:20,947  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:20,947  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:20,947  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:20,948  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713932840, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFilesErasureCoded=0, bucketing_version=2, totalSize=0, rawDataSize=0, numRows=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:20,956  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidorctbl
2024-04-23T21:27:20,979  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:20,979  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=31}
2024-04-23T21:27:20,980  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37); Time taken: 0.032 seconds
2024-04-23T21:27:20,980  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_0f50818b-22ba-4f19-b7ba-ab981a244c37
2024-04-23T21:27:20,985  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-23T21:27:20,992  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:20,992  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-23T21:27:20,993  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:20,993  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:20,996  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 1
2024-04-23T21:27:20,997  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-23T21:27:20,997  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:20,997  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:21,000  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-23T21:27:21,001  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:21,003  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:21,003  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:21,003  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:21,003  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:21,003  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=12, isCompatibleWith_(Configuration)=0, flushCache_()=0, getValidTxns_(long)=0, getDatabase_(String)=3, getValidWriteIds_(List, String)=2, openTxn_(String, TxnType)=3}
2024-04-23T21:27:21,003  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e); Time taken: 0.01 seconds
2024-04-23T21:27:21,004  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e
2024-04-23T21:27:21,004  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e
2024-04-23T21:27:21,022  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e LockResponse(lockid:4, state:ACQUIRED)
2024-04-23T21:27:21,022  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:21,023  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:21,023  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:21,024  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713932841, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=false, rawDataSize=0, numFiles=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, bucketing_version=2, numRows=0, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:21,031  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidorctbl2
2024-04-23T21:27:21,053  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:21,053  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=29}
2024-04-23T21:27:21,054  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e); Time taken: 0.03 seconds
2024-04-23T21:27:21,054  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212720_e7622d3b-ea34-4863-841c-2fbc5599d77e
2024-04-23T21:27:21,059  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-23T21:27:21,067  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:21,067  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-23T21:27:21,068  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:21,068  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:21,071  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 1
2024-04-23T21:27:21,072  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-23T21:27:21,073  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:21,073  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:21,076  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-23T21:27:21,077  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:21,079  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:21,079  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:21,079  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:21,079  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:21,079  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, openTxn_(String, TxnType)=3, getDatabase_(String)=3, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=13, getValidTxns_(long)=1, getValidWriteIds_(List, String)=3}
2024-04-23T21:27:21,079  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94); Time taken: 0.011 seconds
2024-04-23T21:27:21,080  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94
2024-04-23T21:27:21,080  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94
2024-04-23T21:27:21,099  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94 LockResponse(lockid:5, state:ACQUIRED)
2024-04-23T21:27:21,099  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:21,100  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-23T21:27:21,100  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:21,102  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/bfd7de85-9242-400f-9518-754382913d0f/_tmp_space.db/39ae7a0d-ae09-4042-b09f-bf8be9c231b8
2024-04-23T21:27:21,105  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:21,105  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=4, isCompatibleWith_(Configuration)=1}
2024-04-23T21:27:21,106  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94); Time taken: 0.005 seconds
2024-04-23T21:27:21,106  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212721_c49be080-7ecc-4b6b-a21f-7a7638924c94
2024-04-23T21:27:21,110  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-23T21:27:21,117  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:21,118  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-23T21:27:21,118  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:21,119  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:21,122  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 1
2024-04-23T21:27:21,123  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-23T21:27:21,124  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:21,124  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:21,126  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-23T21:27:21,127  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:27:21,129  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:21,129  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:21,129  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:21,129  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:21,129  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, commitTxn_(CommitTxnRequest)=12, getDatabase_(String)=2, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, getValidWriteIds_(List, String)=2, openTxn_(String, TxnType)=3}
2024-04-23T21:27:21,130  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2); Time taken: 0.01 seconds
2024-04-23T21:27:21,130  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2
2024-04-23T21:27:21,130  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2
2024-04-23T21:27:21,149  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2 LockResponse(lockid:6, state:ACQUIRED)
2024-04-23T21:27:21,149  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-23T21:27:21,149  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-23T21:27:21,149  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:21,150  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713932841, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, numFilesErasureCoded=0, transactional=false, numRows=0, rawDataSize=0, totalSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-23T21:27:21,158  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/nonacidnonbucket
2024-04-23T21:27:21,184  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:21,184  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=33}
2024-04-23T21:27:21,184  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2); Time taken: 0.035 seconds
2024-04-23T21:27:21,184  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212721_b11175fe-c151-408d-a2d6-89828a729de2
2024-04-23T21:27:21,191  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-23T21:27:21,200  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:21,200  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-23T21:27:21,201  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-23T21:27:21,202  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-23T21:27:21,205  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 1
2024-04-23T21:27:21,206  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-23T21:27:21,207  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-23T21:27:21,207  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:27:21,211  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:21,241  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:21,241  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-23T21:27:21,241  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:21,241  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:21,241  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:21,241  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:21,252  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:21,253  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-23T21:27:21,253  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-23T21:27:21,277  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-23T21:27:21,390  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:21,390  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:21,390  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-23T21:27:21,391  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-23T21:27:21,394  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-23T21:27:21,394  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:21,394  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-23T21:27:21,394  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:21,405  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:21,410  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-23T21:27:21,412  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-23T21:27:21,423  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-23T21:27:21,423  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtblpart (txnIds: [13])
2024-04-23T21:27:21,425  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-23T21:27:21,432  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {VALUE._col1=Column[_col2], VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-23T21:27:21,432  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {VALUE._col1=Column[_col2], KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-23T21:27:21,434  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-23T21:27:21,435  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-23T21:27:21,436  INFO [main] optimizer.SortedDynPartitionOptimizer: Removed RS_4 and SEL_5 as it was introduced by enforce bucketing/sorting.
2024-04-23T21:27:21,437  INFO [main] optimizer.SortedDynPartitionOptimizer: Inserted RS_7 and SEL_8 as parent of FS_6 and child of SEL_3
2024-04-23T21:27:21,452  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:21,465  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-23T21:27:21,466  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-23T21:27:21,466  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-23T21:27:21,466  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-23T21:27:21,466  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:21,466  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null), FieldSchema(name:col3, type:string, comment:null)], properties:null)
2024-04-23T21:27:21,466  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:21,466  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getMetaConf_(String)=0, flushCache_()=0, getAllTableConstraints_(AllTableConstraintsRequest)=47, getValidTxns_(long)=1, getTable_(GetTableRequest)=68, getValidWriteIds_(List, String)=4, isCompatibleWith_(Configuration)=0, getCheckConstraints_(CheckConstraintsRequest)=1, getNotNullConstraints_(NotNullConstraintsRequest)=2, openTxn_(String, TxnType)=3, allocateTableWriteId_(long, String, String)=10, commitTxn_(CommitTxnRequest)=16}
2024-04-23T21:27:21,467  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe); Time taken: 0.264 seconds
2024-04-23T21:27:21,467  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe
2024-04-23T21:27:21,467  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe
2024-04-23T21:27:21,498  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe LockResponse(lockid:7, state:ACQUIRED)
2024-04-23T21:27:21,498  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-23T21:27:21,502  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-23T21:27:21,503  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe
2024-04-23T21:27:21,503  INFO [main] ql.Driver: Query ID = alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe
Total jobs = 1
2024-04-23T21:27:21,503  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-23T21:27:21,503  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-23T21:27:21,658  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
2024-04-23T21:27:21,658  INFO [main] exec.Utilities: Not using thread pool for getContentSummary
2024-04-23T21:27:21,665  INFO [main] exec.Utilities: BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=1
Number of reduce tasks not specified. Estimated from input data size: 1
2024-04-23T21:27:21,665  INFO [main] exec.Task: Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
2024-04-23T21:27:21,665  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-23T21:27:21,665  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-23T21:27:21,665  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-23T21:27:21,665  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-23T21:27:21,665  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-23T21:27:21,665  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-23T21:27:21,668  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-23T21:27:21,668  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-23T21:27:21,668  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1/dummy_path
2024-04-23T21:27:21,678  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-23T21:27:21,682  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,61KB
2024-04-23T21:27:21,688  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-23T21:27:21,699  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 6,40KB
2024-04-23T21:27:21,700  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:21,704  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1/-mr-10000
2024-04-23T21:27:21,707  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:21,715  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-23T21:27:21,720  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-23T21:27:21,722  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-23T21:27:21,722  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-23T21:27:21,722  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1/dummy_path
2024-04-23T21:27:21,723  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-23T21:27:21,742  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-23T21:27:21,766  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local739999615_0002
2024-04-23T21:27:21,766  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-23T21:27:21,842  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-23T21:27:21,842  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-23T21:27:21,842  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-23T21:27:21,843  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-23T21:27:21,845  INFO [Thread-173] mapred.LocalJobRunner: Waiting for map tasks
2024-04-23T21:27:21,845  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local739999615_0002_m_000000_0
2024-04-23T21:27:21,848  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-23T21:27:21,849  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1/dummy_path/null:0+1
2024-04-23T21:27:21,852  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-23T21:27:21,854  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,61KB
2024-04-23T21:27:21,854  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 1
2024-04-23T21:27:21,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-23T21:27:21,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-23T21:27:21,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-23T21:27:21,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-23T21:27:21,860  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-23T21:27:21,861  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-23T21:27:21,861  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-23T21:27:21,861  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-23T21:27:21,862  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-23T21:27:21,862  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int,col3:string>
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[7]
2024-04-23T21:27:21,863  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-23T21:27:21,865  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [_col2, _bucket_number, _col0] num distributions: 3
2024-04-23T21:27:21,865  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: records written - 1
2024-04-23T21:27:21,865  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_MAP_0:0, 
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_1:1, 
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_UDTF_2:2, 
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_3:2, 
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[7]
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: Total records written - 2. abort - false
2024-04-23T21:27:21,866  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:2, RECORDS_OUT_OPERATOR_RS_7:2, 
2024-04-23T21:27:21,870  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-23T21:27:21,870  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-23T21:27:21,870  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-23T21:27:21,870  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 46; bufvoid = 104857600
2024-04-23T21:27:21,870  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-23T21:27:21,881  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-23T21:27:21,887  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local739999615_0002_m_000000_0 is done. And is in the process of committing
2024-04-23T21:27:21,888  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-23T21:27:21,888  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local739999615_0002_m_000000_0' done.
2024-04-23T21:27:21,888  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local739999615_0002_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=24384
		FILE: Number of bytes written=2373450
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=46
		Map output materialized bytes=56
		Input split bytes=361
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=980418560
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_7=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5670
2024-04-23T21:27:21,888  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local739999615_0002_m_000000_0
2024-04-23T21:27:21,888  INFO [Thread-173] mapred.LocalJobRunner: map task executor complete.
2024-04-23T21:27:21,890  INFO [Thread-173] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-23T21:27:21,890  INFO [pool-13-thread-1] mapred.LocalJobRunner: Starting task: attempt_local739999615_0002_r_000000_0
2024-04-23T21:27:21,893  INFO [pool-13-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-23T21:27:21,893  INFO [pool-13-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66c0c221
2024-04-23T21:27:21,893  WARN [pool-13-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-23T21:27:21,894  INFO [pool-13-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-23T21:27:21,895  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local739999615_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-23T21:27:21,897  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local739999615_0002_m_000000_0 decomp: 52 len: 56 to MEMORY
2024-04-23T21:27:21,898  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local739999615_0002_m_000000_0
2024-04-23T21:27:21,898  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2024-04-23T21:27:21,898  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-23T21:27:21,899  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:21,899  INFO [pool-13-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-23T21:27:21,905  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:21,905  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 52 bytes to disk to satisfy reduce memory limit
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 1 files, 56 bytes from disk
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-23T21:27:21,908  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-23T21:27:21,909  INFO [pool-13-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-23T21:27:21,914  INFO [pool-13-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 6,40KB
2024-04-23T21:27:21,915  INFO [pool-13-thread-1] ExecReducer: 
<SEL>Id =8
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 8 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-23T21:27:21,915  INFO [pool-13-thread-1] exec.SelectOperator: Initializing Operator: SEL[8]
2024-04-23T21:27:21,915  INFO [pool-13-thread-1] exec.SelectOperator: SELECT struct<key:struct<_col2:string,_bucket_number:string,_col0:int>,value:struct<_col1:int>>
2024-04-23T21:27:21,915  INFO [pool-13-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-23T21:27:21,916  INFO [pool-13-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@637d340f, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local739999615_0002/job_local739999615_0002.xml], properties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@33a6d5c8
2024-04-23T21:27:21,919  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1
2024-04-23T21:27:21,919  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1
2024-04-23T21:27:21,922  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart
2024-04-23T21:27:21,923  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-23T21:27:21,924  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-23T21:27:21,933  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-23T21:27:21,942  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2
2024-04-23T21:27:21,942  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2
2024-04-23T21:27:21,945  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart
2024-04-23T21:27:21,946  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-23T21:27:21,954  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-23T21:27:21,960  INFO [pool-13-thread-1] exec.SelectOperator: Closing Operator: SEL[8]
2024-04-23T21:27:21,960  INFO [pool-13-thread-1] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_8:2, 
2024-04-23T21:27:21,960  INFO [pool-13-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-23T21:27:21,960  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-23T21:27:21,963  INFO [pool-13-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0, file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-23T21:27:21,977  INFO [pool-13-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.acidtblpart:2, RECORDS_OUT_OPERATOR_FS_6:2, TOTAL_TABLE_ROWS_WRITTEN:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-23T21:27:21,978  INFO [pool-13-thread-1] mapred.Task: Task:attempt_local739999615_0002_r_000000_0 is done. And is in the process of committing
2024-04-23T21:27:21,979  INFO [pool-13-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-23T21:27:21,979  INFO [pool-13-thread-1] mapred.Task: Task 'attempt_local739999615_0002_r_000000_0' done.
2024-04-23T21:27:21,980  INFO [pool-13-thread-1] mapred.Task: Final Counters for attempt_local739999615_0002_r_000000_0: Counters: 31
	File System Counters
		FILE: Number of bytes read=30995
		FILE: Number of bytes written=2375499
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=56
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=980418560
	HIVE
		CREATED_DYNAMIC_PARTITIONS=2
		CREATED_FILES=2
		RECORDS_OUT_1_default.acidtblpart=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_8=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-23T21:27:21,980  INFO [pool-13-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local739999615_0002_r_000000_0
2024-04-23T21:27:21,980  INFO [Thread-173] mapred.LocalJobRunner: reduce task executor complete.
2024-04-23 21:27:22,850 Stage-1 map = 100%,  reduce = 100%
2024-04-23T21:27:22,850  INFO [main] exec.Task: 2024-04-23 21:27:22,850 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local739999615_0002
2024-04-23T21:27:22,852  INFO [main] exec.Task: Ended Job = job_local739999615_0002
2024-04-23T21:27:22,854  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with attemptId 0.
2024-04-23T21:27:22,854  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest
2024-04-23T21:27:22,854  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000
2024-04-23T21:27:22,856  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtblpart partition (p=null)
2024-04-23T21:27:22,857  INFO [main] exec.Task: Loading data to table default.acidtblpart partition (p=null) from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart
2024-04-23T21:27:22,857  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:22,867  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:22,867  INFO [main] exec.MoveTask: Partition is: {p=null}


2024-04-23T21:27:22,868  INFO [main] exec.Task: 

2024-04-23T21:27:22,868  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:22,877  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:22,879  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:22,889  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:22,890  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.acidtblpart[]	
2024-04-23T21:27:22,914  INFO [load-dynamic-partitionsToAdd-0] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p1 withPartSpec {p=p1}
2024-04-23T21:27:22,914  INFO [load-dynamic-partitionsToAdd-1] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713932825077/warehouse/acidtblpart/p=p2 withPartSpec {p=p2}
2024-04-23T21:27:22,915  INFO [main] metadata.Hive: Number of partitionsToAdd to be added is 2
2024-04-23T21:27:22,919  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=add_partitions	
2024-04-23T21:27:23,015  INFO [main] metadata.Hive: Loaded 2partitionsToAdd
	 Time taken to load dynamic partitions: 0.148 seconds
2024-04-23T21:27:23,016  INFO [main] exec.Task: 	 Time taken to load dynamic partitions: 0.148 seconds
2024-04-23T21:27:23,016  INFO [main] exec.MoveTask: 	 Time taken to load dynamic partitions: 0.148 seconds
2024-04-23T21:27:23,016  INFO [main] exec.MoveTask: Loading partition {p=p1}
2024-04-23T21:27:23,016  INFO [main] exec.MoveTask: Loading partition {p=p2}
	 Time taken for adding to write entity : 0.0 seconds
2024-04-23T21:27:23,016  INFO [main] exec.Task: 	 Time taken for adding to write entity : 0.0 seconds
2024-04-23T21:27:23,016  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-23T21:27:23,017  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,027  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,027  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-23T21:27:23,027  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1/-mr-10000
2024-04-23T21:27:23,042  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,053  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,063  WARN [stats-updater-thread-0] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-23T21:27:23,063  WARN [stats-updater-thread-1] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-23T21:27:23,064  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, numRows, true, 1, false: 
2024-04-23T21:27:23,064  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, rawDataSize, true, 0, false: 
2024-04-23T21:27:23,064  INFO [main] stats.BasicStatsTask: Partition {p=p1} stats: [numFiles=1, numRows=1, totalSize=673, rawDataSize=0, numFilesErasureCoded=0]
2024-04-23T21:27:23,065  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, numRows, true, 1, false: 
2024-04-23T21:27:23,065  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, rawDataSize, true, 0, false: 
2024-04-23T21:27:23,065  INFO [main] stats.BasicStatsTask: Partition {p=p2} stats: [numFiles=1, numRows=1, totalSize=678, rawDataSize=0, numFilesErasureCoded=0]
2024-04-23T21:27:23,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_partitions : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,065  INFO [main] metastore.HMSHandler: New partition values:[p1]
2024-04-23T21:27:23,065  INFO [main] metastore.HMSHandler: New partition values:[p2]
2024-04-23T21:27:23,188  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, insertCount, true, 1, false: 
2024-04-23T21:27:23,188  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, updateCount, true, 0, false: 
2024-04-23T21:27:23,188  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, deleteCount, true, 0, false: 
2024-04-23T21:27:23,190  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, insertCount, true, 1, false: 
2024-04-23T21:27:23,191  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, updateCount, true, 0, false: 
2024-04-23T21:27:23,191  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, deleteCount, true, 0, false: 
2024-04-23T21:27:23,192  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:23,192  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=53, listPartitionNamesRequest_(GetPartitionNamesPsRequest)=21, isCompatibleWith_(Configuration)=1, addDynamicPartitions_(long, long, String, String, List, DataOperationType)=4, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=2, alter_partitions_(String, String, List, EnvironmentContext, String, long)=123, getValidWriteIds_(List, String)=2, add_partitions_(List)=93}
MapReduce Jobs Launched: 
2024-04-23T21:27:23,192  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-23T21:27:23,192  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-23T21:27:23,192  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-23T21:27:23,192  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe); Time taken: 1.69 seconds
2024-04-23T21:27:23,192  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212721_51b873ef-89fd-4653-8713-680648b7eebe
2024-04-23T21:27:23,206  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:23,208  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-23T21:27:23,209  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTblPart set b = 4 where p='p1'
2024-04-23T21:27:23,209  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1
2024-04-23T21:27:23,210  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/bfd7de85-9242-400f-9518-754382913d0f/hive_2024-04-23_21-27-21_201_1740902071092494389-1 on fs with scheme file
2024-04-23T21:27:23,210  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212723_2ac96fe8-bc3d-4d83-a937-98a94625abf7): update acidTblPart set b = 4 where p='p1'
2024-04-23T21:27:23,221  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-23T21:27:23,221  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-23T21:27:23,224  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-23T21:27:23,224  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,235  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,235  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTblPart set b = 4 where p='p1'> as 
<insert into table `default`.`acidTblPart` partition (`p`) select ROW__ID,`a`,`b`, `p` from `default`.`acidTblPart` sort by ROW__ID >
2024-04-23T21:27:23,236  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-23T21:27:23,240  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,250  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,251  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-23T21:27:23,251  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-23T21:27:23,252  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,263  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,264  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-23T21:27:23,264  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-23T21:27:23,264  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,274  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,274  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-23T21:27:23,274  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-23T21:27:23,274  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-23T21:27:23,289  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,302  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,304  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,392  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,403  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,404  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,415  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,415  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_spec_by_expr : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,483  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtblpart, projIndxSet: [0, 2], allowMissingStats: true
2024-04-23T21:27:23,484  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-23T21:27:23,498  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,498  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_aggr_stats_for: table=hive.default.acidtblpart	
2024-04-23T21:27:23,524  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtblpart, Columns: a
No Stats for default@acidtblpart, Columns: a
2024-04-23T21:27:23,524  INFO [main] SessionState: No Stats for default@acidtblpart, Columns: a
2024-04-23T21:27:23,612  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-23T21:27:23,613  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-23T21:27:23,613  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-23T21:27:23,613  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,624  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,625  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-23T21:27:23,631 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-23T21:27:23,632 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-23T21:27:23,632  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-23T21:27:23,633 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<rowid:int,writeid:bigint,bucketid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:27:23,633  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:23,633  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=57, flushCache_()=0, isCompatibleWith_(Configuration)=0, getAllTableConstraints_(AllTableConstraintsRequest)=8, getNotNullConstraints_(NotNullConstraintsRequest)=2, getValidTxns_(long)=2, getCheckConstraints_(CheckConstraintsRequest)=1, commitTxn_(CommitTxnRequest)=15, getValidWriteIds_(List, String)=4, getAggrColStatsFor_(String, String, List, List, String, String)=40, listPartitionsSpecByExpr_(PartitionsByExprRequest, List)=87, getMetaConf_(String)=0, openTxn_(String, TxnType)=10}
2024-04-23T21:27:23,633  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212723_2ac96fe8-bc3d-4d83-a937-98a94625abf7); Time taken: 0.423 seconds
2024-04-23T21:27:23,633  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-23T21:27:23,639  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:23,648  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-23T21:27:23,648  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689): drop table if exists acidTbl
2024-04-23T21:27:23,651  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-23T21:27:23,652  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-23T21:27:23,653  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:23,662  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,663  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:23,663  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:23,663  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:23,663  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {rollbackTxn_(long)=13, openTxn_(String, TxnType)=3, getValidTxns_(long)=1, getTable_(GetTableRequest)=10, isCompatibleWith_(Configuration)=2, flushCache_()=0}
2024-04-23T21:27:23,663  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689); Time taken: 0.015 seconds
2024-04-23T21:27:23,663  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689
2024-04-23T21:27:23,664  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689
2024-04-23T21:27:23,685  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689 LockResponse(lockid:8, state:ACQUIRED)
2024-04-23T21:27:23,685  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:23,685  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689): drop table if exists acidTbl
2024-04-23T21:27:23,685  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:23,685  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:23,696  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,696  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:23,706  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,706  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-23T21:27:23,845  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:23,845  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=11, dropTable_(String, String, boolean, boolean, boolean)=148}
2024-04-23T21:27:23,845  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689); Time taken: 0.16 seconds
2024-04-23T21:27:23,845  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212723_2bcef278-e1e0-458c-9e20-9cc2b8c22689
2024-04-23T21:27:23,850  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-23T21:27:23,858  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:23,858  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-23T21:27:23,859  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-23T21:27:23,859  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584): drop table if exists acidTblPart
2024-04-23T21:27:23,863  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-23T21:27:23,863  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-23T21:27:23,864  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,875  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,875  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:23,875  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:23,875  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:23,876  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=14, getValidTxns_(long)=0, isCompatibleWith_(Configuration)=1, getTable_(GetTableRequest)=11, flushCache_()=0}
2024-04-23T21:27:23,876  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584); Time taken: 0.016 seconds
2024-04-23T21:27:23,876  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584
2024-04-23T21:27:23,877  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584
2024-04-23T21:27:23,896  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584 LockResponse(lockid:9, state:ACQUIRED)
2024-04-23T21:27:23,896  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:23,896  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584): drop table if exists acidTblPart
2024-04-23T21:27:23,896  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:23,896  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,906  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,906  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:23,914  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:23,915  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-23T21:27:24,017  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:24,017  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=10, isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=110}
2024-04-23T21:27:24,017  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584); Time taken: 0.121 seconds
2024-04-23T21:27:24,017  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212723_bdede23c-b145-4065-97c7-84f8739fe584
2024-04-23T21:27:24,022  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-23T21:27:24,030  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:24,031  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-23T21:27:24,032  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-23T21:27:24,033  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3): drop table if exists acidTbl2
2024-04-23T21:27:24,044  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-23T21:27:24,044  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-23T21:27:24,047  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:24,047  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:24,047  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:24,047  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getValidTxns_(long)=2, getTable_(GetTableRequest)=0, openTxn_(String, TxnType)=11, commitTxn_(CommitTxnRequest)=15, isCompatibleWith_(Configuration)=0}
2024-04-23T21:27:24,047  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3); Time taken: 0.014 seconds
2024-04-23T21:27:24,047  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3
2024-04-23T21:27:24,048  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-23T21:27:24,048  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3): drop table if exists acidTbl2
2024-04-23T21:27:24,048  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:24,048  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-23T21:27:24,049  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:24,049  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=0, dropTable_(String, String, boolean, boolean, boolean)=1}
2024-04-23T21:27:24,049  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3); Time taken: 0.001 seconds
2024-04-23T21:27:24,049  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212724_44dda197-cb71-40fd-9eca-b344310e0fe3
2024-04-23T21:27:24,056  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-23T21:27:24,062  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:24,062  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-23T21:27:24,063  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-23T21:27:24,063  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:24,066  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 14
2024-04-23T21:27:24,067  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-23T21:27:24,068  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:24,110  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,110  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:24,110  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:24,111  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:24,111  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getTable_(GetTableRequest)=43, commitTxn_(CommitTxnRequest)=14, isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, getValidTxns_(long)=0}
2024-04-23T21:27:24,111  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079); Time taken: 0.048 seconds
2024-04-23T21:27:24,111  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079
2024-04-23T21:27:24,112  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079
2024-04-23T21:27:24,134  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079 LockResponse(lockid:10, state:ACQUIRED)
2024-04-23T21:27:24,134  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:24,134  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079): drop table if exists nonAcidOrcTbl
2024-04-23T21:27:24,134  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:24,135  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:24,148  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,148  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:24,160  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,160  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-23T21:27:24,308  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:24,308  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, dropTable_(String, String, boolean, boolean, boolean)=160, getTable_(GetTableRequest)=13}
2024-04-23T21:27:24,308  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079); Time taken: 0.174 seconds
2024-04-23T21:27:24,308  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212724_c3e25177-4a9e-4ba3-ab79-d87f2839c079
2024-04-23T21:27:24,314  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-23T21:27:24,322  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:24,322  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-23T21:27:24,323  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:24,323  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:24,327  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-23T21:27:24,327  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-23T21:27:24,328  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:24,343  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,343  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:24,343  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:24,344  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:24,344  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=14, getValidTxns_(long)=1, getTable_(GetTableRequest)=15}
2024-04-23T21:27:24,344  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b); Time taken: 0.02 seconds
2024-04-23T21:27:24,344  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b
2024-04-23T21:27:24,345  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b
2024-04-23T21:27:24,363  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b LockResponse(lockid:11, state:ACQUIRED)
2024-04-23T21:27:24,363  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:24,363  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b): drop table if exists nonAcidOrcTbl2
2024-04-23T21:27:24,364  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:24,364  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:24,377  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,378  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:24,391  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,391  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-23T21:27:24,443  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:24,443  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=65, getTable_(GetTableRequest)=14}
2024-04-23T21:27:24,443  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b); Time taken: 0.08 seconds
2024-04-23T21:27:24,443  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212724_f3fbffa5-08d7-40a5-92a8-3c78c772d34b
2024-04-23T21:27:24,449  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-23T21:27:24,457  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:24,458  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-23T21:27:24,459  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-23T21:27:24,459  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63): drop table if exists nonAcidNonBucket
2024-04-23T21:27:24,463  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-23T21:27:24,463  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-23T21:27:24,464  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:24,482  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,482  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:27:24,482  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:27:24,482  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:27:24,482  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=1, flushCache_()=1, commitTxn_(CommitTxnRequest)=14, getTable_(GetTableRequest)=18}
2024-04-23T21:27:24,483  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63); Time taken: 0.023 seconds
2024-04-23T21:27:24,483  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63
2024-04-23T21:27:24,484  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63
2024-04-23T21:27:24,510  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63 LockResponse(lockid:12, state:ACQUIRED)
2024-04-23T21:27:24,510  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-23T21:27:24,510  INFO [main] ql.Driver: Executing command(queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63): drop table if exists nonAcidNonBucket
2024-04-23T21:27:24,511  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-23T21:27:24,511  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:24,530  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,530  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:24,549  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-23T21:27:24,549  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-23T21:27:24,607  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-23T21:27:24,607  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=76, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=19}
2024-04-23T21:27:24,607  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63); Time taken: 0.096 seconds
2024-04-23T21:27:24,607  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240423212724_c984917e-d0af-49f4-8423-430b6eab5d63
2024-04-23T21:27:24,611  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-23T21:27:24,619  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-23T21:27:24,619  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-23T21:27:24,620  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenateMM" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="12.051"/>
</testsuite>