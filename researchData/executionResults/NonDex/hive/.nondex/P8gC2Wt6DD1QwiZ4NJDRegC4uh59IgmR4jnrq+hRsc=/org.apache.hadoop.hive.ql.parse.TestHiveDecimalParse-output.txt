SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,075764 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@514646ef]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@514646ef) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@5b38c1ec
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7eecb5b8
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,025120 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(charset="null", alwaysWriteExceptions="null", footer="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", Configuration(HiveLog4j2Test), disableAnsi="null", Replace=null, noConsoleNoAnsi="null", PatternSelector=null, header="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(direct="null", target="SYSTEM_ERR", follow="null", bufferedIo="null", immediateFlush="null", bufferSize="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", Configuration(HiveLog4j2Test), name="console", Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(PatternSelector=null, header="null", alwaysWriteExceptions="null", disableAnsi="null", charset="null", Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", Replace=null, footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", maxRandomDelay="null", modulate="true")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(stopCustomActionsOnError="null", ={}, min="null", max="30", fileIndex="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test), compressionLevel="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), fileOwner="null", append="null", fileGroup="null", fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", advertise="null", advertiseURI="null", filePermissions="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), bufferedIo="null", bufferSize="null", immediateFlush="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), Configuration(HiveLog4j2Test), name="DRFA", ignoreExceptions="null", Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 3061782929
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-23T21:44:59.231-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/23-21:45:00.986, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/24-00:00:00.000, nextFileTime=2024/04/23-00:00:00.000, prevFileTime=2024/04/23-00:00:00.000, current=2024/04/23-21:45:00.987, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7eecb5b8 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7eecb5b8
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7eecb5b8 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@610f7aa...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@610f7aa OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@119020fb
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@514646ef
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@514646ef) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@514646ef] started OK.
2024-04-23T21:45:01,086  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-23T21:45:01,493  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-23T21:45:01,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:01,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:01,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:01,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:01,552  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:01,552  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:01,553  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:01,553  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:01,553  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:01,553  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:01,554  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = 1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7
2024-04-23T21:45:01,571  INFO [main] SessionState: Hive Session ID = 1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:01,582  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@4628b1d3.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@4628b1d3.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-23T21:45:01,916  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7
2024-04-23T21:45:01,920  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7
2024-04-23T21:45:01,923  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7/_tmp_space.db
2024-04-23T21:45:01,962  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214501_a48bc1fd-4daa-4f62-b2f2-cdabf709a62f): create table `dec` (d decimal)
2024-04-23T21:45:03,295  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,297  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,298  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,298  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,303  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,310  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,312  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-23T21:45:03,399  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:03,552  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:03,579  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:03,587  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-23T21:45:03,587  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-23T21:45:03,605  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:45:03,610  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-23T21:45:04,236  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:45:04,240  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-23T21:45:04,809  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-23T21:45:04,809  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2489e84a, with PersistenceManager: null will be shutdown
2024-04-23T21:45:04,833  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2489e84a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1084f78c created in the thread with id: 1
2024-04-23T21:45:07,181  WARN [main] metastore.ObjectStore: Version information not found in metastore. metastore.schema.verification is not enabled so recording the schema version 4.0.0
2024-04-23T21:45:07,181  WARN [main] metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 4.0.0, comment = Set by MetaStore alex@127.0.1.1
2024-04-23T21:45:07,181  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2489e84a from thread id: 1
2024-04-23T21:45:07,301  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-23T21:45:07,334  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-23T21:45:07,368  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-23T21:45:07,371  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-23T21:45:07,480  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-23T21:45:07,486  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-23T21:45:07,486  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-23T21:45:07,487  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-23T21:45:07,488  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-23T21:45:07,508  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:45:07,512  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-23T21:45:07,514  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:45:07,515  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-23T21:45:07,517  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-23T21:45:07,520  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-23T21:45:07,522  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-23T21:45:07,522  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-23T21:45:07,528  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-23T21:45:07,530  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-23T21:45:07,532  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:07,658  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:07,704  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_functions	
2024-04-23T21:45:07,990  INFO [main] reflections.Reflections: Reflections took 194 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:45:08,155  INFO [main] reflections.Reflections: Reflections took 136 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:45:08,282  INFO [main] reflections.Reflections: Reflections took 120 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:45:08,350  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214501_a48bc1fd-4daa-4f62-b2f2-cdabf709a62f
2024-04-23T21:45:08,352  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:08,371  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=1f88fdb8-806b-4e7a-9eb6-659eebbcc4f7, clientType=HIVECLI]
2024-04-23T21:45:08,373  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2024-04-23T21:45:08,374  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:08,374  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2489e84a, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1084f78c will be shutdown
2024-04-23T21:45:08,375  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:08,375  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2024-04-23T21:45:08,377  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,378  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:08,379  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,380  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738, with PersistenceManager: null will be shutdown
2024-04-23T21:45:08,381  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@aca3c85 created in the thread with id: 1
2024-04-23T21:45:08,398  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738 from thread id: 1
2024-04-23T21:45:08,398  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,399  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,403  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:08,417  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,417  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,419  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@aca3c85 will be shutdown
2024-04-23T21:45:08,420  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f7e52d1 created in the thread with id: 1
2024-04-23T21:45:08,425  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,426  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,428  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:45:08,571  INFO [main] reflections.Reflections: Reflections took 121 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-23T21:45:08,607  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214501_a48bc1fd-4daa-4f62-b2f2-cdabf709a62f
2024-04-23T21:45:08,608  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:45:08,609  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:45:08,612  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:08,612  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:08,614  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214501_a48bc1fd-4daa-4f62-b2f2-cdabf709a62f); Time taken: 6.652 seconds
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:08,670  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:08,671  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:08,671  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:08,671  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:08,671  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = da1732dd-e827-441c-bd08-0501b6d70a5c
2024-04-23T21:45:08,672  INFO [main] SessionState: Hive Session ID = da1732dd-e827-441c-bd08-0501b6d70a5c
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,673  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,681  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/da1732dd-e827-441c-bd08-0501b6d70a5c
2024-04-23T21:45:08,684  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/da1732dd-e827-441c-bd08-0501b6d70a5c
2024-04-23T21:45:08,688  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/da1732dd-e827-441c-bd08-0501b6d70a5c/_tmp_space.db
2024-04-23T21:45:08,690  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214508_1730975f-4433-4e79-b4ca-ebeaca469140): create table `dec` (d decimal(5))
2024-04-23T21:45:08,691  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:08,691  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:08,692  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@f18b738, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f7e52d1 will be shutdown
2024-04-23T21:45:08,692  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:08,692  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2024-04-23T21:45:08,692  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214508_1730975f-4433-4e79-b4ca-ebeaca469140
2024-04-23T21:45:08,692  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:08,693  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=da1732dd-e827-441c-bd08-0501b6d70a5c, clientType=HIVECLI]
2024-04-23T21:45:08,695  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,697  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:08,697  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,698  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bc2ae16, with PersistenceManager: null will be shutdown
2024-04-23T21:45:08,699  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bc2ae16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d3bf8db created in the thread with id: 1
2024-04-23T21:45:08,705  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bc2ae16 from thread id: 1
2024-04-23T21:45:08,705  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,705  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,706  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:08,706  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:45:08,708  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214508_1730975f-4433-4e79-b4ca-ebeaca469140
2024-04-23T21:45:08,709  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:45:08,709  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:45:08,709  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:08,709  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=2}
2024-04-23T21:45:08,709  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214508_1730975f-4433-4e79-b4ca-ebeaca469140); Time taken: 0.019 seconds
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:08,764  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:08,765  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:08,765  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:08,765  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:08,765  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:08,765  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
Hive Session ID = b3c15cc0-0a8c-4b70-a02f-68abc867d93d
2024-04-23T21:45:08,766  INFO [main] SessionState: Hive Session ID = b3c15cc0-0a8c-4b70-a02f-68abc867d93d
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,767  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,775  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/b3c15cc0-0a8c-4b70-a02f-68abc867d93d
2024-04-23T21:45:08,778  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/b3c15cc0-0a8c-4b70-a02f-68abc867d93d
2024-04-23T21:45:08,781  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/b3c15cc0-0a8c-4b70-a02f-68abc867d93d/_tmp_space.db
2024-04-23T21:45:08,784  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214508_1448d9fb-3a1d-41a3-a58b-e837ad758e87): create table `dec` (d decimal(9,7))
2024-04-23T21:45:08,785  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:08,786  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:08,786  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7bc2ae16, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d3bf8db will be shutdown
2024-04-23T21:45:08,786  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:08,786  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2024-04-23T21:45:08,786  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214508_1448d9fb-3a1d-41a3-a58b-e837ad758e87
2024-04-23T21:45:08,786  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:08,787  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=b3c15cc0-0a8c-4b70-a02f-68abc867d93d, clientType=HIVECLI]
2024-04-23T21:45:08,788  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,790  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:08,790  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,790  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44d43cc9, with PersistenceManager: null will be shutdown
2024-04-23T21:45:08,791  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44d43cc9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@656ec00d created in the thread with id: 1
2024-04-23T21:45:08,796  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44d43cc9 from thread id: 1
2024-04-23T21:45:08,796  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,796  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,796  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:08,797  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-23T21:45:08,799  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214508_1448d9fb-3a1d-41a3-a58b-e837ad758e87
2024-04-23T21:45:08,799  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-23T21:45:08,799  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-23T21:45:08,799  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:08,800  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=2}
2024-04-23T21:45:08,800  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214508_1448d9fb-3a1d-41a3-a58b-e837ad758e87); Time taken: 0.015 seconds
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:08,854  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:08,855  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:08,855  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:08,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:08,855  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:08,856  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
Hive Session ID = f2325459-a381-47e8-8419-f6cdc492bbb3
2024-04-23T21:45:08,856  INFO [main] SessionState: Hive Session ID = f2325459-a381-47e8-8419-f6cdc492bbb3
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,857  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,864  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/f2325459-a381-47e8-8419-f6cdc492bbb3
2024-04-23T21:45:08,868  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/f2325459-a381-47e8-8419-f6cdc492bbb3
2024-04-23T21:45:08,870  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/f2325459-a381-47e8-8419-f6cdc492bbb3/_tmp_space.db
2024-04-23T21:45:08,872  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214508_7440cf25-419f-4773-8feb-4f7f794133c2): create table `dec` (d decimal(66,7))
2024-04-23T21:45:08,873  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:08,874  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:08,874  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44d43cc9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@656ec00d will be shutdown
2024-04-23T21:45:08,874  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:08,874  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2024-04-23T21:45:08,874  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214508_7440cf25-419f-4773-8feb-4f7f794133c2
2024-04-23T21:45:08,874  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:08,874  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f2325459-a381-47e8-8419-f6cdc492bbb3, clientType=HIVECLI]
2024-04-23T21:45:08,875  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,876  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:08,877  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,877  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e27f603, with PersistenceManager: null will be shutdown
2024-04-23T21:45:08,877  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e27f603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1736c1e4 created in the thread with id: 1
2024-04-23T21:45:08,882  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e27f603 from thread id: 1
2024-04-23T21:45:08,882  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,882  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,882  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:08,883  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214508_7440cf25-419f-4773-8feb-4f7f794133c2
FAILED: IllegalArgumentException Decimal precision out of allowed range [1,38]
2024-04-23T21:45:08,895 ERROR [main] ql.Driver: FAILED: IllegalArgumentException Decimal precision out of allowed range [1,38]
java.lang.IllegalArgumentException: Decimal precision out of allowed range [1,38]
	at org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils.validateParameter(HiveDecimalUtils.java:44)
	at org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo.<init>(DecimalTypeInfo.java:36)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.createPrimitiveTypeInfo(TypeInfoFactory.java:165)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getPrimitiveTypeInfo(TypeInfoFactory.java:117)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getDecimalTypeInfo(TypeInfoFactory.java:186)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.getDecimalTypeTypeInfo(ParseUtils.java:261)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeName(BaseSemanticAnalyzer.java:1030)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeStringFromAST(BaseSemanticAnalyzer.java:979)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getColumns(BaseSemanticAnalyzer.java:874)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13430)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12347)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12512)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType3(TestHiveDecimalParse.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:08,896  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:08,896  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:08,896  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214508_7440cf25-419f-4773-8feb-4f7f794133c2); Time taken: 0.024 seconds
2024-04-23T21:45:08,950  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:08,951  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:08,951  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:08,951  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:08,951  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:08,951  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:08,952  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:08,952  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:08,952  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:08,952  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:08,958  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
Hive Session ID = 7487cd25-776b-438c-8fde-13fb4235b4fe
2024-04-23T21:45:08,959  INFO [main] SessionState: Hive Session ID = 7487cd25-776b-438c-8fde-13fb4235b4fe
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,959  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:08,967  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7487cd25-776b-438c-8fde-13fb4235b4fe
2024-04-23T21:45:08,970  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/7487cd25-776b-438c-8fde-13fb4235b4fe
2024-04-23T21:45:08,973  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/7487cd25-776b-438c-8fde-13fb4235b4fe/_tmp_space.db
2024-04-23T21:45:08,975  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214508_3595d9dc-0850-42ae-9560-39f674a499e6): create table `dec` (d decimal(0,7))
2024-04-23T21:45:08,976  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:08,976  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:08,977  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e27f603, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1736c1e4 will be shutdown
2024-04-23T21:45:08,977  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:08,977  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2024-04-23T21:45:08,977  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214508_3595d9dc-0850-42ae-9560-39f674a499e6
2024-04-23T21:45:08,977  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:08,977  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7487cd25-776b-438c-8fde-13fb4235b4fe, clientType=HIVECLI]
2024-04-23T21:45:08,978  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:08,979  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:08,979  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:08,980  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44864536, with PersistenceManager: null will be shutdown
2024-04-23T21:45:08,981  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44864536, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e239337 created in the thread with id: 1
2024-04-23T21:45:08,985  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44864536 from thread id: 1
2024-04-23T21:45:08,985  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:08,986  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:08,986  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:08,986  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214508_3595d9dc-0850-42ae-9560-39f674a499e6
FAILED: IllegalArgumentException Decimal precision out of allowed range [1,38]
2024-04-23T21:45:08,987 ERROR [main] ql.Driver: FAILED: IllegalArgumentException Decimal precision out of allowed range [1,38]
java.lang.IllegalArgumentException: Decimal precision out of allowed range [1,38]
	at org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils.validateParameter(HiveDecimalUtils.java:44)
	at org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo.<init>(DecimalTypeInfo.java:36)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.createPrimitiveTypeInfo(TypeInfoFactory.java:165)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getPrimitiveTypeInfo(TypeInfoFactory.java:117)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getDecimalTypeInfo(TypeInfoFactory.java:186)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.getDecimalTypeTypeInfo(ParseUtils.java:261)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeName(BaseSemanticAnalyzer.java:1030)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeStringFromAST(BaseSemanticAnalyzer.java:979)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getColumns(BaseSemanticAnalyzer.java:874)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13430)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12347)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12512)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType4(TestHiveDecimalParse.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:08,987  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:08,987  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:08,987  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214508_3595d9dc-0850-42ae-9560-39f674a499e6); Time taken: 0.012 seconds
2024-04-23T21:45:09,028  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:09,028  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:09,028  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:09,029  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:09,030  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
Hive Session ID = 9a46798e-e516-4f2f-81b8-cf989a100f83
2024-04-23T21:45:09,030  INFO [main] SessionState: Hive Session ID = 9a46798e-e516-4f2f-81b8-cf989a100f83
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,031  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,038  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/9a46798e-e516-4f2f-81b8-cf989a100f83
2024-04-23T21:45:09,041  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/9a46798e-e516-4f2f-81b8-cf989a100f83
2024-04-23T21:45:09,045  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/9a46798e-e516-4f2f-81b8-cf989a100f83/_tmp_space.db
2024-04-23T21:45:09,047  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214509_936d5b07-3993-4ed3-8a6b-5c15c981f497): create table `dec` (d decimal(7,33))
2024-04-23T21:45:09,048  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:09,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:09,049  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@44864536, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6e239337 will be shutdown
2024-04-23T21:45:09,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:09,049  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2024-04-23T21:45:09,049  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214509_936d5b07-3993-4ed3-8a6b-5c15c981f497
2024-04-23T21:45:09,050  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:09,050  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=9a46798e-e516-4f2f-81b8-cf989a100f83, clientType=HIVECLI]
2024-04-23T21:45:09,051  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:09,053  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:09,053  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:09,054  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6182ffef, with PersistenceManager: null will be shutdown
2024-04-23T21:45:09,054  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6182ffef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d24cdd9 created in the thread with id: 1
2024-04-23T21:45:09,061  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6182ffef from thread id: 1
2024-04-23T21:45:09,061  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:09,061  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:09,062  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:09,062  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214509_936d5b07-3993-4ed3-8a6b-5c15c981f497
FAILED: IllegalArgumentException Decimal scale must be less than or equal to precision
2024-04-23T21:45:09,062 ERROR [main] ql.Driver: FAILED: IllegalArgumentException Decimal scale must be less than or equal to precision
java.lang.IllegalArgumentException: Decimal scale must be less than or equal to precision
	at org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils.validateParameter(HiveDecimalUtils.java:54)
	at org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo.<init>(DecimalTypeInfo.java:36)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.createPrimitiveTypeInfo(TypeInfoFactory.java:165)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getPrimitiveTypeInfo(TypeInfoFactory.java:117)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getDecimalTypeInfo(TypeInfoFactory.java:186)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.getDecimalTypeTypeInfo(ParseUtils.java:261)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeName(BaseSemanticAnalyzer.java:1030)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeStringFromAST(BaseSemanticAnalyzer.java:979)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getColumns(BaseSemanticAnalyzer.java:874)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13430)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12347)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12512)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType5(TestHiveDecimalParse.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:09,063  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:09,063  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:09,063  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214509_936d5b07-3993-4ed3-8a6b-5c15c981f497); Time taken: 0.016 seconds
2024-04-23T21:45:09,115  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:09,115  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:09,115  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:09,115  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:09,115  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:09,116  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
Hive Session ID = ef53447e-cd12-40d3-9ef1-e573cc560df6
2024-04-23T21:45:09,116  INFO [main] SessionState: Hive Session ID = ef53447e-cd12-40d3-9ef1-e573cc560df6
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,117  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,124  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/ef53447e-cd12-40d3-9ef1-e573cc560df6
2024-04-23T21:45:09,127  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/ef53447e-cd12-40d3-9ef1-e573cc560df6
2024-04-23T21:45:09,130  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/ef53447e-cd12-40d3-9ef1-e573cc560df6/_tmp_space.db
2024-04-23T21:45:09,132  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214509_29c86a88-d0d8-434c-ae81-f953f48003bf): create table `dec` (d decimal(7,-1))
FAILED: ParseException line 1:32 extraneous input '-' expecting Number near '<EOF>'
2024-04-23T21:45:09,135 ERROR [main] ql.Driver: FAILED: ParseException line 1:32 extraneous input '-' expecting Number near '<EOF>'
org.apache.hadoop.hive.ql.parse.ParseException: line 1:32 extraneous input '-' expecting Number near '<EOF>'
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:133)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:93)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:85)
	at org.apache.hadoop.hive.ql.Compiler.parse(Compiler.java:170)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:103)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType6(TestHiveDecimalParse.java:110)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:09,135  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:09,135  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:09,135  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214509_29c86a88-d0d8-434c-ae81-f953f48003bf); Time taken: 0.004 seconds
2024-04-23T21:45:09,177  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:09,178  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:09,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:09,179  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:09,179  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
Hive Session ID = 2a46ceeb-5227-4c59-b3f0-0c8c21d9e456
2024-04-23T21:45:09,179  INFO [main] SessionState: Hive Session ID = 2a46ceeb-5227-4c59-b3f0-0c8c21d9e456
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,180  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,187  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/2a46ceeb-5227-4c59-b3f0-0c8c21d9e456
2024-04-23T21:45:09,190  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2a46ceeb-5227-4c59-b3f0-0c8c21d9e456
2024-04-23T21:45:09,193  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/2a46ceeb-5227-4c59-b3f0-0c8c21d9e456/_tmp_space.db
2024-04-23T21:45:09,195  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214509_8ca444bf-7428-4498-96e5-0cad1dbe8958): create table `dec` (d decimal(7,33,4))
FAILED: ParseException line 1:34 missing ) at ',' near ',' in column name or constraint
line 1:35 cannot recognize input near '4' ')' ')' in column name or constraint
2024-04-23T21:45:09,198 ERROR [main] ql.Driver: FAILED: ParseException line 1:34 missing ) at ',' near ',' in column name or constraint
line 1:35 cannot recognize input near '4' ')' ')' in column name or constraint
org.apache.hadoop.hive.ql.parse.ParseException: line 1:34 missing ) at ',' near ',' in column name or constraint
line 1:35 cannot recognize input near '4' ')' ')' in column name or constraint
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:125)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:93)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:85)
	at org.apache.hadoop.hive.ql.Compiler.parse(Compiler.java:170)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:103)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType7(TestHiveDecimalParse.java:126)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:09,198  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:09,198  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:09,198  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214509_8ca444bf-7428-4498-96e5-0cad1dbe8958); Time taken: 0.003 seconds
2024-04-23T21:45:09,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:09,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:09,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:09,241  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:09,242  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
Hive Session ID = 1f52daaf-0cc3-4992-95c9-6eb859a75358
2024-04-23T21:45:09,242  INFO [main] SessionState: Hive Session ID = 1f52daaf-0cc3-4992-95c9-6eb859a75358
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,243  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,250  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/1f52daaf-0cc3-4992-95c9-6eb859a75358
2024-04-23T21:45:09,253  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/1f52daaf-0cc3-4992-95c9-6eb859a75358
2024-04-23T21:45:09,255  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/1f52daaf-0cc3-4992-95c9-6eb859a75358/_tmp_space.db
2024-04-23T21:45:09,257  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214509_c249632f-76bd-42c7-a863-eded495e232a): create table `dec` (d decimal(7a))
FAILED: ParseException line 1:30 mismatched input '7a' expecting Number near '(' in primitive type specification
2024-04-23T21:45:09,259 ERROR [main] ql.Driver: FAILED: ParseException line 1:30 mismatched input '7a' expecting Number near '(' in primitive type specification
org.apache.hadoop.hive.ql.parse.ParseException: line 1:30 mismatched input '7a' expecting Number near '(' in primitive type specification
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:125)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:93)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:85)
	at org.apache.hadoop.hive.ql.Compiler.parse(Compiler.java:170)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:103)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType8(TestHiveDecimalParse.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:09,259  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:09,259  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:09,259  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214509_c249632f-76bd-42c7-a863-eded495e232a); Time taken: 0.002 seconds
2024-04-23T21:45:09,292  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-23T21:45:09,292  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-23T21:45:09,293  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-23T21:45:09,294  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
Hive Session ID = 81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d
2024-04-23T21:45:09,294  INFO [main] SessionState: Hive Session ID = 81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,295  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-23T21:45:09,302  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d
2024-04-23T21:45:09,305  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d
2024-04-23T21:45:09,308  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d/_tmp_space.db
2024-04-23T21:45:09,310  INFO [main] ql.Driver: Compiling command(queryId=alex_20240423214509_7650ce53-96ae-46e7-9b59-efcf8e059599): create table `dec` (d decimal(20,23))
2024-04-23T21:45:09,311  INFO [main] metastore.HiveMetaStoreClient: Mestastore configuration metastore.filter.hook changed from org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook to org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
2024-04-23T21:45:09,311  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-23T21:45:09,311  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6182ffef, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d24cdd9 will be shutdown
2024-04-23T21:45:09,311  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-23T21:45:09,312  INFO [main] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -7
2024-04-23T21:45:09,312  INFO [main] parse.CalcitePlanner: Starting caching scope for: alex_20240423214509_7650ce53-96ae-46e7-9b59-efcf8e059599
2024-04-23T21:45:09,312  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-23T21:45:09,312  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=81e9bb01-cde3-47f3-bc5b-d2bd71c55f1d, clientType=HIVECLI]
2024-04-23T21:45:09,313  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-23T21:45:09,314  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-23T21:45:09,315  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-23T21:45:09,315  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c27e700, with PersistenceManager: null will be shutdown
2024-04-23T21:45:09,316  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c27e700, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2d913116 created in the thread with id: 1
2024-04-23T21:45:09,320  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6c27e700 from thread id: 1
2024-04-23T21:45:09,320  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-23T21:45:09,320  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-23T21:45:09,321  INFO [main] parse.CalcitePlanner: Creating table default.dec position=13
2024-04-23T21:45:09,321  INFO [main] parse.CalcitePlanner: Ending caching scope for: alex_20240423214509_7650ce53-96ae-46e7-9b59-efcf8e059599
FAILED: IllegalArgumentException Decimal scale must be less than or equal to precision
2024-04-23T21:45:09,321 ERROR [main] ql.Driver: FAILED: IllegalArgumentException Decimal scale must be less than or equal to precision
java.lang.IllegalArgumentException: Decimal scale must be less than or equal to precision
	at org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils.validateParameter(HiveDecimalUtils.java:54)
	at org.apache.hadoop.hive.serde2.typeinfo.DecimalTypeInfo.<init>(DecimalTypeInfo.java:36)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.createPrimitiveTypeInfo(TypeInfoFactory.java:165)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getPrimitiveTypeInfo(TypeInfoFactory.java:117)
	at org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory.getDecimalTypeInfo(TypeInfoFactory.java:186)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.getDecimalTypeTypeInfo(ParseUtils.java:261)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeName(BaseSemanticAnalyzer.java:1030)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTypeStringFromAST(BaseSemanticAnalyzer.java:979)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getColumns(BaseSemanticAnalyzer.java:874)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeCreateTable(SemanticAnalyzer.java:13430)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genResolvedParseTree(SemanticAnalyzer.java:12347)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12512)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.parse.TestHiveDecimalParse.testDecimalType9(TestHiveDecimalParse.java:158)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-23T21:45:09,322  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-23T21:45:09,322  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {}
2024-04-23T21:45:09,322  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240423214509_7650ce53-96ae-46e7-9b59-efcf8e059599); Time taken: 0.013 seconds
