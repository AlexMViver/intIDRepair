<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="30.889" tests="3" errors="2" skipped="0" failures="0">
  <properties>
    <property name="build.test.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="test.tmp.dir.uri" value="file:///home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="qfile" value=""/>
    <property name="test.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/warehouse"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="run_disabled" value=""/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.country.format" value="PT"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter7913857915392230708.jar /home/alex/Repositories/hive/ql/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire1009873352462243730tmp surefire_28738228940367196380809tmp"/>
    <property name="nondexExecid" value="Snhwr3I2MCYp2xI1BMYXdetIVL2H5UQXpCxOgAk9NN4="/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/alex/Repositories/hive/ql"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/ql/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/ql/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="spark.home" value=""/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="test.src.tables" value=""/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="qfile_regex" value=""/>
    <property name="hadoop.bin.path" value="/home/alex/Repositories/hive/ql/../testutils/hadoop"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/ql/target"/>
    <property name="mapred.job.tracker" value="local"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/ql/.nondex"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="com.zaxxer.hikari.pool_number" value="3"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="hive.version" value="4.0.0-SNAPSHOT"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="test.data.dir" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="initScript" value=""/>
    <property name="sun.desktop" value="gnome"/>
    <property name="calcite.enable.rexnode.digest.normalize" value="false"/>
    <property name="nondexStart" value="0"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="hadoop.version" value="3.1.0"/>
    <property name="user.timezone" value="US/Pacific"/>
    <property name="test.local.warehouse.dir" value="pfile:///home/alex/Repositories/hive/ql/target/localfs/warehouse"/>
    <property name="os.name" value="Linux"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="clustermode" value=""/>
    <property name="test.build.data" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="test.data.files" value="/home/alex/Repositories/hive/ql/../data/files"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/ql/target/test-classes:/home/alex/Repositories/hive/ql/target/classes:/home/alex/.m2/repository/org/apache/atlas/atlas-client-v2/2.1.0/atlas-client-v2-2.1.0.jar:/home/alex/.m2/repository/cglib/cglib/2.2.2/cglib-2.2.2.jar:/home/alex/.m2/repository/asm/asm/3.3.1/asm-3.3.1.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-client-common/2.1.0/atlas-client-common-2.1.0.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/alex/.m2/repository/org/apache/atlas/atlas-intg/2.1.0/atlas-intg-2.1.0.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.0/jackson-jaxrs-base-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.0/jackson-jaxrs-json-provider-2.12.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/org/springframework/spring-context/4.3.20.RELEASE/spring-context-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-aop/4.3.20.RELEASE/spring-aop-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-beans/4.3.20.RELEASE/spring-beans-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-core/4.3.20.RELEASE/spring-core-4.3.20.RELEASE.jar:/home/alex/.m2/repository/org/springframework/spring-expression/4.3.20.RELEASE/spring-expression-4.3.20.RELEASE.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.10/commons-configuration-1.10.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/alex/Repositories/hive/vector-code-gen/target/classes:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/Repositories/hive/common/target/classes:/home/alex/Repositories/hive/classification/target/classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar:/home/alex/.m2/repository/org/apache/orc/orc-shims/1.6.9/orc-shims-1.6.9.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar:/home/alex/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/home/alex/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/home/alex/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar:/home/alex/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-http/9.3.27.v20190418/jetty-http-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-rewrite/9.3.27.v20190418/jetty-rewrite-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-client/9.3.27.v20190418/jetty-client-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-server/9.3.27.v20190418/jetty-server-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-io/9.3.27.v20190418/jetty-io-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.27.v20190418/jetty-servlet-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-security/9.3.27.v20190418/jetty-security-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.27.v20190418/jetty-webapp-9.3.27.v20190418.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.27.v20190418/jetty-xml-9.3.27.v20190418.jar:/home/alex/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.13.2/log4j-web-2.13.2.jar:/home/alex/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/Repositories/hive/metastore/target/classes:/home/alex/.m2/repository/org/apache/derby/derby/10.14.1.0/derby-10.14.1.0.jar:/home/alex/Repositories/hive/serde/target/classes:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-vector/0.15.1/arrow-vector-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-format/0.15.1/arrow-format-0.15.1.jar:/home/alex/.m2/repository/org/apache/arrow/arrow-memory/0.15.1/arrow-memory-0.15.1.jar:/home/alex/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/home/alex/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/alex/.m2/repository/com/github/davidmoten/flatbuffers-java/1.6.0.1/flatbuffers-java-1.6.0.1.jar:/home/alex/Repositories/hive/parser/target/classes:/home/alex/Repositories/hive/udf/target/classes:/home/alex/Repositories/hive/service-rpc/target/classes:/home/alex/Repositories/hive/llap-client/target/classes:/home/alex/Repositories/hive/llap-common/target/classes:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-api/0.10.5/jjwt-api-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-impl/0.10.5/jjwt-impl-0.10.5.jar:/home/alex/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.10.5/jjwt-jackson-0.10.5.jar:/home/alex/Repositories/hive/llap-tez/target/classes:/home/alex/Repositories/hive/shims/aggregator/target/classes:/home/alex/Repositories/hive/shims/common/target/classes:/home/alex/Repositories/hive/shims/0.23/target/classes:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/3.1.0/hadoop-yarn-server-resourcemanager-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/3.1.0/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/home/alex/.m2/repository/de/ruedigermoeller/fst/2.50/fst-2.50.jar:/home/alex/.m2/repository/com/cedarsoftware/java-util/1.9.0/java-util-1.9.0.jar:/home/alex/.m2/repository/com/cedarsoftware/json-io/2.5.1/json-io-2.5.1.jar:/home/alex/Repositories/hive/shims/scheduler/target/classes:/home/alex/Repositories/hive/spark-client/target/classes:/home/alex/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.0/jackson-module-scala_2.12-2.12.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-yarn_2.12/2.4.5/spark-yarn_2.12-2.4.5.jar:/home/alex/Repositories/hive/storage-api/target/classes:/home/alex/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.11.901/aws-java-sdk-bundle-1.11.901.jar:/home/alex/.m2/repository/com/amazonaws/secretsmanager/aws-secretsmanager-caching-java/1.0.1/aws-secretsmanager-caching-java-1.0.1.jar:/home/alex/.m2/repository/com/esotericsoftware/kryo/5.0.3/kryo-5.0.3.jar:/home/alex/.m2/repository/org/objenesis/objenesis/3.1/objenesis-3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/minlog/1.3.1/minlog-1.3.1.jar:/home/alex/.m2/repository/com/esotericsoftware/reflectasm/1.11.9/reflectasm-1.11.9.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/2.0.0-alpha4/hbase-common-2.0.0-alpha4.jar:/home/alex/.m2/repository/org/apache/hbase/thirdparty/hbase-shaded-miscellaneous/1.0.1/hbase-shaded-miscellaneous-1.0.1.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.2.0-incubating/htrace-core-3.2.0-incubating.jar:/home/alex/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.11.1/parquet-hadoop-bundle-1.11.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/alex/.m2/repository/commons-io/commons-io/2.6/commons-io-2.6.jar:/home/alex/.m2/repository/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/alex/.m2/repository/org/apache/commons/commons-text/1.8/commons-text-1.8.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.13.2/log4j-1.2-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/alex/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/alex/.m2/repository/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/home/alex/.m2/repository/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/3.1.0/hadoop-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.0/hadoop-annotations-3.1.0.jar:/home/alex/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util/9.3.27.v20190418/jetty-util-9.3.27.v20190418.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/alex/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/alex/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/3.1.0/hadoop-auth-3.1.0.jar:/home/alex/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/alex/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/alex/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/alex/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/alex/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-archives/3.1.0/hadoop-archives-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.0/hadoop-yarn-registry-3.1.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/alex/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/alex/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.0/hadoop-mapreduce-client-core-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.0/hadoop-hdfs-client-3.1.0.jar:/home/alex/.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/home/alex/.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.0/hadoop-mapreduce-client-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.1.0/hadoop-hdfs-3.1.0.jar:/home/alex/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.19.v20170502/jetty-util-ajax-9.3.19.v20170502.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.0/hadoop-yarn-api-3.1.0.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.0/hadoop-yarn-common-3.1.0.jar:/home/alex/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/alex/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.0/jackson-module-jaxb-annotations-2.12.0.jar:/home/alex/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/alex/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.0/hadoop-yarn-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-tools/1.6.9/orc-tools-1.6.9.jar:/home/alex/.m2/repository/com/opencsv/opencsv/3.9/opencsv-3.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/org/threeten/threetenbp/1.3.5/threetenbp-1.3.5.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/alex/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.46/tomcat-embed-core-8.5.46.jar:/home/alex/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.46/tomcat-annotations-api-8.5.46.jar:/home/alex/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper/3.5.5/zookeeper-3.5.5.jar:/home/alex/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.5/zookeeper-jute-3.5.5.jar:/home/alex/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/alex/.m2/repository/org/apache/curator/curator-test/4.2.0/curator-test-4.2.0.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-hive/1.1.0-incubating/datasketches-hive-1.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-java/1.3.0-incubating/datasketches-java-1.3.0-incubating.jar:/home/alex/.m2/repository/org/apache/datasketches/datasketches-memory/1.2.0-incubating/datasketches-memory-1.2.0-incubating.jar:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar:/home/alex/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/home/alex/.m2/repository/org/codehaus/groovy/groovy-all/2.4.11/groovy-all-2.4.11.jar:/home/alex/.m2/repository/org/jodd/jodd-util/6.0.0/jodd-util-6.0.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.0/jackson-annotations-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.0/jackson-core-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.0/jackson-databind-2.12.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.12.0/jackson-dataformat-yaml-2.12.0.jar:/home/alex/.m2/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/5.2.4/datanucleus-core-5.2.4.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.25.0/calcite-core-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.25.0/calcite-linq4j-1.25.0.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/com/esri/geometry/esri-geometry-api/2.2.0/esri-geometry-api-2.2.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/sketches-core/0.9.0/sketches-core-0.9.0.jar:/home/alex/.m2/repository/com/yahoo/datasketches/memory/0.9.0/memory-0.9.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-dbcp2/2.7.0/commons-dbcp2-2.7.0.jar:/home/alex/.m2/repository/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.25.0/calcite-druid-1.25.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.12.0/avatica-1.12.0.jar:/home/alex/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/alex/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/classes:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.6.1/HikariCP-2.6.1.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/5.2.4/datanucleus-api-jdo-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/5.2.4/datanucleus-rdbms-5.2.4.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-release/javax.jdo-3.2.0-release.jar:/home/alex/.m2/repository/javax/transaction/javax.transaction-api/1.3/javax.transaction-api-1.3.jar:/home/alex/.m2/repository/org/glassfish/corba/glassfish-corba-omgapi/4.2.2/glassfish-corba-omgapi-4.2.2.jar:/home/alex/.m2/repository/sqlline/sqlline/1.9.0/sqlline-1.9.0.jar:/home/alex/.m2/repository/org/jline/jline-terminal/3.12.1/jline-terminal-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-reader/3.12.1/jline-reader-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jansi/3.12.1/jline-terminal-jansi-3.12.1.jar:/home/alex/.m2/repository/org/fusesource/jansi/jansi/1.18/jansi-1.18.jar:/home/alex/.m2/repository/org/jline/jline-terminal-jna/3.12.1/jline-terminal-jna-3.12.1.jar:/home/alex/.m2/repository/net/java/dev/jna/jna/5.3.1/jna-5.3.1.jar:/home/alex/.m2/repository/org/jline/jline-builtins/3.12.1/jline-builtins-3.12.1.jar:/home/alex/.m2/repository/org/jline/jline-style/3.12.1/jline-style-3.12.1.jar:/home/alex/.m2/repository/com/cronutils/cron-utils/9.1.3/cron-utils-9.1.3.jar:/home/alex/.m2/repository/org/glassfish/javax.el/3.0.0/javax.el-3.0.0.jar:/home/alex/.m2/repository/com/oracle/database/jdbc/ojdbc8/21.3.0.0/ojdbc8-21.3.0.0.jar:/home/alex/.m2/repository/mysql/mysql-connector-java/8.0.27/mysql-connector-java-8.0.27.jar:/home/alex/.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre8/mssql-jdbc-6.2.1.jre8.jar:/home/alex/.m2/repository/org/postgresql/postgresql/42.2.14/postgresql-42.2.14.jar:/home/alex/Repositories/hive/common/target/test-classes:/home/alex/Repositories/hive/standalone-metastore/metastore-common/target/test-classes:/home/alex/.m2/repository/com/github/ben-manes/caffeine/caffeine/2.8.4/caffeine-2.8.4.jar:/home/alex/.m2/repository/org/checkerframework/checker-qual/3.4.0/checker-qual-3.4.0.jar:/home/alex/Repositories/hive/standalone-metastore/metastore-server/target/test-classes:/home/alex/.m2/repository/org/apache/parquet/parquet-column/1.11.1/parquet-column-1.11.1-tests.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-common/1.11.1/parquet-common-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-format-structures/1.11.1/parquet-format-structures-1.11.1.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-encoding/1.11.1/parquet-encoding-1.11.1.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.6.2/junit-jupiter-params-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/org/apache/tez/tez-api/0.10.1/tez-api-0.10.1.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-library/0.10.1/tez-runtime-library-0.10.1.jar:/home/alex/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.21/RoaringBitmap-0.5.21.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client/2.12.1/async-http-client-2.12.1.jar:/home/alex/.m2/repository/org/asynchttpclient/async-http-client-netty-utils/2.12.1/async-http-client-netty-utils-2.12.1.jar:/home/alex/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/alex/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.48.Final/netty-transport-native-kqueue-4.1.48.Final-osx-x86_64.jar:/home/alex/.m2/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/home/alex/.m2/repository/com/typesafe/netty/netty-reactive-streams/2.0.4/netty-reactive-streams-2.0.4.jar:/home/alex/.m2/repository/com/sun/activation/javax.activation/1.2.0/javax.activation-1.2.0.jar:/home/alex/.m2/repository/org/apache/tez/tez-common/0.10.1/tez-common-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-runtime-internals/0.10.1/tez-runtime-internals-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/hadoop-shim/0.10.1/hadoop-shim-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-mapreduce/0.10.1/tez-mapreduce-0.10.1.jar:/home/alex/.m2/repository/org/apache/tez/tez-dag/0.10.1/tez-dag-0.10.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.0/hadoop-yarn-server-web-proxy-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.0/hadoop-yarn-server-common-3.1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/alex/.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/home/alex/.m2/repository/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar:/home/alex/.m2/repository/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar:/home/alex/.m2/repository/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar:/home/alex/.m2/repository/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-client/3.1.0/hadoop-client-3.1.0.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.0/hadoop-mapreduce-client-jobclient-3.1.0.jar:/home/alex/.m2/repository/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar:/home/alex/.m2/repository/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar:/home/alex/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/alex/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/alex/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/alex/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/alex/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar:/home/alex/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar:/home/alex/.m2/repository/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/home/alex/.m2/repository/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar:/home/alex/.m2/repository/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar:/home/alex/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar:/home/alex/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/alex/.m2/repository/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar:/home/alex/.m2/repository/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar:/home/alex/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/alex/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/alex/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/alex/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/alex/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/alex/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4/2.0.2/powermock-module-junit4-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-module-junit4-common/2.0.2/powermock-module-junit4-common-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-reflect/2.0.2/powermock-reflect-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-core/2.0.2/powermock-core-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-mockito2/2.0.2/powermock-api-mockito2-2.0.2.jar:/home/alex/.m2/repository/org/powermock/powermock-api-support/2.0.2/powermock-api-support-2.0.2.jar:/home/alex/.m2/repository/com/google/guava/guava-testlib/19.0/guava-testlib-19.0.jar:/home/alex/.m2/repository/com/google/errorprone/error_prone_annotations/2.0.2/error_prone_annotations-2.0.2.jar:/home/alex/.m2/repository/com/google/re2j/re2j/1.2/re2j-1.2.jar:/home/alex/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/alex/.m2/repository/org/javassist/javassist/3.19.0-GA/javassist-3.19.0-GA.jar:/home/alex/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/alex/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/alex/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/alex/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/3.0.11/commons-compiler-3.0.11.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/3.0.11/janino-3.0.11.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-multipart/1.19/jersey-multipart-1.19.jar:/home/alex/.m2/repository/org/jvnet/mimepull/mimepull/1.9.3/mimepull-1.9.3.jar:/home/alex/.m2/repository/org/apache/kafka/kafka-clients/2.5.0/kafka-clients-2.5.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/alex/.m2/repository/org/mockito/mockito-core/3.4.4/mockito-core-3.4.4.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy/1.10.13/byte-buddy-1.10.13.jar:/home/alex/.m2/repository/net/bytebuddy/byte-buddy-agent/1.10.13/byte-buddy-agent-1.10.13.jar:/home/alex/Repositories/hive/ql/target/testconf:/home/alex/Repositories/hive/ql/../conf:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.security.krb5.conf" value="/home/alex/Repositories/hive/ql/target/testconf/krb5.conf"/>
    <property name="test.dfs.mkdir" value=""/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="1016066"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/ql/target/surefire/surefirebooter7913857915392230708.jar"/>
    <property name="hadoop.log.dir" value="/home/alex/Repositories/hive/ql/target/tmp"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="hive.test.console.log.level" value="INFO"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="maven.local.repository" value="/home/alex/.m2/repository"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/ql"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="user.language.format" value="pt"/>
    <property name="antlr.version" value="3.5.2"/>
    <property name="derby.version" value="10.14.1.0"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="test.output.overwrite" value=""/>
    <property name="java.class.version" value="52.0"/>
    <property name="hive.root" value="/home/alex/Repositories/hive/ql/../"/>
  </properties>
  <testcase name="testConcatenate" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="15.146">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTbl set b = 4 failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-out><![CDATA[log4j: Trying to find [log4j.xml] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7187bac9.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader org.apache.hadoop.hive.ql.exec.UDFClassLoader@7187bac9.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@330bedb4 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
]]></system-out>
    <system-err><![CDATA[SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.2/log4j-slf4j-impl-2.13.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/alex/.m2/repository/org/slf4j/slf4j-simple/1.7.27/slf4j-simple-1.7.27.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
DEBUG StatusLogger Took 0,071514 seconds to load 250 plugins from sun.misc.Launcher$AppClassLoader@330bedb4
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40]...
DEBUG StatusLogger Reconfiguration started for context[name=330bedb4] at URI null (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@3ad83a66
DEBUG StatusLogger Apache Log4j Core 2.13.2 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Installed 2 script engines
DEBUG StatusLogger Oracle Nashorn version: 1.8.0_402, language: ECMAScript, threading: Not Thread Safe, compile: true, names: [nashorn, Nashorn, js, JS, JavaScript, javascript, ECMAScript, ecmascript], factory class: jdk.nashorn.api.scripting.NashornScriptEngineFactory
DEBUG StatusLogger Groovy Scripting Engine version: 2.0, language: Groovy, threading: MULTITHREADED, compile: true, names: [groovy, Groovy], factory class: org.codehaus.groovy.jsr223.GroovyScriptEngineFactory
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/alex/Repositories/hive/common/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0,018909 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 132 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="/home/alex/Repositories/hive/ql/target/tmp/log")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG")
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO")
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/alex/Repositories/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="ERROR", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="INFO", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="WARN", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger createLogger(additivity="true", level="DEBUG", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger createLogger(additivity="null", level="DEBUG", includeLocation="null", ={DRFA, console}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(Replace=null, header="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", charset="null", alwaysWriteExceptions="null", Configuration(HiveLog4j2Test), footer="null", PatternSelector=null, noConsoleNoAnsi="null", disableAnsi="null")
DEBUG StatusLogger PluginManager 'Converter' found 46 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(follow="null", direct="null", target="SYSTEM_ERR", immediateFlush="null", bufferedIo="null", bufferSize="null", ignoreExceptions="null", Configuration(HiveLog4j2Test), PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", ={}, Filter=null)
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(footer="null", Replace=null, PatternSelector=null, Configuration(HiveLog4j2Test), noConsoleNoAnsi="null", pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", disableAnsi="null", alwaysWriteExceptions="null", header="null", charset="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(modulate="true", interval="1", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(min="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test), compressionLevel="null", max="30", fileIndex="null", ={}, stopCustomActionsOnError="null")
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(filePermissions="null", fileName="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log", fileGroup="null", append="null", DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", fileOwner="null", advertiseURI="null", filePattern="/home/alex/Repositories/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), bufferSize="null", immediateFlush="null", bufferedIo="null", name="DRFA", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), ignoreExceptions="null", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/alex/Repositories/hive/ql/target/tmp/log/hive.log seek to 2410535605
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/alex/Repositories/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2024-04-24T05:32:29.921-0700
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2024/04/24-05:32:56.341, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2024/04/25-00:00:00.000, nextFileTime=2024/04/24-00:00:00.000, prevFileTime=2024/04/24-00:00:00.000, current=2024/04/24-05:32:56.341, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@7139992f OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@548e6d58 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@7c1e2a2d
TRACE StatusLogger Reregistering context (1/1): '330bedb4' org.apache.logging.log4j.core.LoggerContext@6d60fe40
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=330bedb4,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=330bedb4] at URI /home/alex/Repositories/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@6d60fe40) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=330bedb4, org.apache.logging.log4j.core.LoggerContext@6d60fe40] started OK.
2024-04-24T05:32:56,472  INFO [main] conf.HiveConf: Found configuration file file:/home/alex/Repositories/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
2024-04-24T05:32:56,859  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-04-24T05:32:56,921  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T05:32:56,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T05:32:56,922  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T05:32:56,923  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T05:32:56,923  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T05:32:56,923  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T05:32:56,924  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T05:32:56,924  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T05:32:56,924  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T05:32:56,925  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T05:32:56,925  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T05:32:57,014  WARN [main] hikari.HikariConfig: HikariPool-1 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T05:32:57,020  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2024-04-24T05:32:57,549  INFO [main] pool.PoolBase: HikariPool-1 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T05:32:57,553  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2024-04-24T05:32:57,555  WARN [main] hikari.HikariConfig: HikariPool-2 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T05:32:57,559  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2024-04-24T05:32:57,563  INFO [main] pool.PoolBase: HikariPool-2 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T05:32:57,563  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2024-04-24T05:32:57,714  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2024-04-24T05:32:57,721  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/alex/Repositories/hive/ql/target/tmp/junit_metastore_db;create=true
Hive Session ID = 2b58cd71-2fc8-461f-9a4a-b6be2a359b14
2024-04-24T05:32:58,632  INFO [main] SessionState: Hive Session ID = 2b58cd71-2fc8-461f-9a4a-b6be2a359b14
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T05:32:58,643  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
2024-04-24T05:32:59,018  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/2b58cd71-2fc8-461f-9a4a-b6be2a359b14
2024-04-24T05:32:59,021  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14
2024-04-24T05:32:59,024  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/_tmp_space.db
2024-04-24T05:32:59,053  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2b58cd71-2fc8-461f-9a4a-b6be2a359b14, clientType=HIVECLI]
2024-04-24T05:32:59,088  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T05:32:59,212  INFO [main] metastore.HMSHandler: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T05:32:59,244  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T05:32:59,247  INFO [main] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2024-04-24T05:32:59,247  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
2024-04-24T05:32:59,249  WARN [main] hikari.HikariConfig: HikariPool-3 - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2024-04-24T05:32:59,252  INFO [main] hikari.HikariDataSource: HikariPool-3 - Starting...
2024-04-24T05:32:59,253  INFO [main] pool.PoolBase: HikariPool-3 - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2024-04-24T05:32:59,254  INFO [main] hikari.HikariDataSource: HikariPool-3 - Start completed.
2024-04-24T05:32:59,650  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2024-04-24T05:32:59,651  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64deb58f, with PersistenceManager: null will be shutdown
2024-04-24T05:32:59,678  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64deb58f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@38b3f208 created in the thread with id: 1
2024-04-24T05:33:01,780  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@64deb58f from thread id: 1
2024-04-24T05:33:01,795  INFO [main] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2024-04-24T05:33:01,821  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2024-04-24T05:33:01,867  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2024-04-24T05:33:01,889  INFO [main] metastore.HMSHandler: Added admin role in metastore
2024-04-24T05:33:01,892  INFO [main] metastore.HMSHandler: Added public role in metastore
2024-04-24T05:33:01,965  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2024-04-24T05:33:01,971  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service with frequency 60000ms.
2024-04-24T05:33:01,975  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service with frequency 300000ms.
2024-04-24T05:33:01,978  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service with frequency 86400000ms.
2024-04-24T05:33:01,979  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service with frequency 3600000ms.
2024-04-24T05:33:01,980  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.events.EventCleanerTask service with frequency 0ms.
2024-04-24T05:33:01,981  INFO [main] metastore.HMSHandler: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service with frequency 86400000ms.
2024-04-24T05:33:01,984  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2024-04-24T05:33:02,118  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T05:33:02,159  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T05:33:02,189  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9): drop table if exists acidTbl
2024-04-24T05:33:03,042  INFO [main] reflections.Reflections: Reflections took 194 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T05:33:03,199  INFO [main] reflections.Reflections: Reflections took 126 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T05:33:03,326  INFO [main] reflections.Reflections: Reflections took 121 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T05:33:03,356  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-24T05:33:03,368  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-24T05:33:03,379  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:03,521  INFO [main] reflections.Reflections: Reflections took 123 ms to scan 2 urls, producing 53 keys and 784 values 
2024-04-24T05:33:03,557  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,558  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,561  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,561  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, openTxn_(String, TxnType)=33, getValidTxns_(long)=7, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:03,562  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9); Time taken: 1.374 seconds
2024-04-24T05:33:03,564  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9
2024-04-24T05:33:03,564  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,567  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9): drop table if exists acidTbl
2024-04-24T05:33:03,570  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,571  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:03,589  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,589  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:03,589  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9); Time taken: 0.022 seconds
2024-04-24T05:33:03,589  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053302_e20ee6a5-5a8e-482a-8842-eb59394924e9
2024-04-24T05:33:03,600  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-24T05:33:03,615  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,617  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-24T05:33:03,619  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T05:33:03,619  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d): drop table if exists acidTblPart
2024-04-24T05:33:03,624  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-24T05:33:03,625  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-24T05:33:03,626  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:03,631  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,631  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,631  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,631  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=4, isCompatibleWith_(Configuration)=1, commitTxn_(CommitTxnRequest)=28, flushCache_()=0, getValidTxns_(long)=1}
2024-04-24T05:33:03,631  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d); Time taken: 0.012 seconds
2024-04-24T05:33:03,632  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d
2024-04-24T05:33:03,632  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,632  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d): drop table if exists acidTblPart
2024-04-24T05:33:03,632  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,633  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:03,639  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,639  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,639  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d); Time taken: 0.007 seconds
2024-04-24T05:33:03,639  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_f955dcee-d3f2-4f1e-8af2-64e74fa2ed6d
2024-04-24T05:33:03,647  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-24T05:33:03,659  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,660  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-24T05:33:03,661  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T05:33:03,662  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e): drop table if exists acidTbl2
2024-04-24T05:33:03,667  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-24T05:33:03,668  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-24T05:33:03,670  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T05:33:03,674  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,675  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,675  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,675  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=4, flushCache_()=0, getValidTxns_(long)=2, isCompatibleWith_(Configuration)=1, commitTxn_(CommitTxnRequest)=22}
2024-04-24T05:33:03,675  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e); Time taken: 0.013 seconds
2024-04-24T05:33:03,675  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e
2024-04-24T05:33:03,675  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,675  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e): drop table if exists acidTbl2
2024-04-24T05:33:03,676  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,676  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T05:33:03,680  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,680  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,680  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e); Time taken: 0.005 seconds
2024-04-24T05:33:03,681  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_20616881-701f-460d-a64b-37b2e982253e
2024-04-24T05:33:03,689  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-24T05:33:03,698  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,698  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-24T05:33:03,699  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T05:33:03,700  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:03,704  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-24T05:33:03,704  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-24T05:33:03,706  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:03,710  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,710  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,710  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,710  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=18, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, flushCache_()=0, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:03,710  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b); Time taken: 0.01 seconds
2024-04-24T05:33:03,711  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b
2024-04-24T05:33:03,711  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,711  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:03,711  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,712  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:03,716  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,716  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,716  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b); Time taken: 0.005 seconds
2024-04-24T05:33:03,716  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_98d527ab-97d9-40f2-b3f0-3c07c883313b
2024-04-24T05:33:03,724  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-24T05:33:03,734  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,735  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-24T05:33:03,736  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:03,736  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:03,740  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-24T05:33:03,741  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-24T05:33:03,743  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:03,747  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,747  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,748  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,748  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, flushCache_()=0, commitTxn_(CommitTxnRequest)=19, openTxn_(String, TxnType)=4, getValidTxns_(long)=1}
2024-04-24T05:33:03,748  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183); Time taken: 0.012 seconds
2024-04-24T05:33:03,749  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183
2024-04-24T05:33:03,749  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,749  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:03,749  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,750  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:03,754  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,754  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,754  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183); Time taken: 0.005 seconds
2024-04-24T05:33:03,755  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_a486bbf7-66b4-4d2f-8087-62ff7c72f183
2024-04-24T05:33:03,763  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-24T05:33:03,774  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,775  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-24T05:33:03,775  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T05:33:03,776  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78): drop table if exists nonAcidNonBucket
2024-04-24T05:33:03,780  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-24T05:33:03,781  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-24T05:33:03,782  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:03,787  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,787  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,787  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,787  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, openTxn_(String, TxnType)=4, commitTxn_(CommitTxnRequest)=20, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,787  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78); Time taken: 0.011 seconds
2024-04-24T05:33:03,787  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78
2024-04-24T05:33:03,787  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:03,788  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78): drop table if exists nonAcidNonBucket
2024-04-24T05:33:03,788  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:03,788  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:03,793  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:03,793  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:03,793  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78); Time taken: 0.005 seconds
2024-04-24T05:33:03,793  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_c7b676ce-71c3-464a-a193-f98c6b8b4f78
2024-04-24T05:33:03,802  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-24T05:33:03,811  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:03,811  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-24T05:33:03,812  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:03,812  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:03,887  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-24T05:33:03,887  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-24T05:33:03,889  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:03,891  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:03,908  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-24T05:33:03,965  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:03,976  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:03,976  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:03,976  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:03,976  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:03,977  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, flushCache_()=0, getValidTxns_(long)=0, isCompatibleWith_(Configuration)=2, getValidWriteIds_(List, String)=11, getDatabase_(String)=5, commitTxn_(CommitTxnRequest)=17}
2024-04-24T05:33:03,977  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96); Time taken: 0.164 seconds
2024-04-24T05:33:03,977  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96
2024-04-24T05:33:03,984  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96
2024-04-24T05:33:04,038  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T05:33:04,038  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,041  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,041  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,151  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713961984, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, numRows=0, rawDataSize=0, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=true, numFilesErasureCoded=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T05:33:04,163  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:04,290  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,290  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=140}
2024-04-24T05:33:04,291  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96); Time taken: 0.249 seconds
2024-04-24T05:33:04,291  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053303_dd1e755f-aa50-45ac-abfa-0066711f7b96
2024-04-24T05:33:04,299  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-24T05:33:04,309  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,310  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-24T05:33:04,310  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,311  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,318  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-24T05:33:04,318  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-24T05:33:04,320  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,320  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:04,323  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-24T05:33:04,324  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:04,326  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:04,327  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:04,327  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:04,327  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:04,327  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, getValidWriteIds_(List, String)=3, commitTxn_(CommitTxnRequest)=19, flushCache_()=0, getDatabase_(String)=2, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:04,327  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5); Time taken: 0.016 seconds
2024-04-24T05:33:04,328  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5
2024-04-24T05:33:04,328  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5
2024-04-24T05:33:04,357  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T05:33:04,357  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,358  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,358  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,360  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713961984, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{transactional=true, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T05:33:04,369  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart
2024-04-24T05:33:04,397  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,397  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=37, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:04,398  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5); Time taken: 0.039 seconds
2024-04-24T05:33:04,398  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_b8886e88-8bbc-4a13-bbb3-62a290aa90b5
2024-04-24T05:33:04,404  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-24T05:33:04,413  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,415  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-24T05:33:04,416  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,417  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,421  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 2
2024-04-24T05:33:04,421  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-24T05:33:04,423  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,423  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:04,427  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-24T05:33:04,427  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:04,429  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:04,429  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:04,430  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:04,430  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:04,430  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, commitTxn_(CommitTxnRequest)=18, openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getDatabase_(String)=2, getValidWriteIds_(List, String)=4, getValidTxns_(long)=1}
2024-04-24T05:33:04,430  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa); Time taken: 0.013 seconds
2024-04-24T05:33:04,430  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa
2024-04-24T05:33:04,431  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa
2024-04-24T05:33:04,460  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T05:33:04,460  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,460  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,460  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,462  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713961984, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, rawDataSize=0, totalSize=0, transactional=false, bucketing_version=2, numRows=0, numFilesErasureCoded=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:04,470  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidorctbl
2024-04-24T05:33:04,501  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,501  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=39}
2024-04-24T05:33:04,501  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa); Time taken: 0.041 seconds
2024-04-24T05:33:04,501  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_0c3b89c2-42bd-42fe-a160-72aadd3886aa
2024-04-24T05:33:04,507  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-24T05:33:04,515  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,516  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-24T05:33:04,516  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,517  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,521  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 2
2024-04-24T05:33:04,521  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-24T05:33:04,523  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,523  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:04,526  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-24T05:33:04,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:04,529  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:04,529  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:04,529  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:04,529  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:04,530  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getValidWriteIds_(List, String)=3, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=15, getDatabase_(String)=2}
2024-04-24T05:33:04,530  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e); Time taken: 0.012 seconds
2024-04-24T05:33:04,530  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e
2024-04-24T05:33:04,530  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e
2024-04-24T05:33:04,558  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T05:33:04,558  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,558  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,559  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,560  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713961984, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numRows=0, numFiles=0, rawDataSize=0, totalSize=0, numFilesErasureCoded=0, bucketing_version=2, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:04,568  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidorctbl2
2024-04-24T05:33:04,594  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,594  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, createTable_(Table)=34}
2024-04-24T05:33:04,594  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e); Time taken: 0.036 seconds
2024-04-24T05:33:04,594  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_98b5480a-351d-463d-aa62-d40ebd08c94e
2024-04-24T05:33:04,600  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-24T05:33:04,607  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,607  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-24T05:33:04,608  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,609  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,613  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 2
2024-04-24T05:33:04,613  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-24T05:33:04,614  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,615  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:04,618  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-24T05:33:04,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:04,621  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:04,621  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:04,621  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:04,621  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:04,621  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=0, commitTxn_(CommitTxnRequest)=13, getDatabase_(String)=3, isCompatibleWith_(Configuration)=2, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-24T05:33:04,621  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d); Time taken: 0.013 seconds
2024-04-24T05:33:04,621  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d
2024-04-24T05:33:04,622  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d
2024-04-24T05:33:04,647  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T05:33:04,647  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,648  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:04,648  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,650  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/_tmp_space.db/2521f571-a9ba-487b-ae7c-127dd9c879ea
2024-04-24T05:33:04,654  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,654  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=4, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:04,654  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d); Time taken: 0.006 seconds
2024-04-24T05:33:04,654  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_8c09e9eb-a46d-4894-b5b0-c4397eb9496d
2024-04-24T05:33:04,660  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-24T05:33:04,668  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,668  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-24T05:33:04,669  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,670  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,673  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 4
2024-04-24T05:33:04,674  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-24T05:33:04,675  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,675  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:04,679  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-24T05:33:04,679  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:04,681  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:04,681  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:04,681  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:04,682  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:04,682  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getDatabase_(String)=2, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=14, getValidWriteIds_(List, String)=4, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-24T05:33:04,682  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe); Time taken: 0.012 seconds
2024-04-24T05:33:04,682  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe
2024-04-24T05:33:04,682  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe
2024-04-24T05:33:04,708  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T05:33:04,708  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:04,708  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:04,708  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:04,710  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713961984, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, numRows=0, numFilesErasureCoded=0, rawDataSize=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, bucketing_version=2, transactional=false}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:04,718  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidnonbucket
2024-04-24T05:33:04,742  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:04,742  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=33, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:04,743  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe); Time taken: 0.034 seconds
2024-04-24T05:33:04,743  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_b96e63dd-661f-4864-b4d2-750df72dd9fe
2024-04-24T05:33:04,748  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-24T05:33:04,757  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:04,757  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-24T05:33:04,758  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Initializing local cache in HiveMetaStoreClient...
2024-04-24T05:33:04,785  INFO [main] metastore.HiveMetaStoreClientWithLocalCache: Local cache initialized in HiveMetaStoreClient: com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalManualCache@389008d1
2024-04-24T05:33:04,785  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTbl values(1,2),(4,5)
2024-04-24T05:33:04,785  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad): insert into acidTbl values(1,2),(4,5)
2024-04-24T05:33:04,792  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 7
2024-04-24T05:33:04,792  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-24T05:33:04,793  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:04,793  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:05,322  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,328  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,329  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,329  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,329  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,329  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,330  WARN [main] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2024-04-24T05:33:05,383  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:05,425  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:05,426  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T05:33:05,426  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:05,426  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:05,426  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:05,429  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:05,441  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:05,441  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T05:33:05,441  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-24T05:33:06,527  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T05:33:07,153  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:07,153  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:07,153  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:07,155  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T05:33:07,158  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:07,158  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:07,160  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:07,161  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:07,174  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:07,208  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-24T05:33:07,211  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-24T05:33:07,231  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-24T05:33:07,232  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtbl (txnIds: [13])
2024-04-24T05:33:07,239  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T05:33:07,289  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-24T05:33:07,290  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col0=Column[_col1]}
2024-04-24T05:33:07,298  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T05:33:07,309  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T05:33:07,341  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:07,354  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:07,384  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T05:33:07,390  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T05:33:07,391  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T05:33:07,391  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:07,391  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:07,392  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null)], properties:null)
2024-04-24T05:33:07,392  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:07,392  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, getNotNullConstraints_(NotNullConstraintsRequest)=3, flushCache_()=0, getTable_(GetTableRequest)=82, allocateTableWriteId_(long, String, String)=13, getValidWriteIds_(List, String)=7, getAllTableConstraints_(AllTableConstraintsRequest)=52, getCheckConstraints_(CheckConstraintsRequest)=3, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=14}
2024-04-24T05:33:07,392  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad); Time taken: 2.607 seconds
2024-04-24T05:33:07,393  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad
2024-04-24T05:33:07,393  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad
2024-04-24T05:33:07,423  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T05:33:07,423  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-24T05:33:07,427  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad): insert into acidTbl values(1,2),(4,5)
2024-04-24T05:33:07,427  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad
2024-04-24T05:33:07,427  INFO [main] ql.Driver: Query ID = alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad
Total jobs = 1
2024-04-24T05:33:07,427  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T05:33:07,427  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T05:33:07,596  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T05:33:07,596  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T05:33:07,596  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T05:33:07,596  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T05:33:07,596  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T05:33:07,596  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T05:33:07,596  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T05:33:07,596  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T05:33:07,604  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T05:33:07,607  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-24T05:33:07,608  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1/dummy_path
2024-04-24T05:33:07,676  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T05:33:07,698  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,27KB
2024-04-24T05:33:07,705  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T05:33:07,711  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T05:33:07,822  INFO [main] beanutils.FluentPropertyBeanIntrospector: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2024-04-24T05:33:07,836  WARN [main] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2024-04-24T05:33:07,851  INFO [main] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-04-24T05:33:07,851  INFO [main] impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-24T05:33:07,864  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1/-mr-10000
2024-04-24T05:33:07,876  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:07,920  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T05:33:07,928  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T05:33:07,935  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-24T05:33:07,935  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-24T05:33:07,935  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1/dummy_path
2024-04-24T05:33:07,935  INFO [main] io.NullRowsInputFormat$NullRowsRecordReader: Using null rows input format
2024-04-24T05:33:07,941  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T05:33:07,973  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T05:33:08,083  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1061460252_0001
2024-04-24T05:33:08,083  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T05:33:08,221  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T05:33:08,222  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T05:33:08,223  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T05:33:08,224  INFO [Thread-72] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T05:33:08,237  INFO [Thread-72] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T05:33:08,240  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1061460252_0001_m_000000_0
2024-04-24T05:33:08,283  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T05:33:08,292  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1/dummy_path/null:0+1
2024-04-24T05:33:08,298  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T05:33:08,323  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,27KB
2024-04-24T05:33:08,331  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T05:33:08,344  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T05:33:08,344  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T05:33:08,344  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T05:33:08,345  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T05:33:08,345  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T05:33:08,347  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T05:33:08,351  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T05:33:08,353  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T05:33:08,355  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T05:33:08,355  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T05:33:08,358  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T05:33:08,358  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-24T05:33:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-24T05:33:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int>
2024-04-24T05:33:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[4]
2024-04-24T05:33:08,359  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T05:33:08,377  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [reducesinkkey0] num distributions: 1
2024-04-24T05:33:08,378  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: records written - 1
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_INTERMEDIATE:0, DESERIALIZE_ERRORS:0, RECORDS_OUT_OPERATOR_MAP_0:0, RECORDS_IN:3, 
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T05:33:08,379  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_UDTF_2:2, 
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_3:2, 
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[4]
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[4]: Total records written - 2. abort - false
2024-04-24T05:33:08,380  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:2, RECORDS_OUT_OPERATOR_RS_4:2, 
2024-04-24T05:33:08,386  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T05:33:08,386  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T05:33:08,386  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T05:33:08,386  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 32; bufvoid = 104857600
2024-04-24T05:33:08,386  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-24T05:33:08,402  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T05:33:08,413  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1061460252_0001_m_000000_0 is done. And is in the process of committing
2024-04-24T05:33:08,415  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T05:33:08,415  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1061460252_0001_m_000000_0' done.
2024-04-24T05:33:08,417  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1061460252_0001_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=5734
		FILE: Number of bytes written=1188092
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=32
		Map output materialized bytes=48
		Input split bytes=360
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=956301312
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_4=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5330
2024-04-24T05:33:08,417  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1061460252_0001_m_000000_0
2024-04-24T05:33:08,417  INFO [Thread-72] mapred.LocalJobRunner: map task executor complete.
2024-04-24T05:33:08,422  INFO [Thread-72] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T05:33:08,422  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1061460252_0001_r_000000_0
2024-04-24T05:33:08,429  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T05:33:08,431  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35751e8b
2024-04-24T05:33:08,433  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:08,447  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T05:33:08,449  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1061460252_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T05:33:08,474  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1061460252_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T05:33:08,476  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1061460252_0001_m_000000_0
2024-04-24T05:33:08,478  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T05:33:08,479  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T05:33:08,479  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:08,479  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T05:33:08,491  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:08,491  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T05:33:08,494  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T05:33:08,494  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T05:33:08,495  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T05:33:08,495  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:08,495  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T05:33:08,496  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:08,498  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T05:33:08,501  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T05:33:08,502  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T05:33:08,502  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-24T05:33:08,502  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-24T05:33:08,502  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T05:33:08,503  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@6bbedca6, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1061460252_0001/job_local1061460252_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@45223a4d
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_5:0, 
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 0
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:08,507  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:08,508  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse
2024-04-24T05:33:08,531  INFO [pool-8-thread-1] exec.FileSinkOperator: TOTAL_TABLE_ROWS_WRITTEN:0, RECORDS_OUT_1_default.acidtbl:0, RECORDS_OUT_OPERATOR_FS_6:0, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T05:33:08,531  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1061460252_0001_r_000000_0 is done. And is in the process of committing
2024-04-24T05:33:08,532  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T05:33:08,532  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1061460252_0001_r_000000_0' done.
2024-04-24T05:33:08,533  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1061460252_0001_r_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=11814
		FILE: Number of bytes written=1188151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=956301312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T05:33:08,533  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1061460252_0001_r_000000_0
2024-04-24T05:33:08,533  INFO [pool-8-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1061460252_0001_r_000001_0
2024-04-24T05:33:08,534  INFO [pool-8-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T05:33:08,534  INFO [pool-8-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6774e5ee
2024-04-24T05:33:08,534  WARN [pool-8-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:08,536  INFO [pool-8-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T05:33:08,537  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1061460252_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T05:33:08,540  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1061460252_0001_m_000000_0 decomp: 38 len: 42 to MEMORY
2024-04-24T05:33:08,540  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 38 bytes from map-output for attempt_local1061460252_0001_m_000000_0
2024-04-24T05:33:08,540  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->38
2024-04-24T05:33:08,541  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T05:33:08,541  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:08,541  INFO [pool-8-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T05:33:08,549  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:08,549  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-24T05:33:08,551  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 38 bytes to disk to satisfy reduce memory limit
2024-04-24T05:33:08,552  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 1 files, 42 bytes from disk
2024-04-24T05:33:08,552  INFO [pool-8-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T05:33:08,552  INFO [pool-8-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:08,552  INFO [pool-8-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
2024-04-24T05:33:08,552  INFO [pool-8-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:08,553  INFO [pool-8-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T05:33:08,555  INFO [pool-8-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,91KB
2024-04-24T05:33:08,556  INFO [pool-8-thread-1] ExecReducer: 
<SEL>Id =5
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 5 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T05:33:08,556  INFO [pool-8-thread-1] exec.SelectOperator: Initializing Operator: SEL[5]
2024-04-24T05:33:08,557  INFO [pool-8-thread-1] exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:int>,value:struct<_col0:int>>
2024-04-24T05:33:08,557  INFO [pool-8-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T05:33:08,557  INFO [pool-8-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@6bbedca6, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local1061460252_0001/job_local1061460252_0001.xml], properties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtbl, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, numFilesErasureCoded=0, columns.comments=&amp#0;, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@379fb7c
2024-04-24T05:33:08,558  INFO [pool-8-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:08,558  INFO [pool-8-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:08,558  INFO [pool-8-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse
2024-04-24T05:33:08,559  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-24T05:33:08,571  INFO [pool-8-thread-1] impl.HadoopShimsPre2_7: Can't get KeyProvider for ORC encryption from hadoop.security.key.provider.path.
2024-04-24T05:33:08,575  INFO [pool-8-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T05:33:08,622  INFO [pool-8-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T05:33:08,635  INFO [pool-8-thread-1] exec.SelectOperator: Closing Operator: SEL[5]
2024-04-24T05:33:08,636  INFO [pool-8-thread-1] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_5:2, 
2024-04-24T05:33:08,636  INFO [pool-8-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T05:33:08,636  INFO [pool-8-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-24T05:33:08,673  INFO [pool-8-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-24T05:33:08,686  INFO [pool-8-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.acidtbl:2, RECORDS_OUT_INTERMEDIATE:0, TOTAL_TABLE_ROWS_WRITTEN:2, RECORDS_OUT_OPERATOR_FS_6:2, 
2024-04-24T05:33:08,687  INFO [pool-8-thread-1] mapred.Task: Task:attempt_local1061460252_0001_r_000001_0 is done. And is in the process of committing
2024-04-24T05:33:08,688  INFO [pool-8-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T05:33:08,688  INFO [pool-8-thread-1] mapred.Task: Task 'attempt_local1061460252_0001_r_000001_0' done.
2024-04-24T05:33:08,688  INFO [pool-8-thread-1] mapred.Task: Final Counters for attempt_local1061460252_0001_r_000001_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=17924
		FILE: Number of bytes written=1189236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=42
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=956301312
	HIVE
		CREATED_FILES=1
		RECORDS_OUT_1_default.acidtbl=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_5=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T05:33:08,688  INFO [pool-8-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1061460252_0001_r_000001_0
2024-04-24T05:33:08,688  INFO [Thread-72] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 05:33:09,241 Stage-1 map = 100%,  reduce = 100%
2024-04-24T05:33:09,242  INFO [main] exec.Task: 2024-04-24 05:33:09,241 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1061460252_0001
2024-04-24T05:33:09,246  INFO [main] exec.Task: Ended Job = job_local1061460252_0001
2024-04-24T05:33:09,248  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest with attemptId 0.
2024-04-24T05:33:09,248  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000/000001_0.manifest
2024-04-24T05:33:09,250  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl/_tmp.delta_0000001_0000001_0000
2024-04-24T05:33:09,252  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtbl
2024-04-24T05:33:09,253  INFO [main] exec.Task: Loading data to table default.acidtbl from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:09,253  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,265  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,265  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,276  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,277  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-24T05:33:09,338  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T05:33:09,339  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,350  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,350  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T05:33:09,350  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1/-mr-10000
2024-04-24T05:33:09,355  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,365  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,382  WARN [main] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T05:33:09,382  INFO [main] FileOperations: Read stats for default.acidtbl/, numRows, true, 2, false: 
2024-04-24T05:33:09,382  INFO [main] FileOperations: Read stats for default.acidtbl/, rawDataSize, true, 0, false: 
2024-04-24T05:33:09,383  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: hive.default.acidtbl newtbl=acidtbl	
2024-04-24T05:33:09,416  INFO [main] FileOperations: Read stats for default.acidtbl/, insertCount, true, 2, false: 
2024-04-24T05:33:09,416  INFO [main] FileOperations: Read stats for default.acidtbl/, updateCount, true, 0, false: 
2024-04-24T05:33:09,416  INFO [main] FileOperations: Read stats for default.acidtbl/, deleteCount, true, 0, false: 
2024-04-24T05:33:09,419  INFO [main] stats.BasicStatsTask: Table default.acidtbl stats: [numFiles=1, numRows=2, totalSize=699, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T05:33:09,420  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:09,420  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {alter_table_(String, String, String, Table, EnvironmentContext, String)=91, getTable_(GetTableRequest)=47, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=3, isCompatibleWith_(Configuration)=0}
MapReduce Jobs Launched: 
2024-04-24T05:33:09,420  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T05:33:09,426  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T05:33:09,426  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T05:33:09,427  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad); Time taken: 1.993 seconds
2024-04-24T05:33:09,427  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053304_0a262231-b2b8-4c05-bab1-05d130ac2aad
2024-04-24T05:33:09,439  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:09,441  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-24T05:33:09,442  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTbl set b = 4
2024-04-24T05:33:09,442  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1
2024-04-24T05:33:09,443  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/2b58cd71-2fc8-461f-9a4a-b6be2a359b14/hive_2024-04-24_05-33-04_785_415800944933556856-1 on fs with scheme file
2024-04-24T05:33:09,444  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053309_14819c21-ffec-4889-a273-950e1d7c11b4): update acidTbl set b = 4
2024-04-24T05:33:09,457  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-24T05:33:09,457  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-24T05:33:09,461  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-24T05:33:09,461  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,472  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,472  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTbl set b = 4> as 
<insert into table `default`.`acidTbl` select ROW__ID,`a`,`b` from `default`.`acidTbl` sort by ROW__ID >
2024-04-24T05:33:09,475  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T05:33:09,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,491  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,491  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T05:33:09,491  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T05:33:09,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,503  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,504  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T05:33:09,504  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T05:33:09,504  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,516  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,516  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T05:33:09,516  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-24T05:33:09,531  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,542  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,544  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,688  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtbl, projIndxSet: [0], allowMissingStats: true
2024-04-24T05:33:09,695  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,710  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,711  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtbl	
2024-04-24T05:33:09,726  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,727  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table_statistics_req: table=hive.default.acidtbl	
2024-04-24T05:33:09,750  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtbl, Columns: a
No Stats for default@acidtbl, Columns: a
2024-04-24T05:33:09,750  INFO [main] SessionState: No Stats for default@acidtbl, Columns: a
2024-04-24T05:33:09,839  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T05:33:09,840  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T05:33:09,840  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T05:33:09,840  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,851  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,859 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T05:33:09,860 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-24T05:33:09,860  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T05:33:09,861 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenate(TestTxnConcatenate.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T05:33:09,862  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:09,862  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=12, getValidTxns_(long)=3, getAllTableConstraints_(AllTableConstraintsRequest)=7, flushCache_()=0, getTable_(GetTableRequest)=57, getNotNullConstraints_(NotNullConstraintsRequest)=1, commitTxn_(CommitTxnRequest)=15, getCheckConstraints_(CheckConstraintsRequest)=1, getValidWriteIds_(List, String)=5, getTableColumnStatistics_(String, String, List, String)=53, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:09,862  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053309_14819c21-ffec-4889-a273-950e1d7c11b4); Time taken: 0.419 seconds
2024-04-24T05:33:09,863  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-24T05:33:09,867  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:09,878  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T05:33:09,878  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74): drop table if exists acidTbl
2024-04-24T05:33:09,882  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-24T05:33:09,883  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-24T05:33:09,884  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,895  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,895  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:09,895  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:09,895  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:09,895  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, rollbackTxn_(long)=13, openTxn_(String, TxnType)=3, getTable_(GetTableRequest)=11, flushCache_()=0}
2024-04-24T05:33:09,895  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74); Time taken: 0.017 seconds
2024-04-24T05:33:09,896  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74
2024-04-24T05:33:09,896  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74
2024-04-24T05:33:09,921  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74 LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T05:33:09,921  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:09,921  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74): drop table if exists acidTbl
2024-04-24T05:33:09,921  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:09,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,932  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,932  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:09,945  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:09,945  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:10,170  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,170  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=237, getTable_(GetTableRequest)=11}
2024-04-24T05:33:10,170  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74); Time taken: 0.248 seconds
2024-04-24T05:33:10,170  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053309_f6b9427e-4994-41b1-91bb-57dd466a9c74
2024-04-24T05:33:10,176  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-24T05:33:10,185  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,186  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-24T05:33:10,187  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T05:33:10,187  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a): drop table if exists acidTblPart
2024-04-24T05:33:10,192  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-24T05:33:10,192  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-24T05:33:10,195  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:10,238  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,238  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,238  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,238  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,238  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=16, isCompatibleWith_(Configuration)=1, flushCache_()=1, openTxn_(String, TxnType)=4, getTable_(GetTableRequest)=44}
2024-04-24T05:33:10,239  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a); Time taken: 0.051 seconds
2024-04-24T05:33:10,239  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a
2024-04-24T05:33:10,239  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a
2024-04-24T05:33:10,274  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T05:33:10,275  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:10,275  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a): drop table if exists acidTblPart
2024-04-24T05:33:10,275  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,275  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:10,287  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,288  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:10,303  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,303  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:10,376  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,377  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13, dropTable_(String, String, boolean, boolean, boolean)=88}
2024-04-24T05:33:10,377  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a); Time taken: 0.101 seconds
2024-04-24T05:33:10,377  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_d2605a6b-bf9d-4431-a09c-0574a7090a1a
2024-04-24T05:33:10,384  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-24T05:33:10,392  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,393  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-24T05:33:10,393  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T05:33:10,394  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052): drop table if exists acidTbl2
2024-04-24T05:33:10,398  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-24T05:33:10,398  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-24T05:33:10,400  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,400  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,400  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,400  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, flushCache_()=0, isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=16, getTable_(GetTableRequest)=1}
2024-04-24T05:33:10,400  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052); Time taken: 0.006 seconds
2024-04-24T05:33:10,400  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052
2024-04-24T05:33:10,401  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:10,401  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052): drop table if exists acidTbl2
2024-04-24T05:33:10,401  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,402  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-24T05:33:10,402  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,402  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=1, getTable_(GetTableRequest)=0, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:10,403  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052); Time taken: 0.001 seconds
2024-04-24T05:33:10,403  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_33db5384-c24b-4fe9-be34-8f9410cff052
2024-04-24T05:33:10,410  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-24T05:33:10,417  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,417  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-24T05:33:10,418  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T05:33:10,418  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:10,422  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 14
2024-04-24T05:33:10,422  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-24T05:33:10,424  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:10,454  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,454  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,454  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,454  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,455  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, flushCache_()=0, commitTxn_(CommitTxnRequest)=15, getValidTxns_(long)=1, getTable_(GetTableRequest)=31, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:10,455  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3); Time taken: 0.036 seconds
2024-04-24T05:33:10,455  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3
2024-04-24T05:33:10,456  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3
2024-04-24T05:33:10,477  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3 LockResponse(lockid:10, state:ACQUIRED)
2024-04-24T05:33:10,477  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:10,477  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:10,478  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,478  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:10,492  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:10,505  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,505  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:10,566  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,566  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=14, dropTable_(String, String, boolean, boolean, boolean)=74}
2024-04-24T05:33:10,567  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3); Time taken: 0.089 seconds
2024-04-24T05:33:10,567  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_c6bbfc6e-a256-465e-b492-a7473b238dc3
2024-04-24T05:33:10,572  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-24T05:33:10,579  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,579  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-24T05:33:10,580  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:10,580  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:10,583  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-24T05:33:10,583  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-24T05:33:10,584  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:10,595  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,596  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,596  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,596  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,596  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, openTxn_(String, TxnType)=2, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=11, flushCache_()=0}
2024-04-24T05:33:10,596  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f); Time taken: 0.016 seconds
2024-04-24T05:33:10,596  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f
2024-04-24T05:33:10,597  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f
2024-04-24T05:33:10,618  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f LockResponse(lockid:11, state:ACQUIRED)
2024-04-24T05:33:10,618  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:10,618  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:10,618  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,619  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:10,632  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,633  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:10,647  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,647  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:10,696  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,696  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=63, getTable_(GetTableRequest)=15}
2024-04-24T05:33:10,696  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f); Time taken: 0.078 seconds
2024-04-24T05:33:10,696  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_c8425aa9-fe4e-4d06-b8ab-ad5dae02066f
2024-04-24T05:33:10,701  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-24T05:33:10,710  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,710  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-24T05:33:10,711  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T05:33:10,712  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6): drop table if exists nonAcidNonBucket
2024-04-24T05:33:10,715  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-24T05:33:10,716  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-24T05:33:10,717  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:10,732  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,732  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,732  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,732  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,732  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {flushCache_()=0, getTable_(GetTableRequest)=15, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=15}
2024-04-24T05:33:10,732  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6); Time taken: 0.02 seconds
2024-04-24T05:33:10,733  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6
2024-04-24T05:33:10,733  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6
2024-04-24T05:33:10,753  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6 LockResponse(lockid:12, state:ACQUIRED)
2024-04-24T05:33:10,753  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:10,753  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6): drop table if exists nonAcidNonBucket
2024-04-24T05:33:10,753  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,753  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:10,767  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,767  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:10,781  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:10,781  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:10,834  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,834  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=66, getTable_(GetTableRequest)=14}
2024-04-24T05:33:10,834  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6); Time taken: 0.081 seconds
2024-04-24T05:33:10,834  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_c22e69a3-1a8a-42af-abba-cd3e78a923b6
2024-04-24T05:33:10,839  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-24T05:33:10,847  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,847  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-24T05:33:10,848  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenatePart" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="3.995">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update acidTblPart set b = 4 where p='p1' failed: (responseCode = 40000, errorMessage = FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  , hiveErrorCode = 40000, SQLState = 42000, exception = No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:247)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
]]></error>
    <system-err><![CDATA[2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T05:33:10,943  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T05:33:10,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T05:33:10,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T05:33:10,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T05:33:10,946  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
Hive Session ID = 0214fd12-5bb2-4c13-80cb-f053f4585e42
2024-04-24T05:33:10,949  INFO [main] SessionState: Hive Session ID = 0214fd12-5bb2-4c13-80cb-f053f4585e42
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T05:33:10,949  INFO [main] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/alex/Repositories/hive/conf/ivysettings.xml will be used
2024-04-24T05:33:10,955  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/0214fd12-5bb2-4c13-80cb-f053f4585e42
2024-04-24T05:33:10,958  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42
2024-04-24T05:33:10,960  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/0214fd12-5bb2-4c13-80cb-f053f4585e42/_tmp_space.db
2024-04-24T05:33:10,960  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=0214fd12-5bb2-4c13-80cb-f053f4585e42, clientType=HIVECLI]
2024-04-24T05:33:10,961  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T05:33:10,961  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d): drop table if exists acidTbl
2024-04-24T05:33:10,971  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2024-04-24T05:33:10,971  INFO [main] lockmgr.DbTxnManager: Opened txnid:1
2024-04-24T05:33:10,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:10,977  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:10,977  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:10,977  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:10,977  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=9, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=2, commitTxn_(CommitTxnRequest)=13, flushCache_()=0}
2024-04-24T05:33:10,978  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d); Time taken: 0.016 seconds
2024-04-24T05:33:10,978  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d
2024-04-24T05:33:10,978  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:10,978  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d): drop table if exists acidTbl
2024-04-24T05:33:10,978  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:10,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:10,982  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:10,982  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:10,983  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d); Time taken: 0.004 seconds
2024-04-24T05:33:10,983  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_d89a11cb-decb-4306-a155-07ec542fbe4d
2024-04-24T05:33:10,989  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2024-04-24T05:33:10,995  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:10,996  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2024-04-24T05:33:10,997  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T05:33:10,997  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e): drop table if exists acidTblPart
2024-04-24T05:33:11,000  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2024-04-24T05:33:11,001  INFO [main] lockmgr.DbTxnManager: Opened txnid:2
2024-04-24T05:33:11,001  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:11,005  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,005  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,005  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,005  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, flushCache_()=0, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=0, openTxn_(String, TxnType)=2}
2024-04-24T05:33:11,005  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e); Time taken: 0.008 seconds
2024-04-24T05:33:11,005  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:2 for queryId=alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e
2024-04-24T05:33:11,005  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:11,005  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e): drop table if exists acidTblPart
2024-04-24T05:33:11,006  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,006  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:11,009  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,010  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,010  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e); Time taken: 0.004 seconds
2024-04-24T05:33:11,010  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053310_925caab6-68d1-46ad-9520-086d7060892e
2024-04-24T05:33:11,016  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2024-04-24T05:33:11,023  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,023  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2024-04-24T05:33:11,024  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T05:33:11,024  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725): drop table if exists acidTbl2
2024-04-24T05:33:11,027  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2024-04-24T05:33:11,027  INFO [main] lockmgr.DbTxnManager: Opened txnid:3
2024-04-24T05:33:11,028  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T05:33:11,032  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,032  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,032  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,032  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=14, flushCache_()=0, openTxn_(String, TxnType)=2, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=0}
2024-04-24T05:33:11,032  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725); Time taken: 0.008 seconds
2024-04-24T05:33:11,033  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:3 for queryId=alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725
2024-04-24T05:33:11,033  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:11,033  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725): drop table if exists acidTbl2
2024-04-24T05:33:11,033  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,033  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl2	
2024-04-24T05:33:11,037  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,037  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,037  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725); Time taken: 0.004 seconds
2024-04-24T05:33:11,037  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_bea01bfa-016d-46fc-a29e-521b62e88725
2024-04-24T05:33:11,042  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2024-04-24T05:33:11,048  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,049  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2024-04-24T05:33:11,049  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T05:33:11,050  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:11,052  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4]) with min_open_txn: 1
2024-04-24T05:33:11,053  INFO [main] lockmgr.DbTxnManager: Opened txnid:4
2024-04-24T05:33:11,054  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:11,057  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,057  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,057  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,057  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=12, getValidTxns_(long)=0, flushCache_()=0}
2024-04-24T05:33:11,057  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4); Time taken: 0.008 seconds
2024-04-24T05:33:11,058  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:4 for queryId=alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4
2024-04-24T05:33:11,058  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:11,058  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:11,058  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,058  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:11,062  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,062  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,062  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4); Time taken: 0.004 seconds
2024-04-24T05:33:11,062  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_316ff70e-a2a8-4436-ad83-cda884537ee4
2024-04-24T05:33:11,068  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2024-04-24T05:33:11,075  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,075  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2024-04-24T05:33:11,076  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:11,076  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:11,079  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([5]) with min_open_txn: 1
2024-04-24T05:33:11,079  INFO [main] lockmgr.DbTxnManager: Opened txnid:5
2024-04-24T05:33:11,080  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:11,084  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,084  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,084  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,084  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, openTxn_(String, TxnType)=2, flushCache_()=0, isCompatibleWith_(Configuration)=0, getValidTxns_(long)=0}
2024-04-24T05:33:11,084  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c); Time taken: 0.008 seconds
2024-04-24T05:33:11,084  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:5 for queryId=alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c
2024-04-24T05:33:11,084  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:11,084  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:11,085  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,085  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:11,088  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,089  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,089  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c); Time taken: 0.004 seconds
2024-04-24T05:33:11,089  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_d3e7953c-e38f-44d4-8e3e-e2fddae1804c
2024-04-24T05:33:11,095  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2024-04-24T05:33:11,102  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,103  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2024-04-24T05:33:11,103  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T05:33:11,104  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14): drop table if exists nonAcidNonBucket
2024-04-24T05:33:11,107  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([6]) with min_open_txn: 1
2024-04-24T05:33:11,107  INFO [main] lockmgr.DbTxnManager: Opened txnid:6
2024-04-24T05:33:11,108  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:11,112  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,112  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,112  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,112  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=14, flushCache_()=0, openTxn_(String, TxnType)=3}
2024-04-24T05:33:11,112  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14); Time taken: 0.008 seconds
2024-04-24T05:33:11,112  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:6 for queryId=alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14
2024-04-24T05:33:11,112  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:11,113  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14): drop table if exists nonAcidNonBucket
2024-04-24T05:33:11,113  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,113  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:11,117  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,117  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,117  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14); Time taken: 0.004 seconds
2024-04-24T05:33:11,117  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_da714d68-600e-4670-bce9-13616cd9fb14
2024-04-24T05:33:11,123  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2024-04-24T05:33:11,131  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,131  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2024-04-24T05:33:11,132  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,132  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,136  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([7]) with min_open_txn: 1
2024-04-24T05:33:11,136  INFO [main] lockmgr.DbTxnManager: Opened txnid:7
2024-04-24T05:33:11,137  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,137  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,144  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl position=13
2024-04-24T05:33:11,144  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,146  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,146  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,146  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,146  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,147  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, getValidWriteIds_(List, String)=7, getDatabase_(String)=2, flushCache_()=0, openTxn_(String, TxnType)=3, commitTxn_(CommitTxnRequest)=14, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,147  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226); Time taken: 0.014 seconds
2024-04-24T05:33:11,147  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:7 for queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226
2024-04-24T05:33:11,147  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226
2024-04-24T05:33:11,172  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T05:33:11,172  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,173  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226): create table acidTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,173  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,174  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTbl, dbName:default, owner:alex, createTime:1713961991, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, numFilesErasureCoded=0, totalSize=0, numFiles=0, numRows=0, transactional=true, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T05:33:11,182  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtbl
2024-04-24T05:33:11,233  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,233  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=59, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,233  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226); Time taken: 0.06 seconds
2024-04-24T05:33:11,234  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_b0afed35-b489-4fb4-91a4-72a7cfb1b226
2024-04-24T05:33:11,238  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2024-04-24T05:33:11,246  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,249  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2024-04-24T05:33:11,249  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,250  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,253  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([8]) with min_open_txn: 1
2024-04-24T05:33:11,254  INFO [main] lockmgr.DbTxnManager: Opened txnid:8
2024-04-24T05:33:11,255  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,255  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,258  INFO [main] parse.CalcitePlanner: Creating table default.acidTblPart position=13
2024-04-24T05:33:11,258  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,260  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,260  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,260  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,260  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,261  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=15, getDatabase_(String)=2, isCompatibleWith_(Configuration)=0, flushCache_()=0, getValidTxns_(long)=1, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=3}
2024-04-24T05:33:11,261  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c); Time taken: 0.01 seconds
2024-04-24T05:33:11,261  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:8 for queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c
2024-04-24T05:33:11,261  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c
2024-04-24T05:33:11,280  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T05:33:11,280  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,281  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c): create table acidTblPart(a int, b int) partitioned by (p string) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,282  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,283  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:acidTblPart, dbName:default, owner:alex, createTime:1713961991, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:string, comment:null)], parameters:{bucketing_version=2, transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER, writeId:0)	
2024-04-24T05:33:11,290  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart
2024-04-24T05:33:11,311  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,311  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=29, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,311  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c); Time taken: 0.03 seconds
2024-04-24T05:33:11,311  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_a459ffcf-1ac8-44d4-9b22-17f654715d0c
2024-04-24T05:33:11,316  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2024-04-24T05:33:11,323  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,324  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2024-04-24T05:33:11,324  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,325  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,328  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([9]) with min_open_txn: 1
2024-04-24T05:33:11,328  INFO [main] lockmgr.DbTxnManager: Opened txnid:9
2024-04-24T05:33:11,329  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,329  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,332  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl position=13
2024-04-24T05:33:11,332  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,334  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,334  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,334  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,334  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,334  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, getValidWriteIds_(List, String)=3, isCompatibleWith_(Configuration)=2, commitTxn_(CommitTxnRequest)=12, getDatabase_(String)=2, flushCache_()=0, openTxn_(String, TxnType)=2}
2024-04-24T05:33:11,334  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d); Time taken: 0.009 seconds
2024-04-24T05:33:11,335  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:9 for queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d
2024-04-24T05:33:11,335  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d
2024-04-24T05:33:11,352  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T05:33:11,353  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,353  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d): create table nonAcidOrcTbl(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,353  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,354  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl, dbName:default, owner:alex, createTime:1713961991, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=0, transactional=false, bucketing_version=2, rawDataSize=0, numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, numFiles=0, numFilesErasureCoded=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:11,361  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidorctbl
2024-04-24T05:33:11,382  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,382  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=28, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,382  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d); Time taken: 0.029 seconds
2024-04-24T05:33:11,382  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_a0de9541-90b2-4358-bd23-b197238d343d
2024-04-24T05:33:11,387  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2024-04-24T05:33:11,394  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,395  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2024-04-24T05:33:11,395  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,396  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,399  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([10]) with min_open_txn: 1
2024-04-24T05:33:11,399  INFO [main] lockmgr.DbTxnManager: Opened txnid:10
2024-04-24T05:33:11,400  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,400  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,403  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidOrcTbl2 position=13
2024-04-24T05:33:11,403  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,405  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,405  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,405  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,405  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,405  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=2, flushCache_()=0, openTxn_(String, TxnType)=2, commitTxn_(CommitTxnRequest)=13, getValidTxns_(long)=1, isCompatibleWith_(Configuration)=0, getDatabase_(String)=2}
2024-04-24T05:33:11,405  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030); Time taken: 0.009 seconds
2024-04-24T05:33:11,406  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:10 for queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030
2024-04-24T05:33:11,406  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030
2024-04-24T05:33:11,424  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T05:33:11,424  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,424  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030): create table nonAcidOrcTbl2(a int, b int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,424  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,426  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidOrcTbl2, dbName:default, owner:alex, createTime:1713961991, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[a], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{bucketing_version=2, numFiles=0, numFilesErasureCoded=0, rawDataSize=0, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:11,433  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidorctbl2
2024-04-24T05:33:11,454  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,454  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=29, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,455  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030); Time taken: 0.03 seconds
2024-04-24T05:33:11,455  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_070b9dfb-7ebc-46ec-a2de-6d957d99b030
2024-04-24T05:33:11,459  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2024-04-24T05:33:11,467  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,468  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2024-04-24T05:33:11,468  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,469  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,472  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11]) with min_open_txn: 1
2024-04-24T05:33:11,472  INFO [main] lockmgr.DbTxnManager: Opened txnid:11
2024-04-24T05:33:11,473  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,473  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,476  INFO [main] parse.CalcitePlanner: Creating table default.acidTbl2 position=24
2024-04-24T05:33:11,477  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,479  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,479  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,479  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,479  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,479  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidWriteIds_(List, String)=3, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, flushCache_()=0, commitTxn_(CommitTxnRequest)=13, getDatabase_(String)=2, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,480  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019); Time taken: 0.01 seconds
2024-04-24T05:33:11,480  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:11 for queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019
2024-04-24T05:33:11,480  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019
2024-04-24T05:33:11,499  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T05:33:11,499  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,500  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019): create temporary  table acidTbl2(a int, b int, c int) clustered by (c) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T05:33:11,500  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,502  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/scratchdir/alex/0214fd12-5bb2-4c13-80cb-f053f4585e42/_tmp_space.db/90011ade-694d-46a4-a5f0-35b510c8ae1f
2024-04-24T05:33:11,505  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,505  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=4, isCompatibleWith_(Configuration)=1}
2024-04-24T05:33:11,506  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019); Time taken: 0.005 seconds
2024-04-24T05:33:11,506  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_f107c37a-2e3a-4328-a48e-472671bf7019
2024-04-24T05:33:11,510  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2024-04-24T05:33:11,517  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,518  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2024-04-24T05:33:11,518  INFO [main] ql.TxnCommandsBaseForTests: Running the query: create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,519  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,522  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([12]) with min_open_txn: 1
2024-04-24T05:33:11,522  INFO [main] lockmgr.DbTxnManager: Opened txnid:12
2024-04-24T05:33:11,523  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,523  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,526  INFO [main] parse.CalcitePlanner: Creating table default.nonAcidNonBucket position=13
2024-04-24T05:33:11,526  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T05:33:11,528  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,528  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,528  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:11,529  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,529  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=1, getDatabase_(String)=2, getValidTxns_(long)=0, getValidWriteIds_(List, String)=3, openTxn_(String, TxnType)=2, flushCache_()=0, commitTxn_(CommitTxnRequest)=12}
2024-04-24T05:33:11,529  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9); Time taken: 0.009 seconds
2024-04-24T05:33:11,529  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:12 for queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9
2024-04-24T05:33:11,530  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9
2024-04-24T05:33:11,548  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9 LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T05:33:11,548  INFO [main] ql.Driver: Operation CREATETABLE obtained 1 locks
2024-04-24T05:33:11,548  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9): create table nonAcidNonBucket(a int, b int) stored as orc TBLPROPERTIES ('transactional'='false')
2024-04-24T05:33:11,549  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:11,550  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:nonAcidNonBucket, dbName:default, owner:alex, createTime:1713961991, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{rawDataSize=0, numFiles=0, numFilesErasureCoded=0, numRows=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true","COLUMN_STATS":{"a":"true","b":"true"}}, transactional=false, bucketing_version=2, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false, catName:hive, ownerType:USER)	
2024-04-24T05:33:11,557  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/nonacidnonbucket
2024-04-24T05:33:11,578  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:11,578  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {createTable_(Table)=29, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:11,579  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9); Time taken: 0.03 seconds
2024-04-24T05:33:11,579  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_ab21e141-0e21-4989-a8b4-b05c132deea9
2024-04-24T05:33:11,584  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2024-04-24T05:33:11,591  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:11,591  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2024-04-24T05:33:11,592  INFO [main] ql.TxnCommandsBaseForTests: Running the query: insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T05:33:11,592  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T05:33:11,596  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([13]) with min_open_txn: 1
2024-04-24T05:33:11,596  INFO [main] lockmgr.DbTxnManager: Opened txnid:13
2024-04-24T05:33:11,597  INFO [main] parse.CalcitePlanner: Starting caching scope for: 
2024-04-24T05:33:11,597  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T05:33:11,600  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:11,625  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:11,625  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T05:33:11,625  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:11,625  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:11,625  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:11,625  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:11,635  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:11,636  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T05:33:11,636  INFO [main] parse.CalcitePlanner: Disabling LLAP IO encode as ETL query is detected
2024-04-24T05:33:11,658  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive._dummy_database._dummy_table	
2024-04-24T05:33:11,759  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:11,759  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:11,759  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T05:33:11,760  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive._dummy_database._dummy_table	
2024-04-24T05:33:11,763  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T05:33:11,763  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:11,763  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T05:33:11,763  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:11,772  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:11,775  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-24T05:33:11,776  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-24T05:33:11,787  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 13
2024-04-24T05:33:11,787  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=acidtblpart (txnIds: [13])
2024-04-24T05:33:11,788  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T05:33:11,792  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 oldColExprMap: {KEY.reducesinkkey0=Column[_col0], VALUE._col1=Column[_col2], VALUE._col0=Column[_col1]}
2024-04-24T05:33:11,792  INFO [main] optimizer.ColumnPrunerProcFactory: RS 4 newColExprMap: {VALUE._col1=Column[_col2], VALUE._col0=Column[_col1], KEY.reducesinkkey0=Column[_col0]}
2024-04-24T05:33:11,793  INFO [main] optimizer.BucketVersionPopulator: not considering bucketingVersion for: TS[0] because it has -1<2 buckets 
2024-04-24T05:33:11,794  INFO [main] optimizer.SortedDynPartitionOptimizer: Sorted dynamic partitioning optimization kicked in..
2024-04-24T05:33:11,795  INFO [main] optimizer.SortedDynPartitionOptimizer: Removed RS_4 and SEL_5 as it was introduced by enforce bucketing/sorting.
2024-04-24T05:33:11,796  INFO [main] optimizer.SortedDynPartitionOptimizer: Inserted RS_7 and SEL_8 as parent of FS_6 and child of SEL_3
2024-04-24T05:33:11,805  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:11,815  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Examining input format to see if vectorization is enabled.
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map vectorization enabled: false
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map vectorized: false
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map vectorizedVertexNum: 0
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map enabledConditionsMet: [hive.vectorized.use.vectorized.input.format IS true]
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map enabledConditionsNotMet: [Could not enable vectorization due to partition column names size 1 is greater than the number of table column names size 0 IS false]
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Map inputFileFormatClassNameSet: [org.apache.hadoop.hive.ql.io.NullRowsInputFormat]
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Reduce vectorization enabled: false
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Reduce vectorized: false
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Reduce vectorizedVertexNum: 1
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Reducer hive.vectorized.execution.reduce.enabled: true
2024-04-24T05:33:11,816  INFO [main] physical.Vectorizer: Reducer engine: mr
2024-04-24T05:33:11,816  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T05:33:11,816  INFO [main] parse.CalcitePlanner: Ending caching scope for: 
2024-04-24T05:33:11,816  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:11,817  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:int, comment:null), FieldSchema(name:col3, type:string, comment:null)], properties:null)
2024-04-24T05:33:11,817  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:11,817  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {commitTxn_(CommitTxnRequest)=13, getCheckConstraints_(CheckConstraintsRequest)=2, allocateTableWriteId_(long, String, String)=8, isCompatibleWith_(Configuration)=2, getValidWriteIds_(List, String)=3, getTable_(GetTableRequest)=55, getMetaConf_(String)=0, getAllTableConstraints_(AllTableConstraintsRequest)=43, flushCache_()=0, getNotNullConstraints_(NotNullConstraintsRequest)=1, openTxn_(String, TxnType)=3, getValidTxns_(long)=1}
2024-04-24T05:33:11,817  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573); Time taken: 0.225 seconds
2024-04-24T05:33:11,817  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:13 for queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573
2024-04-24T05:33:11,818  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573
2024-04-24T05:33:11,842  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573 LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T05:33:11,842  INFO [main] ql.Driver: Operation QUERY obtained 1 locks
2024-04-24T05:33:11,845  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573): insert into acidTblPart values(1,2,'p1'),(4,5,'p2')
2024-04-24T05:33:11,846  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573
2024-04-24T05:33:11,846  INFO [main] ql.Driver: Query ID = alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573
Total jobs = 1
2024-04-24T05:33:11,846  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T05:33:11,846  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T05:33:11,983  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
2024-04-24T05:33:11,983  INFO [main] exec.Utilities: Not using thread pool for getContentSummary
2024-04-24T05:33:11,990  INFO [main] exec.Utilities: BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=1
Number of reduce tasks not specified. Estimated from input data size: 1
2024-04-24T05:33:11,991  INFO [main] exec.Task: Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
2024-04-24T05:33:11,991  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T05:33:11,991  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T05:33:11,991  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T05:33:11,991  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T05:33:11,991  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T05:33:11,991  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T05:33:11,993  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T05:33:11,993  INFO [main] exec.Utilities: Processing alias $hdt$_0:_dummy_table
2024-04-24T05:33:11,993  INFO [main] exec.Utilities: Adding 1 inputs; the first input is file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1/dummy_path
2024-04-24T05:33:12,003  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T05:33:12,008  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 5,61KB
2024-04-24T05:33:12,013  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T05:33:12,024  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 6,40KB
2024-04-24T05:33:12,025  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:12,029  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1/-mr-10000
2024-04-24T05:33:12,032  WARN [main] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:12,040  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T05:33:12,044  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T05:33:12,045  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 
2024-04-24T05:33:12,045  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = 
2024-04-24T05:33:12,045  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1/dummy_path
2024-04-24T05:33:12,046  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T05:33:12,065  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T05:33:12,087  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local669155860_0002
2024-04-24T05:33:12,087  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T05:33:12,164  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T05:33:12,165  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T05:33:12,165  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T05:33:12,165  INFO [Thread-173] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T05:33:12,168  INFO [Thread-173] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T05:33:12,168  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local669155860_0002_m_000000_0
2024-04-24T05:33:12,171  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T05:33:12,172  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.hive.ql.io.NullRowsInputFormat:file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1/dummy_path/null:0+1
2024-04-24T05:33:12,174  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T05:33:12,176  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 5,61KB
2024-04-24T05:33:12,177  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 1
2024-04-24T05:33:12,182  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T05:33:12,183  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T05:33:12,183  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T05:33:12,183  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T05:33:12,183  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T05:33:12,183  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T05:33:12,184  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing Operator: MAP[0]
2024-04-24T05:33:12,184  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing Operator: TS[0]
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[1]
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT null
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Initializing Operator: UDTF[2]
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing Operator: SEL[3]
2024-04-24T05:33:12,185  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<col1:int,col2:int,col3:string>
2024-04-24T05:33:12,186  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing Operator: RS[7]
2024-04-24T05:33:12,186  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T05:33:12,187  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [_col2, _bucket_number, _col0] num distributions: 3
2024-04-24T05:33:12,187  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: records written - 1
2024-04-24T05:33:12,187  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing Operator: MAP[0]
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: Total records read - 3. abort - false
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_OUT_OPERATOR_MAP_0:0, DESERIALIZE_ERRORS:0, RECORDS_OUT_INTERMEDIATE:0, RECORDS_IN:3, 
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing Operator: TS[0]
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_TS_0:1, 
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[1]
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_1:1, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: Closing Operator: UDTF[2]
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.UDTFOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_UDTF_2:2, 
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing Operator: SEL[3]
2024-04-24T05:33:12,188  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: RECORDS_OUT_INTERMEDIATE:0, RECORDS_OUT_OPERATOR_SEL_3:2, 
2024-04-24T05:33:12,189  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing Operator: RS[7]
2024-04-24T05:33:12,189  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[7]: Total records written - 2. abort - false
2024-04-24T05:33:12,189  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:2, RECORDS_OUT_OPERATOR_RS_7:2, 
2024-04-24T05:33:12,191  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T05:33:12,191  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T05:33:12,191  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T05:33:12,191  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 46; bufvoid = 104857600
2024-04-24T05:33:12,191  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2024-04-24T05:33:12,202  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T05:33:12,208  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local669155860_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T05:33:12,209  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2024-04-24T05:33:12,209  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local669155860_0002_m_000000_0' done.
2024-04-24T05:33:12,210  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local669155860_0002_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=24375
		FILE: Number of bytes written=2373438
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=2
		Map output bytes=46
		Map output materialized bytes=56
		Input split bytes=361
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=958922752
	HIVE
		DESERIALIZE_ERRORS=0
		RECORDS_IN=3
		RECORDS_OUT_INTERMEDIATE=2
		RECORDS_OUT_OPERATOR_MAP_0=0
		RECORDS_OUT_OPERATOR_RS_7=2
		RECORDS_OUT_OPERATOR_SEL_1=1
		RECORDS_OUT_OPERATOR_SEL_3=2
		RECORDS_OUT_OPERATOR_TS_0=1
		RECORDS_OUT_OPERATOR_UDTF_2=2
	File Input Format Counters 
		Bytes Read=5670
2024-04-24T05:33:12,210  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local669155860_0002_m_000000_0
2024-04-24T05:33:12,210  INFO [Thread-173] mapred.LocalJobRunner: map task executor complete.
2024-04-24T05:33:12,211  INFO [Thread-173] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T05:33:12,211  INFO [pool-13-thread-1] mapred.LocalJobRunner: Starting task: attempt_local669155860_0002_r_000000_0
2024-04-24T05:33:12,214  INFO [pool-13-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T05:33:12,214  INFO [pool-13-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30686f6
2024-04-24T05:33:12,214  WARN [pool-13-thread-1] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-04-24T05:33:12,215  INFO [pool-13-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T05:33:12,216  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local669155860_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T05:33:12,219  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local669155860_0002_m_000000_0 decomp: 52 len: 56 to MEMORY
2024-04-24T05:33:12,220  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local669155860_0002_m_000000_0
2024-04-24T05:33:12,220  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2024-04-24T05:33:12,220  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T05:33:12,221  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:12,221  INFO [pool-13-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T05:33:12,227  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:12,227  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 52 bytes to disk to satisfy reduce memory limit
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 1 files, 56 bytes from disk
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 33 bytes
2024-04-24T05:33:12,230  INFO [pool-13-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T05:33:12,231  INFO [pool-13-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T05:33:12,236  INFO [pool-13-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 6,40KB
2024-04-24T05:33:12,237  INFO [pool-13-thread-1] ExecReducer: 
<SEL>Id =8
  <Children>
    <FS>Id =6
      <Children>
      <\Children>
      <Parent>Id = 8 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T05:33:12,237  INFO [pool-13-thread-1] exec.SelectOperator: Initializing Operator: SEL[8]
2024-04-24T05:33:12,237  INFO [pool-13-thread-1] exec.SelectOperator: SELECT struct<key:struct<_col2:string,_bucket_number:string,_col0:int>,value:struct<_col1:int>>
2024-04-24T05:33:12,237  INFO [pool-13-thread-1] exec.FileSinkOperator: Initializing Operator: FS[6]
2024-04-24T05:33:12,237  INFO [pool-13-thread-1] exec.FileSinkOperator: Using serializer : AbstractSerDe [log=org.apache.logging.slf4j.Log4jLogger@6bbedca6, configuration=Optional[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml, file:/home/alex/Repositories/hive/ql/target/tmp/TestTxnConcatenate/mapred/local/localRunner/alex/job_local669155860_0002/job_local669155860_0002.xml], properties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart, column.name.delimiter=,}, tableProperties={transactional_properties=default, name=default.acidtblpart, transactional=true, columns.types=int:int, bucket_field_name=a, columns=a,b, columns.comments=&amp#0;, partition_columns.types=string, partition_columns=p, bucketing_version=2, bucket_count=2, serialization.lib=org.apache.hadoop.hive.ql.io.orc.OrcSerde, file.inputformat=org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, location=file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart, file.outputformat=org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, column.name.delimiter=,}, partitionProperties=Optional.empty, columnNames=[a, b], columnTypes=[int, int], getClass()=class org.apache.hadoop.hive.ql.io.orc.OrcSerde] and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@24c4563d
2024-04-24T05:33:12,240  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1
2024-04-24T05:33:12,240  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1
2024-04-24T05:33:12,243  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart
2024-04-24T05:33:12,244  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 1
2024-04-24T05:33:12,244  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T05:33:12,252  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T05:33:12,261  INFO [pool-13-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2
2024-04-24T05:33:12,261  INFO [pool-13-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2
2024-04-24T05:33:12,276  INFO [pool-13-thread-1] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart
2024-04-24T05:33:12,280  INFO [pool-13-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 blockSize: 268435456 compression: Compress: ZLIB buffer: 32768
2024-04-24T05:33:12,288  INFO [pool-13-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0 with stripeSize: 8388608 options: Compress: ZLIB buffer: 32768
2024-04-24T05:33:12,293  INFO [pool-13-thread-1] exec.SelectOperator: Closing Operator: SEL[8]
2024-04-24T05:33:12,293  INFO [pool-13-thread-1] exec.SelectOperator: RECORDS_OUT_OPERATOR_SEL_8:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T05:33:12,293  INFO [pool-13-thread-1] exec.FileSinkOperator: Closing Operator: FS[6]
2024-04-24T05:33:12,293  INFO [pool-13-thread-1] exec.FileSinkOperator: FS[6]: records written - 2
2024-04-24T05:33:12,296  INFO [pool-13-thread-1] FileOperations: Writing manifest to file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with [file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1/delta_0000001_0000001_0000/bucket_00001_0, file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2/delta_0000001_0000001_0000/bucket_00001_0]
2024-04-24T05:33:12,310  INFO [pool-13-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.acidtblpart:2, TOTAL_TABLE_ROWS_WRITTEN:2, RECORDS_OUT_OPERATOR_FS_6:2, RECORDS_OUT_INTERMEDIATE:0, 
2024-04-24T05:33:12,310  INFO [pool-13-thread-1] mapred.Task: Task:attempt_local669155860_0002_r_000000_0 is done. And is in the process of committing
2024-04-24T05:33:12,312  INFO [pool-13-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T05:33:12,312  INFO [pool-13-thread-1] mapred.Task: Task 'attempt_local669155860_0002_r_000000_0' done.
2024-04-24T05:33:12,312  INFO [pool-13-thread-1] mapred.Task: Final Counters for attempt_local669155860_0002_r_000000_0: Counters: 31
	File System Counters
		FILE: Number of bytes read=30986
		FILE: Number of bytes written=2375487
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=56
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=994050048
	HIVE
		CREATED_DYNAMIC_PARTITIONS=2
		CREATED_FILES=2
		RECORDS_OUT_1_default.acidtblpart=2
		RECORDS_OUT_INTERMEDIATE=0
		RECORDS_OUT_OPERATOR_FS_6=2
		RECORDS_OUT_OPERATOR_SEL_8=2
		TOTAL_TABLE_ROWS_WRITTEN=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2024-04-24T05:33:12,312  INFO [pool-13-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local669155860_0002_r_000000_0
2024-04-24T05:33:12,312  INFO [Thread-173] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 05:33:13,179 Stage-1 map = 100%,  reduce = 100%
2024-04-24T05:33:13,179  INFO [main] exec.Task: 2024-04-24 05:33:13,179 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local669155860_0002
2024-04-24T05:33:13,183  INFO [main] exec.Task: Ended Job = job_local669155860_0002
2024-04-24T05:33:13,184  INFO [main] FileOperations: Found manifest file file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest with attemptId 0.
2024-04-24T05:33:13,184  INFO [main] FileOperations: Looking at manifest file: file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000/000000_0.manifest
2024-04-24T05:33:13,185  INFO [main] FileOperations: Deleting manifest directory file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/_tmp.delta_0000001_0000001_0000
2024-04-24T05:33:13,187  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table default.acidtblpart partition (p=null)
2024-04-24T05:33:13,187  INFO [main] exec.Task: Loading data to table default.acidtblpart partition (p=null) from file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart
2024-04-24T05:33:13,187  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,196  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,196  INFO [main] exec.MoveTask: Partition is: {p=null}


2024-04-24T05:33:13,197  INFO [main] exec.Task: 

2024-04-24T05:33:13,198  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,206  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,208  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,216  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,217  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_names_ps : tbl=hive.default.acidtblpart[]	
2024-04-24T05:33:13,240  INFO [load-dynamic-partitionsToAdd-0] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p2 withPartSpec {p=p2}
2024-04-24T05:33:13,240  INFO [load-dynamic-partitionsToAdd-1] metadata.Hive: New loading path = file:/home/alex/Repositories/hive/ql/target/tmp/org.apache.hadoop.hive.ql.TestTxnLoadData-1713961976422/warehouse/acidtblpart/p=p1 withPartSpec {p=p1}
2024-04-24T05:33:13,241  INFO [main] metadata.Hive: Number of partitionsToAdd to be added is 2
2024-04-24T05:33:13,244  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=add_partitions	
2024-04-24T05:33:13,329  INFO [main] metadata.Hive: Loaded 2partitionsToAdd
	 Time taken to load dynamic partitions: 0.132 seconds
2024-04-24T05:33:13,329  INFO [main] exec.Task: 	 Time taken to load dynamic partitions: 0.132 seconds
2024-04-24T05:33:13,329  INFO [main] exec.MoveTask: 	 Time taken to load dynamic partitions: 0.132 seconds
2024-04-24T05:33:13,330  INFO [main] exec.MoveTask: Loading partition {p=p2}
2024-04-24T05:33:13,330  INFO [main] exec.MoveTask: Loading partition {p=p1}
	 Time taken for adding to write entity : 0.001 seconds
2024-04-24T05:33:13,330  INFO [main] exec.Task: 	 Time taken for adding to write entity : 0.001 seconds
2024-04-24T05:33:13,330  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T05:33:13,330  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,339  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,339  INFO [main] stats.BasicStatsTask: Executing stats task
2024-04-24T05:33:13,339  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1/-mr-10000
2024-04-24T05:33:13,341  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,352  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,362  WARN [stats-updater-thread-1] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T05:33:13,362  WARN [stats-updater-thread-0] FileOperations: Computing stats for an ACID table; stats may be inaccurate
2024-04-24T05:33:13,363  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, numRows, true, 1, false: 
2024-04-24T05:33:13,363  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, rawDataSize, true, 0, false: 
2024-04-24T05:33:13,363  INFO [main] stats.BasicStatsTask: Partition {p=p2} stats: [numFiles=1, numRows=1, totalSize=678, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T05:33:13,363  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, numRows, true, 1, false: 
2024-04-24T05:33:13,363  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, rawDataSize, true, 0, false: 
2024-04-24T05:33:13,363  INFO [main] stats.BasicStatsTask: Partition {p=p1} stats: [numFiles=1, numRows=1, totalSize=673, rawDataSize=0, numFilesErasureCoded=0]
2024-04-24T05:33:13,364  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_partitions : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,364  INFO [main] metastore.HMSHandler: New partition values:[p2]
2024-04-24T05:33:13,364  INFO [main] metastore.HMSHandler: New partition values:[p1]
2024-04-24T05:33:13,481  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, insertCount, true, 1, false: 
2024-04-24T05:33:13,481  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, updateCount, true, 0, false: 
2024-04-24T05:33:13,481  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p2/, deleteCount, true, 0, false: 
2024-04-24T05:33:13,484  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, insertCount, true, 1, false: 
2024-04-24T05:33:13,484  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, updateCount, true, 0, false: 
2024-04-24T05:33:13,484  INFO [main] FileOperations: Read stats for default.acidtblpart/p=p1/, deleteCount, true, 0, false: 
2024-04-24T05:33:13,485  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:13,485  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {listPartitionNamesRequest_(GetPartitionNamesPsRequest)=20, add_partitions_(List)=82, addDynamicPartitions_(long, long, String, String, List, DataOperationType)=3, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=47, updateTransactionalStatistics_(UpdateTransactionalStatsRequest)=3, getValidWriteIds_(List, String)=1, alter_partitions_(String, String, List, EnvironmentContext, String, long)=117}
MapReduce Jobs Launched: 
2024-04-24T05:33:13,485  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T05:33:13,485  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T05:33:13,485  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T05:33:13,485  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573); Time taken: 1.64 seconds
2024-04-24T05:33:13,485  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053311_73ad57e1-27a8-4ed0-8bcf-4616ef8ea573
2024-04-24T05:33:13,497  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:13,499  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2024-04-24T05:33:13,500  INFO [main] ql.TxnCommandsBaseForTests: Running the query: update acidTblPart set b = 4 where p='p1'
2024-04-24T05:33:13,500  INFO [main] ql.Context: Deleting scratch dir: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1
2024-04-24T05:33:13,501  INFO [main] cleanup.SyncCleanupService: Deleted directory: file:/home/alex/Repositories/hive/ql/target/tmp/localscratchdir/0214fd12-5bb2-4c13-80cb-f053f4585e42/hive_2024-04-24_05-33-11_592_3367247561815638688-1 on fs with scheme file
2024-04-24T05:33:13,501  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053313_17b5d88e-c519-4297-b277-e6243ab0119d): update acidTblPart set b = 4 where p='p1'
2024-04-24T05:33:13,512  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([14]) with min_open_txn: 14
2024-04-24T05:33:13,513  INFO [main] lockmgr.DbTxnManager: Opened txnid:14
2024-04-24T05:33:13,515  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting caching scope for: 
2024-04-24T05:33:13,515  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:13,525  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,525  INFO [main] parse.RewriteSemanticAnalyzer: Going to reparse <update acidTblPart set b = 4 where p='p1'> as 
<insert into table `default`.`acidTblPart` partition (`p`) select ROW__ID,`a`,`b`, `p` from `default`.`acidTblPart` sort by ROW__ID >
2024-04-24T05:33:13,526  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T05:33:13,531  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:13,540  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,540  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T05:33:13,540  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T05:33:13,541  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,552  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,553  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T05:33:13,553  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T05:33:13,553  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:13,562  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,563  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-24T05:33:13,563  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T05:33:13,563  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Disabling LLAP IO encode as ETL query is detected
2024-04-24T05:33:13,576  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_table_constraints : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,589  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_not_null_constraints : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,590  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_check_constraints : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,689  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,704  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,705  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,720  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,720  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_partitions_spec_by_expr : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,799  INFO [main] calcite.RelOptHiveTable: Calculating column statistics for default.acidtblpart, projIndxSet: [0, 2], allowMissingStats: true
2024-04-24T05:33:13,800  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidtblpart	
2024-04-24T05:33:13,811  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,812  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_aggr_stats_for: table=hive.default.acidtblpart	
2024-04-24T05:33:13,836  WARN [main] calcite.RelOptHiveTable: No Stats for default@acidtblpart, Columns: a
No Stats for default@acidtblpart, Columns: a
2024-04-24T05:33:13,836  INFO [main] SessionState: No Stats for default@acidtblpart, Columns: a
2024-04-24T05:33:13,915  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T05:33:13,915  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T05:33:13,915  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T05:33:13,915  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:13,926  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,926  WARN [main] parse.BaseSemanticAnalyzer: Dynamic partitioning is used; only validating 0 columns
2024-04-24T05:33:13,932 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed, skipping CBO. 
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60) ~[classes/:?]
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168) ~[classes/:?]
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149) ~[classes/:?]
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140) ~[classes/:?]
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_402]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_402]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_402]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_402]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.jar:4.13]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.jar:4.13]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.jar:4.13]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54) ~[junit-4.13.jar:4.13]
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.jar:4.13]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.jar:4.13]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.jar:4.13]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.jar:4.13]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_402]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_402]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_402]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_402]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_402]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_402]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.2.jar:5.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) [junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) [surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) [surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2024-04-24T05:33:13,933 ERROR [main] parse.UpdateDeleteSemanticAnalyzer: CBO failed due to missing column stats (see previous errors), skipping CBO
2024-04-24T05:33:13,933  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Ending caching scope for: 
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T05:33:13,933 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<writeid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<writeid:bigint,bucketid:int,rowid:bigint>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:130)
	at org.apache.hadoop.hive.ql.exec.MethodUtils.getMethodInternal(MethodUtils.java:60)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.TimestampCastRestrictorResolver.getEvalMethod(TimestampCastRestrictorResolver.java:68)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:168)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:149)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:235)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:584)
	at org.apache.hadoop.hive.ql.parse.type.ExprNodeDescExprFactory.createFuncCallExpr(ExprNodeDescExprFactory.java:97)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:762)
	at org.apache.hadoop.hive.ql.parse.type.TypeCheckProcFactory$DefaultExprProcessor.createConversionCast(TypeCheckProcFactory.java:783)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:8725)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6906)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:7335)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:11063)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:10938)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11853)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:11723)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:626)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12558)
	at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:456)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:67)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:208)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:63)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyze(UpdateDeleteSemanticAnalyzer.java:53)
	at org.apache.hadoop.hive.ql.parse.RewriteSemanticAnalyzer.analyzeInternal(RewriteSemanticAnalyzer.java:72)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:317)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:105)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:500)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:453)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:181)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:153)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:140)
	at org.apache.hadoop.hive.ql.TxnCommandsBaseForTests.runStatementOnDriver(TxnCommandsBaseForTests.java:245)
	at org.apache.hadoop.hive.ql.TestTxnConcatenate.testConcatenatePart(TestTxnConcatenate.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T05:33:13,933  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:13,933  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getNotNullConstraints_(NotNullConstraintsRequest)=1, getValidTxns_(long)=2, isCompatibleWith_(Configuration)=1, commitTxn_(CommitTxnRequest)=15, getCheckConstraints_(CheckConstraintsRequest)=2, getValidWriteIds_(List, String)=6, getAllTableConstraints_(AllTableConstraintsRequest)=7, getTable_(GetTableRequest)=50, getMetaConf_(String)=0, openTxn_(String, TxnType)=11, getAggrColStatsFor_(String, String, List, List, String, String)=36, listPartitionsSpecByExpr_(PartitionsByExprRequest, List)=106, flushCache_()=0}
2024-04-24T05:33:13,934  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053313_17b5d88e-c519-4297-b277-e6243ab0119d); Time taken: 0.432 seconds
2024-04-24T05:33:13,934  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: null
2024-04-24T05:33:13,938  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:13,947  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl
2024-04-24T05:33:13,947  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7): drop table if exists acidTbl
2024-04-24T05:33:13,950  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([15]) with min_open_txn: 14
2024-04-24T05:33:13,951  INFO [main] lockmgr.DbTxnManager: Opened txnid:15
2024-04-24T05:33:13,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:13,961  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,961  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:13,961  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:13,961  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:13,961  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {rollbackTxn_(long)=13, isCompatibleWith_(Configuration)=0, flushCache_()=0, getTable_(GetTableRequest)=9, openTxn_(String, TxnType)=3, getValidTxns_(long)=1}
2024-04-24T05:33:13,961  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7); Time taken: 0.014 seconds
2024-04-24T05:33:13,962  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:15 for queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7
2024-04-24T05:33:13,962  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7
2024-04-24T05:33:13,982  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7 LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T05:33:13,982  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:13,982  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7): drop table if exists acidTbl
2024-04-24T05:33:13,982  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:13,983  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:13,992  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:13,992  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:14,005  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,005  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTbl	
2024-04-24T05:33:14,166  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,166  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=9, isCompatibleWith_(Configuration)=1, dropTable_(String, String, boolean, boolean, boolean)=174}
2024-04-24T05:33:14,166  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7); Time taken: 0.184 seconds
2024-04-24T05:33:14,166  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053313_9520bff9-69cb-493d-b01f-24ef4119b2d7
2024-04-24T05:33:14,171  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2024-04-24T05:33:14,179  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,179  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2024-04-24T05:33:14,180  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTblPart
2024-04-24T05:33:14,180  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd): drop table if exists acidTblPart
2024-04-24T05:33:14,183  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([16]) with min_open_txn: 14
2024-04-24T05:33:14,184  INFO [main] lockmgr.DbTxnManager: Opened txnid:16
2024-04-24T05:33:14,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:14,194  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,194  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:14,194  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:14,194  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:14,195  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, commitTxn_(CommitTxnRequest)=13, getTable_(GetTableRequest)=9, getValidTxns_(long)=1, openTxn_(String, TxnType)=3, flushCache_()=0}
2024-04-24T05:33:14,195  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd); Time taken: 0.014 seconds
2024-04-24T05:33:14,195  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:16 for queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd
2024-04-24T05:33:14,195  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd
2024-04-24T05:33:14,214  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T05:33:14,214  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:14,214  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd): drop table if exists acidTblPart
2024-04-24T05:33:14,214  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:14,215  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:14,224  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,224  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:14,233  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,233  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.acidTblPart	
2024-04-24T05:33:14,339  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,339  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getTable_(GetTableRequest)=9, isCompatibleWith_(Configuration)=1, dropTable_(String, String, boolean, boolean, boolean)=115}
2024-04-24T05:33:14,339  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd); Time taken: 0.125 seconds
2024-04-24T05:33:14,339  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053314_7215c810-0df6-4d27-8fad-39d6e369a0bd
2024-04-24T05:33:14,344  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2024-04-24T05:33:14,352  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,354  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2024-04-24T05:33:14,355  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists acidTbl2
2024-04-24T05:33:14,355  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8): drop table if exists acidTbl2
2024-04-24T05:33:14,366  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([17]) with min_open_txn: 14
2024-04-24T05:33:14,366  INFO [main] lockmgr.DbTxnManager: Opened txnid:17
2024-04-24T05:33:14,369  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:14,369  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:14,369  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:14,369  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=3, openTxn_(String, TxnType)=10, flushCache_()=0, commitTxn_(CommitTxnRequest)=16, getTable_(GetTableRequest)=0, isCompatibleWith_(Configuration)=0}
2024-04-24T05:33:14,369  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8); Time taken: 0.014 seconds
2024-04-24T05:33:14,370  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:17 for queryId=alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8
2024-04-24T05:33:14,370  INFO [main] ql.Driver: Operation DROPTABLE obtained 0 locks
2024-04-24T05:33:14,370  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8): drop table if exists acidTbl2
2024-04-24T05:33:14,370  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:14,371  INFO [main] metadata.SessionHiveMetaStoreClient: Column stats doesn't exist for db=default temp table=acidTbl2
2024-04-24T05:33:14,371  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,371  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=0, dropTable_(String, String, boolean, boolean, boolean)=1}
2024-04-24T05:33:14,371  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8); Time taken: 0.001 seconds
2024-04-24T05:33:14,372  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053314_9393b37b-6f47-4fc4-a37b-1decf52064d8
2024-04-24T05:33:14,377  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2024-04-24T05:33:14,384  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,384  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2024-04-24T05:33:14,385  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl
2024-04-24T05:33:14,385  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:14,388  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([18]) with min_open_txn: 14
2024-04-24T05:33:14,388  INFO [main] lockmgr.DbTxnManager: Opened txnid:18
2024-04-24T05:33:14,389  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:14,430  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,430  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:14,430  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:14,430  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:14,430  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=2, getTable_(GetTableRequest)=41, flushCache_()=0, commitTxn_(CommitTxnRequest)=12, isCompatibleWith_(Configuration)=1, getValidTxns_(long)=1}
2024-04-24T05:33:14,430  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5); Time taken: 0.045 seconds
2024-04-24T05:33:14,430  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:18 for queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5
2024-04-24T05:33:14,431  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5
2024-04-24T05:33:14,453  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5 LockResponse(lockid:10, state:ACQUIRED)
2024-04-24T05:33:14,453  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:14,453  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5): drop table if exists nonAcidOrcTbl
2024-04-24T05:33:14,454  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:14,454  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:14,466  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,466  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:14,478  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,478  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl	
2024-04-24T05:33:14,594  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,594  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=128, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=12}
2024-04-24T05:33:14,595  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5); Time taken: 0.141 seconds
2024-04-24T05:33:14,595  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053314_b9f77d8f-f20a-4dc0-9adf-b24c6c3689a5
2024-04-24T05:33:14,599  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2024-04-24T05:33:14,607  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,607  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2024-04-24T05:33:14,608  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:14,608  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:14,611  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([19]) with min_open_txn: 15
2024-04-24T05:33:14,612  INFO [main] lockmgr.DbTxnManager: Opened txnid:19
2024-04-24T05:33:14,613  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:14,624  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,625  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:14,625  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:14,625  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:14,625  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=0, commitTxn_(CommitTxnRequest)=13, flushCache_()=0, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=13, openTxn_(String, TxnType)=3}
2024-04-24T05:33:14,625  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e); Time taken: 0.017 seconds
2024-04-24T05:33:14,625  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:19 for queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e
2024-04-24T05:33:14,626  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e
2024-04-24T05:33:14,644  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e LockResponse(lockid:11, state:ACQUIRED)
2024-04-24T05:33:14,644  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:14,644  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e): drop table if exists nonAcidOrcTbl2
2024-04-24T05:33:14,644  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:14,644  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:14,659  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,659  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:14,674  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidOrcTbl2	
2024-04-24T05:33:14,725  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,725  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {dropTable_(String, String, boolean, boolean, boolean)=66, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=15}
2024-04-24T05:33:14,726  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e); Time taken: 0.081 seconds
2024-04-24T05:33:14,726  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053314_17f5664e-4f38-4792-99b2-f448209e077e
2024-04-24T05:33:14,731  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2024-04-24T05:33:14,739  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,739  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2024-04-24T05:33:14,740  INFO [main] ql.TxnCommandsBaseForTests: Running the query: drop table if exists nonAcidNonBucket
2024-04-24T05:33:14,740  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7): drop table if exists nonAcidNonBucket
2024-04-24T05:33:14,744  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 15
2024-04-24T05:33:14,744  INFO [main] lockmgr.DbTxnManager: Opened txnid:20
2024-04-24T05:33:14,746  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:14,762  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,762  INFO [main] ql.Driver: Semantic Analysis Completed (retrial = false)
2024-04-24T05:33:14,762  INFO [main] ql.Driver: Created Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T05:33:14,762  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T05:33:14,763  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {getValidTxns_(long)=1, commitTxn_(CommitTxnRequest)=14, isCompatibleWith_(Configuration)=0, flushCache_()=0, getTable_(GetTableRequest)=16, openTxn_(String, TxnType)=3}
2024-04-24T05:33:14,763  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7); Time taken: 0.022 seconds
2024-04-24T05:33:14,763  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:20 for queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7
2024-04-24T05:33:14,764  INFO [main] lockmgr.DbLockManager: Requesting lock for queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7
2024-04-24T05:33:14,783  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7 LockResponse(lockid:12, state:ACQUIRED)
2024-04-24T05:33:14,783  INFO [main] ql.Driver: Operation DROPTABLE obtained 1 locks
2024-04-24T05:33:14,783  INFO [main] ql.Driver: Executing command(queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7): drop table if exists nonAcidNonBucket
2024-04-24T05:33:14,783  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T05:33:14,784  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:14,794  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,795  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:14,805  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T05:33:14,806  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.nonAcidNonBucket	
2024-04-24T05:33:14,844  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T05:33:14,844  INFO [main] metadata.Hive: Total time spent in each metastore function (ms): {isCompatibleWith_(Configuration)=0, dropTable_(String, String, boolean, boolean, boolean)=50, getTable_(GetTableRequest)=10}
2024-04-24T05:33:14,844  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7); Time taken: 0.061 seconds
2024-04-24T05:33:14,844  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424053314_38feb02d-e5e4-460c-9f64-f692d7c541d7
2024-04-24T05:33:14,849  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2024-04-24T05:33:14,855  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2024-04-24T05:33:14,855  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2024-04-24T05:33:14,856  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
]]></system-err>
  </testcase>
  <testcase name="testConcatenateMM" classname="org.apache.hadoop.hive.ql.TestTxnConcatenate" time="11.736"/>
</testsuite>