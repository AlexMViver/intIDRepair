2024-04-24T09:18:10,686  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:18:10,687  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:18:10,688  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:18:10,689  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f24c1c, with PersistenceManager: null will be shutdown
2024-04-24T09:18:10,690  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f24c1c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@24e0b828 created in the thread with id: 412
2024-04-24T09:18:10,705  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f24c1c from thread id: 412
2024-04-24T09:18:10,826  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testHCatPartitionedTable, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:string, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T09:18:10,853  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/44419/testhcatpartitionedtable
2024-04-24T09:18:11,262  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:18:11,262  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:18:11,262  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:18:11,262  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:18:11,263  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:18:11,264  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T09:18:11,266  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, javax.jdo.option.ConnectionUserName=APP, test.property1=value1, hive.stats.column.autogather=true, hive.llap.io.cache.orc.alloc.max=2097152, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.llap.io.use.lrfu=true, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.fetch.task.conversion=minimal, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.in.test=true, hive.support.concurrency=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.ignore.mapjoin.hint=false, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, hive.strict.timestamp.conversion=false, iceberg.hive.keep.stats=true}
2024-04-24T09:18:11,299  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T09:18:11,341  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T09:18:11,341  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:44419]
2024-04-24T09:18:11,341  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:44419)
2024-04-24T09:18:11,341  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:44419) current connections: 2
2024-04-24T09:18:11,342  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T09:18:11,405  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:18:11,407  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T09:18:11,407  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T09:18:11,407  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68b78854, with PersistenceManager: null will be shutdown
2024-04-24T09:18:11,408  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68b78854, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2471d77c created in the thread with id: 419
2024-04-24T09:18:11,412  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68b78854 from thread id: 419
2024-04-24T09:18:11,457  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:18:11,535  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:18:11,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:18:11,654  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:18:11,655  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:18:11,655  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:18:11,655  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:18:11,831  INFO [main] client.RMProxy: Connecting to ResourceManager at Lenovo-Bot/127.0.1.1:35333
2024-04-24T09:18:12,604  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T09:18:12,604  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T09:18:12,604  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T09:18:12,604  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T09:18:12,604  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T09:18:12,605  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T09:18:12,606  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T09:18:12,611  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T09:18:13,130  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T09:18:13,139  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T09:18:13,251  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T09:18:13,400  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T09:18:13,444  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1713975481617_0001
2024-04-24T09:18:13,444  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T09:18:13,763  INFO [main] mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
2024-04-24T09:18:14,479  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T09:18:14,479  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T09:18:14,492  INFO [main] impl.YarnClientImpl: Submitted application application_1713975481617_0001
2024-04-24T09:18:14,629  INFO [main] mapreduce.Job: The url to track the job: http://Lenovo-Bot:0/proxy/application_1713975481617_0001/
2024-04-24T09:18:14,631  INFO [main] mapreduce.Job: Running job: job_1713975481617_0001
2024-04-24T09:18:15,073  INFO [Socket Reader #1 for port 41727] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:20,329  INFO [Socket Reader #1 for port 35349] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:21,750  INFO [main] mapreduce.Job: Job job_1713975481617_0001 running in uber mode : false
2024-04-24T09:18:21,753  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T09:18:22,684  INFO [Socket Reader #1 for port 41727] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:22,696  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713975481617_0001
2024-04-24T09:18:25,863  INFO [main] mapreduce.Job: Task Id : attempt_1713975481617_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:18:26,570  INFO [Socket Reader #1 for port 41727] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:27,643  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713975481617_0001
2024-04-24T09:18:28,618  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner started
2024-04-24T09:18:28,618  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner complete
2024-04-24T09:18:30,918  INFO [main] mapreduce.Job: Task Id : attempt_1713975481617_0001_m_000000_1, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:18:31,619  INFO [Socket Reader #1 for port 41727] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:32,489  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713975481617_0001
2024-04-24T09:18:34,941  INFO [main] mapreduce.Job: Task Id : attempt_1713975481617_0001_m_000000_2, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T09:18:36,643  INFO [Socket Reader #1 for port 41727] ipc.Server: Auth successful for appattempt_1713975481617_0001_000001 (auth:SIMPLE)
2024-04-24T09:18:37,223  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713975481617_0001
2024-04-24T09:18:40,971  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T09:18:44,998  INFO [main] mapreduce.Job: Job job_1713975481617_0001 failed with state FAILED due to: Task failed task_1713975481617_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2024-04-24T09:18:45,215  INFO [main] mapreduce.Job: Counters: 9
	Job Counters 
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=3
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=12412
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=12412
		Total vcore-milliseconds taken by all map tasks=12412
		Total megabyte-milliseconds taken by all map tasks=12709888
2024-04-24T09:18:45,230  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:18:45,259  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T09:18:45,280  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T09:18:45,343  WARN [ContainersLauncher #0] nodemanager.DefaultContainerExecutor: Exit code from container container_1713975481617_0001_01_000001 is : 143
2024-04-24T09:19:02,407 ERROR [Thread[Thread-276,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:19:02,413  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T09:19:02,417  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T09:19:02,418 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T09:19:02,422  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T09:19:02,422  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T09:19:02,422  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T09:19:02,423  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T09:19:02,423  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T09:19:02,423 ERROR [Thread[Thread-99,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:19:02,423  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T09:19:02,424  INFO [main] impl.MetricsSystemImpl: Stopping JobHistoryServer metrics system...
2024-04-24T09:19:02,439  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system stopped.
2024-04-24T09:19:02,439  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system shutdown complete.
2024-04-24T09:19:02,443  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T09:19:02,443  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T09:19:02,447 ERROR [Thread[Thread-73,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T09:19:02,464  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T09:19:02,464  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T09:19:02,464  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@68b78854, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2471d77c will be shutdown
2024-04-24T09:19:02,465  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2024-04-24T09:19:02,465  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
