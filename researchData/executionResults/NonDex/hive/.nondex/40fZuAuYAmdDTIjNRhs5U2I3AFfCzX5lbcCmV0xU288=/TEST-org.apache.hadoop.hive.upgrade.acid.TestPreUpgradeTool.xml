<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="60.975" tests="6" errors="3" skipped="0" failures="1">
  <properties>
    <property name="sun.desktop" value="gnome"/>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="nondexStart" value="0"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="log4j.configurationFile" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/hive-log4j2.properties"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="java.vm.vendor" value="Private Build"/>
    <property name="nondexPrintstack" value="false"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value="Europe/Lisbon"/>
    <property name="user.country.format" value="PT"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.tmp.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64"/>
    <property name="nondexLogging" value="CONFIG"/>
    <property name="sun.java.command" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire 2024-04-23T21-59-46_173-jvmRun1 surefire7003144543524800487tmp surefire_39791644611025128453273tmp"/>
    <property name="surefire.test.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/test-classes:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/classes:/home/alex/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-metastore/2.3.3/hive-metastore-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-serde/2.3.3/hive-serde-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-common/2.3.3/hive-common-2.3.3.jar:/home/alex/.m2/repository/jline/jline/2.12/jline-2.12.jar:/home/alex/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/home/alex/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/home/alex/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/home/alex/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/home/alex/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/home/alex/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-web/2.6.2/log4j-web-2.6.2.jar:/home/alex/.m2/repository/com/tdunning/json/1.8/json-1.8.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.0/metrics-jvm-3.1.0.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.0/metrics-json-3.1.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.5/jackson-databind-2.6.5.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar:/home/alex/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.5/jackson-core-2.6.5.jar:/home/alex/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/home/alex/.m2/repository/org/apache/hive/hive-service-rpc/2.3.3/hive-service-rpc-2.3.3.jar:/home/alex/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/home/alex/.m2/repository/org/apache/parquet/parquet-hadoop-bundle/1.8.1/parquet-hadoop-bundle-1.8.1.jar:/home/alex/.m2/repository/org/apache/hive/hive-shims/2.3.3/hive-shims-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-common/2.3.3/hive-shims-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-0.23/2.3.3/hive-shims-0.23-2.3.3.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.7.2/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.7.2/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.7.2/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/alex/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/2.3.3/hive-shims-scheduler-2.3.3.jar:/home/alex/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/home/alex/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/home/alex/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-client/1.1.1/hbase-client-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-annotations/1.1.1/hbase-annotations-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-common/1.1.1/hbase-common-1.1.1.jar:/home/alex/.m2/repository/org/apache/hbase/hbase-protocol/1.1.1/hbase-protocol-1.1.1.jar:/home/alex/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/alex/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/alex/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/alex/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/alex/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/alex/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar:/home/alex/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/alex/.m2/repository/org/apache/derby/derby/10.10.2.0/derby-10.10.2.0.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar:/home/alex/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar:/home/alex/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/home/alex/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar:/home/alex/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/home/alex/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/home/alex/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar:/home/alex/.m2/repository/javax/transaction/transaction-api/1.1/transaction-api-1.1.jar:/home/alex/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/alex/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar:/home/alex/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar:/home/alex/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-api/0.6.0/tephra-api-0.6.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-core/0.6.0/tephra-core-0.6.0.jar:/home/alex/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/alex/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/alex/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-assistedinject/3.0/guice-assistedinject-3.0.jar:/home/alex/.m2/repository/it/unimi/dsi/fastutil/6.5.6/fastutil-6.5.6.jar:/home/alex/.m2/repository/org/apache/twill/twill-common/0.6.0-incubating/twill-common-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-core/0.6.0-incubating/twill-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-api/0.6.0-incubating/twill-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-api/0.6.0-incubating/twill-discovery-api-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-discovery-core/0.6.0-incubating/twill-discovery-core-0.6.0-incubating.jar:/home/alex/.m2/repository/org/apache/twill/twill-zookeeper/0.6.0-incubating/twill-zookeeper-0.6.0-incubating.jar:/home/alex/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.0/metrics-core-3.1.0.jar:/home/alex/.m2/repository/co/cask/tephra/tephra-hbase-compat-1.0/0.6.0/tephra-hbase-compat-1.0-0.6.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/alex/.m2/repository/org/apache/hive/hive-exec/2.3.3/hive-exec-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-vector-code-gen/2.3.3/hive-vector-code-gen-2.3.3.jar:/home/alex/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/home/alex/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-tez/2.3.3/hive-llap-tez-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-client/2.3.3/hive-llap-client-2.3.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-llap-common/2.3.3/hive-llap-common-2.3.3.jar:/home/alex/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/home/alex/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/alex/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/alex/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.6.2/log4j-1.2-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-api/2.6.2/log4j-api-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-core/2.6.2/log4j-core-2.6.2.jar:/home/alex/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.6.2/log4j-slf4j-impl-2.6.2.jar:/home/alex/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/home/alex/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/home/alex/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/home/alex/.m2/repository/org/apache/commons/commons-compress/1.9/commons-compress-1.9.jar:/home/alex/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-core/1.10.0/calcite-core-1.10.0.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-linq4j/1.10.0/calcite-linq4j-1.10.0.jar:/home/alex/.m2/repository/net/hydromatic/eigenbase-properties/1.1.5/eigenbase-properties-1.1.5.jar:/home/alex/.m2/repository/org/codehaus/janino/janino/2.7.6/janino-2.7.6.jar:/home/alex/.m2/repository/org/codehaus/janino/commons-compiler/2.7.6/commons-compiler-2.7.6.jar:/home/alex/.m2/repository/org/apache/calcite/calcite-druid/1.10.0/calcite-druid-1.10.0.jar:/home/alex/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica/1.8.0/avatica-1.8.0.jar:/home/alex/.m2/repository/org/apache/calcite/avatica/avatica-metrics/1.8.0/avatica-metrics-1.8.0.jar:/home/alex/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/alex/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-common/2.7.2/hadoop-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.2/hadoop-annotations-2.7.2.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/home/alex/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/alex/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/alex/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/alex/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/alex/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/alex/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/alex/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/alex/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/alex/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/alex/.m2/repository/asm/asm/3.1/asm-3.1.jar:/home/alex/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/alex/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/alex/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/alex/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/alex/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/alex/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/alex/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/alex/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/alex/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/alex/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/alex/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/alex/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.2/hadoop-auth-2.7.2.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/alex/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/alex/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/alex/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/alex/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/alex/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.2/hadoop-mapreduce-client-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.2/hadoop-yarn-common-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.2/hadoop-yarn-api-2.7.2.jar:/home/alex/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/alex/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/alex/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/alex/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/alex/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.2/hadoop-yarn-client-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.2/hadoop-mapreduce-client-core-2.7.2.jar:/home/alex/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.2/hadoop-yarn-server-common-2.7.2.jar:/home/alex/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/alex/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/alex/.m2/repository/org/apache/orc/orc-core/1.3.3/orc-core-1.3.3.jar:/home/alex/.m2/repository/io/airlift/aircompressor/0.3/aircompressor-0.3.jar:/home/alex/.m2/repository/org/apache/hive/hive-storage-api/2.2.1/hive-storage-api-2.2.1.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.6.2/junit-jupiter-engine-5.6.2.jar:/home/alex/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-engine/1.6.2/junit-platform-engine-1.6.2.jar:/home/alex/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/alex/.m2/repository/org/junit/platform/junit-platform-commons/1.6.2/junit-platform-commons-1.6.2.jar:/home/alex/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.6.2/junit-jupiter-api-5.6.2.jar:/home/alex/.m2/repository/org/junit/vintage/junit-vintage-engine/5.6.2/junit-vintage-engine-5.6.2.jar:/home/alex/.m2/repository/junit/junit/4.13/junit-4.13.jar:/home/alex/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/src/test/resources:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/testconf/conf:"/>
    <property name="nondexExecid" value="40fZuAuYAmdDTIjNRhs5U2I3AFfCzX5lbcCmV0xU288="/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/alex"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="metastore.schema.verification" value="false"/>
    <property name="java.home" value="/usr/lib/jvm/java-8-openjdk-amd64/jre"/>
    <property name="basedir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="nondexEnd" value="9223372036854775807"/>
    <property name="metastore.warehouse.dir" value="file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/warehouse"/>
    <property name="derby.stream.error.file" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/derby.log"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="nondexFilter" value=".*"/>
    <property name="nondexSeed" value="1016066"/>
    <property name="surefire.real.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar"/>
    <property name="log4j.debug" value="true"/>
    <property name="sun.boot.class.path" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex/nondex-instr.jar:/home/alex/.m2/repository/edu/illinois/nondex-common/2.1.7/nondex-common-2.1.7.jar:/home/alex/.m2/repository/edu/illinois/nondex-annotations/2.1.7/nondex-annotations-2.1.7.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_402-8u402-ga-2ubuntu1~22.04-b06"/>
    <property name="user.name" value="alex"/>
    <property name="path.separator" value=":"/>
    <property name="javax.jdo.option.ConnectionURL" value="jdbc:derby:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/junit_metastore_db;create=true"/>
    <property name="os.version" value="6.5.0-28-generic"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="localRepository" value="/home/alex/.m2/repository"/>
    <property name="build.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target"/>
    <property name="nondexDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="nondexJarDir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/.nondex"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp"/>
    <property name="java.version" value="1.8.0_402"/>
    <property name="user.dir" value="/home/alex/Repositories/hive/upgrade-acid/pre-upgrade"/>
    <property name="os.arch" value="amd64"/>
    <property name="nondexMode" value="FULL"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.language.format" value="pt"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="derby.version" value=""/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib"/>
    <property name="java.vendor" value="Private Build"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.402-b06"/>
    <property name="java.specification.maintenance.version" value="5"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="datanucleus.schema.autoCreateAll" value="true"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpgradeExternalTableNoReadPermissionForTable" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="9.856"/>
  <testcase name="testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.506">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TInclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
]]></error>
    <system-err><![CDATA[2024-04-24T20:45:00,616  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:00,616  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:00,616  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:00,616  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:00,616  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:00,617  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:00,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:00,649  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:00,805  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:00,806  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:00,806  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:00,806  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:00,806  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:00,963  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b
2024-04-24T20:45:00,966  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b
2024-04-24T20:45:00,969  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/_tmp_space.db
2024-04-24T20:45:00,970  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2d37e171-9bf6-46c0-be0b-2e4e94060d7b, clientType=HIVECLI]
2024-04-24T20:45:00,970  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:45:00,970  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TInclude
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:01,013  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:01,014  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:01,014  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:01,015  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:01,017  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:01,017  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:01,017  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,017  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,019  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:01,019  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:01,019  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:01,020  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.049 seconds
2024-04-24T20:45:01,020  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,020  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TInclude
2024-04-24T20:45:01,020  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:01,020  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,020  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,022 ERROR [main] metadata.Hive: Table TInclude not found: default.TInclude table not found
2024-04-24T20:45:01,022  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,022  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,024  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:01,024  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.004 seconds
OK
2024-04-24T20:45:01,024  INFO [main] ql.Driver: OK
2024-04-24T20:45:01,024  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:01,025  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TExclude
2024-04-24T20:45:01,026  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:01,026  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:01,028  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:01,028  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:01,028  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:01,028  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.003 seconds
2024-04-24T20:45:01,029  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,029  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TExclude
2024-04-24T20:45:01,029  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:01,029  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:01,029  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:01,031 ERROR [main] metadata.Hive: Table TExclude not found: default.TExclude table not found
2024-04-24T20:45:01,031  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:01,031  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:01,033  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:01,033  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.004 seconds
OK
2024-04-24T20:45:01,033  INFO [main] ql.Driver: OK
2024-04-24T20:45:01,033  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:01,034  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:01,035  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:01,035  INFO [main] parse.CalcitePlanner: Creating table default.TInclude position=13
2024-04-24T20:45:01,036  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:01,036  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:01,041  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:01,041  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:01,041  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:01,041  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.007 seconds
2024-04-24T20:45:01,042  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,042  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132)
2024-04-24T20:45:01,063  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:45:01,063  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,063  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:01,064  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:01,065  INFO [main] exec.DDLTask: creating table default.TInclude on null
2024-04-24T20:45:01,065  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987901, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, rawDataSize=0, transactional=true, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:01,065  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:default, owner:alex, createTime:1713987901, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, rawDataSize=0, transactional=true, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:01,074  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude
2024-04-24T20:45:01,117  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:01,118  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.054 seconds
OK
2024-04-24T20:45:01,118  INFO [main] ql.Driver: OK
2024-04-24T20:45:01,118  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,118  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 txnid:0]
2024-04-24T20:45:01,125  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:01,128  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:01,129  INFO [main] parse.CalcitePlanner: Creating table default.TExclude position=13
2024-04-24T20:45:01,129  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:01,129  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:01,138  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:01,138  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:01,138  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:01,139  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.013 seconds
2024-04-24T20:45:01,139  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,139  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132)
2024-04-24T20:45:01,157  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:45:01,157  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,157  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): create table TExclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:01,158  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:01,159  INFO [main] exec.DDLTask: creating table default.TExclude on null
2024-04-24T20:45:01,159  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987901, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, transactional=true, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:01,159  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExclude, dbName:default, owner:alex, createTime:1713987901, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, transactional=true, totalSize=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:01,169  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/texclude
2024-04-24T20:45:01,197  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:01,197  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.04 seconds
OK
2024-04-24T20:45:01,197  INFO [main] ql.Driver: OK
2024-04-24T20:45:01,197  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,197  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 txnid:0]
2024-04-24T20:45:01,202  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:45:01,203  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:01,204  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,204  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,221  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:01,227  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:01,227  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:01,227  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:01,227  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:01,227  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,228  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,244  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:01,318  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:45:01,318  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:45:01,319  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:45:01,319  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:45:01,323  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:01,323  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:01,339  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:01,339  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:01,340  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:01,340  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:01,340  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:01,359  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1
2024-04-24T20:45:01,377  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:45:01,377  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:45:01,379  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:45:01,379  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:45:01,379  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tinclude
2024-04-24T20:45:01,389  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:45:01,389  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:01,389  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:45:01,389  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:01,389  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.187 seconds
2024-04-24T20:45:01,393  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:01,423  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:01,424  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:01,435  INFO [main] compactor.HouseKeeperServiceBase: Started org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService with delay/interval = 100/1000 MILLISECONDS
2024-04-24T20:45:01,446  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:45:01,446  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,446  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132)
2024-04-24T20:45:01,469  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:45:01,480  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:45:01,481  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:45:01,481  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:01,481  INFO [main] ql.Driver: Query ID = alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
Total jobs = 1
2024-04-24T20:45:01,481  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:45:01,481  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:45:01,482  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:45:01,483  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:45:01,483  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:45:01,483  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:45:01,483  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:45:01,483  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:45:01,483  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:45:01,483  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:45:01,483  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:45:01,483  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:45:01,483  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:01,490  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:45:01,496  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:01,500  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:45:01,505  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:45:01,506  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:01,507  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10001
2024-04-24T20:45:01,509  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:01,510  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/map.xml
2024-04-24T20:45:01,510  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/reduce.xml
2024-04-24T20:45:01,513  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:45:01,539  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.AcidOpenTxnsCounterService: OpenTxnsCounter ran for 0seconds.  isAliveCounter=-2147483647
2024-04-24T20:45:01,590  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/map.xml
2024-04-24T20:45:01,591  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:45:01,591  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:45:01,591  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:01,595  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:45:01,596  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:45:01,609  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:45:01,624  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local541769738_0002
2024-04-24T20:45:01,667  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:45:01,668  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:45:01,668  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:01,669  INFO [Thread-127] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:01,670  INFO [Thread-127] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:45:01,670  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local541769738_0002_m_000000_0
2024-04-24T20:45:01,676  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:01,677  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:01,679  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/map.xml
2024-04-24T20:45:01,679  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:45:01,683  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:01,684  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:45:01,704  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:45:01,704  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:45:01,705  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:45:01,705  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:45:01,705  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:45:01,707  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:45:01,707  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,707  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,707  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/map.xml
2024-04-24T20:45:01,707  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:45:01,708  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:45:01,709  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:45:01,709  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:45:01,709  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:45:01,709  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:45:01,710  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:45:01,719  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/map.xml
2024-04-24T20:45:01,719  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:45:01,721  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:45:01,721  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:45:01,722  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:45:01,723  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:45:01,724  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:45:01,724  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:45:01,724  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:45:01,724  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:45:01,728  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:45:01,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local541769738_0002_m_000000_0 is done. And is in the process of committing
2024-04-24T20:45:01,732  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:01,732  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local541769738_0002_m_000000_0' done.
2024-04-24T20:45:01,732  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local541769738_0002_m_000000_0
2024-04-24T20:45:01,732  INFO [Thread-127] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:45:01,735  INFO [Thread-127] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:45:01,735  INFO [pool-20-thread-1] mapred.LocalJobRunner: Starting task: attempt_local541769738_0002_r_000000_0
2024-04-24T20:45:01,742  INFO [pool-20-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:01,745  INFO [pool-20-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@484d8b86
2024-04-24T20:45:01,758  INFO [pool-20-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:01,760  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local541769738_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:01,778  INFO [localfetcher#1] reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local541769738_0002_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:45:01,780  INFO [localfetcher#1] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local541769738_0002_m_000000_0
2024-04-24T20:45:01,781  INFO [localfetcher#1] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:45:01,782  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:01,782  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:01,783  INFO [pool-20-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:01,787  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:01,788  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:01,788  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:01,788  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:45:01,789  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:01,789  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:01,789  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:01,789  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:01,791  INFO [pool-20-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,791  INFO [pool-20-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,791  INFO [pool-20-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/reduce.xml
2024-04-24T20:45:01,791  INFO [pool-20-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:01,795  INFO [pool-20-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:45:01,796  INFO [pool-20-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:01,796  INFO [pool-20-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:01,796  INFO [pool-20-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:01,797  INFO [pool-20-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:01,797  INFO [pool-20-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@4149d6a9 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@ece5c61
2024-04-24T20:45:01,799  INFO [pool-20-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:01,799  INFO [pool-20-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:45:01,799  INFO [pool-20-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:01,808  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:45:01,809  INFO [pool-20-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:01,814  INFO [pool-20-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:01,814  INFO [pool-20-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:01,814  INFO [pool-20-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:01,814  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:45:01,824  INFO [pool-20-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:3, 
2024-04-24T20:45:01,824  INFO [pool-20-thread-1] mapred.Task: Task:attempt_local541769738_0002_r_000000_0 is done. And is in the process of committing
2024-04-24T20:45:01,825  INFO [pool-20-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:01,825  INFO [pool-20-thread-1] mapred.Task: Task 'attempt_local541769738_0002_r_000000_0' done.
2024-04-24T20:45:01,825  INFO [pool-20-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local541769738_0002_r_000000_0
2024-04-24T20:45:01,825  INFO [pool-20-thread-1] mapred.LocalJobRunner: Starting task: attempt_local541769738_0002_r_000001_0
2024-04-24T20:45:01,826  INFO [pool-20-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:01,826  INFO [pool-20-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38ff28cf
2024-04-24T20:45:01,827  INFO [pool-20-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:01,827  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local541769738_0002_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:01,828  INFO [localfetcher#2] reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local541769738_0002_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:45:01,828  INFO [localfetcher#2] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local541769738_0002_m_000000_0
2024-04-24T20:45:01,828  INFO [localfetcher#2] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:45:01,829  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:01,829  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:01,829  INFO [pool-20-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:01,830  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:01,830  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:01,831  INFO [pool-20-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10003/141dd501-42c4-4a95-8615-bf27d591efaa/reduce.xml
2024-04-24T20:45:01,832  INFO [pool-20-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:01,836  INFO [pool-20-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,70KB
2024-04-24T20:45:01,837  INFO [pool-20-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:01,837  INFO [pool-20-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:01,837  INFO [pool-20-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@1b149eb6 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@20d1f4be
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:45:01,838  INFO [pool-20-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:01,844  INFO [pool-20-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:01,849  INFO [pool-20-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:01,854  INFO [pool-20-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tinclude:0, 
2024-04-24T20:45:01,854  INFO [pool-20-thread-1] mapred.Task: Task:attempt_local541769738_0002_r_000001_0 is done. And is in the process of committing
2024-04-24T20:45:01,855  INFO [pool-20-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:01,855  INFO [pool-20-thread-1] mapred.Task: Task 'attempt_local541769738_0002_r_000001_0' done.
2024-04-24T20:45:01,855  INFO [pool-20-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local541769738_0002_r_000001_0
2024-04-24T20:45:01,855  INFO [Thread-127] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:45:02,682 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:45:02,682  INFO [main] exec.Task: 2024-04-24 20:45:02,682 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local541769738_0002
2024-04-24T20:45:02,685  INFO [main] exec.Task: Ended Job = job_local541769738_0002
2024-04-24T20:45:02,686  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/-ext-10000
2024-04-24T20:45:02,686  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:45:02,686  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:02,686  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:02,687  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:02,687  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tinclude
2024-04-24T20:45:02,687  INFO [main] exec.Task: Loading data to table default.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/-ext-10000
2024-04-24T20:45:02,688  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:45:02,688  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:45:02,714  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:02,715  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:02,716  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:02,716  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:02,718  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:02,720  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:02,720  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:02,735  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:45:02,735  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:45:02,753  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:45:02,754  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-01_202_1930893861455678400-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:45:02,755  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:45:02,755  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:45:02,786  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:45:02,786  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:45:02,786  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:02,786  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:02,787  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:02,787  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:02,788  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:45:02,788  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:02,816  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:02,817  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:02,817  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:02,818  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:02,820  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:02,820  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:02,832  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/2d37e171-9bf6-46c0-be0b-2e4e94060d7b/hive_2024-04-24_20-45-01_202_1930893861455678400-1/-mr-10001
2024-04-24T20:45:02,833  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={}}
2024-04-24T20:45:02,833  INFO [main] fs.FSStatsAggregator: Read stats : {default.tinclude/={numRows=3, rawDataSize=0}}
2024-04-24T20:45:02,834  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:45:02,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:45:02,848  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:02,848  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:02,849  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:02,849  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:02,850  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tinclude newtbl=tinclude
2024-04-24T20:45:02,850  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tinclude newtbl=tinclude	
2024-04-24T20:45:02,875  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:02,875  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:02,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:02,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:02,876  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:02,876  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:02,877  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:02,879  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:02,879  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:02,903  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:45:02,903  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:45:02,917  INFO [main] exec.StatsTask: Table default.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:45:02,918  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:45:02,918  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:45:02,918  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:02,918  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:02,918  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 1.438 seconds
OK
2024-04-24T20:45:02,918  INFO [main] ql.Driver: OK
2024-04-24T20:45:02,918  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:02,933  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): update TInclude set a = 1 where b = 2
2024-04-24T20:45:02,936  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:02,936  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:02,949  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `default`.`TInclude` select ROW__ID,`a`,`b` from `default`.`TInclude` sort by ROW__ID >
2024-04-24T20:45:02,952  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:45:02,952  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:02,952  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:02,965  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:02,965  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:02,965  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:45:02,965  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tinclude
2024-04-24T20:45:02,965  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tinclude	
2024-04-24T20:45:02,979  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:45:02,979  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:45:02,979  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:02,979  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:02,993  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:03,022  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tinclude/.hive-staging_hive_2024-04-24_20-45-02_949_6243030291788170054-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:45:03,036 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredTablesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:45:03,036  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:03,037  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.104 seconds
2024-04-24T20:45:03,037  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:03,039  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TInclude
2024-04-24T20:45:03,040  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:03,040  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:03,053  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:03,053  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:03,054  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:03,054  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.015 seconds
2024-04-24T20:45:03,054  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:03,054  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tinclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132)
2024-04-24T20:45:03,069  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:45:03,069  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:03,069  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TInclude
2024-04-24T20:45:03,069  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:03,070  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:03,070  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:03,087  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TInclude
2024-04-24T20:45:03,088  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TInclude	
2024-04-24T20:45:03,107  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TInclude
2024-04-24T20:45:03,107  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TInclude	
2024-04-24T20:45:03,820  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:03,821  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:03,848  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:03,848  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:03,849  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:03,880  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:03,881  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.811 seconds
OK
2024-04-24T20:45:03,881  INFO [main] ql.Driver: OK
2024-04-24T20:45:03,881  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:03,881  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 txnid:0]
2024-04-24T20:45:03,887  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TExclude
2024-04-24T20:45:03,888  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:03,888  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:03,909  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:03,909  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:03,909  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:03,910  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.022 seconds
2024-04-24T20:45:03,910  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:03,910  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texclude, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132)
2024-04-24T20:45:03,927  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:45:03,927  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:03,927  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132): drop table if exists TExclude
2024-04-24T20:45:03,927  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:03,927  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:03,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:03,940  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExclude
2024-04-24T20:45:03,940  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExclude	
2024-04-24T20:45:03,954  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExclude
2024-04-24T20:45:03,954  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExclude	
2024-04-24T20:45:04,006  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:04,006  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:04,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:04,035  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:04,035  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:04,036  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:04,065  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,065  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132); Time taken: 0.138 seconds
OK
2024-04-24T20:45:04,065  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,065  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132
2024-04-24T20:45:04,065  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:5 queryId=alex_20240424204500_ef7dcdd3-e12d-425a-b393-f9b762390132 txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgrade" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="3.309">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TAcid set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
]]></error>
    <system-err><![CDATA[2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:04,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:04,107  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:04,134  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:04,134  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:04,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:04,275  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:04,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:04,450  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf
2024-04-24T20:45:04,452  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf
2024-04-24T20:45:04,455  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf/_tmp_space.db
2024-04-24T20:45:04,455  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=6b0c129d-6e44-4604-94f5-183dcabdf7cf, clientType=HIVECLI]
2024-04-24T20:45:04,455  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:45:04,455  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcid
2024-04-24T20:45:04,456  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:04,456  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:04,458  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,458  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,458  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,459  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.003 seconds
2024-04-24T20:45:04,459  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,459  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcid
2024-04-24T20:45:04,459  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,459  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:04,459  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:04,461 ERROR [main] metadata.Hive: Table TAcid not found: default.TAcid table not found
2024-04-24T20:45:04,461  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:04,461  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:04,463  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,464  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.004 seconds
OK
2024-04-24T20:45:04,464  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,464  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:04,464  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcidPart
2024-04-24T20:45:04,465  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:04,465  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:04,467  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,467  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,467  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,467  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.003 seconds
2024-04-24T20:45:04,468  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,468  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcidPart
2024-04-24T20:45:04,468  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,468  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:04,468  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:04,470 ERROR [main] metadata.Hive: Table TAcidPart not found: default.TAcidPart table not found
2024-04-24T20:45:04,470  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:04,470  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:04,472  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,473  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.004 seconds
OK
2024-04-24T20:45:04,473  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,473  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:04,473  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlat
2024-04-24T20:45:04,474  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:04,474  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:04,476  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,476  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,476  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,476  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.003 seconds
2024-04-24T20:45:04,476  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,476  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlat
2024-04-24T20:45:04,477  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,477  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:04,477  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:04,479 ERROR [main] metadata.Hive: Table TFlat not found: default.TFlat table not found
2024-04-24T20:45:04,479  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:04,479  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:04,481  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,481  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.005 seconds
OK
2024-04-24T20:45:04,481  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,481  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:04,481  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlatText
2024-04-24T20:45:04,482  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:04,482  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:04,484  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,484  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,484  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,484  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.003 seconds
2024-04-24T20:45:04,484  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,484  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlatText
2024-04-24T20:45:04,485  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,485  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:04,485  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:04,487 ERROR [main] metadata.Hive: Table TFlatText not found: default.TFlatText table not found
2024-04-24T20:45:04,487  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:04,487  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:04,489  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,489  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.005 seconds
OK
2024-04-24T20:45:04,489  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,489  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:04,489  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:04,492  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:04,492  INFO [main] parse.CalcitePlanner: Creating table default.TAcid position=13
2024-04-24T20:45:04,492  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:04,492  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:04,497  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,497  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,497  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,497  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.008 seconds
2024-04-24T20:45:04,498  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,498  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:04,521  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:45:04,521  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,521  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TAcid (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:04,521  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,522  INFO [main] exec.DDLTask: creating table default.TAcid on null
2024-04-24T20:45:04,523  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0, numRows=0, numFiles=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:04,523  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcid, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, transactional=true, rawDataSize=0, numRows=0, numFiles=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:04,531  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid
2024-04-24T20:45:04,599  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,599  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.078 seconds
OK
2024-04-24T20:45:04,599  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,599  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,600  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:04,604  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:04,606  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:04,606  INFO [main] parse.CalcitePlanner: Creating table default.TAcidPart position=13
2024-04-24T20:45:04,606  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:04,606  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:04,610  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,610  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,611  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,611  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.007 seconds
2024-04-24T20:45:04,611  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,612  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:04,626  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:45:04,626  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,626  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TAcidPart (a int, b int) partitioned by (p tinyint)  clustered by (b) into 2 buckets  stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:04,626  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,628  INFO [main] exec.DDLTask: creating table default.TAcidPart on null
2024-04-24T20:45:04,628  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:04,628  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TAcidPart, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:p, type:tinyint, comment:null)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:04,641  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacidpart
2024-04-24T20:45:04,667  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,668  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.041 seconds
OK
2024-04-24T20:45:04,668  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,668  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,668  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:04,673  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:45:04,674  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:04,674  INFO [main] parse.CalcitePlanner: Creating table default.TFlat position=13
2024-04-24T20:45:04,674  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:04,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:04,679  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,679  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,679  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,679  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.006 seconds
2024-04-24T20:45:04,679  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,680  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:04,693  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:45:04,693  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,693  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:45:04,693  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,694  INFO [main] exec.DDLTask: creating table default.TFlat on null
2024-04-24T20:45:04,695  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numFiles=0, rawDataSize=0, transactional=false, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:04,695  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlat, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, totalSize=0, numFiles=0, rawDataSize=0, transactional=false, numRows=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:04,695  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:45:04,704  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tflat
2024-04-24T20:45:04,750  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,750  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.056 seconds
OK
2024-04-24T20:45:04,750  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,750  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,750  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:04,755  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:45:04,756  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:04,756  INFO [main] parse.CalcitePlanner: Creating table default.TFlatText position=13
2024-04-24T20:45:04,757  INFO [main] metastore.HiveMetaStore: 0: get_database: default
2024-04-24T20:45:04,757  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: default	
2024-04-24T20:45:04,762  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:04,762  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:04,762  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:04,763  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.007 seconds
2024-04-24T20:45:04,763  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,764  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:default, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:04,779  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:45:04,780  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,780  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')
2024-04-24T20:45:04,780  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:04,781  INFO [main] exec.DDLTask: creating table default.TFlatText on null
2024-04-24T20:45:04,782  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=false, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:04,782  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TFlatText, dbName:default, owner:alex, createTime:1713987904, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{transactional=false, numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:04,783  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:45:04,795  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tflattext
2024-04-24T20:45:04,825  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:04,826  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.045 seconds
OK
2024-04-24T20:45:04,826  INFO [main] ql.Driver: OK
2024-04-24T20:45:04,826  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:04,826  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:04,831  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:45:04,832  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:04,833  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:04,833  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:04,910  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:04,916  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:04,916  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:04,916  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:04,916  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:04,916  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:04,916  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:04,942  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:05,021  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:45:05,021  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:45:05,024  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:45:05,025  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:45:05,031  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:05,031  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:05,049  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:05,049  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:05,049  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:05,050  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:05,050  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:05,064  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1
2024-04-24T20:45:05,077  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:45:05,078  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:45:05,079  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:45:05,079  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:45:05,079  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) default.tacid
2024-04-24T20:45:05,098  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:45:05,098  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:05,098  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:45:05,098  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:05,099  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.267 seconds
2024-04-24T20:45:05,105  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:45:05,105  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:05,105  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:default, tablename:tacid, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:05,125  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:5, state:ACQUIRED)
2024-04-24T20:45:05,129  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): insert into TAcid values(1,2),(3,4),(5,6)
2024-04-24T20:45:05,129  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
2024-04-24T20:45:05,129  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:05,129  INFO [main] ql.Driver: Query ID = alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
Total jobs = 1
2024-04-24T20:45:05,129  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:45:05,129  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:45:05,130  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:45:05,130  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:45:05,130  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:45:05,130  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:45:05,130  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:45:05,130  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:45:05,130  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:45:05,130  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:45:05,131  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:45:05,131  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:45:05,131  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:05,136  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:45:05,138  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:05,143  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:45:05,148  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:45:05,149  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:05,149  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10001
2024-04-24T20:45:05,151  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:05,152  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/map.xml
2024-04-24T20:45:05,152  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/reduce.xml
2024-04-24T20:45:05,156  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:45:05,224  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/map.xml
2024-04-24T20:45:05,224  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:45:05,224  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:45:05,225  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:05,228  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:45:05,228  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:45:05,241  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:45:05,253  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local492730526_0003
2024-04-24T20:45:05,291  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:45:05,292  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:45:05,292  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:05,293  INFO [Thread-243] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:05,294  INFO [Thread-243] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:45:05,294  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local492730526_0003_m_000000_0
2024-04-24T20:45:05,297  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:05,298  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:05,299  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/map.xml
2024-04-24T20:45:05,300  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:45:05,302  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:05,303  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:45:05,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:45:05,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:45:05,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:45:05,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:45:05,308  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:45:05,309  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:45:05,309  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,309  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,309  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/map.xml
2024-04-24T20:45:05,309  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:45:05,310  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:45:05,311  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/map.xml
2024-04-24T20:45:05,312  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:45:05,312  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:45:05,312  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: DESERIALIZE_ERRORS:0, RECORDS_IN:3, 
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:45:05,313  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:45:05,315  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:45:05,315  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:45:05,315  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:45:05,315  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:45:05,315  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:45:05,316  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:45:05,317  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local492730526_0003_m_000000_0 is done. And is in the process of committing
2024-04-24T20:45:05,319  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/6b0c129d-6e44-4604-94f5-183dcabdf7cf/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:05,319  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local492730526_0003_m_000000_0' done.
2024-04-24T20:45:05,319  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local492730526_0003_m_000000_0
2024-04-24T20:45:05,320  INFO [Thread-243] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:45:05,320  INFO [Thread-243] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:45:05,321  INFO [pool-26-thread-1] mapred.LocalJobRunner: Starting task: attempt_local492730526_0003_r_000000_0
2024-04-24T20:45:05,323  INFO [pool-26-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:05,323  INFO [pool-26-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@212747b3
2024-04-24T20:45:05,323  INFO [pool-26-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:05,324  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local492730526_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:05,327  INFO [localfetcher#3] reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local492730526_0003_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:45:05,327  INFO [localfetcher#3] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local492730526_0003_m_000000_0
2024-04-24T20:45:05,327  INFO [localfetcher#3] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:45:05,327  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:05,328  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:05,328  INFO [pool-26-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:05,329  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:05,330  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:05,330  INFO [pool-26-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,330  INFO [pool-26-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,330  INFO [pool-26-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/reduce.xml
2024-04-24T20:45:05,330  INFO [pool-26-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:05,333  INFO [pool-26-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:45:05,333  INFO [pool-26-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:05,333  INFO [pool-26-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:05,333  INFO [pool-26-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:05,334  INFO [pool-26-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:05,334  INFO [pool-26-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@558b7b16 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@4e0ab4cb
2024-04-24T20:45:05,335  INFO [pool-26-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:05,335  INFO [pool-26-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:45:05,335  INFO [pool-26-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:05,339  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:45:05,339  INFO [pool-26-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:05,344  INFO [pool-26-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:05,344  INFO [pool-26-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:05,344  INFO [pool-26-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:05,344  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:45:05,351  INFO [pool-26-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:3, 
2024-04-24T20:45:05,351  INFO [pool-26-thread-1] mapred.Task: Task:attempt_local492730526_0003_r_000000_0 is done. And is in the process of committing
2024-04-24T20:45:05,352  INFO [pool-26-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:05,352  INFO [pool-26-thread-1] mapred.Task: Task 'attempt_local492730526_0003_r_000000_0' done.
2024-04-24T20:45:05,352  INFO [pool-26-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local492730526_0003_r_000000_0
2024-04-24T20:45:05,352  INFO [pool-26-thread-1] mapred.LocalJobRunner: Starting task: attempt_local492730526_0003_r_000001_0
2024-04-24T20:45:05,353  INFO [pool-26-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:05,353  INFO [pool-26-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6265c52a
2024-04-24T20:45:05,353  INFO [pool-26-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:05,354  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local492730526_0003_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:05,355  INFO [localfetcher#4] reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local492730526_0003_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:45:05,355  INFO [localfetcher#4] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local492730526_0003_m_000000_0
2024-04-24T20:45:05,355  INFO [localfetcher#4] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:45:05,355  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:05,356  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:05,356  INFO [pool-26-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:05,357  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:05,357  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:05,358  INFO [pool-26-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10003/b1810f63-b1d9-472a-8339-76bf114aea5c/reduce.xml
2024-04-24T20:45:05,359  INFO [pool-26-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:05,361  INFO [pool-26-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,68KB
2024-04-24T20:45:05,361  INFO [pool-26-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:05,361  INFO [pool-26-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:05,362  INFO [pool-26-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:05,362  INFO [pool-26-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@7e926fc and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@30866441
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:45:05,363  INFO [pool-26-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:05,368  INFO [pool-26-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:05,372  INFO [pool-26-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:05,377  INFO [pool-26-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_default.tacid:0, 
2024-04-24T20:45:05,377  INFO [pool-26-thread-1] mapred.Task: Task:attempt_local492730526_0003_r_000001_0 is done. And is in the process of committing
2024-04-24T20:45:05,378  INFO [pool-26-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:05,378  INFO [pool-26-thread-1] mapred.Task: Task 'attempt_local492730526_0003_r_000001_0' done.
2024-04-24T20:45:05,378  INFO [pool-26-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local492730526_0003_r_000001_0
2024-04-24T20:45:05,378  INFO [Thread-243] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:45:06,310 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:45:06,310  INFO [main] exec.Task: 2024-04-24 20:45:06,310 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local492730526_0003
2024-04-24T20:45:06,315  INFO [main] exec.Task: Ended Job = job_local492730526_0003
2024-04-24T20:45:06,316  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/-ext-10000
2024-04-24T20:45:06,316  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:45:06,316  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:06,316  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:06,317  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:06,317  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table default.tacid
2024-04-24T20:45:06,317  INFO [main] exec.Task: Loading data to table default.tacid from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/-ext-10000
2024-04-24T20:45:06,318  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:45:06,318  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:06,343  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:06,344  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:06,345  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:06,346  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:06,355  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:06,356  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:06,368  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:45:06,368  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:45:06,381  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:45:06,382  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-04_831_1496577704030627444-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:45:06,383  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:45:06,383  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:45:06,418  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:45:06,418  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:45:06,419  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:06,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:06,419  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:06,419  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:06,421  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:45:06,421  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:45:06,446  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:06,446  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:06,446  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:06,446  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:06,446  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:06,447  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:06,448  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:06,449  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:06,451  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:06,451  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:06,466  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/6b0c129d-6e44-4604-94f5-183dcabdf7cf/hive_2024-04-24_20-45-04_831_1496577704030627444-1/-mr-10001
2024-04-24T20:45:06,467  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={numRows=3, rawDataSize=0}}
2024-04-24T20:45:06,467  INFO [main] fs.FSStatsAggregator: Read stats : {default.tacid/={}}
2024-04-24T20:45:06,467  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:45:06,467  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:45:06,488  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:06,488  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:06,488  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:06,488  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:06,490  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=default tbl=tacid newtbl=tacid
2024-04-24T20:45:06,490  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=tacid newtbl=tacid	
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:06,520  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:06,521  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:06,521  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:06,523  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:06,523  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:06,543  INFO [main] hive.log: Updating table stats fast for tacid
2024-04-24T20:45:06,543  INFO [main] hive.log: Updated size of table tacid to 802
2024-04-24T20:45:06,557  INFO [main] exec.StatsTask: Table default.tacid stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:45:06,558  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:45:06,559  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:45:06,559  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:06,559  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:06,559  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 1.429 seconds
OK
2024-04-24T20:45:06,559  INFO [main] ql.Driver: OK
2024-04-24T20:45:06,559  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:06,577  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): update TAcid set a = 1 where b = 2
2024-04-24T20:45:06,577  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,577  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,589  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TAcid set a = 1 where b = 2> as 
<insert into table `default`.`TAcid` select ROW__ID,`a`,`b` from `default`.`TAcid` sort by ROW__ID >
2024-04-24T20:45:06,590  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:45:06,590  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,590  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,603  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:06,603  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:06,603  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:45:06,603  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=tacid
2024-04-24T20:45:06,603  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=tacid	
2024-04-24T20:45:06,615  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:45:06,615  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:45:06,615  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,615  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,628  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:06,630  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/tacid/.hive-staging_hive_2024-04-24_20-45-06_589_292489615464906632-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:45:06,640 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgrade(TestPreUpgradeTool.java:100)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:45:06,641  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:06,641  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.066 seconds
2024-04-24T20:45:06,641  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:06,642  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcid
2024-04-24T20:45:06,642  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,642  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,657  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:06,658  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:06,658  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:06,658  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.016 seconds
2024-04-24T20:45:06,658  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:06,659  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacid, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:06,673  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:6, state:ACQUIRED)
2024-04-24T20:45:06,673  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:06,673  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcid
2024-04-24T20:45:06,674  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:06,674  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,674  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,690  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcid
2024-04-24T20:45:06,690  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcid	
2024-04-24T20:45:06,702  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcid
2024-04-24T20:45:06,702  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcid	
2024-04-24T20:45:06,844  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:06,844  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:06,890  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:06,891  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:06,921  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:06,922  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.248 seconds
OK
2024-04-24T20:45:06,922  INFO [main] ql.Driver: OK
2024-04-24T20:45:06,922  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:06,922  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:6 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:06,926  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcidPart
2024-04-24T20:45:06,927  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:06,927  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:06,939  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:06,939  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:06,939  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:06,940  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.013 seconds
2024-04-24T20:45:06,940  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:06,940  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tacidpart, operationType:NO_TXN, isAcid:true, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:07,043  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:7, state:ACQUIRED)
2024-04-24T20:45:07,043  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,043  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TAcidPart
2024-04-24T20:45:07,043  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:07,044  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:07,044  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:07,057  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TAcidPart
2024-04-24T20:45:07,057  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TAcidPart	
2024-04-24T20:45:07,073  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TAcidPart
2024-04-24T20:45:07,073  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TAcidPart	
2024-04-24T20:45:07,131  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:07,131  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:07,160  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:07,161  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:07,180  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:07,180  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.137 seconds
OK
2024-04-24T20:45:07,180  INFO [main] ql.Driver: OK
2024-04-24T20:45:07,180  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,180  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:7 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:07,184  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlat
2024-04-24T20:45:07,185  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:07,185  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:07,196  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:07,197  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:07,197  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:07,197  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.013 seconds
2024-04-24T20:45:07,197  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,197  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflat, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:07,210  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:8, state:ACQUIRED)
2024-04-24T20:45:07,210  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,210  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlat
2024-04-24T20:45:07,210  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:07,210  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:07,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:07,223  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlat
2024-04-24T20:45:07,223  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlat	
2024-04-24T20:45:07,234  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlat
2024-04-24T20:45:07,234  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlat	
2024-04-24T20:45:07,282  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:07,283  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:07,283  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.073 seconds
OK
2024-04-24T20:45:07,283  INFO [main] ql.Driver: OK
2024-04-24T20:45:07,283  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,283  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:8 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
2024-04-24T20:45:07,287  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlatText
2024-04-24T20:45:07,287  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:07,287  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:07,299  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:07,299  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:07,299  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:07,300  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.012 seconds
2024-04-24T20:45:07,300  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,300  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:tflattext, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa)
2024-04-24T20:45:07,313  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa LockResponse(lockid:9, state:ACQUIRED)
2024-04-24T20:45:07,313  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,313  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa): drop table if exists TFlatText
2024-04-24T20:45:07,313  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:07,313  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:07,313  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:07,325  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TFlatText
2024-04-24T20:45:07,325  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TFlatText	
2024-04-24T20:45:07,337  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TFlatText
2024-04-24T20:45:07,337  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TFlatText	
2024-04-24T20:45:07,382  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:07,382  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:07,383  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa); Time taken: 0.069 seconds
OK
2024-04-24T20:45:07,383  INFO [main] ql.Driver: OK
2024-04-24T20:45:07,383  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa
2024-04-24T20:45:07,383  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:9 queryId=alex_20240424204504_d46ef173-8dd0-446d-95a0-ddccc1b5f3fa txnid:0]
]]></system-err>
  </testcase>
  <testcase name="testUpgradeExternalTableNoReadPermissionForDatabase" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="6.673">
    <failure type="java.lang.AssertionError"><![CDATA[java.lang.AssertionError
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:303)
]]></failure>
    <system-err><![CDATA[2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:07,411  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:07,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:07,412  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:07,412  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:07,412  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:07,412  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:07,438  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:07,439  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:07,539  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.TxnHandler: Failed to update number of open transactions
2024-04-24T20:45:07,540  INFO [org.apache.hadoop.hive.ql.txn.AcidOpenTxnsCounterService-0] txn.TxnHandler: Non-retryable error in countOpenTxns() : Table/View 'TXNS' does not exist. (SQLState=42X05, ErrorCode=20000)
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:07,610  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:07,611  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:07,767  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f
2024-04-24T20:45:07,769  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f
2024-04-24T20:45:07,771  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f/_tmp_space.db
2024-04-24T20:45:07,771  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f78071e8-4344-4f2d-8103-cb53585dca8f, clientType=HIVECLI]
2024-04-24T20:45:07,772  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:45:07,772  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): drop database if exists test cascade
2024-04-24T20:45:07,773  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:45:07,773  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:45:07,778  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:45:07,778  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:45:07,786  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:07,786  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:07,804  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:07,804  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:07,804  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:07,804  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.032 seconds
2024-04-24T20:45:07,804  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:07,805  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c)
2024-04-24T20:45:07,826  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:45:07,826  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:07,826  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): drop database if exists test cascade
2024-04-24T20:45:07,826  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:07,826  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:45:07,826  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:45:07,831  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:07,831  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:07,834  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:45:07,834  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:45:07,835  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:07,835  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:07,837  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:45:07,837  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:45:07,843  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:45:07,927  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:07,952  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:07,972 ERROR [main] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:171)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.derby.impl.jdbc.Util.newBatchUpdateException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:424)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:676)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:644)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:731)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:89)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:450)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:210)
	at org.datanucleus.TransactionImpl.commit(TransactionImpl.java:274)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:107)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: java.sql.SQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 95 more
Caused by: java.sql.SQLException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
	... 103 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 97 more

2024-04-24T20:45:09,973  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:45:09,973  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:45:09,978  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:09,978  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:09,980  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:45:09,980  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:45:09,982  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:45:09,985  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:10,010  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:10,011  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:10,023 ERROR [main] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:171)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
NestedThrowablesStackTrace:
java.sql.BatchUpdateException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.derby.impl.jdbc.Util.newBatchUpdateException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeLargeBatch(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeBatch(Unknown Source)
	at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:424)
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)
	at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:676)
	at org.datanucleus.store.rdbms.SQLController.processStatementsForConnection(SQLController.java:644)
	at org.datanucleus.store.rdbms.SQLController$1.transactionFlushed(SQLController.java:731)
	at org.datanucleus.store.connection.AbstractManagedConnection.transactionFlushed(AbstractManagedConnection.java:89)
	at org.datanucleus.store.connection.ConnectionManagerImpl$2.transactionFlushed(ConnectionManagerImpl.java:450)
	at org.datanucleus.TransactionImpl.flush(TransactionImpl.java:210)
	at org.datanucleus.TransactionImpl.commit(TransactionImpl.java:274)
	at org.datanucleus.api.jdo.JDOTransaction.commit(JDOTransaction.java:107)
	at org.apache.hadoop.hive.metastore.ObjectStore.commitTransaction(ObjectStore.java:620)
	at sun.reflect.GeneratedMethodAccessor74.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy35.commitTransaction(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database_core(HiveMetaStore.java:1112)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_database(HiveMetaStore.java:1171)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy36.drop_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:868)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
	at com.sun.proxy.$Proxy37.dropDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:484)
	at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:4263)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:324)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:199)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2183)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1839)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1526)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testUpgradeExternalTableNoReadPermissionForDatabase(TestPreUpgradeTool.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
Caused by: java.sql.SQLIntegrityConstraintViolationException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeBatchElement(Unknown Source)
	... 95 more
Caused by: java.sql.SQLException: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source)
	... 103 more
Caused by: ERROR 23503: DELETE on table 'DBS' caused a violation of foreign key constraint 'TBLS_FK1' for key (11).  The statement has been rolled back.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.sql.execute.ReferencedKeyRIChecker.doCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.RISetChecker.doPKCheck(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.collectAffectedRows(Unknown Source)
	at org.apache.derby.impl.sql.execute.DeleteResultSet.open(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
	... 97 more

2024-04-24T20:45:12,024  INFO [main] metastore.HiveMetaStore: 0: drop_database: test
2024-04-24T20:45:12,024  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: test	
2024-04-24T20:45:12,029  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:12,029  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:12,032  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=test pat=*
2024-04-24T20:45:12,032  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=test pat=*	
2024-04-24T20:45:12,075  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=test tbl=texternal
2024-04-24T20:45:12,075  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=test tbl=texternal	
2024-04-24T20:45:12,180  INFO [main] metastore.ObjectStore: Dropping database test along with all tables
2024-04-24T20:45:12,186  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db does not exist; Force to delete it.
2024-04-24T20:45:12,186 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987824955/warehouse/test.db
2024-04-24T20:45:12,186  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:12,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:12,213  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:12,226  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:12,226  INFO [main] metadata.Hive: Total time spent in this metastore function was greater than 1000ms : dropDatabase_(String, boolean, boolean, boolean, )=4399
2024-04-24T20:45:12,226  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 4.4 seconds
OK
2024-04-24T20:45:12,226  INFO [main] ql.Driver: OK
2024-04-24T20:45:12,226  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,226  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c txnid:0]
2024-04-24T20:45:12,231  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): drop table if exists TExternal
2024-04-24T20:45:12,231  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:45:12,231  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:45:12,244  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:12,244  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:12,245  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:12,245  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.015 seconds
2024-04-24T20:45:12,245  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,245  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:default, tablename:texternal, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c)
2024-04-24T20:45:12,262  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:45:12,262  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,262  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): drop table if exists TExternal
2024-04-24T20:45:12,262  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:12,263  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:45:12,263  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:45:12,275  INFO [main] metastore.HiveMetaStore: 0: get_table : db=default tbl=TExternal
2024-04-24T20:45:12,275  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=default tbl=TExternal	
2024-04-24T20:45:12,286  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=default tbl=TExternal
2024-04-24T20:45:12,286  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=TExternal	
2024-04-24T20:45:12,342  WARN [main] common.FileUtils: File file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/texternal does not exist; Force to delete it.
2024-04-24T20:45:12,343 ERROR [main] common.FileUtils: Failed to delete file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/texternal
2024-04-24T20:45:12,343  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:12,343  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.081 seconds
OK
2024-04-24T20:45:12,343  INFO [main] ql.Driver: OK
2024-04-24T20:45:12,343  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,343  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:2 queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c txnid:0]
2024-04-24T20:45:12,347  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): create database test
2024-04-24T20:45:12,348  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:12,349  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:12,349  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:12,349  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.002 seconds
2024-04-24T20:45:12,349  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,349  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): create database test
2024-04-24T20:45:12,349  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:12,351  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:45:12,351  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:test, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:45:12,352  WARN [main] metastore.ObjectStore: Failed to get database test, returning NoSuchObjectException
2024-04-24T20:45:12,355  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db
2024-04-24T20:45:12,378  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:12,378  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.029 seconds
OK
2024-04-24T20:45:12,379  INFO [main] ql.Driver: OK
2024-04-24T20:45:12,379  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:12,379  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:45:12,380  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:12,380  INFO [main] parse.CalcitePlanner: Creating table test.TExternal position=13
2024-04-24T20:45:12,380  INFO [main] metastore.HiveMetaStore: 0: get_database: test
2024-04-24T20:45:12,380  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: test	
2024-04-24T20:45:12,384  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:12,384  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:12,384  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:12,385  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.005 seconds
2024-04-24T20:45:12,385  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,385  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:test, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c)
2024-04-24T20:45:12,397  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:45:12,397  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,397  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): create table test.TExternal (a int, b int) stored as orc tblproperties('transactional'='false')
2024-04-24T20:45:12,398  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:12,399  INFO [main] exec.DDLTask: creating table test.TExternal on null
2024-04-24T20:45:12,399  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987912, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, totalSize=0, transactional=false, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:12,399  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TExternal, dbName:test, owner:alex, createTime:1713987912, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=0, COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, numRows=0, totalSize=0, transactional=false, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:12,400  INFO [main] metastore.TransactionalValidationListener: 'transactional'='false' is no longer a valid property and will be ignored
2024-04-24T20:45:12,407  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal
2024-04-24T20:45:12,454  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:12,454  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.057 seconds
OK
2024-04-24T20:45:12,454  INFO [main] ql.Driver: OK
2024-04-24T20:45:12,454  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,454  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c txnid:0]
2024-04-24T20:45:12,458  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:45:12,459  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:12,459  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:45:12,459  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:45:12,472  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:12,477  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:12,477  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:12,478  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:12,478  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:12,478  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:45:12,478  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:45:12,490  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:12,555  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:45:12,555  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:45:12,558  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:45:12,558  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:45:12,563  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:12,563  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:12,578  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:12,578  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:12,578  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:12,578  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=TExternal
2024-04-24T20:45:12,578  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=TExternal	
2024-04-24T20:45:12,590  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1
2024-04-24T20:45:12,604  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:45:12,604  INFO [main] ppd.OpProcFactory: Processing for FS(3)
2024-04-24T20:45:12,604  INFO [main] ppd.OpProcFactory: Processing for SEL(2)
2024-04-24T20:45:12,604  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:45:12,604  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:45:12,612  INFO [main] optimizer.GenMRFileSink1: using CombineHiveInputformat for the merge job
2024-04-24T20:45:12,612  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:12,612  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:12,625  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:45:12,625  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:12,625  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:45:12,625  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:12,626  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 0.167 seconds
2024-04-24T20:45:12,626  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,626  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockRequest(component:[LockComponent(type:EXCLUSIVE, level:TABLE, dbname:test, tablename:texternal, operationType:INSERT, isAcid:false, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c)
2024-04-24T20:45:12,637  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c LockResponse(lockid:4, state:ACQUIRED)
2024-04-24T20:45:12,638  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,638  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c): insert into test.TExternal values(1,2),(3,4),(5,6)
2024-04-24T20:45:12,638  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:45:12,638  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:12,638  INFO [main] ql.Driver: Query ID = alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
Total jobs = 1
2024-04-24T20:45:12,638  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:45:12,638  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:45:12,639  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:45:12,639  INFO [main] exec.Task: Number of reduce tasks is set to 0 since there's no reduce operator
2024-04-24T20:45:12,639  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:45:12,639  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:45:12,639  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:12,644  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:45:12,646  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:45:12,647  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:12,648  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10001
2024-04-24T20:45:12,649  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:12,650  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10004/55c03980-8ed0-42fa-addc-98747319c5a9/map.xml
2024-04-24T20:45:12,654  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:45:12,712  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10004/55c03980-8ed0-42fa-addc-98747319c5a9/map.xml
2024-04-24T20:45:12,713  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:45:12,713  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:45:12,713  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:12,717  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:45:12,717  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:45:12,729  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:45:12,741  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1121096523_0004
2024-04-24T20:45:12,782  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:45:12,782  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:45:12,782  INFO [Thread-365] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:12,782  INFO [Thread-365] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:12,784  INFO [Thread-365] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:45:12,784  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1121096523_0004_m_000000_0
2024-04-24T20:45:12,786  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:12,787  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:12,788  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10004/55c03980-8ed0-42fa-addc-98747319c5a9/map.xml
2024-04-24T20:45:12,788  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:45:12,790  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:45:12,791  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2024-04-24T20:45:12,793  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:12,793  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:12,793  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10004/55c03980-8ed0-42fa-addc-98747319c5a9/map.xml
2024-04-24T20:45:12,793  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:45:12,794  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:45:12,794  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:45:12,794  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:45:12,794  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:45:12,795  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Initializing operator FS[3]
2024-04-24T20:45:12,796  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@62024733 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@234a6a8b
2024-04-24T20:45:12,796  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10004/55c03980-8ed0-42fa-addc-98747319c5a9/map.xml
2024-04-24T20:45:12,796  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_tmp.-ext-10002/000000_0
2024-04-24T20:45:12,796  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_task_tmp.-ext-10002/_tmp.000000_0
2024-04-24T20:45:12,796  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_tmp.-ext-10002/000000_0
2024-04-24T20:45:12,798  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 1
2024-04-24T20:45:12,798  INFO [LocalJobRunner Map Task Executor #0] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:45:12,802  INFO [LocalJobRunner Map Task Executor #0] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_task_tmp.-ext-10002/_tmp.000000_0 with stripeSize: 67108864 blockSize: 268435456 compression: ZLIB bufferSize: 262144
2024-04-24T20:45:12,802  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: Closing operator FS[3]
2024-04-24T20:45:12,803  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: FS[3]: records written - 3
2024-04-24T20:45:12,810  INFO [LocalJobRunner Map Task Executor #0] exec.FileSinkOperator: RECORDS_OUT_1_test.texternal:3, 
2024-04-24T20:45:12,810  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:45:12,810  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1121096523_0004_m_000000_0 is done. And is in the process of committing
2024-04-24T20:45:12,812  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/f78071e8-4344-4f2d-8103-cb53585dca8f/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:12,812  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1121096523_0004_m_000000_0' done.
2024-04-24T20:45:12,812  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1121096523_0004_m_000000_0
2024-04-24T20:45:12,812  INFO [Thread-365] mapred.LocalJobRunner: map task executor complete.
2024-04-24 20:45:13,786 Stage-1 map = 100%,  reduce = 0%
2024-04-24T20:45:13,786  INFO [main] exec.Task: 2024-04-24 20:45:13,786 Stage-1 map = 100%,  reduce = 0%
Ended Job = job_local1121096523_0004
2024-04-24T20:45:13,788  INFO [main] exec.Task: Ended Job = job_local1121096523_0004
2024-04-24T20:45:13,790  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/_tmp.-ext-10002 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/-ext-10002
2024-04-24T20:45:13,790  INFO [main] ql.Driver: Starting task [Stage-7:CONDITIONAL] in serial mode
Stage-4 is selected by condition resolver.
2024-04-24T20:45:13,791  INFO [main] exec.Task: Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
2024-04-24T20:45:13,791  INFO [main] exec.Task: Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
2024-04-24T20:45:13,791  INFO [main] exec.Task: Stage-5 is filtered out by condition resolver.
2024-04-24T20:45:13,791  INFO [main] ql.Driver: Starting task [Stage-4:MOVE] in serial mode
2024-04-24T20:45:13,791  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:13,791  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:13,791  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:13,791  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/-ext-10000
2024-04-24T20:45:13,792  INFO [main] exec.Task: Moving data to directory file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/-ext-10000 from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/-ext-10002
2024-04-24T20:45:13,792  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:13,792  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:13,808  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table test.texternal
2024-04-24T20:45:13,808  INFO [main] exec.Task: Loading data to table test.texternal from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/test.db/texternal/.hive-staging_hive_2024-04-24_20-45-12_458_1026018885064862291-1/-ext-10000
2024-04-24T20:45:13,809  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:13,809  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:13,843  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:13,844  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:13,844  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:13,844  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:13,852  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:13,853  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:13,864  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:13,864  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:13,876  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:13,876  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:13,884  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:45:13,884  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:45:13,920  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:45:13,920  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:45:13,921  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:13,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:13,921  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:13,921  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:13,922  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:13,922  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:13,945  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:13,946  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:13,946  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:13,947  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:13,948  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:13,948  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:13,960  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/f78071e8-4344-4f2d-8103-cb53585dca8f/hive_2024-04-24_20-45-12_458_1026018885064862291-1/-mr-10001
2024-04-24T20:45:13,960  INFO [main] fs.FSStatsAggregator: Read stats : {test.texternal/={rawDataSize=24, numRows=3}}
2024-04-24T20:45:13,961  INFO [main] metastore.HiveMetaStore: 0: get_table : db=test tbl=texternal
2024-04-24T20:45:13,961  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=test tbl=texternal	
2024-04-24T20:45:13,974  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	numRows	3
2024-04-24T20:45:13,974  INFO [main] fs.FSStatsAggregator: Read stats for : test.texternal/	rawDataSize	24
2024-04-24T20:45:13,974  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:13,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:13,974  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:13,974  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:13,975  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=test tbl=texternal newtbl=texternal
2024-04-24T20:45:13,975  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=test tbl=texternal newtbl=texternal	
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:14,002  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:14,003  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:14,003  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:14,003  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:14,005  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:14,005  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:14,025  INFO [main] hive.log: Updating table stats fast for texternal
2024-04-24T20:45:14,025  INFO [main] hive.log: Updated size of table texternal to 244
2024-04-24T20:45:14,036  INFO [main] exec.StatsTask: Table test.texternal stats: [numFiles=1, numRows=3, totalSize=244, rawDataSize=24]
2024-04-24T20:45:14,036  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:45:14,036  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:45:14,036  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:14,036  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:14,036  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c); Time taken: 1.398 seconds
OK
2024-04-24T20:45:14,037  INFO [main] ql.Driver: OK
2024-04-24T20:45:14,037  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c
2024-04-24T20:45:14,037  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:4 queryId=alex_20240424204507_14793f17-20d2-4cda-832a-495e4fbd904c txnid:0]
2024-04-24T20:45:14,040  INFO [main] acid.PreUpgradeTool: Starting with RunOptions{outputDir='/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713', execute=true, dbRegex='.*', tableRegex='.*', tableType=null, tablePoolSize=8}
2024-04-24T20:45:14,040  INFO [main] acid.PreUpgradeTool: Using Hive Version: 2.3.3 build: 2.3.3 from 8a511e3f79b43d4be41cd231cf5c99e43b248383 by daijy source checksum fb9b95d9baaf3f968c457dee42d015d4
2024-04-24T20:45:14,041  INFO [main] acid.PreUpgradeTool: Creating metastore client for PreUpgradeTool
2024-04-24T20:45:14,042  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:14,044  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:14,044  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:14,049  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f78071e8-4344-4f2d-8103-cb53585dca8f, clientType=HIVECLI]
2024-04-24T20:45:14,049  INFO [main] metastore.HiveMetaStore: 0: get_databases: .*
2024-04-24T20:45:14,049  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_databases: .*	
2024-04-24T20:45:14,052  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
2024-04-24T20:45:14,052  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
2024-04-24T20:45:14,056  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=test pat=.*
2024-04-24T20:45:14,056  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=test pat=.*	
2024-04-24T20:45:14,058  INFO [main] acid.PreUpgradeTool: No compaction is necessary
2024-04-24T20:45:14,059  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:14,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:14,059  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:14,059  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
]]></system-err>
  </testcase>
  <testcase name="testConcurrency" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="35.184"/>
  <testcase name="testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven" classname="org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool" time="2.434">
    <error type="java.lang.RuntimeException"><![CDATA[java.lang.RuntimeException: update TInclude set a = 1 where b = 2 failed: (40000,FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  ,42000No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  )
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:422)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:179)
]]></error>
    <system-err><![CDATA[2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:49,270  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:49,295  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:49,444  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:49,582  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5
2024-04-24T20:45:49,584  INFO [main] session.SessionState: Created local directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5
2024-04-24T20:45:49,587  INFO [main] session.SessionState: Created HDFS directory: /home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5/_tmp_space.db
2024-04-24T20:45:49,587  INFO [main] sqlstd.SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5af3846b-cc6e-4911-9433-0af9c34376b5, clientType=HIVECLI]
2024-04-24T20:45:49,587  WARN [main] session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2024-04-24T20:45:49,587  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DInclude cascade
2024-04-24T20:45:49,588  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:49,588  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:49,589  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:45:49,589  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,589  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:49,589  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,590  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.002 seconds
2024-04-24T20:45:49,590  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,590  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DInclude cascade
2024-04-24T20:45:49,590  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:49,591  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.0 seconds
OK
2024-04-24T20:45:49,591  INFO [main] ql.Driver: OK
2024-04-24T20:45:49,591  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:49,591  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DExclude cascade
2024-04-24T20:45:49,591  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:45:49,591  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:45:49,592  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:45:49,592  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,592  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:49,592  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,593  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.001 seconds
2024-04-24T20:45:49,593  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,593  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DExclude cascade
2024-04-24T20:45:49,593  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:49,594  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.0 seconds
OK
2024-04-24T20:45:49,594  INFO [main] ql.Driver: OK
2024-04-24T20:45:49,594  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:49,594  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): create database DInclude
2024-04-24T20:45:49,594  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,594  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:49,594  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,595  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.0 seconds
2024-04-24T20:45:49,595  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,595  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): create database DInclude
2024-04-24T20:45:49,595  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:49,596  INFO [main] metastore.HiveMetaStore: 0: create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)
2024-04-24T20:45:49,596  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_database: Database(name:DInclude, description:null, locationUri:null, parameters:null, ownerName:alex, ownerType:USER)	
2024-04-24T20:45:49,597  WARN [main] metastore.ObjectStore: Failed to get database DInclude, returning NoSuchObjectException
2024-04-24T20:45:49,600  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db
2024-04-24T20:45:49,616  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:49,617  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.021 seconds
OK
2024-04-24T20:45:49,617  INFO [main] ql.Driver: OK
2024-04-24T20:45:49,617  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:49,617  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): use DInclude
2024-04-24T20:45:49,618  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:49,618  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:49,623  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,623  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:49,623  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,623  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.006 seconds
2024-04-24T20:45:49,623  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,624  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): use DInclude
2024-04-24T20:45:49,624  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:49,624  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:49,624  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:49,629  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:49,629  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:49,633  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:49,634  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.009 seconds
OK
2024-04-24T20:45:49,634  INFO [main] ql.Driver: OK
2024-04-24T20:45:49,634  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:49,634  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:49,635  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:49,635  INFO [main] parse.CalcitePlanner: Creating table DInclude.TInclude position=13
2024-04-24T20:45:49,635  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:49,635  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:49,640  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,640  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:49,640  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,640  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.006 seconds
2024-04-24T20:45:49,641  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,641  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockRequest(component:[LockComponent(type:SHARED_READ, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c)
2024-04-24T20:45:49,658  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockResponse(lockid:1, state:ACQUIRED)
2024-04-24T20:45:49,659  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,659  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): create table TInclude (a int, b int) clustered by (b) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true')
2024-04-24T20:45:49,659  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:49,661  INFO [main] exec.DDLTask: creating table DInclude.TInclude on null
2024-04-24T20:45:49,662  INFO [main] metastore.HiveMetaStore: 0: create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987949, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numFiles=0, transactional=true, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2024-04-24T20:45:49,663  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=create_table: Table(tableName:TInclude, dbName:DInclude, owner:alex, createTime:1713987949, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:2, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:[b], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{COLUMN_STATS_ACCURATE={"BASIC_STATS":"true"}, rawDataSize=0, numFiles=0, transactional=true, numRows=0, totalSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{alex=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:alex, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2024-04-24T20:45:49,675  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude
2024-04-24T20:45:49,726  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:49,726  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.067 seconds
OK
2024-04-24T20:45:49,726  INFO [main] ql.Driver: OK
2024-04-24T20:45:49,726  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,726  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:1 queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c txnid:0]
2024-04-24T20:45:49,730  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:45:49,731  INFO [main] parse.CalcitePlanner: Starting Semantic Analysis
2024-04-24T20:45:49,731  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:49,731  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:49,779  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:49,784  INFO [main] parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:49,784  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:49,784  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:49,784  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:49,784  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:49,784  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:49,801  INFO [main] parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:49,855  INFO [main] metastore.HiveMetaStore: 0: get_all_databases
2024-04-24T20:45:49,855  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_databases	
2024-04-24T20:45:49,857  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=default
2024-04-24T20:45:49,857  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=default	
2024-04-24T20:45:49,863  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:45:49,863  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:45:49,866  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=test
2024-04-24T20:45:49,866  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=test	
2024-04-24T20:45:49,880  INFO [main] parse.CalcitePlanner: Get metadata for source tables
2024-04-24T20:45:49,880  INFO [main] parse.CalcitePlanner: Get metadata for subqueries
2024-04-24T20:45:49,880  INFO [main] parse.CalcitePlanner: Get metadata for destination tables
2024-04-24T20:45:49,880  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:49,880  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:49,891  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1
2024-04-24T20:45:49,902  INFO [main] parse.CalcitePlanner: CBO Succeeded; optimized logical plan.
2024-04-24T20:45:49,902  INFO [main] ppd.OpProcFactory: Processing for FS(5)
2024-04-24T20:45:49,902  INFO [main] ppd.OpProcFactory: Processing for SEL(4)
2024-04-24T20:45:49,902  INFO [main] ppd.OpProcFactory: Processing for SEL(3)
2024-04-24T20:45:49,903  INFO [main] ppd.OpProcFactory: Processing for RS(2)
2024-04-24T20:45:49,903  INFO [main] ppd.OpProcFactory: Processing for SEL(1)
2024-04-24T20:45:49,903  INFO [main] ppd.OpProcFactory: Processing for TS(0)
2024-04-24T20:45:49,903  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 oldColExprMap: {VALUE._col1=Column[_col1], VALUE._col0=Column[_col0]}
2024-04-24T20:45:49,903  INFO [main] optimizer.ColumnPrunerProcFactory: RS 2 newColExprMap: {VALUE._col0=Column[_col0], VALUE._col1=Column[_col1]}
2024-04-24T20:45:49,903  INFO [main] correlation.AbstractCorrelationProcCtx: Overriding hive.optimize.reducededuplication.min.reducer to 1 due to a write to transactional table(s) dinclude.tinclude
2024-04-24T20:45:49,920  INFO [main] parse.CalcitePlanner: Completed plan generation
2024-04-24T20:45:49,920  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:49,920  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:int, comment:null), FieldSchema(name:_col1, type:int, comment:null)], properties:null)
2024-04-24T20:45:49,921  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:49,921  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.191 seconds
2024-04-24T20:45:49,927  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: null
2024-04-24T20:45:49,927  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:1 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,927  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockRequest(component:[LockComponent(type:SHARED_READ, level:TABLE, dbname:dinclude, tablename:tinclude, operationType:INSERT, isAcid:true, isDynamicPartitionWrite:false)], txnid:1, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c)
2024-04-24T20:45:49,942  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockResponse(lockid:2, state:ACQUIRED)
2024-04-24T20:45:49,945  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): insert into TInclude values(1,2),(3,4),(5,6)
2024-04-24T20:45:49,945  WARN [main] ql.Driver: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
2024-04-24T20:45:49,945  INFO [main] ql.Driver: WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.
Query ID = alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:49,945  INFO [main] ql.Driver: Query ID = alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
Total jobs = 1
2024-04-24T20:45:49,945  INFO [main] ql.Driver: Total jobs = 1
Launching Job 1 out of 1
2024-04-24T20:45:49,945  INFO [main] ql.Driver: Launching Job 1 out of 1
2024-04-24T20:45:49,946  INFO [main] ql.Driver: Starting task [Stage-1:MAPRED] in serial mode
Number of reduce tasks determined at compile time: 2
2024-04-24T20:45:49,946  INFO [main] exec.Task: Number of reduce tasks determined at compile time: 2
In order to change the average load for a reducer (in bytes):
2024-04-24T20:45:49,946  INFO [main] exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
2024-04-24T20:45:49,946  INFO [main] exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
2024-04-24T20:45:49,946  INFO [main] exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
2024-04-24T20:45:49,946  INFO [main] exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
2024-04-24T20:45:49,946  INFO [main] exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
2024-04-24T20:45:49,946  INFO [main] exec.Task:   set mapreduce.job.reduces=<number>
2024-04-24T20:45:49,946  INFO [main] mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.HiveInputFormat
2024-04-24T20:45:49,946  INFO [main] exec.Utilities: Processing alias values__tmp__table__1
2024-04-24T20:45:49,947  INFO [main] exec.Utilities: Content Summary not cached for file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:49,951  INFO [main] exec.SerializationUtilities: Serializing MapWork using kryo
2024-04-24T20:45:49,953  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:49,957  INFO [main] exec.SerializationUtilities: Serializing ReduceWork using kryo
2024-04-24T20:45:49,960  INFO [main] exec.Utilities: Serialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:45:49,960  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:49,961  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10001
2024-04-24T20:45:49,963  INFO [main] jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2024-04-24T20:45:49,963  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/map.xml
2024-04-24T20:45:49,963  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/reduce.xml
2024-04-24T20:45:49,966  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T20:45:50,030  INFO [main] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/map.xml
2024-04-24T20:45:50,031  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.ids = 0,1
2024-04-24T20:45:50,031  INFO [main] io.HiveInputFormat: hive.io.file.readcolumn.names = tmp_values_col1,tmp_values_col2
2024-04-24T20:45:50,031  INFO [main] io.HiveInputFormat: Generating splits for dirs: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5/_tmp_space.db/Values__Tmp__Table__1
2024-04-24T20:45:50,034  INFO [main] mapred.FileInputFormat: Total input paths to process : 1
2024-04-24T20:45:50,035  INFO [main] io.HiveInputFormat: number of splits 1
2024-04-24T20:45:50,048  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T20:45:50,060  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1223177649_0025
2024-04-24T20:45:50,102  INFO [main] mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
2024-04-24T20:45:50,102  INFO [main] exec.Task: Job running in-process (local Hadoop)
2024-04-24T20:45:50,102  INFO [Thread-3745] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:50,102  INFO [Thread-3745] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
2024-04-24T20:45:50,104  INFO [Thread-3745] mapred.LocalJobRunner: Waiting for map tasks
2024-04-24T20:45:50,104  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1223177649_0025_m_000000_0
2024-04-24T20:45:50,106  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:50,107  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: org.apache.hadoop.mapred.TextInputFormat:file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:50,108  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/map.xml
2024-04-24T20:45:50,108  INFO [LocalJobRunner Map Task Executor #0] exec.SerializationUtilities: Deserializing MapWork using kryo
2024-04-24T20:45:50,109  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: Deserialized plan (via FILE) - name: null size: 3,66KB
2024-04-24T20:45:50,110  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 2
2024-04-24T20:45:50,116  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-24T20:45:50,116  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-24T20:45:50,116  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: soft limit at 83886080
2024-04-24T20:45:50,116  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-24T20:45:50,116  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-24T20:45:50,117  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-24T20:45:50,117  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,117  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,117  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/map.xml
2024-04-24T20:45:50,117  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Initializing operator MAP[0]
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] mr.ExecMapper: 
<MAP>Id =0
  <Children>null
  <\Children>
  <Parent><\Parent>
<\MAP>
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Initializing operator TS[0]
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Initializing operator SEL[1]
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: SELECT struct<tmp_values_col1:string,tmp_values_col2:string>
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Initializing operator RS[2]
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Using tag = -1
2024-04-24T20:45:50,118  INFO [LocalJobRunner Map Task Executor #0] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/map.xml
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: keys are [] num distributions: 0
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 1
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: MAP[0]: records read - 1
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: Closing operator MAP[0]
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.MapOperator: RECORDS_IN:3, DESERIALIZE_ERRORS:0, 
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.TableScanOperator: Closing operator TS[0]
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.SelectOperator: Closing operator SEL[1]
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: Closing operator RS[2]
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RS[2]: records written - 3
2024-04-24T20:45:50,119  INFO [LocalJobRunner Map Task Executor #0] exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3, 
2024-04-24T20:45:50,120  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2024-04-24T20:45:50,120  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Starting flush of map output
2024-04-24T20:45:50,120  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Spilling map output
2024-04-24T20:45:50,120  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2024-04-24T20:45:50,120  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2024-04-24T20:45:50,121  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Finished spill 0
2024-04-24T20:45:50,122  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1223177649_0025_m_000000_0 is done. And is in the process of committing
2024-04-24T20:45:50,123  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/scratchdir/alex/5af3846b-cc6e-4911-9433-0af9c34376b5/_tmp_space.db/Values__Tmp__Table__1/data_file:0+12
2024-04-24T20:45:50,123  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1223177649_0025_m_000000_0' done.
2024-04-24T20:45:50,123  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1223177649_0025_m_000000_0
2024-04-24T20:45:50,123  INFO [Thread-3745] mapred.LocalJobRunner: map task executor complete.
2024-04-24T20:45:50,124  INFO [Thread-3745] mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-24T20:45:50,124  INFO [pool-160-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1223177649_0025_r_000000_0
2024-04-24T20:45:50,126  INFO [pool-160-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:50,126  INFO [pool-160-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f554f81
2024-04-24T20:45:50,127  INFO [pool-160-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:50,127  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1223177649_0025_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:50,129  INFO [localfetcher#205] reduce.LocalFetcher: localfetcher#205 about to shuffle output of map attempt_local1223177649_0025_m_000000_0 decomp: 50 len: 54 to MEMORY
2024-04-24T20:45:50,129  INFO [localfetcher#205] reduce.InMemoryMapOutput: Read 50 bytes from map-output for attempt_local1223177649_0025_m_000000_0
2024-04-24T20:45:50,129  INFO [localfetcher#205] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->50
2024-04-24T20:45:50,130  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:50,130  INFO [pool-160-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:50,130  INFO [pool-160-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:50,130  INFO [pool-160-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:50,130  INFO [pool-160-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:50,130  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 50 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merging 1 files, 54 bytes from disk
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 43 bytes
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/reduce.xml
2024-04-24T20:45:50,131  INFO [pool-160-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:50,133  INFO [pool-160-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:45:50,133  INFO [pool-160-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:50,133  INFO [pool-160-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:50,134  INFO [pool-160-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:50,134  INFO [pool-160-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:50,134  INFO [pool-160-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@4be70c80 and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@5edb6b3a
2024-04-24T20:45:50,135  INFO [pool-160-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:50,135  INFO [pool-160-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000000_0
2024-04-24T20:45:50,135  INFO [pool-160-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_tmp.-ext-10000/000000_0
2024-04-24T20:45:50,140  INFO [pool-160-thread-1] exec.FileSinkOperator: FS[5]: records written - 1
2024-04-24T20:45:50,140  INFO [pool-160-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:50,144  INFO [pool-160-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000000_0/delta_0000001_0000001_0000/bucket_00000 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:50,144  INFO [pool-160-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:50,144  INFO [pool-160-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:50,144  INFO [pool-160-thread-1] exec.FileSinkOperator: FS[5]: records written - 3
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:3, 
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] mapred.Task: Task:attempt_local1223177649_0025_r_000000_0 is done. And is in the process of committing
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] mapred.Task: Task 'attempt_local1223177649_0025_r_000000_0' done.
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1223177649_0025_r_000000_0
2024-04-24T20:45:50,150  INFO [pool-160-thread-1] mapred.LocalJobRunner: Starting task: attempt_local1223177649_0025_r_000001_0
2024-04-24T20:45:50,151  INFO [pool-160-thread-1] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-04-24T20:45:50,151  INFO [pool-160-thread-1] mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a0bb15b
2024-04-24T20:45:50,151  INFO [pool-160-thread-1] reduce.MergeManagerImpl: MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-24T20:45:50,152  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: attempt_local1223177649_0025_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2024-04-24T20:45:50,153  INFO [localfetcher#206] reduce.LocalFetcher: localfetcher#206 about to shuffle output of map attempt_local1223177649_0025_m_000000_0 decomp: 2 len: 6 to MEMORY
2024-04-24T20:45:50,153  INFO [localfetcher#206] reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1223177649_0025_m_000000_0
2024-04-24T20:45:50,153  INFO [localfetcher#206] reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2024-04-24T20:45:50,153  INFO [EventFetcher for fetching Map Completion Events] reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-24T20:45:50,153  INFO [pool-160-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:50,153  INFO [pool-160-thread-1] reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2024-04-24T20:45:50,153  INFO [pool-160-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] mapred.Merger: Merging 1 sorted segments
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] mapred.LocalJobRunner: 1 / 1 copied.
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] ExecReducer: conf classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] ExecReducer: thread classpath = [file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/surefire/surefirebooter2314653923882576367.jar]
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] exec.Utilities: PLAN PATH = file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10003/adff605b-267a-47ec-8599-8abb68fc98c4/reduce.xml
2024-04-24T20:45:50,154  INFO [pool-160-thread-1] exec.SerializationUtilities: Deserializing ReduceWork using kryo
2024-04-24T20:45:50,156  INFO [pool-160-thread-1] exec.Utilities: Deserialized plan (via FILE) - name: null size: 4,75KB
2024-04-24T20:45:50,156  INFO [pool-160-thread-1] ExecReducer: 
<SEL>Id =3
  <Children>
    <FS>Id =5
      <Children>
      <\Children>
      <Parent>Id = 3 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\SEL>
2024-04-24T20:45:50,156  INFO [pool-160-thread-1] exec.SelectOperator: Initializing operator SEL[3]
2024-04-24T20:45:50,156  INFO [pool-160-thread-1] exec.SelectOperator: SELECT struct<key:struct<>,value:struct<_col0:string,_col1:string>>
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: Initializing operator FS[5]
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.ql.io.orc.OrcSerde@7a1a449f and formatter : org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat@4dacb3ee
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.SelectOperator: Closing operator SEL[3]
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: Closing operator FS[5]
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: FS[5]: records written - 0
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:50,157  INFO [pool-160-thread-1] exec.FileSinkOperator: Writing to temp file: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000001_0
2024-04-24T20:45:50,158  INFO [pool-160-thread-1] exec.FileSinkOperator: New Final Path: FS file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_tmp.-ext-10000/000001_0
2024-04-24T20:45:50,162  INFO [pool-160-thread-1] impl.PhysicalFsWriter: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:50,166  INFO [pool-160-thread-1] impl.WriterImpl: ORC writer created for path: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_task_tmp.-ext-10000/_tmp.000001_0/delta_0000001_0000001_0000/bucket_00001 with stripeSize: 8388608 blockSize: 268435456 compression: ZLIB bufferSize: 32768
2024-04-24T20:45:50,171  INFO [pool-160-thread-1] exec.FileSinkOperator: RECORDS_OUT_1_dinclude.tinclude:0, 
2024-04-24T20:45:50,172  INFO [pool-160-thread-1] mapred.Task: Task:attempt_local1223177649_0025_r_000001_0 is done. And is in the process of committing
2024-04-24T20:45:50,172  INFO [pool-160-thread-1] mapred.LocalJobRunner: reduce > reduce
2024-04-24T20:45:50,172  INFO [pool-160-thread-1] mapred.Task: Task 'attempt_local1223177649_0025_r_000001_0' done.
2024-04-24T20:45:50,172  INFO [pool-160-thread-1] mapred.LocalJobRunner: Finishing task: attempt_local1223177649_0025_r_000001_0
2024-04-24T20:45:50,172  INFO [Thread-3745] mapred.LocalJobRunner: reduce task executor complete.
2024-04-24 20:45:51,104 Stage-1 map = 100%,  reduce = 100%
2024-04-24T20:45:51,105  INFO [main] exec.Task: 2024-04-24 20:45:51,104 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1223177649_0025
2024-04-24T20:45:51,106  INFO [main] exec.Task: Ended Job = job_local1223177649_0025
2024-04-24T20:45:51,109  INFO [main] exec.FileSinkOperator: Moving tmp dir: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/_tmp.-ext-10000 to: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/-ext-10000
2024-04-24T20:45:51,110  INFO [main] ql.Driver: Starting task [Stage-0:MOVE] in serial mode
2024-04-24T20:45:51,110  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:51,110  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:51,111  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:51,111  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Loading data to table dinclude.tinclude
2024-04-24T20:45:51,111  INFO [main] exec.Task: Loading data to table dinclude.tinclude from file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/-ext-10000
2024-04-24T20:45:51,115  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:45:51,115  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:51,152  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:51,152  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:51,153  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:51,161  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:51,161  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:51,171  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:45:51,171  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:45:51,182  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/-ext-10000/000001_0/delta_0000001_0000001_0000/bucket_00001 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00001
2024-04-24T20:45:51,183  INFO [main] metadata.Hive: Moving bucket file:///home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-49_730_4674513095064582673-1/-ext-10000/000000_0/delta_0000001_0000001_0000/bucket_00000 to file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/delta_0000001_0000001_0000/bucket_00000
2024-04-24T20:45:51,183  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:45:51,183  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:45:51,209  INFO [main] ql.Driver: Starting task [Stage-2:STATS] in serial mode
2024-04-24T20:45:51,210  INFO [main] exec.StatsTask: Executing stats task
2024-04-24T20:45:51,210  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:51,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:51,210  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:51,210  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:51,211  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:45:51,211  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:51,234  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:51,234  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:51,235  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:51,236  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:51,236  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:51,246  INFO [main] fs.FSStatsPublisher: created : file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/localscratchdir/5af3846b-cc6e-4911-9433-0af9c34376b5/hive_2024-04-24_20-45-49_730_4674513095064582673-1/-mr-10001
2024-04-24T20:45:51,246  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={}}
2024-04-24T20:45:51,247  INFO [main] fs.FSStatsAggregator: Read stats : {dinclude.tinclude/={numRows=3, rawDataSize=0}}
2024-04-24T20:45:51,247  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:45:51,247  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:45:51,260  INFO [main] metastore.HiveMetaStore: 0: Cleaning up thread local RawStore...
2024-04-24T20:45:51,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2024-04-24T20:45:51,261  INFO [main] metastore.HiveMetaStore: 0: Done cleaning up thread local RawStore
2024-04-24T20:45:51,261  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2024-04-24T20:45:51,263  INFO [main] metastore.HiveMetaStore: 0: alter_table: db=dinclude tbl=tinclude newtbl=tinclude
2024-04-24T20:45:51,263  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=alter_table: db=dinclude tbl=tinclude newtbl=tinclude	
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.txn.valid.txns does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:51,287  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:51,288  WARN [main] conf.HiveConf: HiveConf of name hive.doing.acid does not exist
2024-04-24T20:45:51,288  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:51,288  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:51,288  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:51,288  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T20:45:51,289  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2024-04-24T20:45:51,290  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
2024-04-24T20:45:51,290  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2024-04-24T20:45:51,310  INFO [main] hive.log: Updating table stats fast for tinclude
2024-04-24T20:45:51,310  INFO [main] hive.log: Updated size of table tinclude to 802
2024-04-24T20:45:51,320  INFO [main] exec.StatsTask: Table dinclude.tinclude stats: [numFiles=2, numRows=0, totalSize=802, rawDataSize=0]
2024-04-24T20:45:51,320  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
MapReduce Jobs Launched: 
2024-04-24T20:45:51,320  INFO [main] ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2024-04-24T20:45:51,320  INFO [main] ql.Driver: Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:51,320  INFO [main] ql.Driver: Total MapReduce CPU Time Spent: 0 msec
2024-04-24T20:45:51,320  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 1.375 seconds
OK
2024-04-24T20:45:51,320  INFO [main] ql.Driver: OK
2024-04-24T20:45:51,320  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:51,331  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): update TInclude set a = 1 where b = 2
2024-04-24T20:45:51,331  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:51,331  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:51,341  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Going to reparse <update TInclude set a = 1 where b = 2> as 
<insert into table `DInclude`.`TInclude` select ROW__ID,`a`,`b` from `DInclude`.`TInclude` sort by ROW__ID >
2024-04-24T20:45:51,342  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Starting Semantic Analysis
2024-04-24T20:45:51,342  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:51,342  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:51,352  INFO [main] session.SessionState: Could not get hdfsEncryptionShim, it is only applicable to hdfs filesystem.
2024-04-24T20:45:51,353  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed phase 1 of Semantic Analysis
2024-04-24T20:45:51,353  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for source tables
2024-04-24T20:45:51,353  INFO [main] metastore.HiveMetaStore: 0: get_table : db=dinclude tbl=tinclude
2024-04-24T20:45:51,353  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=dinclude tbl=tinclude	
2024-04-24T20:45:51,363  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for subqueries
2024-04-24T20:45:51,363  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Get metadata for destination tables
2024-04-24T20:45:51,363  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=TInclude
2024-04-24T20:45:51,363  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=TInclude	
2024-04-24T20:45:51,374  INFO [main] parse.UpdateDeleteSemanticAnalyzer: Completed getting MetaData in Semantic Analysis
2024-04-24T20:45:51,375  INFO [main] common.FileUtils: Creating directory if it doesn't exist: file:/home/alex/Repositories/hive/upgrade-acid/pre-upgrade/target/tmp/org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool-1713987890713/warehouse/dinclude.db/tinclude/.hive-staging_hive_2024-04-24_20-45-51_341_4932465196382127963-1
FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
2024-04-24T20:45:51,384 ERROR [main] ql.Driver: FAILED: NoMatchingMethodException No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
org.apache.hadoop.hive.ql.exec.NoMatchingMethodException: No matching method for class org.apache.hadoop.hive.ql.udf.UDFToInteger with (struct<transactionid:bigint,bucketid:int,rowid:bigint>). Possible choices: _FUNC_(bigint)  _FUNC_(boolean)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(struct<bucketid:bigint,transactionid:bigint,rowid:int>)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void)  
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1231)
	at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getMethodInternal(FunctionRegistry.java:1009)
	at org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver.getEvalMethod(DefaultUDFMethodResolver.java:59)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.initialize(GenericUDFBridge.java:167)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDF.initializeAndFoldConstants(GenericUDF.java:141)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:236)
	at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:268)
	at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getFuncExprNodeDescWithUdfData(TypeCheckProcFactory.java:865)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.createConversionCast(ParseUtils.java:161)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getPartitionColsFromBucketColsForUpdateDelete(SemanticAnalyzer.java:7678)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6648)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6857)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9772)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:9644)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10549)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:10427)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:11125)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:11138)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10807)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:73)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:462)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeUpdate(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:84)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:258)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:512)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.runStatementOnDriver(TestPreUpgradeTool.java:420)
	at org.apache.hadoop.hive.upgrade.acid.TestPreUpgradeTool.testOnlyFilteredDatabasesAreUpgradedWhenRegexIsGiven(TestPreUpgradeTool.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2024-04-24T20:45:51,384  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:51,384  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.054 seconds
2024-04-24T20:45:51,384  INFO [main] lockmgr.DbLockManager: releaseLocks: []
2024-04-24T20:45:51,385  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DInclude cascade
2024-04-24T20:45:51,385  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:51,385  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:51,389  INFO [main] metastore.HiveMetaStore: 0: get_tables: db=DInclude pat=.*
2024-04-24T20:45:51,389  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_tables: db=DInclude pat=.*	
2024-04-24T20:45:51,391  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:51,391  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:51,391  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:51,391  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.007 seconds
2024-04-24T20:45:51,392  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:51,392  INFO [main] lockmgr.DbLockManager: Requesting: queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockRequest(component:[LockComponent(type:EXCLUSIVE, level:DB, dbname:dinclude, operationType:NO_TXN, isDynamicPartitionWrite:false)], txnid:0, user:alex, hostname:Lenovo-Bot, agentInfo:alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c)
2024-04-24T20:45:51,401  INFO [main] lockmgr.DbLockManager: Response to queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c LockResponse(lockid:3, state:ACQUIRED)
2024-04-24T20:45:51,401  INFO [main] lockmgr.DbTxnManager: Started heartbeat with delay/interval = 150000/150000 MILLISECONDS for query: alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:51,401  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DInclude cascade
2024-04-24T20:45:51,402  INFO [main] ql.Driver: Starting task [Stage-0:DDL] in serial mode
2024-04-24T20:45:51,402  INFO [main] metastore.HiveMetaStore: 0: get_database: DInclude
2024-04-24T20:45:51,402  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DInclude	
2024-04-24T20:45:51,410  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=DInclude
2024-04-24T20:45:51,410  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=DInclude	
2024-04-24T20:45:51,414  INFO [main] metastore.HiveMetaStore: 0: get_table : db=DInclude tbl=tinclude
2024-04-24T20:45:51,414  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_table : db=DInclude tbl=tinclude	
2024-04-24T20:45:51,429  INFO [main] metastore.HiveMetaStore: 0: drop_table : db=DInclude tbl=tinclude
2024-04-24T20:45:51,429  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_table : db=DInclude tbl=tinclude	
2024-04-24T20:45:51,554  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:51,555  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:51,583  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:51,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:51,604  INFO [main] metastore.HiveMetaStore: 0: drop_database: DInclude
2024-04-24T20:45:51,604  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=drop_database: DInclude	
2024-04-24T20:45:51,610  INFO [main] metastore.HiveMetaStore: 0: get_all_tables: db=dinclude
2024-04-24T20:45:51,610  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_all_tables: db=dinclude	
2024-04-24T20:45:51,612  INFO [main] metastore.HiveMetaStore: 0: get_functions: db=dinclude pat=*
2024-04-24T20:45:51,612  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_functions: db=dinclude pat=*	
2024-04-24T20:45:51,616  INFO [main] metastore.ObjectStore: Dropping database DInclude along with all tables
2024-04-24T20:45:51,629  INFO [main] fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2024-04-24T20:45:51,629  INFO [main] txn.TxnHandler: Hacking in canned values for transaction manager
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.server2.operation.log.purgePolicy.timeToLive does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.enabled does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.query.reexecution.stats.persist.scope does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.stats.fetch.bitvector does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.scheduled.queries.executor.enabled does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.cbo.fallback.strategy does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.strict.timestamp.conversion does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T20:45:51,653  WARN [main] conf.HiveConf: HiveConf of name hive.query.results.cache.enabled does not exist
2024-04-24T20:45:51,671  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:51,672  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.27 seconds
OK
2024-04-24T20:45:51,672  INFO [main] ql.Driver: OK
2024-04-24T20:45:51,672  INFO [main] lockmgr.DbTxnManager: Stopped heartbeat for query: alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:51,672  INFO [main] lockmgr.DbLockManager: releaseLocks: [lockid:3 queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c txnid:0]
2024-04-24T20:45:51,676  INFO [main] ql.Driver: Compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DExclude cascade
2024-04-24T20:45:51,676  INFO [main] metastore.HiveMetaStore: 0: get_database: DExclude
2024-04-24T20:45:51,676  INFO [main] HiveMetaStore.audit: ugi=alex	ip=unknown-ip-addr	cmd=get_database: DExclude	
2024-04-24T20:45:51,677  WARN [main] metastore.ObjectStore: Failed to get database DExclude, returning NoSuchObjectException
2024-04-24T20:45:51,677  INFO [main] ql.Driver: Semantic Analysis Completed
2024-04-24T20:45:51,677  INFO [main] ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2024-04-24T20:45:51,677  INFO [main] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2024-04-24T20:45:51,678  INFO [main] ql.Driver: Completed compiling command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.001 seconds
2024-04-24T20:45:51,678  INFO [main] lockmgr.DbTxnManager: Setting lock request transaction to txnid:0 for queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c
2024-04-24T20:45:51,678  INFO [main] ql.Driver: Executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c): drop database if exists DExclude cascade
2024-04-24T20:45:51,678  INFO [main] metadata.Hive: Dumping metastore api call timing information for : execution phase
2024-04-24T20:45:51,678  INFO [main] ql.Driver: Completed executing command(queryId=alex_20240424204549_99958438-b8e8-474d-a952-d5de7532441c); Time taken: 0.0 seconds
OK
2024-04-24T20:45:51,678  INFO [main] ql.Driver: OK
2024-04-24T20:45:51,678  INFO [main] lockmgr.DbLockManager: releaseLocks: []
]]></system-err>
  </testcase>
</testsuite>