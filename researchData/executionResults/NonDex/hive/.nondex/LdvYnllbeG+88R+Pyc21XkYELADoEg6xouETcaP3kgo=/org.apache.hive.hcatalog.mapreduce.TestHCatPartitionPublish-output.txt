2024-04-24T08:56:33,272  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:56:33,274  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:56:33,275  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:56:33,276  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c252295, with PersistenceManager: null will be shutdown
2024-04-24T08:56:33,278  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c252295, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@71c03815 created in the thread with id: 412
2024-04-24T08:56:33,296  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1c252295 from thread id: 412
2024-04-24T08:56:33,445  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testHCatPartitionedTable, dbName:default, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:c1, type:int, comment:), FieldSchema(name:c2, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:testHCatPartitionedTable, serializationLib:org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:PaRT1, type:string, comment:), FieldSchema(name:part0, type:string, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2024-04-24T08:56:33,477  INFO [TThreadPoolServer WorkerProcess-%d] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/alex/Repositories/hive/hcatalog/core/target/warehouse/41159/testhcatpartitionedtable
2024-04-24T08:56:34,089  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:56:34,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:56:34,090  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:56:34,091  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:56:34,092  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:56:34,092  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:56:34,093  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2024-04-24T08:56:34,096  INFO [main] common.HCatUtil: Configuration differences={datanucleus.connectionPool.maxPoolSize=4, hive.llap.io.cache.orc.alloc.max=2097152, test.property1=value1, javax.jdo.option.ConnectionUserName=APP, hive.stats.column.autogather=true, mapreduce.jobtracker.staging.root.dir=${test.tmp.dir}/cli/mapred/staging, hive.query.results.cache.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore, hive.llap.io.use.lrfu=true, javax.jdo.option.ConnectionPassword=mine, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, test.data.scripts=${hive.root}/data/scripts, datanucleus.schema.autoCreateAll=true, hive.users.in.admin.role=hive_admin_user, hive.llap.io.cache.orc.size=8388608, hive.exec.mode.local.auto=false, hive.dummyparam.test.server.specific.config.hivesite=from.hive-site.xml, test.var.hiveconf.property=${hive.exec.default.partition.name}, hive.materializedview.rewriting=true, hive.dummyparam.test.server.specific.config.override=from.hive-site.xml, hive.fetch.task.conversion=minimal, hive.metastore.metadb.dir=file://${test.tmp.dir}/metadb/, hive.conf.restricted.list=dummy.config.value, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.query.reexecution.stats.persist.scope=query, hive.cbo.fallback.strategy=TEST, hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, test.data.files=${hive.root}/data/files, hive.metastore.client.cache.enabled=true, hive.stats.key.prefix.reserve.length=0, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.exec.submit.local.task.via.child=false, hive.auto.convert.join=false, hive.llap.io.cache.orc.alloc.min=32768, hive.stats.fetch.bitvector=true, hive.llap.io.allocator.direct=false, hive.metastore.schema.verification=false, javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver, hive.support.concurrency=true, hive.in.test=true, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.llap.io.cache.orc.arena.size=8388608, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, test.log.dir=${test.tmp.dir}/log/, hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.PostExecutePrinter, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.llap.cache.allow.synthetic.fileid=true, hive.scheduled.queries.executor.enabled=false, hive.ignore.mapjoin.hint=false, hive.metastore.client.cache.maxSize=10Mb, hive.metastore.client.cache.recordStats=true, hive.mapjoin.max.gc.time.percentage=0.99, hive.test.dummystats.aggregator=value2, hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.PreExecutePrinter, org.apache.hadoop.hive.ql.hooks.EnforceReadOnlyTables, org.apache.hadoop.hive.ql.hooks.MaterializedViewRegistryPropertiesHook, iceberg.hive.keep.stats=true, hive.strict.timestamp.conversion=false}
2024-04-24T08:56:34,153  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
2024-04-24T08:56:34,213  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2024-04-24T08:56:34,213  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:41159]
2024-04-24T08:56:34,213  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:41159)
2024-04-24T08:56:34,214  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:41159) current connections: 2
2024-04-24T08:56:34,215  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=alex (auth:SIMPLE) retries=1 delay=1 lifetime=0
2024-04-24T08:56:34,287  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:56:34,289  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2024-04-24T08:56:34,289  INFO [TThreadPoolServer WorkerProcess-%d] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2024-04-24T08:56:34,290  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c877cd, with PersistenceManager: null will be shutdown
2024-04-24T08:56:34,290  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c877cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b722c2a created in the thread with id: 419
2024-04-24T08:56:34,297  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c877cd from thread id: 419
2024-04-24T08:56:34,357  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:56:34,509  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:56:34,686  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:56:34,687  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:56:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:56:34,688  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:56:34,939  INFO [main] client.RMProxy: Connecting to ResourceManager at Lenovo-Bot/127.0.1.1:35525
2024-04-24T08:56:36,189  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2024-04-24T08:56:36,189  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2024-04-24T08:56:36,189  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2024-04-24T08:56:36,189  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2024-04-24T08:56:36,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2024-04-24T08:56:36,190  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2024-04-24T08:56:36,190  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2024-04-24T08:56:36,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2024-04-24T08:56:36,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2024-04-24T08:56:36,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2024-04-24T08:56:36,191  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2024-04-24T08:56:36,192  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf is set. Applying configuration differences.
2024-04-24T08:56:36,198  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2024-04-24T08:56:36,946  WARN [main] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-04-24T08:56:36,955  WARN [main] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2024-04-24T08:56:37,088  INFO [main] input.FileInputFormat: Total input files to process : 1
2024-04-24T08:56:37,255  INFO [main] mapreduce.JobSubmitter: number of splits:1
2024-04-24T08:56:37,310  INFO [main] mapreduce.JobSubmitter: Submitting tokens for job: job_1713974179292_0001
2024-04-24T08:56:37,310  INFO [main] mapreduce.JobSubmitter: Executing with tokens: []
2024-04-24T08:56:37,763  INFO [main] mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
2024-04-24T08:56:38,683  INFO [main] impl.YarnClientImpl: Submitted application application_1713974179292_0001
2024-04-24T08:56:38,764  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T08:56:38,764  WARN [SchedulerEventDispatcher:Event Processor] capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2024-04-24T08:56:38,852  INFO [main] mapreduce.Job: The url to track the job: http://Lenovo-Bot:0/proxy/application_1713974179292_0001/
2024-04-24T08:56:38,855  INFO [main] mapreduce.Job: Running job: job_1713974179292_0001
2024-04-24T08:56:40,419  INFO [Socket Reader #1 for port 45693] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:56:46,296  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner started
2024-04-24T08:56:46,296  INFO [Log Scanner/Cleaner #0] hs.JobHistory: History Cleaner complete
2024-04-24T08:56:48,182  INFO [Socket Reader #1 for port 40917] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:56:50,180  INFO [main] mapreduce.Job: Job job_1713974179292_0001 running in uber mode : false
2024-04-24T08:56:50,181  INFO [main] mapreduce.Job:  map 0% reduce 0%
2024-04-24T08:56:50,709  INFO [Socket Reader #1 for port 45693] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:56:50,722  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713974179292_0001
2024-04-24T08:56:54,304  INFO [main] mapreduce.Job: Task Id : attempt_1713974179292_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:56:55,561  INFO [Socket Reader #1 for port 45693] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:56:56,531  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713974179292_0001
2024-04-24T08:57:00,378  INFO [main] mapreduce.Job: Task Id : attempt_1713974179292_0001_m_000000_1, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:57:01,594  INFO [Socket Reader #1 for port 45693] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:57:02,187  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713974179292_0001
2024-04-24T08:57:06,415  INFO [main] mapreduce.Job: Task Id : attempt_1713974179292_0001_m_000000_2, Status : FAILED
Error: java.io.IOException: Exception to mimic job failure.
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:231)
	at org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish$MapFail.map(TestHCatPartitionPublish.java:224)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2024-04-24T08:57:07,616  INFO [Socket Reader #1 for port 45693] ipc.Server: Auth successful for appattempt_1713974179292_0001_000001 (auth:SIMPLE)
2024-04-24T08:57:08,052  INFO [NM ContainerManager dispatcher] mapred.ShuffleHandler: Added token for job_1713974179292_0001
2024-04-24T08:57:13,442  INFO [main] mapreduce.Job:  map 100% reduce 0%
2024-04-24T08:57:19,478  INFO [main] mapreduce.Job: Job job_1713974179292_0001 failed with state FAILED due to: Task failed task_1713974179292_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2024-04-24T08:57:19,705  INFO [main] mapreduce.Job: Counters: 9
	Job Counters 
		Failed map tasks=4
		Launched map tasks=4
		Other local map tasks=3
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=15928
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=15928
		Total vcore-milliseconds taken by all map tasks=15928
		Total megabyte-milliseconds taken by all map tasks=16310272
2024-04-24T08:57:19,727  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:57:19,755  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testHCatPartitionedTable	
2024-04-24T08:57:19,778  INFO [TThreadPoolServer WorkerProcess-%d] metastore.HMSHandler: Skipping translation for processor with null
2024-04-24T08:57:19,856  WARN [ContainersLauncher #0] nodemanager.DefaultContainerExecutor: Exit code from container container_1713974179292_0001_01_000001 is : 143
2024-04-24T08:57:36,895 ERROR [Thread[Thread-276,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:57:36,905  WARN [ApplicationMaster Launcher] amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2024-04-24T08:57:36,909 ERROR [SchedulerEventDispatcher:Event Processor] event.EventDispatcher: Returning, interrupted : java.lang.InterruptedException
2024-04-24T08:57:36,909  INFO [Ping Checker] util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2024-04-24T08:57:36,916  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:57:36,916  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor thread interrupted
2024-04-24T08:57:36,916  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:57:36,916  INFO [Ping Checker] util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2024-04-24T08:57:36,917 ERROR [Thread[Thread-99,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:57:36,917  INFO [Ping Checker] util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2024-04-24T08:57:36,917  INFO [main] event.AsyncDispatcher: AsyncDispatcher is draining to stop, ignoring any new events.
2024-04-24T08:57:36,918  INFO [main] impl.MetricsSystemImpl: Stopping JobHistoryServer metrics system...
2024-04-24T08:57:36,940  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system stopped.
2024-04-24T08:57:36,941  INFO [main] impl.MetricsSystemImpl: JobHistoryServer metrics system shutdown complete.
2024-04-24T08:57:36,946  INFO [main] hs.JobHistory: Stopping JobHistory
2024-04-24T08:57:36,946  INFO [main] hs.JobHistory: Stopping History Cleaner/Move To Done
2024-04-24T08:57:36,951 ERROR [Thread[Thread-73,5,main]] delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2024-04-24T08:57:36,972  INFO [pool-2-thread-1] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 1
2024-04-24T08:57:36,972  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2024-04-24T08:57:36,972  INFO [TThreadPoolServer WorkerProcess-%d] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c877cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5b722c2a will be shutdown
2024-04-24T08:57:36,973  INFO [TThreadPoolServer WorkerProcess-%d] HiveMetaStore.audit: ugi=alex	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
