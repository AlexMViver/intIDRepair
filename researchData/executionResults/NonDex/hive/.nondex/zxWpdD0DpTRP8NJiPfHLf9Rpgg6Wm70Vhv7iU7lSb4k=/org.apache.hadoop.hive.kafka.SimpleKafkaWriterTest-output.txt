2024-04-24T12:39:52,678  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New topics: [Set(TEST-CREATE_TOPIC)], deleted topics: [Set()], new partition replica assignment [Map(TEST-CREATE_TOPIC-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))]
2024-04-24T12:39:52,679  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for TEST-CREATE_TOPIC-0
2024-04-24T12:39:52,706  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:39:52,724  INFO [data-plane-kafka-request-handler-1] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(TEST-CREATE_TOPIC-0)
2024-04-24T12:39:52,767  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:39:52,798  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035] Loading producer state till offset 0 with message format version 2
2024-04-24T12:39:52,802  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:52,802  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:52,802  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987592802
2024-04-24T12:39:52,804  INFO [data-plane-kafka-request-handler-1] log.Log: [Log partition=TEST-CREATE_TOPIC-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms
2024-04-24T12:39:52,806  INFO [data-plane-kafka-request-handler-1] log.LogManager: Created log for partition TEST-CREATE_TOPIC-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035/TEST-CREATE_TOPIC-0 with properties {unclean.leader.election.enable -> false, message.format.version -> 2.5-IV0, segment.ms -> 604800000, preallocate -> false, cleanup.policy -> [delete], message.downconversion.enable -> true, segment.bytes -> 1073741824, max.message.bytes -> 1048588, file.delete.delay.ms -> 60000, segment.jitter.ms -> 0, delete.retention.ms -> 86400000, min.insync.replicas -> 1, message.timestamp.type -> CreateTime, flush.ms -> 9223372036854775807, min.compaction.lag.ms -> 0, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807, max.compaction.lag.ms -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, compression.type -> producer, retention.ms -> 604800000, retention.bytes -> -1, message.timestamp.difference.max.ms -> 9223372036854775807, index.interval.bytes -> 4096}.
2024-04-24T12:39:52,807  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] No checkpointed highwatermark is found for partition TEST-CREATE_TOPIC-0
2024-04-24T12:39:52,808  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] Log loaded for partition TEST-CREATE_TOPIC-0 with initial high watermark 0
2024-04-24T12:39:52,808  INFO [data-plane-kafka-request-handler-1] cluster.Partition: [Partition TEST-CREATE_TOPIC-0 broker=0] TEST-CREATE_TOPIC-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:39:52,809  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:39:52,813  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:39:52,823  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:39:52,837  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:52,837  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:52,837  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987592837
2024-04-24T12:39:52,848  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9290]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:39:52,874  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:52,874  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:52,875  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987592874
2024-04-24T12:39:52,877  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:39:52,883  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:39:52,884  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:39:52,889  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:52,889  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:52,892  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:39:52,904  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:52,905  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:52,905  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987592904
2024-04-24T12:39:52,907  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:6090]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 1000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 100
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 100
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:39:52,917  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:52,917  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:52,917  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987592916
2024-04-24T12:39:52,917  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [t]
2024-04-24T12:39:52,918  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:39:52,919  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:39:52,983  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:39:52,983  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:39:52,988  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:52,988  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,089  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:53,089  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,135  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:39:53,135  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,339  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:39:53,340  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,343  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:53,343  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,700  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:53,700  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,797  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Connection to node -1 (localhost/127.0.0.1:6090) could not be established. Broker may not be available.
2024-04-24T12:39:53,797  WARN [kafka-producer-network-thread | producer-2] clients.NetworkClient: [Producer clientId=producer-2] Bootstrap broker localhost:6090 (id: -1 rack: null) disconnected
2024-04-24T12:39:53,933 ERROR [main] kafka.SimpleKafkaWriter: WriterId [d72eee90-e57d-4ec3-bd8b-950900ac5f10] lost record from Topic [t], delivery Semantic [AT_LEAST_ONCE] -> ACTION=ABORT, ERROR caused by [Topic t not present in metadata after 1000 ms.]
2024-04-24T12:39:53,935  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [d72eee90-e57d-4ec3-bd8b-950900ac5f10]
2024-04-24T12:39:53,936  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [d72eee90-e57d-4ec3-bd8b-950900ac5f10]
2024-04-24T12:39:53,936  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:39:53,939  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [d72eee90-e57d-4ec3-bd8b-950900ac5f10] Delivery semantic [AT_LEAST_ONCE], Topic[t], Total sent Records [1], Total Lost Records [1]
2024-04-24T12:39:53,939 ERROR [main] kafka.SimpleKafkaWriter: Send Exception Aborting write from writerId [d72eee90-e57d-4ec3-bd8b-950900ac5f10]
2024-04-24T12:39:53,939  INFO [main] producer.KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 0 ms.
2024-04-24T12:39:53,943  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:39:53,943  INFO [main] kafka.SimpleKafkaWriterTest: setting up Config
2024-04-24T12:39:53,948  INFO [main] consumer.ConsumerConfig: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 3001
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 100
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 3002
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 3001
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-04-24T12:39:53,957  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:53,957  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:53,957  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987593957
2024-04-24T12:39:53,958  INFO [main] producer.ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-04-24T12:39:53,969  INFO [main] utils.AppInfoParser: Kafka version: 2.5.0
2024-04-24T12:39:53,969  INFO [main] utils.AppInfoParser: Kafka commitId: 66563e712b0b9f84
2024-04-24T12:39:53,969  INFO [main] utils.AppInfoParser: Kafka startTimeMs: 1713987593969
2024-04-24T12:39:53,969  INFO [main] kafka.SimpleKafkaWriter: Starting WriterId [null], Delivery Semantic [AT_LEAST_ONCE], Target Kafka Topic [134b93eb-8fa3-43f0-92df-8aa5bfe8a729]
2024-04-24T12:39:53,993  INFO [data-plane-kafka-request-handler-2] zk.AdminZkClient: Creating topic 134b93eb-8fa3-43f0-92df-8aa5bfe8a729 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0))
2024-04-24T12:39:53,997  INFO [data-plane-kafka-request-handler-2] server.KafkaApis: [KafkaApi-0] Auto creation of topic 134b93eb-8fa3-43f0-92df-8aa5bfe8a729 with 1 partitions and replication factor 1 is successful
2024-04-24T12:39:53,998  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New topics: [Set(134b93eb-8fa3-43f0-92df-8aa5bfe8a729)], deleted topics: [Set()], new partition replica assignment [Map(134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))]
2024-04-24T12:39:53,998  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] New partition creation callback for 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0
2024-04-24T12:39:54,007  WARN [kafka-producer-network-thread | producer-3] clients.NetworkClient: [Producer clientId=producer-3] Error while fetching metadata with correlation id 1 : {134b93eb-8fa3-43f0-92df-8aa5bfe8a729=LEADER_NOT_AVAILABLE}
2024-04-24T12:39:54,007  INFO [data-plane-kafka-request-handler-3] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0)
2024-04-24T12:39:54,008  INFO [kafka-producer-network-thread | producer-3] clients.Metadata: [Producer clientId=producer-3] Cluster ID: rgIQCIcuRxSXehng-DtlEg
2024-04-24T12:39:54,011  INFO [data-plane-kafka-request-handler-3] log.Log: [Log partition=134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035] Loading producer state till offset 0 with message format version 2
2024-04-24T12:39:54,011  INFO [data-plane-kafka-request-handler-3] log.Log: [Log partition=134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0, dir=/home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2024-04-24T12:39:54,012  INFO [data-plane-kafka-request-handler-3] log.LogManager: Created log for partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 in /home/alex/Repositories/hive/kafka-handler/target/tmp/kafka-log-dir-7614485203157000035/134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 with properties {index.interval.bytes -> 4096, file.delete.delay.ms -> 60000, message.timestamp.difference.max.ms -> 9223372036854775807, delete.retention.ms -> 86400000, segment.index.bytes -> 10485760, segment.jitter.ms -> 0, preallocate -> false, flush.messages -> 9223372036854775807, segment.bytes -> 1073741824, retention.bytes -> -1, compression.type -> producer, cleanup.policy -> [delete], message.timestamp.type -> CreateTime, unclean.leader.election.enable -> false, max.message.bytes -> 1048588, min.cleanable.dirty.ratio -> 0.5, segment.ms -> 604800000, message.format.version -> 2.5-IV0, retention.ms -> 604800000, flush.ms -> 9223372036854775807, max.compaction.lag.ms -> 9223372036854775807, message.downconversion.enable -> true, min.compaction.lag.ms -> 0, min.insync.replicas -> 1}.
2024-04-24T12:39:54,013  INFO [data-plane-kafka-request-handler-3] cluster.Partition: [Partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 broker=0] No checkpointed highwatermark is found for partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0
2024-04-24T12:39:54,013  INFO [data-plane-kafka-request-handler-3] cluster.Partition: [Partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 broker=0] Log loaded for partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 with initial high watermark 0
2024-04-24T12:39:54,013  INFO [data-plane-kafka-request-handler-3] cluster.Partition: [Partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 broker=0] 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1.
2024-04-24T12:39:54,277  INFO [main] kafka.SimpleKafkaWriter: Flushing Kafka Producer with writerId [53c93021-f187-497a-8fda-b9c1c30a644d]
2024-04-24T12:39:54,355  INFO [main] kafka.SimpleKafkaWriter: Closing WriterId [53c93021-f187-497a-8fda-b9c1c30a644d]
2024-04-24T12:39:54,355  INFO [main] producer.KafkaProducer: [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2024-04-24T12:39:54,359  INFO [main] kafka.SimpleKafkaWriter: Closed WriterId [53c93021-f187-497a-8fda-b9c1c30a644d] Delivery semantic [AT_LEAST_ONCE], Topic[134b93eb-8fa3-43f0-92df-8aa5bfe8a729], Total sent Records [17384], Total Lost Records [0]
2024-04-24T12:39:54,360  INFO [main] consumer.KafkaConsumer: [Consumer clientId=consumer-4, groupId=null] Subscribed to partition(s): 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0
2024-04-24T12:39:54,366  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Seeking to EARLIEST offset of partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0
2024-04-24T12:39:54,386  INFO [main] clients.Metadata: [Consumer clientId=consumer-4, groupId=null] Cluster ID: rgIQCIcuRxSXehng-DtlEg
2024-04-24T12:39:54,412  INFO [main] internals.SubscriptionState: [Consumer clientId=consumer-4, groupId=null] Resetting offset for partition 134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0 to offset 0.
2024-04-24T12:39:54,508  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:54,508  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:54,840  INFO [main] kafka.SimpleKafkaWriterTest: tearDown
2024-04-24T12:39:54,841  INFO [main] server.KafkaServer: [KafkaServer id=0] shutting down
2024-04-24T12:39:54,841  INFO [main] server.KafkaServer: [KafkaServer id=0] Starting controlled shutdown
2024-04-24T12:39:54,850  INFO [controller-event-thread] controller.KafkaController: [Controller id=0] Shutting down broker 0
2024-04-24T12:39:54,856  INFO [main] server.KafkaServer: [KafkaServer id=0] Controlled shutdown succeeded
2024-04-24T12:39:54,863  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutting down
2024-04-24T12:39:54,863  INFO [/config/changes-event-process-thread] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Stopped
2024-04-24T12:39:54,863  INFO [main] common.ZkNodeChangeNotificationListener$ChangeEventProcessThread: [/config/changes-event-process-thread]: Shutdown completed
2024-04-24T12:39:54,864  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopping socket server request processors
2024-04-24T12:39:54,873  INFO [main] network.SocketServer: [SocketServer brokerId=0] Stopped socket server request processors
2024-04-24T12:39:54,874  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shutting down
2024-04-24T12:39:54,876  INFO [main] server.KafkaRequestHandlerPool: [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-04-24T12:39:54,878  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutting down
2024-04-24T12:39:55,017  INFO [ExpirationReaper-0-AlterAcls] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Stopped
2024-04-24T12:39:55,017  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-04-24T12:39:55,019  INFO [main] server.KafkaApis: [KafkaApi-0] Shutdown complete.
2024-04-24T12:39:55,020  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutting down
2024-04-24T12:39:55,103  INFO [ExpirationReaper-0-topic] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Stopped
2024-04-24T12:39:55,103  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-topic]: Shutdown completed
2024-04-24T12:39:55,106  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutting down.
2024-04-24T12:39:55,108  INFO [main] transaction.ProducerIdManager: [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2024-04-24T12:39:55,109  INFO [main] transaction.TransactionStateManager: [Transaction State Manager 0]: Shutdown complete
2024-04-24T12:39:55,109  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutting down
2024-04-24T12:39:55,113  INFO [TxnMarkerSenderThread-0] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Stopped
2024-04-24T12:39:55,113  INFO [main] transaction.TransactionMarkerChannelManager: [Transaction Marker Channel Manager 0]: Shutdown completed
2024-04-24T12:39:55,115  INFO [main] transaction.TransactionCoordinator: [TransactionCoordinator id=0] Shutdown complete.
2024-04-24T12:39:55,117  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutting down.
2024-04-24T12:39:55,118  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutting down
2024-04-24T12:39:55,308  INFO [ExpirationReaper-0-Heartbeat] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Stopped
2024-04-24T12:39:55,308  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-04-24T12:39:55,309  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutting down
2024-04-24T12:39:55,508  INFO [ExpirationReaper-0-Rebalance] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Stopped
2024-04-24T12:39:55,508  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-04-24T12:39:55,510  INFO [main] group.GroupCoordinator: [GroupCoordinator 0]: Shutdown complete.
2024-04-24T12:39:55,512  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shutting down
2024-04-24T12:39:55,512  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutting down
2024-04-24T12:39:55,513  INFO [LogDirFailureHandler] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Stopped
2024-04-24T12:39:55,513  INFO [main] server.ReplicaManager$LogDirFailureHandler: [LogDirFailureHandler]: Shutdown completed
2024-04-24T12:39:55,513  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutting down
2024-04-24T12:39:55,514  INFO [main] server.ReplicaFetcherManager: [ReplicaFetcherManager on broker 0] shutdown completed
2024-04-24T12:39:55,514  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-04-24T12:39:55,515  INFO [main] server.ReplicaAlterLogDirsManager: [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-04-24T12:39:55,515  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutting down
2024-04-24T12:39:55,599  INFO [ExpirationReaper-0-Fetch] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Stopped
2024-04-24T12:39:55,599  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Fetch]: Shutdown completed
2024-04-24T12:39:55,601  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutting down
2024-04-24T12:39:55,670  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:55,671  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:55,800  INFO [ExpirationReaper-0-Produce] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Stopped
2024-04-24T12:39:55,800  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-Produce]: Shutdown completed
2024-04-24T12:39:55,801  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-04-24T12:39:56,000  INFO [ExpirationReaper-0-DeleteRecords] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Stopped
2024-04-24T12:39:56,000  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-04-24T12:39:56,001  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutting down
2024-04-24T12:39:56,201  INFO [ExpirationReaper-0-ElectLeader] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Stopped
2024-04-24T12:39:56,201  INFO [main] server.DelayedOperationPurgatory$ExpiredOperationReaper: [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-04-24T12:39:56,207  INFO [main] server.ReplicaManager: [ReplicaManager broker=0] Shut down completely
2024-04-24T12:39:56,209  INFO [main] log.LogManager: Shutting down.
2024-04-24T12:39:56,211  INFO [main] log.LogCleaner: Shutting down the log cleaner.
2024-04-24T12:39:56,212  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutting down
2024-04-24T12:39:56,213  INFO [kafka-log-cleaner-thread-0] log.LogCleaner: [kafka-log-cleaner-thread-0]: Stopped
2024-04-24T12:39:56,213  INFO [main] log.LogCleaner: [kafka-log-cleaner-thread-0]: Shutdown completed
2024-04-24T12:39:56,230  INFO [pool-9-thread-1] log.ProducerStateManager: [ProducerStateManager partition=134b93eb-8fa3-43f0-92df-8aa5bfe8a729-0] Writing producer snapshot at offset 17384
2024-04-24T12:39:56,247  INFO [main] log.LogManager: Shutdown complete.
2024-04-24T12:39:56,247  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutting down
2024-04-24T12:39:56,248  INFO [controller-event-thread] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Stopped
2024-04-24T12:39:56,248  INFO [main] controller.ControllerEventManager$ControllerEventThread: [ControllerEventThread controllerId=0] Shutdown completed
2024-04-24T12:39:56,250  INFO [main] controller.ZkPartitionStateMachine: [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-04-24T12:39:56,251  INFO [main] controller.ZkReplicaStateMachine: [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-04-24T12:39:56,251  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutting down
2024-04-24T12:39:56,251  INFO [Controller-0-to-broker-0-send-thread] controller.RequestSendThread: [RequestSendThread controllerId=0] Stopped
2024-04-24T12:39:56,251  INFO [main] controller.RequestSendThread: [RequestSendThread controllerId=0] Shutdown completed
2024-04-24T12:39:56,256  INFO [main] controller.KafkaController: [Controller id=0] Resigned
2024-04-24T12:39:56,257  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closing.
2024-04-24T12:39:56,361  INFO [main] zookeeper.ZooKeeper: Session: 0x100096813be0000 closed
2024-04-24T12:39:56,363  INFO [main] zookeeper.ZooKeeperClient: [ZooKeeperClient Kafka server] Closed.
2024-04-24T12:39:56,363  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutting down
2024-04-24T12:39:56,582  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:56,582  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:56,752  INFO [ThrottledChannelReaper-Fetch] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Stopped
2024-04-24T12:39:56,752  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-04-24T12:39:56,752  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutting down
2024-04-24T12:39:57,743  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9290) could not be established. Broker may not be available.
2024-04-24T12:39:57,743  WARN [kafka-producer-network-thread | producer-1] clients.NetworkClient: [Producer clientId=producer-1] Bootstrap broker localhost:9290 (id: -1 rack: null) disconnected
2024-04-24T12:39:57,752  INFO [ThrottledChannelReaper-Produce] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Stopped
2024-04-24T12:39:57,752  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Produce]: Shutdown completed
2024-04-24T12:39:57,753  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutting down
2024-04-24T12:39:57,754  INFO [ThrottledChannelReaper-Request] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Stopped
2024-04-24T12:39:57,754  INFO [main] server.ClientQuotaManager$ThrottledChannelReaper: [ThrottledChannelReaper-Request]: Shutdown completed
2024-04-24T12:39:57,756  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutting down socket server
2024-04-24T12:39:57,786  INFO [main] network.SocketServer: [SocketServer brokerId=0] Shutdown completed
2024-04-24T12:39:57,800  INFO [main] server.KafkaServer: [KafkaServer id=0] shut down completed
2024-04-24T12:39:57,800  INFO [ConnnectionExpirer] server.NIOServerCnxnFactory: ConnnectionExpirerThread interrupted
2024-04-24T12:39:57,801  INFO [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0] server.NIOServerCnxnFactory: accept thread exitted run method
2024-04-24T12:39:57,801  INFO [NIOServerCxnFactory.SelectorThread-0] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:39:57,801  INFO [NIOServerCxnFactory.SelectorThread-1] server.NIOServerCnxnFactory: selector thread exitted run method
2024-04-24T12:39:57,801  INFO [main] server.ZooKeeperServer: shutting down
2024-04-24T12:39:57,801  INFO [main] server.SessionTrackerImpl: Shutting down
2024-04-24T12:39:57,801  INFO [main] server.PrepRequestProcessor: Shutting down
2024-04-24T12:39:57,801  INFO [main] server.SyncRequestProcessor: Shutting down
2024-04-24T12:39:57,801  INFO [ProcessThread(sid:0 cport:40845):] server.PrepRequestProcessor: PrepRequestProcessor exited loop!
2024-04-24T12:39:57,802  INFO [SyncThread:0] server.SyncRequestProcessor: SyncRequestProcessor exited!
2024-04-24T12:39:57,802  INFO [main] server.FinalRequestProcessor: shutdown of request processor complete
