24/05/17 01:56:50 INFO hbase.HBaseTestingUtility: Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
24/05/17 01:56:50 INFO util.GSet: VM type       = 64-bit
24/05/17 01:56:50 INFO util.GSet: 2% max memory = 16.86 MB
24/05/17 01:56:50 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/05/17 01:56:50 INFO util.GSet: recommended=2097152, actual=2097152
24/05/17 01:56:51 INFO namenode.FSNamesystem: fsOwner=idflakies
24/05/17 01:56:51 INFO namenode.FSNamesystem: supergroup=supergroup
24/05/17 01:56:51 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/05/17 01:56:51 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/05/17 01:56:51 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/05/17 01:56:51 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/name1 has been successfully formatted.
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/name2 has been successfully formatted.
24/05/17 01:56:51 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
24/05/17 01:56:51 INFO util.GSet: VM type       = 64-bit
24/05/17 01:56:51 INFO util.GSet: 2% max memory = 16.86 MB
24/05/17 01:56:51 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/05/17 01:56:51 INFO util.GSet: recommended=2097152, actual=2097152
24/05/17 01:56:51 INFO namenode.FSNamesystem: fsOwner=idflakies
24/05/17 01:56:51 INFO namenode.FSNamesystem: supergroup=supergroup
24/05/17 01:56:51 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/05/17 01:56:51 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/05/17 01:56:51 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/05/17 01:56:51 INFO namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
24/05/17 01:56:51 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/05/17 01:56:51 INFO common.Storage: Number of files = 1
24/05/17 01:56:51 INFO common.Storage: Number of files under construction = 0
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 loaded in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Edits file /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 01:56:51 INFO namenode.NameCache: initialized with 0 entries 0 lookups
24/05/17 01:56:51 INFO namenode.FSNamesystem: Finished loading FSImage in 157 msecs
24/05/17 01:56:51 INFO namenode.FSNamesystem: Total number of blocks = 0
24/05/17 01:56:51 INFO namenode.FSNamesystem: Number of invalid blocks = 0
24/05/17 01:56:51 INFO namenode.FSNamesystem: Number of under-replicated blocks = 0
24/05/17 01:56:51 INFO namenode.FSNamesystem: Number of  over-replicated blocks = 0
24/05/17 01:56:51 INFO hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 22 msec
24/05/17 01:56:51 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
24/05/17 01:56:51 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
24/05/17 01:56:51 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
24/05/17 01:56:51 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
24/05/17 01:56:51 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/05/17 01:56:51 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/05/17 01:56:51 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/05/17 01:56:51 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/05/17 01:56:51 INFO ipc.Server: Starting SocketReader
24/05/17 01:56:51 INFO namenode.NameNode: Namenode up at: localhost/127.0.0.1:45453
24/05/17 01:56:51 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
24/05/17 01:56:51 INFO http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
24/05/17 01:56:51 INFO http.HttpServer: dfs.webhdfs.enabled = false
24/05/17 01:56:51 INFO http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
24/05/17 01:56:51 INFO http.HttpServer: listener.getLocalPort() returned 44539 webServer.getConnectors()[0].getLocalPort() returned 44539
24/05/17 01:56:51 INFO http.HttpServer: Jetty bound to port 44539
24/05/17 01:56:51 INFO mortbay.log: jetty-6.1.26
24/05/17 01:56:51 INFO mortbay.log: Extract jar:file:/home/idflakies/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar!/webapps/hdfs to /tmp/Jetty_localhost_44539_hdfs____.j4d4zf/webapp
24/05/17 01:56:51 INFO mortbay.log: Started SelectChannelConnector@localhost:44539
24/05/17 01:56:51 INFO namenode.NameNode: Web-server up at: localhost:44539
24/05/17 01:56:51 INFO ipc.Server: IPC Server Responder: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server listener on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 0 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 1 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 2 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 3 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 4 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 5 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 6 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 7 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 8 on 45453: starting
24/05/17 01:56:51 INFO ipc.Server: IPC Server handler 9 on 45453: starting
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/data/data2
24/05/17 01:56:51 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
24/05/17 01:56:51 WARN util.MBeans: Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:151)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:930)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:51 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/data/data1, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/05/17 01:56:51 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/1bd5592f-bf7d-42ec-aa2a-9887cb4dff7b/dfscluster_e11c1e24-7c5b-4aa9-97e0-a00b835420ff/dfs/data/data2, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/05/17 01:56:51 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:51 INFO hbase.HBaseTestingUtility: Shutting down minicluster
24/05/17 01:56:51 INFO hbase.HBaseTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:51 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/d0bf9d39-27bc-4692-ae15-e6a6cb54d0dc/dfscluster_356d20d5-891d-4c27-896f-811b45b2a728/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/d0bf9d39-27bc-4692-ae15-e6a6cb54d0dc/dfscluster_356d20d5-891d-4c27-896f-811b45b2a728/dfs/data/data2
24/05/17 01:56:52 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestPublisher.setUpBeforeClass(TestPublisher.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 2 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/25066b92-14e4-40b8-9e7f-d610bc4a6365/dfscluster_354f8fcc-ef16-4102-92b3-2da62cb17aad/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/25066b92-14e4-40b8-9e7f-d610bc4a6365/dfscluster_354f8fcc-ef16-4102-92b3-2da62cb17aad/dfs/data/data2
24/05/17 01:56:52 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.master.TestMaster.beforeAllTests(TestMaster.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/9120b819-da36-4a25-b2b2-e9fef832bd8d/dfscluster_ecae7f33-1735-4408-a233-1a4de7c9cf6f/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/9120b819-da36-4a25-b2b2-e9fef832bd8d/dfscluster_ecae7f33-1735-4408-a233-1a4de7c9cf6f/dfs/data/data2
24/05/17 01:56:52 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestSubscriber.setUpBeforeClass(TestSubscriber.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:52 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/12e03e2f-9a21-474b-b32d-63fc389f443e/dfscluster_f7f557eb-aa0e-4450-b123-5cb2ea4ad4e5/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/12e03e2f-9a21-474b-b32d-63fc389f443e/dfscluster_f7f557eb-aa0e-4450-b123-5cb2ea4ad4e5/dfs/data/data2
24/05/17 01:56:53 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.setUpBeforeClass(TestJdbcResultFormatter.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.tearDownAfterClass(TestJdbcResultFormatter.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/baf2b17a-72cd-46c4-a905-3f1e126fc276/dfscluster_7a4aa9c0-5dc8-4333-a711-b41324482f82/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/baf2b17a-72cd-46c4-a905-3f1e126fc276/dfscluster_7a4aa9c0-5dc8-4333-a711-b41324482f82/dfs/data/data2
24/05/17 01:56:53 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.fserver.redo.TestRedoLog.before(TestRedoLog.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
2013-04-13 04:04:654
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,name from User where user_id=1 limit 1;
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, name]
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 01:56:53 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false]]], fetchRows=0]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,photo_id,full_url,thumbnail_url from Photo where user_id=99999999999 and photo_id=0.1;
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL TableSource Photo
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem photo_id
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem full_url
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem thumbnail_url
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, photo_id, full_url, thumbnail_url]
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 99999999999 AND photo_id = 0.1
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
2 Filter Field:
	Field user_id  Type EQUAL Value 99999999999
	Field photo_id  Type EQUAL Value 0.1
	


24/05/17 01:56:53 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x17Hv\xE7\xFF\x00\x00\x00\x00\x00 from Photo
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=Photo, primayKey=[0, 0, 0, 23, 72, 118, -25, -1, 0, 0, 0, 0, 0], columns=[ColumnAction [tableName=Photo, familyName=cf, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=photo_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=full_url, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=thumbnail_url, value=null, isIndex=false]]], fetchRows=0]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1;
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 01:56:53 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1 for update ;
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 01:56:53 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 01:56:53 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 01:56:53 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:53 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:53 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
--------------------------------------------
SELECT			SELECT
STAR			*
FROM			FROM
IDENTIFIER		T
WHERE			WHERE
IDENTIFIER		F1
EQ			=
QUES			?
ORDER			ORDER
BY			BY
IDENTIFIER		F2
EOF			null
--------------------------------------------
24/05/17 01:56:53 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table MetricsEntityGroupWrapperStub DEADBEEF001
24/05/17 01:56:53 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/05/17 01:56:53 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/05/17 01:56:53 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TWO
24/05/17 01:56:53 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/e4b5ad52-3007-476f-8221-de40a574abdf/dfscluster_8accc312-8dcc-4101-8438-9ebe217b94ed/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/e4b5ad52-3007-476f-8221-de40a574abdf/dfscluster_8accc312-8dcc-4101-8438-9ebe217b94ed/dfs/data/data2
24/05/17 01:56:54 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestPreparedStatement.beforeClass(TestPreparedStatement.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestPreparedStatement.afterClass(TestPreparedStatement.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES IN Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES FROM Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User2 {Required Int64 user_id; Required String name; }  primary key(user_id),  entity group root,  entity group key(user_id),  partition by range('aaa', 'zzz', 10); 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User2 { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=[[B@4f8969b0, [B@1bdf8190, [B@192f2f27, [B@8a589a2, [B@c65a5ef, [B@6b5176f2, [B@b672aa8, [B@2fab4aff, [B@ec0c838]]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@62923ee6]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL DROP INDEX PhotosByTime ON Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: DropIndexPlan DropIndexPlan [indexName=PhotosByTime, tableName=Photo]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@372ea2bc]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTag on Photo(tag);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTag
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@4cc76301]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES LIKE 'pattern'
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL SHOW CREATE TABLE Photo
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL TRUNCATE TABLE Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: TruncateTablePlan TruncateTablePlan [tableNames=[Photo]]
24/05/17 01:56:54 INFO druid.TestDruidDDLParser: TruncateTablePlan [tableNames=[Photo]]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy1 int32 FIRST
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  OPTIONAL INT32 dummy1 COLUMNFAMILY d;
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string columnfamily cf comment 'aaa'
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY cf;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy2 int32 AFTER thumbnail_url
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL INT32 dummy2 COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE COLUMN thumbnail_url thumbnail_url INT32
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url thumbnail_url INT32
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url rename_url INT64;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT64 rename_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo DROP COLUMN full_url, DROP COLUMN thumbnail_url;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);

CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  REQUIRED INT64 time COLUMNFAMILY d;
  REQUIRED STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  REPEATED STRING tag COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;

24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL DROP TABLE Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo], ifExists=false]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL DROP TABLE IF EXISTS Photo, User;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo, User], ifExists=false]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 01:56:54 DEBUG druid.DruidParser: Parsing SQL DESCRIBE Photo;
24/05/17 01:56:54 DEBUG druid.DruidDDLParser: DescTablePlan DescTablePlan 
24/05/17 01:56:54 INFO server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:49966
24/05/17 01:56:54 INFO persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/idflakies/alibaba/wasp/target/test-data/94232215-c8b3-4588-8f8c-226177d6e56a/dfscluster_c021b92b-18a5-4f97-8e60-1cfd88f3ff14/zookeeper_0/version-2/snapshot.0
24/05/17 01:56:54 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34124
24/05/17 01:56:54 DEBUG master.FMaster: Set serverside FConnection retries=100
24/05/17 01:56:54 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMaster
24/05/17 01:56:54 DEBUG zookeeper.ZKUtil: master:34445 opening connection to ZooKeeper with ensemble (localhost:49966)
24/05/17 01:56:54 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 12482@a9f87c527aeb
24/05/17 01:56:54 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34140
24/05/17 01:56:54 INFO persistence.FileTxnLog: Creating new log file: log.1
24/05/17 01:56:54 DEBUG zookeeper.ZooKeeperWatcher: master:34445 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
24/05/17 01:56:54 DEBUG zookeeper.ZooKeeperWatcher: master:34445-0xff8f844437c50000 connected
24/05/17 01:56:54 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMasterMonitorProtocol
24/05/17 01:56:54 DEBUG ipc.NettyTransceiver: Using Netty bootstrap options: {connectTimeoutMillis=3000, tcpNoDelay=true}
24/05/17 01:56:54 DEBUG ipc.NettyTransceiver: Connecting to a9f87c527aeb/172.17.0.2:34445
24/05/17 01:56:54 DEBUG ipc.NettyTransceiver: [id: 0x10567255] OPEN
24/05/17 01:56:54 INFO ipc.NettyTransceiver: Successfully connected to bookie: a9f87c527aeb/172.17.0.2:34445
24/05/17 01:56:54 DEBUG ipc.NettyTransceiver: [id: 0x10567255, /172.17.0.2:47770 => a9f87c527aeb/172.17.0.2:34445] BOUND: /172.17.0.2:47770
24/05/17 01:56:54 DEBUG ipc.NettyTransceiver: [id: 0x10567255, /172.17.0.2:47770 => a9f87c527aeb/172.17.0.2:34445] CONNECTED: a9f87c527aeb/172.17.0.2:34445
24/05/17 01:56:54 DEBUG ipc.NettyServer: [id: 0x1749724e, /172.17.0.2:47770 => /172.17.0.2:34445] OPEN
24/05/17 01:56:54 DEBUG ipc.NettyServer: [id: 0x1749724e, /172.17.0.2:47770 => /172.17.0.2:34445] BOUND: /172.17.0.2:34445
24/05/17 01:56:54 DEBUG ipc.NettyServer: [id: 0x1749724e, /172.17.0.2:47770 => /172.17.0.2:34445] CONNECTED: /172.17.0.2:47770
24/05/17 01:56:54 WARN ipc.NettyServer: Unable to read call parameters for client /172.17.0.2:47770
com.alibaba.wasp.ipc.ServerNotRunningYetException: Server is not running yet
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.messageReceived(NettyServer.java:203)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75)
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.handleUpstream(NettyServer.java:171)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:563)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:45)
	at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/05/17 01:56:54 ERROR ipc.NettyTransceiver: Fatal Exception.
24/05/17 01:56:54 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 1 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/bb366e45-0d7c-4f9e-883d-eb93cd08532d/dfscluster_045d4073-e228-4d93-83be-5f83a06bef58/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/bb366e45-0d7c-4f9e-883d-eb93cd08532d/dfscluster_045d4073-e228-4d93-83be-5f83a06bef58/dfs/data/data2
24/05/17 01:56:54 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:54 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:54 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.plan.execute.TestExecutionEngine.before(TestExecutionEngine.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:54 DEBUG executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-unit_test, corePoolSize=5, maxPoolSize=5
24/05/17 01:56:54 INFO executor.TestExecutorService: Waiting for all event handlers to start...
24/05/17 01:56:54 INFO executor.TestExecutorService: Running process #2, threadName=MASTER_SERVER_OPERATIONS-unit_test-3
24/05/17 01:56:54 INFO executor.TestExecutorService: Running process #4, threadName=MASTER_SERVER_OPERATIONS-unit_test-1
24/05/17 01:56:54 INFO executor.TestExecutorService: Running process #3, threadName=MASTER_SERVER_OPERATIONS-unit_test-2
24/05/17 01:56:54 INFO executor.TestExecutorService: Running process #5, threadName=MASTER_SERVER_OPERATIONS-unit_test-4
24/05/17 01:56:54 INFO executor.TestExecutorService: Running process #1, threadName=MASTER_SERVER_OPERATIONS-unit_test-0
24/05/17 01:56:55 INFO executor.TestExecutorService: Got status dump:
Status for executor: Executor-1-MASTER_SERVER_OPERATIONS-unit_test
=======================================
0 events queued, 5 running
Running:
  Running on thread 'MASTER_SERVER_OPERATIONS-unit_test-4': Event #5 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)
  Thread 237 (MASTER_SERVER_OPERATIONS-unit_test-4):
    State: WAITING
    Blocked count: 1
    Waited count: 1
    Waiting on java.util.concurrent.atomic.AtomicBoolean@ddf20fd
    Stack:
      java.lang.Object.wait(Native Method)
      java.lang.Object.wait(Object.java:502)
      com.alibaba.wasp.executor.TestExecutorService$TestEventHandler.process(TestExecutorService.java:167)
      com.alibaba.wasp.executor.EventHandler.run(EventHandler.java:198)
      java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
      java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
      java.lang.Thread.run(Thread.java:748)

  Running on thread 'MASTER_SERVER_OPERATIONS-unit_test-3': Event #4 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)
  Thread 236 (MASTER_SERVER_OPERATIONS-unit_test-3):
    State: WAITING
    Blocked count: 0
    Waited count: 1
    Waiting on java.util.concurrent.atomic.AtomicBoolean@ddf20fd
    Stack:
      java.lang.Object.wait(Native Method)
      java.lang.Object.wait(Object.java:502)
      com.alibaba.wasp.executor.TestExecutorService$TestEventHandler.process(TestExecutorService.java:167)
      com.alibaba.wasp.executor.EventHandler.run(EventHandler.java:198)
Waiting for all event handlers to finish...
      java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
      java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
      java.lang.Thread.run(Thread.java:748)

  Running on thread 'MASTER_SERVER_OPERATIONS-unit_test-2': Event #3 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)
  Thread 235 (MASTER_SERVER_OPERATIONS-unit_test-2):
    State: WAITING
    Blocked count: 2
    Waited count: 1
    Waiting on java.util.concurrent.atomic.AtomicBoolean@ddf20fd
    Stack:
      java.lang.Object.wait(Native Method)
      java.lang.Object.wait(Object.java:502)
      com.alibaba.wasp.executor.TestExecutorService$TestEventHandler.process(TestExecutorService.java:167)
      com.alibaba.wasp.executor.EventHandler.run(EventHandler.java:198)
      java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
      java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
      java.lang.Thread.run(Thread.java:748)

  Running on thread 'MASTER_SERVER_OPERATIONS-unit_test-1': Event #2 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)
  Thread 234 (MASTER_SERVER_OPERATIONS-unit_test-1):
    State: WAITING
    Blocked count: 2
    Waited count: 1
    Waiting on java.util.concurrent.atomic.AtomicBoolean@ddf20fd
    Stack:
      java.lang.Object.wait(Native Method)
      java.lang.Object.wait(Object.java:502)
      com.alibaba.wasp.executor.TestExecutorService$TestEventHandler.process(TestExecutorService.java:167)
      com.alibaba.wasp.executor.EventHandler.run(EventHandler.java:198)
      java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
      java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
      java.lang.Thread.run(Thread.java:748)

  Running on thread 'MASTER_SERVER_OPERATIONS-unit_test-0': Event #1 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)
  Thread 233 (MASTER_SERVER_OPERATIONS-unit_test-0):
    State: WAITING
    Blocked count: 1
    Waited count: 1
    Waiting on java.util.concurrent.atomic.AtomicBoolean@ddf20fd
    Stack:
      java.lang.Object.wait(Native Method)
      java.lang.Object.wait(Object.java:502)
      com.alibaba.wasp.executor.TestExecutorService$TestEventHandler.process(TestExecutorService.java:167)
      com.alibaba.wasp.executor.EventHandler.run(EventHandler.java:198)
      java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
      java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
      java.lang.Thread.run(Thread.java:748)


24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #11, threadName=MASTER_SERVER_OPERATIONS-unit_test-4
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #12, threadName=MASTER_SERVER_OPERATIONS-unit_test-0
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #15, threadName=MASTER_SERVER_OPERATIONS-unit_test-2
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #14, threadName=MASTER_SERVER_OPERATIONS-unit_test-4
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #19, threadName=MASTER_SERVER_OPERATIONS-unit_test-2
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #17, threadName=MASTER_SERVER_OPERATIONS-unit_test-0
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #22, threadName=MASTER_SERVER_OPERATIONS-unit_test-2
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #25, threadName=MASTER_SERVER_OPERATIONS-unit_test-2
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #27, threadName=MASTER_SERVER_OPERATIONS-unit_test-4
24/05/17 01:56:55 INFO executor.TestExecutorService: Running process #29, threadName=MASTER_SERVER_OPERATIONS-unit_test-4
24/05/17 01:56:57 ERROR executor.ExecutorService: Cannot submit [Event #16 of type M_SERVER_SHUTDOWN (class com.alibaba.wasp.executor.TestExecutorService$TestEventHandler)] because the executor is missing. Is this process shutting down?
24/05/17 01:56:57 DEBUG master.TestOpenedEntityGroupHandler: 

TRR: Starting cluster

24/05/17 01:56:57 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 1 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/59987d8b-ccc3-4454-8490-e665c9065a66/dfscluster_d8743f0f-4a37-4aa3-9386-cd244c93cae4/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/59987d8b-ccc3-4454-8490-e665c9065a66/dfscluster_d8743f0f-4a37-4aa3-9386-cd244c93cae4/dfs/data/data2
24/05/17 01:56:57 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:57 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:57 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.master.TestOpenedEntityGroupHandler.testOpenedEntityGroupHandlerOnMasterRestart(TestOpenedEntityGroupHandler.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:57 INFO server.ZooKeeperServer: Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /home/idflakies/alibaba/wasp/target/test-data/f911fc82-9ec8-4bef-adf6-33f809af510a/dfscluster_94e4f2d2-8c40-42f4-9f85-c4fc3ae0aafb/zookeeper_0/version-2 snapdir /home/idflakies/alibaba/wasp/target/test-data/f911fc82-9ec8-4bef-adf6-33f809af510a/dfscluster_94e4f2d2-8c40-42f4-9f85-c4fc3ae0aafb/zookeeper_0/version-2
24/05/17 01:56:57 INFO server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:59933
24/05/17 01:56:57 INFO persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/idflakies/alibaba/wasp/target/test-data/f911fc82-9ec8-4bef-adf6-33f809af510a/dfscluster_94e4f2d2-8c40-42f4-9f85-c4fc3ae0aafb/zookeeper_0/version-2/snapshot.0
24/05/17 01:56:57 WARN jmx.MBeanRegistry: Failed to register MBean StandaloneServer_port-1
24/05/17 01:56:57 WARN server.ZooKeeperServer: Failed to register with JMX
javax.management.InstanceAlreadyExistsException: org.apache.ZooKeeperService:name0=StandaloneServer_port-1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.zookeeper.jmx.MBeanRegistry.register(MBeanRegistry.java:98)
	at org.apache.zookeeper.server.ZooKeeperServer.registerJMX(ZooKeeperServer.java:355)
	at org.apache.zookeeper.server.ZooKeeperServer.startup(ZooKeeperServer.java:388)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.startup(NIOServerCnxnFactory.java:123)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:178)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniZKCluster(HBaseTestingUtility.java:518)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniZKCluster(HBaseTestingUtility.java:502)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniZKCluster(HBaseTestingUtility.java:488)
	at com.alibaba.wasp.master.TestOpenedEntityGroupHandler.testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches(TestOpenedEntityGroupHandler.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 01:56:57 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:54878
24/05/17 01:56:57 INFO server.NIOServerCnxn: Processing stat command from /127.0.0.1:54878
24/05/17 01:56:57 INFO server.NIOServerCnxn: Stat command output
24/05/17 01:56:57 INFO server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:54878 (no session established for client)
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: MockServer,123,-1 opening connection to ZooKeeper with ensemble (localhost:59933)
24/05/17 01:56:57 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:59933 sessionTimeout=180000 watcher=MockServer,123,-1
24/05/17 01:56:57 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 12482@a9f87c527aeb
24/05/17 01:56:57 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:54894
24/05/17 01:56:57 DEBUG server.ZooKeeperServer: Session establishment request from client /127.0.0.1:54894 client's lastZxid is 0x0
24/05/17 01:56:57 INFO server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:54894
24/05/17 01:56:57 INFO persistence.FileTxnLog: Creating new log file: log.1
24/05/17 01:56:57 INFO server.ZooKeeperServer: Established session 0xff8f8444442d0000 with negotiated timeout 40000 for client /127.0.0.1:54894
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: MockServer,123,-1 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: MockServer,123,-1-0xff8f8444442d0000 connected
24/05/17 01:56:57 INFO fserver.EntityGroup: creating EntityGroup testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches Table == CREATE TABLE testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches { 
  REQUIRED INT32 column1 COLUMNFAMILY d;
  REQUIRED INT64 column2 COLUMNFAMILY d;
  REQUIRED STRING column3 COLUMNFAMILY d;
  OPTIONAL FLOAT column4 COLUMNFAMILY d;
  OPTIONAL DOUBLE column5 COLUMNFAMILY d;
  OPTIONAL DATETIME column6 COLUMNFAMILY d;
  REPEATED PROTOBUF column7 COLUMNFAMILY d;
  OPTIONAL STRING column8 COLUMNFAMILY d;
} 
PRIMARY KEY(column1),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(column1);
 Table name == testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches
24/05/17 01:56:57 DEBUG fserver.EntityGroup: Instantiated testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840.
24/05/17 01:56:57 ERROR server.NIOServerCnxnFactory: Thread Thread[Thread-217,5,main] died
java.lang.NullPointerException
	at com.alibaba.wasp.fserver.EntityGroup.run(EntityGroup.java:1264)
	at java.lang.Thread.run(Thread.java:748)
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: unittest opening connection to ZooKeeper with ensemble (localhost:59933)
24/05/17 01:56:57 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:59933 sessionTimeout=180000 watcher=unittest
24/05/17 01:56:57 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 12482@a9f87c527aeb
24/05/17 01:56:57 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:54906
24/05/17 01:56:57 DEBUG server.ZooKeeperServer: Session establishment request from client /127.0.0.1:54906 client's lastZxid is 0x0
24/05/17 01:56:57 INFO server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:54906
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest Creating unassigned node for 679f1ddce0b852b737860e01f1d84840 in OFFLINE state
24/05/17 01:56:57 INFO server.ZooKeeperServer: Established session 0xff8f8444442d0001 with negotiated timeout 40000 for client /127.0.0.1:54906
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest Received ZooKeeper Event, type=None, state=SyncConnected, path=null
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest-0xff8f8444442d0001 connected
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Attempting to transition node 679f1ddce0b852b737860e01f1d84840 from M_ZK_ENTITYGROUP_OFFLINE to FSERVER_ZK_ENTITYGROUP_OPENING
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: unittest-0xff8f8444442d0001 Retrieved 161 byte(s) of data from znode /wasp/unassigned/679f1ddce0b852b737860e01f1d84840; data=entityGroup=testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840., state=M_ZK_ENTITYGROUP_OFFLINE, servername=MockServer,123,-1, createTime=1715911017649, payload.length=0
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest-0xff8f8444442d0001 Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/wasp/unassigned/679f1ddce0b852b737860e01f1d84840
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Successfully transitioned node 679f1ddce0b852b737860e01f1d84840 from M_ZK_ENTITYGROUP_OFFLINE to FSERVER_ZK_ENTITYGROUP_OPENING
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Attempting to transition node 679f1ddce0b852b737860e01f1d84840 from FSERVER_ZK_ENTITYGROUP_OPENING to FSERVER_ZK_ENTITYGROUP_OPENED
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: unittest-0xff8f8444442d0001 Retrieved 161 byte(s) of data from znode /wasp/unassigned/679f1ddce0b852b737860e01f1d84840; data=entityGroup=testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840., state=FSERVER_ZK_ENTITYGROUP_OPENING, servername=MockServer,123,-1, createTime=1715911017658, payload.length=0
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Successfully transitioned node 679f1ddce0b852b737860e01f1d84840 from FSERVER_ZK_ENTITYGROUP_OPENING to FSERVER_ZK_ENTITYGROUP_OPENED
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: unittest-0xff8f8444442d0001 Retrieved 161 byte(s) of data from znode /wasp/unassigned/679f1ddce0b852b737860e01f1d84840 and set watcher; entityGroup=testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840., state=FSERVER_ZK_ENTITYGROUP_OPENED, servername=MockServer,123,-1, createTime=1715911017664, payload.length=0
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Attempting to transition node 679f1ddce0b852b737860e01f1d84840 from FSERVER_ZK_ENTITYGROUP_OPENED to FSERVER_ZK_ENTITYGROUP_OPENED
24/05/17 01:56:57 DEBUG zookeeper.ZKUtil: unittest-0xff8f8444442d0001 Retrieved 161 byte(s) of data from znode /wasp/unassigned/679f1ddce0b852b737860e01f1d84840; data=entityGroup=testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840., state=FSERVER_ZK_ENTITYGROUP_OPENED, servername=MockServer,123,-1, createTime=1715911017664, payload.length=0
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest-0xff8f8444442d0001 Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/wasp/unassigned/679f1ddce0b852b737860e01f1d84840
24/05/17 01:56:57 DEBUG zookeeper.ZKAssign: unittest-0xff8f8444442d0001 Successfully transitioned node 679f1ddce0b852b737860e01f1d84840 from FSERVER_ZK_ENTITYGROUP_OPENED to FSERVER_ZK_ENTITYGROUP_OPENED
24/05/17 01:56:57 WARN handler.OpenedEntityGroupHandler: Skipping the onlining of testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840. because entityGroups is NOT in EGIT -- presuming this is because it SPLIT
24/05/17 01:56:57 DEBUG fserver.EntityGroup: Closing testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840.
24/05/17 01:56:57 DEBUG fserver.EntityGroup: Updates disabled for entityGroup testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840.
24/05/17 01:56:57 INFO fserver.EntityGroup: Running commit transaction of testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840. before close
24/05/17 01:56:57 INFO fserver.EntityGroup: Closed testShouldNotCompeleteOpenedEntityGroupSuccessfullyIfVersionMismatches,\x00\x00\x00\x00,1715911017583.679f1ddce0b852b737860e01f1d84840.
24/05/17 01:56:57 INFO server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:54894 which had sessionid 0xff8f8444442d0000
24/05/17 01:56:57 INFO server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:54906 which had sessionid 0xff8f8444442d0001
24/05/17 01:56:57 INFO server.NIOServerCnxnFactory: NIOServerCnxn factory exited run method
24/05/17 01:56:57 INFO server.ZooKeeperServer: shutting down
24/05/17 01:56:57 INFO server.SessionTrackerImpl: Shutting down
24/05/17 01:56:57 INFO server.PrepRequestProcessor: Shutting down
24/05/17 01:56:57 INFO server.SyncRequestProcessor: Shutting down
24/05/17 01:56:57 INFO server.PrepRequestProcessor: PrepRequestProcessor exited loop!
24/05/17 01:56:57 INFO server.SyncRequestProcessor: SyncRequestProcessor exited!
24/05/17 01:56:57 INFO server.FinalRequestProcessor: shutdown of request processor complete
24/05/17 01:56:57 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:57 INFO wasp.WaspTestingUtility: Minicluster is down
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 } [srvr=1 rgns=0 avg=0.0 max=0 min=0]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=1 entityGroups=0 average=0.0 mostloaded=0 leastloaded=0
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1 } [srvr=1 rgns=1 avg=1.0 max=1 min=1]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=1 entityGroups=1 average=1.0 mostloaded=1 leastloaded=1
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:10 } [srvr=1 rgns=10 avg=10.0 max=10 min=10]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=1 entityGroups=10 average=10.0 mostloaded=10 leastloaded=10
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv68821:0 } [srvr=2 rgns=0 avg=0.0 max=0 min=0]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=0 average=0.0 mostloaded=0 leastloaded=0
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:0 , srv21098:2 } [srvr=2 rgns=2 avg=1.0 max=1 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=2, numServers=2, max=1, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 5ms. Moving 1 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv68821:1 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:1 , srv21098:2 } [srvr=2 rgns=3 avg=1.5 max=2 min=1]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=3 average=1.5 mostloaded=2 leastloaded=1
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:2 , srv68821:2 } [srvr=2 rgns=4 avg=2.0 max=2 min=2]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=4 average=2.0 mostloaded=2 leastloaded=2
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:2 , srv68821:3 } [srvr=2 rgns=5 avg=2.5 max=3 min=2]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=5 average=2.5 mostloaded=3 leastloaded=2
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:2 , srv68821:4 } [srvr=2 rgns=6 avg=3.0 max=3 min=3]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=6, numServers=2, max=3, min=3
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 1 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:3 , srv68821:3 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1 , srv68821:1 } [srvr=2 rgns=2 avg=1.0 max=1 min=1]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=2 average=1.0 mostloaded=1 leastloaded=1
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv68821:1 } [srvr=2 rgns=1 avg=0.5 max=1 min=0]
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Skipping load balancing because balanced cluster; servers=2 entityGroups=1 average=0.5 mostloaded=1 leastloaded=0
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : {  }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:1 , srv21098:10 } [srvr=2 rgns=11 avg=5.5 max=6 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=11, numServers=2, max=6, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 4 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:5 , srv21098:6 }
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: MockServer,123,-1-0xff8f8444442d0000 Received ZooKeeper Event, type=None, state=Disconnected, path=null
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest-0xff8f8444442d0001 Received ZooKeeper Event, type=None, state=Disconnected, path=null
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: unittest-0xff8f8444442d0001 Received Disconnected from ZooKeeper, ignoring
24/05/17 01:56:57 DEBUG zookeeper.ZooKeeperWatcher: MockServer,123,-1-0xff8f8444442d0000 Received Disconnected from ZooKeeper, ignoring
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:14 , srv68821:1432 } [srvr=2 rgns=1446 avg=723.0 max=723 min=723]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=1446, numServers=2, max=723, min=723
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 8ms. Moving 709 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:723 , srv68821:723 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:47 , srv68821:53 } [srvr=2 rgns=100 avg=50.0 max=50 min=50]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=100, numServers=2, max=50, min=50
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 3 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:50 , srv68821:50 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv68821:1 , srv54512:2 } [srvr=3 rgns=3 avg=1.0 max=1 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=3, numServers=3, max=1, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 1 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv54512:1 , srv68821:1 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1 , srv54512:2 , srv68821:3 } [srvr=3 rgns=6 avg=2.0 max=2 min=2]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=6, numServers=3, max=2, min=2
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 1 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:2 , srv54512:2 , srv68821:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv54512:2 , srv68821:2 } [srvr=3 rgns=4 avg=1.3333334 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=4, numServers=3, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 1 entityGroups off of 0 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv68821:1 , srv54512:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv68821:0 , srv54512:3 } [srvr=3 rgns=3 avg=1.0 max=1 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=3, numServers=3, max=1, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 2 entityGroups off of 1 overloaded servers onto 2 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv54512:1 , srv68821:1 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv68821:0 , srv54512:4 } [srvr=3 rgns=4 avg=1.3333334 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=4, numServers=3, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 2 entityGroups off of 1 overloaded servers onto 2 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv68821:1 , srv54512:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:0 , srv21098:20 , srv54512:20 } [srvr=3 rgns=40 avg=13.333333 max=14 min=13]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=40, numServers=3, max=14, min=13
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 13 entityGroups off of 2 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv54512:13 , srv68821:13 , srv21098:14 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv54512:1 , srv68821:2 , srv88959:3 } [srvr=4 rgns=6 avg=1.5 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=6, numServers=4, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 1 entityGroups off of 1 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv54512:1 , srv68821:2 , srv88959:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv54512:0 , srv68821:0 , srv88959:0 , srv21098:4 } [srvr=4 rgns=4 avg=1.0 max=1 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=4, numServers=4, max=1, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 1ms. Moving 3 entityGroups off of 1 overloaded servers onto 3 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:1 , srv54512:1 , srv68821:1 , srv88959:1 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv54512:0 , srv68821:0 , srv88959:0 , srv21098:5 } [srvr=4 rgns=5 avg=1.25 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=5, numServers=4, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 3 entityGroups off of 1 overloaded servers onto 3 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv54512:1 , srv68821:1 , srv88959:1 , srv21098:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:0 , srv88959:0 , srv21098:6 , srv54512:6 } [srvr=4 rgns=12 avg=3.0 max=3 min=3]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=12, numServers=4, max=3, min=3
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 6 entityGroups off of 2 overloaded servers onto 2 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:3 , srv54512:3 , srv68821:3 , srv88959:3 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:0 , srv88959:0 , srv54512:2 , srv21098:6 } [srvr=4 rgns=8 avg=2.0 max=2 min=2]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=8, numServers=4, max=2, min=2
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 4 entityGroups off of 1 overloaded servers onto 2 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:2 , srv54512:2 , srv68821:2 , srv88959:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv68821:0 , srv88959:0 , srv54512:1 , srv21098:6 } [srvr=4 rgns=7 avg=1.75 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=7, numServers=4, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 4 entityGroups off of 1 overloaded servers onto 2 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv54512:1 , srv21098:2 , srv68821:2 , srv88959:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv54512:0 , srv68821:0 , srv88959:0 , srv21098:6 } [srvr=4 rgns=6 avg=1.5 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=6, numServers=4, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 4 entityGroups off of 1 overloaded servers onto 3 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:1 , srv88959:1 , srv21098:2 , srv54512:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:4 , srv54512:4 , srv68821:4 , srv88959:7 } [srvr=4 rgns=19 avg=4.75 max=5 min=4]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=19, numServers=4, max=5, min=4
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 2 entityGroups off of 1 overloaded servers onto 0 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:4 , srv21098:5 , srv54512:5 , srv88959:5 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:4 , srv54512:4 , srv68821:4 , srv88959:8 } [srvr=4 rgns=20 avg=5.0 max=5 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=20, numServers=4, max=5, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 3 entityGroups off of 1 overloaded servers onto 3 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:5 , srv54512:5 , srv68821:5 , srv88959:5 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:0 , srv54512:0 , srv68821:0 , srv88959:7 } [srvr=4 rgns=7 avg=1.75 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=7, numServers=4, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 5 entityGroups off of 1 overloaded servers onto 3 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:1 , srv21098:2 , srv54512:2 , srv88959:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1 , srv54512:1 , srv68821:1 , srv88959:1 , srv71852:4 } [srvr=5 rgns=8 avg=1.6 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=8, numServers=5, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 1ms. Moving 2 entityGroups off of 1 overloaded servers onto 0 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:1 , srv88959:1 , srv21098:2 , srv54512:2 , srv71852:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1 , srv54512:2 , srv68821:3 , srv71852:4 , srv88959:5 , srv93945:6 , srv15032:7 , srv82273:8 , srv61957:9 , srv69746:10 , srv18221:11 , srv3212:12 , srv19875:13 , srv98724:14 , srv88811:15 } [srvr=15 rgns=120 avg=8.0 max=8 min=8]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=120, numServers=15, max=8, min=8
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 28 entityGroups off of 7 overloaded servers onto 7 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv15032:8 , srv18221:8 , srv19875:8 , srv21098:8 , srv3212:8 , srv54512:8 , srv61957:8 , srv68821:8 , srv69746:8 , srv71852:8 , srv82273:8 , srv88811:8 , srv88959:8 , srv93945:8 , srv98724:8 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:0 , srv18221:0 , srv19875:0 , srv21098:0 , srv3212:0 , srv54512:0 , srv61957:0 , srv68821:0 , srv69746:0 , srv71852:10 } [srvr=10 rgns=10 avg=1.0 max=1 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=10, numServers=10, max=1, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 0ms. Moving 9 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv3212:1 , srv54512:1 , srv61957:1 , srv68821:1 , srv69746:1 , srv71852:1 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv3212:1 , srv88959:5 , srv15032:6 , srv18221:6 , srv19875:6 , srv21098:6 , srv82273:6 , srv88811:6 , srv93945:6 , srv98724:6 } [srvr=10 rgns=54 avg=5.4 max=6 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=54, numServers=10, max=6, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 4 entityGroups off of 0 overloaded servers onto 1 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv3212:5 , srv82273:5 , srv88811:5 , srv88959:5 , srv93945:5 , srv98724:5 , srv15032:6 , srv18221:6 , srv19875:6 , srv21098:6 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:0 , srv18221:0 , srv19875:0 , srv21098:0 , srv54512:0 , srv61957:0 , srv68821:0 , srv69746:0 , srv71852:0 , srv3212:54 } [srvr=10 rgns=54 avg=5.4 max=6 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=54, numServers=10, max=6, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 48 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:5 , srv54512:5 , srv61957:5 , srv68821:5 , srv69746:5 , srv71852:5 , srv15032:6 , srv18221:6 , srv19875:6 , srv3212:6 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:0 , srv18221:0 , srv19875:0 , srv21098:0 , srv82273:0 , srv88811:0 , srv88959:0 , srv93945:0 , srv98724:0 , srv3212:55 } [srvr=10 rgns=55 avg=5.5 max=6 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=55, numServers=10, max=6, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 49 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv82273:5 , srv88811:5 , srv88959:5 , srv93945:5 , srv98724:5 , srv15032:6 , srv18221:6 , srv19875:6 , srv21098:6 , srv3212:6 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:0 , srv18221:0 , srv19875:0 , srv21098:0 , srv54512:0 , srv61957:0 , srv68821:0 , srv69746:0 , srv71852:0 , srv3212:56 } [srvr=10 rgns=56 avg=5.6 max=6 min=5]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=56, numServers=10, max=6, min=5
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 50 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv61957:5 , srv68821:5 , srv69746:5 , srv71852:5 , srv15032:6 , srv18221:6 , srv19875:6 , srv21098:6 , srv3212:6 , srv54512:6 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:0 , srv18221:0 , srv19875:0 , srv21098:0 , srv82273:0 , srv88811:0 , srv88959:0 , srv93945:0 , srv98724:0 , srv3212:16 } [srvr=10 rgns=16 avg=1.6 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=16, numServers=10, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 14 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv88811:1 , srv88959:1 , srv93945:1 , srv98724:1 , srv15032:2 , srv18221:2 , srv19875:2 , srv21098:2 , srv3212:2 , srv82273:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv54512:1 , srv61957:1 , srv68821:1 , srv69746:1 , srv71852:1 , srv3212:8 } [srvr=10 rgns=17 avg=1.7 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=17, numServers=10, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 6 entityGroups off of 1 overloaded servers onto 0 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv68821:1 , srv69746:1 , srv71852:1 , srv15032:2 , srv18221:2 , srv19875:2 , srv21098:2 , srv3212:2 , srv54512:2 , srv61957:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv82273:1 , srv88811:1 , srv88959:1 , srv93945:1 , srv98724:1 , srv3212:9 } [srvr=10 rgns=18 avg=1.8 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=18, numServers=10, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 7 entityGroups off of 1 overloaded servers onto 0 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv93945:1 , srv98724:1 , srv15032:2 , srv18221:2 , srv19875:2 , srv21098:2 , srv3212:2 , srv82273:2 , srv88811:2 , srv88959:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv54512:1 , srv61957:1 , srv68821:1 , srv69746:1 , srv71852:1 , srv3212:10 } [srvr=10 rgns=19 avg=1.9 max=2 min=1]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=19, numServers=10, max=2, min=1
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 8 entityGroups off of 1 overloaded servers onto 0 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv71852:1 , srv15032:2 , srv18221:2 , srv19875:2 , srv21098:2 , srv3212:2 , srv54512:2 , srv61957:2 , srv68821:2 , srv69746:2 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv82273:1 , srv88811:1 , srv88959:1 , srv93945:1 , srv98724:1 , srv3212:123 } [srvr=10 rgns=132 avg=13.2 max=14 min=13]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=132, numServers=10, max=14, min=13
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 0ms. Moving 109 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv18221:13 , srv19875:13 , srv21098:13 , srv82273:13 , srv88811:13 , srv88959:13 , srv93945:13 , srv98724:13 , srv15032:14 , srv3212:14 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv15032:1 , srv18221:1 , srv19875:1 , srv21098:1 , srv54512:1 , srv61957:1 , srv68821:1 , srv69746:1 , srv71852:1 , srv3212:155 } [srvr=10 rgns=164 avg=16.4 max=17 min=16]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=164, numServers=10, max=17, min=16
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 1ms. Moving 138 entityGroups off of 1 overloaded servers onto 9 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv21098:16 , srv54512:16 , srv61957:16 , srv68821:16 , srv69746:16 , srv71852:16 , srv15032:17 , srv18221:17 , srv19875:17 , srv3212:17 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv82273:0 , srv88811:0 , srv15032:1 , srv18221:1 , srv93945:1 , srv98724:1 , srv54512:12 , srv21098:133 , srv3212:138 , srv88959:144 , srv19875:1123 , srv61957:1444 } [srvr=12 rgns=2998 avg=249.83333 max=250 min=249]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=2998, numServers=12, max=250, min=249
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 4ms. Moving 2067 entityGroups off of 2 overloaded servers onto 10 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv3212:249 , srv88959:249 , srv15032:250 , srv18221:250 , srv19875:250 , srv21098:250 , srv54512:250 , srv61957:250 , srv82273:250 , srv88811:250 , srv93945:250 , srv98724:250 }
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv18221:0 , srv68821:0 , srv69746:0 , srv15032:1 , srv21098:1 , srv19875:4 , srv82273:12 , srv54512:133 , srv61957:138 , srv71852:144 , srv3212:1123 , srv88811:1444 } [srvr=12 rgns=3000 avg=250.0 max=250 min=250]
24/05/17 01:56:57 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=3000, numServers=12, max=250, min=250
24/05/17 01:56:57 INFO balancer.DefaultLoadBalancer: Calculated a load balance in 4ms. Moving 2067 entityGroups off of 2 overloaded servers onto 10 less loaded servers
24/05/17 01:56:57 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv15032:250 , srv18221:250 , srv19875:250 , srv21098:250 , srv3212:250 , srv54512:250 , srv61957:250 , srv68821:250 , srv69746:250 , srv71852:250 , srv82273:250 , srv88811:250 }
24/05/17 01:56:58 INFO server.SessionTrackerImpl: SessionTrackerImpl exited loop!
24/05/17 01:56:58 INFO balancer.TestDefaultLoadBalancer: Mock Cluster : { srv21098:1385 , srv93945:1392 , srv18221:1535 , srv88959:1538 , srv3212:1542 , srv19875:1553 , srv15032:1557 , srv98724:1561 , srv54512:1619 } [srvr=9 rgns=13682 avg=1520.2222 max=1521 min=1520]
24/05/17 01:56:58 DEBUG balancer.DefaultLoadBalancer: Balance parameter: numEntityGroups=13682, numServers=9, max=1521, min=1520
24/05/17 01:56:58 INFO balancer.DefaultLoadBalancer: Done. Calculated a load balance in 1ms. Moving 263 entityGroups off of 7 overloaded servers onto 2 less loaded servers
24/05/17 01:56:58 INFO balancer.TestDefaultLoadBalancer: Mock Balance : { srv15032:1520 , srv19875:1520 , srv21098:1520 , srv3212:1520 , srv54512:1520 , srv93945:1520 , srv98724:1520 , srv18221:1521 , srv88959:1521 }
24/05/17 01:56:58 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/27d9e1bd-7bc0-42ce-8ec2-93e9a0b8f741/dfscluster_8db2b4f4-5e2b-4dd2-8fb8-137b8afaff43/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/27d9e1bd-7bc0-42ce-8ec2-93e9a0b8f741/dfscluster_8db2b4f4-5e2b-4dd2-8fb8-137b8afaff43/dfs/data/data2
24/05/17 01:56:58 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 01:56:58 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 01:56:58 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.client.TestFromClientSide.setUpBeforeClass(TestFromClientSide.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
