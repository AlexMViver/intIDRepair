24/05/17 02:05:31 INFO hbase.HBaseTestingUtility: Starting up minicluster with 1 master(s) and 1 regionserver(s) and 1 datanode(s)
24/05/17 02:05:31 INFO util.GSet: VM type       = 64-bit
24/05/17 02:05:31 INFO util.GSet: 2% max memory = 16.86 MB
24/05/17 02:05:31 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/05/17 02:05:31 INFO util.GSet: recommended=2097152, actual=2097152
24/05/17 02:05:31 INFO namenode.FSNamesystem: fsOwner=idflakies
24/05/17 02:05:31 INFO namenode.FSNamesystem: supergroup=supergroup
24/05/17 02:05:31 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/05/17 02:05:31 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/05/17 02:05:31 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/05/17 02:05:31 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/05/17 02:05:31 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:31 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/name1 has been successfully formatted.
24/05/17 02:05:31 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:31 INFO common.Storage: Storage directory /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/name2 has been successfully formatted.
24/05/17 02:05:32 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-namenode.properties, hadoop-metrics2.properties
24/05/17 02:05:32 INFO util.GSet: VM type       = 64-bit
24/05/17 02:05:32 INFO util.GSet: 2% max memory = 16.86 MB
24/05/17 02:05:32 INFO util.GSet: capacity      = 2^21 = 2097152 entries
24/05/17 02:05:32 INFO util.GSet: recommended=2097152, actual=2097152
24/05/17 02:05:32 INFO namenode.FSNamesystem: fsOwner=idflakies
24/05/17 02:05:32 INFO namenode.FSNamesystem: supergroup=supergroup
24/05/17 02:05:32 INFO namenode.FSNamesystem: isPermissionEnabled=true
24/05/17 02:05:32 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
24/05/17 02:05:32 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
24/05/17 02:05:32 INFO namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
24/05/17 02:05:32 INFO namenode.NameNode: Caching file names occuring more than 10 times 
24/05/17 02:05:32 INFO common.Storage: Number of files = 1
24/05/17 02:05:32 INFO common.Storage: Number of files under construction = 0
24/05/17 02:05:32 INFO common.Storage: Image file of size 115 loaded in 0 seconds.
24/05/17 02:05:32 INFO common.Storage: Edits file /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
24/05/17 02:05:32 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:32 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:32 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:32 INFO common.Storage: Image file of size 115 saved in 0 seconds.
24/05/17 02:05:32 INFO namenode.NameCache: initialized with 0 entries 0 lookups
24/05/17 02:05:32 INFO namenode.FSNamesystem: Finished loading FSImage in 151 msecs
24/05/17 02:05:32 INFO namenode.FSNamesystem: Total number of blocks = 0
24/05/17 02:05:32 INFO namenode.FSNamesystem: Number of invalid blocks = 0
24/05/17 02:05:32 INFO namenode.FSNamesystem: Number of under-replicated blocks = 0
24/05/17 02:05:32 INFO namenode.FSNamesystem: Number of  over-replicated blocks = 0
24/05/17 02:05:32 INFO hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 22 msec
24/05/17 02:05:32 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs.
24/05/17 02:05:32 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
24/05/17 02:05:32 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
24/05/17 02:05:32 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list
24/05/17 02:05:32 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/05/17 02:05:32 INFO namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/05/17 02:05:32 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
24/05/17 02:05:32 INFO namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
24/05/17 02:05:32 INFO ipc.Server: Starting SocketReader
24/05/17 02:05:32 INFO namenode.NameNode: Namenode up at: localhost/127.0.0.1:34567
24/05/17 02:05:32 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
24/05/17 02:05:32 INFO http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
24/05/17 02:05:32 INFO http.HttpServer: dfs.webhdfs.enabled = false
24/05/17 02:05:32 INFO http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
24/05/17 02:05:32 INFO http.HttpServer: listener.getLocalPort() returned 42037 webServer.getConnectors()[0].getLocalPort() returned 42037
24/05/17 02:05:32 INFO http.HttpServer: Jetty bound to port 42037
24/05/17 02:05:32 INFO mortbay.log: jetty-6.1.26
24/05/17 02:05:32 INFO mortbay.log: Extract jar:file:/home/idflakies/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar!/webapps/hdfs to /tmp/Jetty_localhost_42037_hdfs____.s3w4cg/webapp
24/05/17 02:05:32 INFO mortbay.log: Started SelectChannelConnector@localhost:42037
24/05/17 02:05:32 INFO namenode.NameNode: Web-server up at: localhost:42037
24/05/17 02:05:32 INFO ipc.Server: IPC Server Responder: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server listener on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 0 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 1 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 2 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 3 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 4 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 5 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 6 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 7 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 8 on 34567: starting
24/05/17 02:05:32 INFO ipc.Server: IPC Server handler 9 on 34567: starting
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/data/data2
24/05/17 02:05:32 WARN impl.MetricsSystemImpl: Metrics system not started: Cannot locate configuration: tried hadoop-metrics2-datanode.properties, hadoop-metrics2.properties
24/05/17 02:05:32 WARN util.MBeans: Hadoop:service=DataNode,name=MetricsSystem,sub=Control
javax.management.InstanceAlreadyExistsException: MXBean already registered with name Hadoop:service=NameNode,name=MetricsSystem,sub=Control
	at com.sun.jmx.mbeanserver.MXBeanLookup.addReference(MXBeanLookup.java:151)
	at com.sun.jmx.mbeanserver.MXBeanSupport.register(MXBeanSupport.java:160)
	at com.sun.jmx.mbeanserver.MBeanSupport.preRegister2(MBeanSupport.java:173)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:930)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:56)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.initSystemMBean(MetricsSystemImpl.java:500)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:140)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:40)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1520)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1496)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:417)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:32 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/data/data1, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/05/17 02:05:32 WARN datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/idflakies/alibaba/wasp/target/test-data/f19495f3-dd42-4a06-87b8-0aeca0aefb85/dfscluster_9286d5a7-3a50-48c8-8b61-ede4d9abb7d2/dfs/data/data2, expected: rwxr-xr-x, while actual: rwxrwxr-x
24/05/17 02:05:32 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:32 INFO hbase.HBaseTestingUtility: Shutting down minicluster
24/05/17 02:05:32 INFO hbase.HBaseTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:562)
	at com.alibaba.wasp.meta.TestFMetaStore.setUpBeforeClass(TestFMetaStore.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:32 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/8d3b51c1-089a-45f7-9dc6-5d6745adbc85/dfscluster_b14d2832-14c3-41f6-83ed-a2c21480cc69/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/8d3b51c1-089a-45f7-9dc6-5d6745adbc85/dfscluster_b14d2832-14c3-41f6-83ed-a2c21480cc69/dfs/data/data2
24/05/17 02:05:33 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestPublisher.setUpBeforeClass(TestPublisher.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 2 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/b9277906-709b-4a07-b8bd-3f53a0baf237/dfscluster_385a8df9-bb70-4e5b-aecf-320f054e0f8d/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/b9277906-709b-4a07-b8bd-3f53a0baf237/dfscluster_385a8df9-bb70-4e5b-aecf-320f054e0f8d/dfs/data/data2
24/05/17 02:05:33 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.master.TestMaster.beforeAllTests(TestMaster.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/4a9cd7b4-2691-4363-b424-eadcaba41311/dfscluster_0658cd0d-b472-43c1-88b7-011dcfcf9a2a/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/4a9cd7b4-2691-4363-b424-eadcaba41311/dfscluster_0658cd0d-b472-43c1-88b7-011dcfcf9a2a/dfs/data/data2
24/05/17 02:05:33 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.messagequeue.TestSubscriber.setUpBeforeClass(TestSubscriber.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:33 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/702f5ba7-e67b-4ced-a584-6c69a468fc62/dfscluster_bccb0029-0e50-4bb4-95a9-cd0bdd2d2b8e/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/702f5ba7-e67b-4ced-a584-6c69a468fc62/dfscluster_bccb0029-0e50-4bb4-95a9-cd0bdd2d2b8e/dfs/data/data2
24/05/17 02:05:34 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.setUpBeforeClass(TestJdbcResultFormatter.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestJdbcResultFormatter.tearDownAfterClass(TestJdbcResultFormatter.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/3cead664-30a7-4078-a353-1b032f17664f/dfscluster_2dc18e3c-b5aa-406e-85f0-86cc52f11d10/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/3cead664-30a7-4078-a353-1b032f17664f/dfscluster_2dc18e3c-b5aa-406e-85f0-86cc52f11d10/dfs/data/data2
24/05/17 02:05:34 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.fserver.redo.TestRedoLog.before(TestRedoLog.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
2013-04-13 04:04:603
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,name from User where user_id=1 limit 1;
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, name]
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 02:05:34 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false]]], fetchRows=0]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL SELECT user_id,photo_id,full_url,thumbnail_url from Photo where user_id=99999999999 and photo_id=0.1;
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL TableSource Photo
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem photo_id
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem full_url
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem thumbnail_url
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [user_id, photo_id, full_url, thumbnail_url]
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 99999999999 AND photo_id = 0.1
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
2 Filter Field:
	Field user_id  Type EQUAL Value 99999999999
	Field photo_id  Type EQUAL Value 0.1
	


24/05/17 02:05:34 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x17Hv\xE7\xFF\x00\x00\x00\x00\x00 from Photo
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=Photo, primayKey=[0, 0, 0, 23, 72, 118, -25, -1, 0, 0, 0, 0, 0], columns=[ColumnAction [tableName=Photo, familyName=cf, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=photo_id, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=full_url, value=null, isIndex=false], ColumnAction [tableName=Photo, familyName=d, columnName=thumbnail_url, value=null, isIndex=false]]], fetchRows=0]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1;
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 02:05:34 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL SELECT * from User where user_id=1 for update ;
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL TableSource User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem user_id
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem name
24/05/17 02:05:34 DEBUG druid.DruidDQLParser:  SQLSelectItem value
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:Select columns [*]
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: SELECT SQL:where user_id = 1
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: ActionInfo TYPE: null
1 Filter Field:
	Field user_id  Type EQUAL Value 1
	


24/05/17 02:05:34 DEBUG druid.DruidDQLParser: GET  \x00\x00\x00\x00\x00\x00\x00\x01 from User
24/05/17 02:05:34 DEBUG druid.DruidDQLParser: QueryPlan LocalQueryPlan [scanAction=null, getAction=GetAction [readerMode=INCONSISTENT, tableName=User, primayKey=[0, 0, 0, 0, 0, 0, 0, 1], columns=[ColumnAction [tableName=User, familyName=d, columnName=user_id, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=name, value=null, isIndex=false], ColumnAction [tableName=User, familyName=d, columnName=value, value=null, isIndex=false]]], fetchRows=0]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:34 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:34 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
--------------------------------------------
SELECT			SELECT
STAR			*
FROM			FROM
IDENTIFIER		T
WHERE			WHERE
IDENTIFIER		F1
EQ			=
QUES			?
ORDER			ORDER
BY			BY
IDENTIFIER		F2
EOF			null
--------------------------------------------
24/05/17 02:05:34 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table MetricsEntityGroupWrapperStub DEADBEEF001
24/05/17 02:05:34 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/05/17 02:05:34 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TEST
24/05/17 02:05:34 DEBUG fserver.MetricsEntityGroupSourceImpl: Creating new MetricsEntityGroupSourceImpl for table null TWO
24/05/17 02:05:34 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 3 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/88b77eda-0368-4d55-bf3c-395675b02a27/dfscluster_60ac4930-b544-47c8-9dad-f32c89047083/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/88b77eda-0368-4d55-bf3c-395675b02a27/dfscluster_60ac4930-b544-47c8-9dad-f32c89047083/dfs/data/data2
24/05/17 02:05:35 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.jdbc.TestPreparedStatement.beforeClass(TestPreparedStatement.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
java.lang.NullPointerException
	at com.alibaba.wasp.jdbc.TestPreparedStatement.afterClass(TestPreparedStatement.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES IN Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL SHOW INDEXES FROM Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: ShowIndexesPlan ShowIndexesPlan [tableName = Photo]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User2 {Required Int64 user_id; Required String name; }  primary key(user_id),  entity group root,  entity group key(user_id),  partition by range('aaa', 'zzz', 10); 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User2 { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=[[B@54361a9, [B@32232e55, [B@5217f3d0, [B@37ebc9d8, [B@293bb8a5, [B@2416a51, [B@6fa590ba, [B@6e9319f, [B@72e34f77]]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@2fab4aff]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL DROP INDEX PhotosByTime ON Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: DropIndexPlan DropIndexPlan [indexName=PhotosByTime, tableName=Photo]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTime on Photo(user_id,time);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTime
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@532a02d9]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE index PhotosByTag on Photo(tag);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL IndexName PhotosByTag
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: Create Index SQL TableName Photo
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateIndexPlan CreateIndexPlan [index=com.alibaba.wasp.meta.Index@611f8234]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL SHOW TABLES LIKE 'pattern'
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL SHOW CREATE TABLE Photo
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: ShowTablesPlan ShowTablesPlan 
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL TRUNCATE TABLE Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: TruncateTablePlan TruncateTablePlan [tableNames=[Photo]]
24/05/17 02:05:35 INFO druid.TestDruidDDLParser: TruncateTablePlan [tableNames=[Photo]]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy1 int32 FIRST
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  OPTIONAL INT32 dummy1 COLUMNFAMILY d;
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN DateOfBirth string columnfamily cf comment 'aaa'
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
  OPTIONAL STRING DateOfBirth COLUMNFAMILY cf;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo ADD COLUMN dummy2 int32 AFTER thumbnail_url
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL INT32 dummy2 COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE COLUMN thumbnail_url thumbnail_url INT32
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url thumbnail_url INT32
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT32 thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo CHANGE thumbnail_url rename_url INT64;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL INT64 rename_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL ALTER TABLE Photo DROP COLUMN full_url, DROP COLUMN thumbnail_url;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: AlterTablePlan AlterTablePlan [oldTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, newTable=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);

CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  REQUIRED INT64 time COLUMNFAMILY d;
  REQUIRED STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  REPEATED STRING tag COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;

24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL DROP TABLE Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo], ifExists=false]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL DROP TABLE IF EXISTS Photo, User;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: DropTablePlan DropTablePlan [tableNames=[Photo, User], ifExists=false]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE User { Required Int64 user_id; Required String name; Optional DOUBLE value; }  primary key(user_id),  entity group root, entity group key(user_id);
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE User { 
  REQUIRED INT64 user_id COLUMNFAMILY d;
  REQUIRED STRING name COLUMNFAMILY d;
  OPTIONAL DOUBLE value COLUMNFAMILY d;
} 
PRIMARY KEY(user_id),
ENTITY GROUP ROOT,
ENTITY GROUP KEY(user_id);
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL CREATE TABLE Photo { Required Int64 user_id columnfamily cf comment 'aaa';  Required Int32 photo_id comment 'child primary key';  Optional Int64 time; Optional String full_url;  Optional String thumbnail_url; Optional string tag; Optional DATETIME date; Optional Int32 int32Type; }  primary key(user_id,photo_id),  in table User,  Entity Group Key(user_id) references User; 
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: CreateTablePlan CreateTablePlan [table=CREATE TABLE Photo { 
  REQUIRED INT64 user_id COLUMNFAMILY cf;
  REQUIRED INT32 photo_id COLUMNFAMILY d;
  OPTIONAL INT64 time COLUMNFAMILY d;
  OPTIONAL STRING full_url COLUMNFAMILY d;
  OPTIONAL STRING thumbnail_url COLUMNFAMILY d;
  OPTIONAL STRING tag COLUMNFAMILY d;
  OPTIONAL DATETIME date COLUMNFAMILY d;
  OPTIONAL INT32 int32Type COLUMNFAMILY d;
} 
PRIMARY KEY(user_id, photo_id, ),
 IN TABLE User,
 ENTITY GROUP KEY(user_id) REFERENCES User;
, splitKeys=null]
24/05/17 02:05:35 DEBUG druid.DruidParser: Parsing SQL DESCRIBE Photo;
24/05/17 02:05:35 DEBUG druid.DruidDDLParser: DescTablePlan DescTablePlan 
24/05/17 02:05:35 INFO server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:64501
24/05/17 02:05:35 INFO persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/idflakies/alibaba/wasp/target/test-data/1027ae9e-11da-4cc8-9fd3-0c5d4e5c1bff/dfscluster_74cf3970-f033-43a4-8206-0d515f574c5f/zookeeper_0/version-2/snapshot.0
24/05/17 02:05:35 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60192
24/05/17 02:05:35 DEBUG master.FMaster: Set serverside FConnection retries=100
24/05/17 02:05:35 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMaster
24/05/17 02:05:35 DEBUG zookeeper.ZKUtil: master:42909 opening connection to ZooKeeper with ensemble (localhost:64501)
24/05/17 02:05:35 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 37082@a9f87c527aeb
24/05/17 02:05:35 INFO server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60202
24/05/17 02:05:35 INFO persistence.FileTxnLog: Creating new log file: log.1
24/05/17 02:05:35 DEBUG zookeeper.ZooKeeperWatcher: master:42909 Received ZooKeeper Event, type=None, state=SyncConnected, path=null
24/05/17 02:05:35 DEBUG zookeeper.ZooKeeperWatcher: master:42909-0xff8f844c2a940000 connected
24/05/17 02:05:35 DEBUG ipc.WaspRPC: Using com.alibaba.wasp.ipc.ProtobufRpcEngine for com.alibaba.wasp.master.FMasterMonitorProtocol
24/05/17 02:05:35 DEBUG ipc.NettyTransceiver: Using Netty bootstrap options: {connectTimeoutMillis=3000, tcpNoDelay=true}
24/05/17 02:05:35 DEBUG ipc.NettyTransceiver: Connecting to a9f87c527aeb/172.17.0.2:42909
24/05/17 02:05:35 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036] OPEN
24/05/17 02:05:35 INFO ipc.NettyTransceiver: Successfully connected to bookie: a9f87c527aeb/172.17.0.2:42909
24/05/17 02:05:35 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036, /172.17.0.2:49178 => a9f87c527aeb/172.17.0.2:42909] BOUND: /172.17.0.2:49178
24/05/17 02:05:35 DEBUG ipc.NettyTransceiver: [id: 0x7b02e036, /172.17.0.2:49178 => a9f87c527aeb/172.17.0.2:42909] CONNECTED: a9f87c527aeb/172.17.0.2:42909
24/05/17 02:05:35 DEBUG ipc.NettyServer: [id: 0x5ea3da78, /172.17.0.2:49178 => /172.17.0.2:42909] OPEN
24/05/17 02:05:35 DEBUG ipc.NettyServer: [id: 0x5ea3da78, /172.17.0.2:49178 => /172.17.0.2:42909] BOUND: /172.17.0.2:42909
24/05/17 02:05:35 DEBUG ipc.NettyServer: [id: 0x5ea3da78, /172.17.0.2:49178 => /172.17.0.2:42909] CONNECTED: /172.17.0.2:49178
24/05/17 02:05:35 WARN ipc.NettyServer: Unable to read call parameters for client /172.17.0.2:49178
com.alibaba.wasp.ipc.ServerNotRunningYetException: Server is not running yet
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.messageReceived(NettyServer.java:203)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75)
	at com.alibaba.wasp.ipc.NettyServer$NettyServerWaspHandler.handleUpstream(NettyServer.java:171)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:563)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:45)
	at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/05/17 02:05:35 ERROR ipc.NettyTransceiver: Fatal Exception.
24/05/17 02:05:35 INFO wasp.WaspTestingUtility: Starting up minicluster with 1 master(s) and 1 fserver(s) 
Starting DataNode 0 with dfs.data.dir: /home/idflakies/alibaba/wasp/target/test-data/5399eaef-67c1-4725-99ee-4384636a5c98/dfscluster_7e1d3cf0-536d-49b9-82e6-35b3afc7b153/dfs/data/data1,/home/idflakies/alibaba/wasp/target/test-data/5399eaef-67c1-4725-99ee-4384636a5c98/dfscluster_7e1d3cf0-536d-49b9-82e6-35b3afc7b153/dfs/data/data2
24/05/17 02:05:35 ERROR datanode.DataNode: All directories in dfs.data.dir are invalid.
24/05/17 02:05:35 INFO wasp.WaspTestingUtility: Shutting down mini wasp cluster
24/05/17 02:05:35 INFO wasp.WaspTestingUtility: Minicluster is down
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:422)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:280)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:451)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:619)
	at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster(HBaseTestingUtility.java:575)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:172)
	at com.alibaba.wasp.WaspTestingUtility.startMiniCluster(WaspTestingUtility.java:144)
	at com.alibaba.wasp.plan.execute.TestExecutionEngine.before(TestExecutionEngine.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:136)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.execute(JUnitTestExecutor.java:246)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.executeWithJUnit4Runner(JUnitTestExecutor.java:315)
	at edu.illinois.cs.testrunner.execution.JUnitTestExecutor.runOrder(JUnitTestExecutor.java:46)
	at edu.illinois.cs.testrunner.execution.Executor$.$anonfun$run$1(Executor.scala:30)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.util.Try$.apply(Try.scala:209)
	at edu.illinois.cs.testrunner.execution.Executor$.run(Executor.scala:28)
	at edu.illinois.cs.testrunner.execution.Executor$.main(Executor.scala:18)
	at edu.illinois.cs.testrunner.execution.Executor.main(Executor.scala)
